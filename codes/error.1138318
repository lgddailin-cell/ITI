2025-12-12 20:37:05,197 INFO     Parameters: Namespace(cuda='True', seed=10, do_train='True', do_valid='True', do_test='True', evaluate_train=False, countries=False, regions=None, data_path='/home/25171213997/ITI/data/YAGO3-10/', model='ITI_ComplEx', double_entity_embedding=False, double_relation_embedding=False, negative_sample_size=200, hidden_dim=1000, house_dim=2, house_num=2, housd_num=2, types_num=2, thred=0.7, gamma=26.0, negative_adversarial_sampling=True, adversarial_temperature=1.16010547465235, batch_size=200, regularization=0.0881968094660471, ent_reg=0.0, rel_reg=0.0, test_batch_size=2, uni_weight=False, learning_rate=0.00258708538141072, cpu_num=10, init_checkpoint=None, save_path='/home/25171213997/ITI/complex/', max_steps=250000, warm_up_steps=20000, save_checkpoint_steps=4000, valid_steps=10000, log_steps=100, test_log_steps=100, nentity=123182, nrelation=37)
2025-12-12 20:37:05,198 INFO     Model: ITI_ComplEx
2025-12-12 20:37:05,198 INFO     Data Path: /home/25171213997/ITI/data/YAGO3-10/
2025-12-12 20:37:05,198 INFO     #entity: 123182
2025-12-12 20:37:05,198 INFO     #relation: 37
2025-12-12 20:37:06,855 INFO     #train: 1079040
2025-12-12 20:37:06,864 INFO     #valid: 5000
2025-12-12 20:37:06,872 INFO     #test: 5000
2025-12-12 20:37:08,970 INFO     Model Parameter Configuration:
2025-12-12 20:37:08,974 INFO     Parameter gamma: torch.Size([1]), require_grad = False
2025-12-12 20:37:08,974 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False
2025-12-12 20:37:08,974 INFO     Parameter entity_embedding: torch.Size([123182, 500, 2]), require_grad = True
2025-12-12 20:37:08,974 INFO     Parameter head_type_vec: torch.Size([123182]), require_grad = False
2025-12-12 20:37:08,974 INFO     Parameter head_type_mat: torch.Size([571, 500, 2]), require_grad = True
2025-12-12 20:37:08,974 INFO     Parameter tail_type_mat: torch.Size([571, 500, 2]), require_grad = True
2025-12-12 20:37:08,974 INFO     Parameter relation_embedding: torch.Size([37, 500, 4]), require_grad = True
2025-12-12 20:37:08,974 INFO     Parameter r1_dir_head: torch.Size([571, 1, 1]), require_grad = True
2025-12-12 20:37:08,974 INFO     Parameter r2_dir_tail: torch.Size([571, 1, 1]), require_grad = True
2025-12-12 20:37:08,974 INFO     Parameter r1_scale_head: torch.Size([571, 500, 1]), require_grad = True
2025-12-12 20:37:08,974 INFO     Parameter r2_scale_tail: torch.Size([571, 500, 1]), require_grad = True
2025-12-12 20:37:08,974 INFO     Parameter k_dir_head: torch.Size([37, 1, 2]), require_grad = True
2025-12-12 20:37:08,975 INFO     Parameter k_dir_tail: torch.Size([37, 1, 2]), require_grad = True
2025-12-12 20:37:08,975 INFO     Parameter k_scale_head: torch.Size([37, 500, 2]), require_grad = True
2025-12-12 20:37:08,975 INFO     Parameter k_scale_tail: torch.Size([37, 500, 2]), require_grad = True
2025-12-12 20:37:08,975 INFO     Parameter relation_weight: torch.Size([37, 500, 2]), require_grad = True
2025-12-12 20:37:21,304 INFO     Ramdomly Initializing ITI_ComplEx Model...
2025-12-12 20:37:21,305 INFO     Start Training...
2025-12-12 20:37:21,305 INFO     init_step = 1
2025-12-12 20:37:21,305 INFO     batch_size = 200
2025-12-12 20:37:21,305 INFO     negative_adversarial_sampling = 1
2025-12-12 20:37:21,305 INFO     hidden_dim = 1000
2025-12-12 20:37:21,305 INFO     gamma = 26.000000
2025-12-12 20:37:21,305 INFO     negative_adversarial_sampling = True
2025-12-12 20:37:21,305 INFO     adversarial_temperature = 1.160105
2025-12-12 20:37:21,305 INFO     learning_rate = 0
2025-12-12 20:37:29,643 INFO     Training average regularization at step 100: 0.015180
2025-12-12 20:37:29,644 INFO     Training average positive_sample_loss at step 100: 0.692863
2025-12-12 20:37:29,644 INFO     Training average negative_sample_loss at step 100: 0.693152
2025-12-12 20:37:29,644 INFO     Training average loss at step 100: 0.708188
2025-12-12 20:37:36,986 INFO     Training average regularization at step 200: 0.016341
2025-12-12 20:37:36,987 INFO     Training average positive_sample_loss at step 200: 0.690712
2025-12-12 20:37:36,987 INFO     Training average negative_sample_loss at step 200: 0.693193
2025-12-12 20:37:36,987 INFO     Training average loss at step 200: 0.708293
2025-12-12 20:37:44,398 INFO     Training average regularization at step 300: 0.051194
2025-12-12 20:37:44,399 INFO     Training average positive_sample_loss at step 300: 0.681844
2025-12-12 20:37:44,399 INFO     Training average negative_sample_loss at step 300: 0.695892
2025-12-12 20:37:44,399 INFO     Training average loss at step 300: 0.740062
2025-12-12 20:37:51,698 INFO     Training average regularization at step 400: 0.077758
2025-12-12 20:37:51,698 INFO     Training average positive_sample_loss at step 400: 0.667603
2025-12-12 20:37:51,698 INFO     Training average negative_sample_loss at step 400: 0.699722
2025-12-12 20:37:51,698 INFO     Training average loss at step 400: 0.761421
2025-12-12 20:37:58,963 INFO     Training average regularization at step 500: 0.091106
2025-12-12 20:37:58,963 INFO     Training average positive_sample_loss at step 500: 0.648975
2025-12-12 20:37:58,963 INFO     Training average negative_sample_loss at step 500: 0.704714
2025-12-12 20:37:58,963 INFO     Training average loss at step 500: 0.767951
2025-12-12 20:38:06,231 INFO     Training average regularization at step 600: 0.103282
2025-12-12 20:38:06,232 INFO     Training average positive_sample_loss at step 600: 0.627261
2025-12-12 20:38:06,232 INFO     Training average negative_sample_loss at step 600: 0.710520
2025-12-12 20:38:06,232 INFO     Training average loss at step 600: 0.772173
2025-12-12 20:38:13,547 INFO     Training average regularization at step 700: 0.114682
2025-12-12 20:38:13,548 INFO     Training average positive_sample_loss at step 700: 0.598805
2025-12-12 20:38:13,548 INFO     Training average negative_sample_loss at step 700: 0.716660
2025-12-12 20:38:13,548 INFO     Training average loss at step 700: 0.772415
2025-12-12 20:38:20,838 INFO     Training average regularization at step 800: 0.124643
2025-12-12 20:38:20,838 INFO     Training average positive_sample_loss at step 800: 0.577008
2025-12-12 20:38:20,839 INFO     Training average negative_sample_loss at step 800: 0.719251
2025-12-12 20:38:20,839 INFO     Training average loss at step 800: 0.772772
2025-12-12 20:38:28,123 INFO     Training average regularization at step 900: 0.133163
2025-12-12 20:38:28,123 INFO     Training average positive_sample_loss at step 900: 0.555514
2025-12-12 20:38:28,123 INFO     Training average negative_sample_loss at step 900: 0.716125
2025-12-12 20:38:28,123 INFO     Training average loss at step 900: 0.768983
2025-12-12 20:38:35,407 INFO     Training average regularization at step 1000: 0.140605
2025-12-12 20:38:35,408 INFO     Training average positive_sample_loss at step 1000: 0.547475
2025-12-12 20:38:35,408 INFO     Training average negative_sample_loss at step 1000: 0.699923
2025-12-12 20:38:35,408 INFO     Training average loss at step 1000: 0.764304
2025-12-12 20:38:42,844 INFO     Training average regularization at step 1100: 0.147351
2025-12-12 20:38:42,845 INFO     Training average positive_sample_loss at step 1100: 0.534780
2025-12-12 20:38:42,845 INFO     Training average negative_sample_loss at step 1100: 0.685429
2025-12-12 20:38:42,845 INFO     Training average loss at step 1100: 0.757456
2025-12-12 20:38:50,133 INFO     Training average regularization at step 1200: 0.153625
2025-12-12 20:38:50,134 INFO     Training average positive_sample_loss at step 1200: 0.524274
2025-12-12 20:38:50,134 INFO     Training average negative_sample_loss at step 1200: 0.673854
2025-12-12 20:38:50,134 INFO     Training average loss at step 1200: 0.752690
2025-12-12 20:38:57,378 INFO     Training average regularization at step 1300: 0.159513
2025-12-12 20:38:57,378 INFO     Training average positive_sample_loss at step 1300: 0.514182
2025-12-12 20:38:57,378 INFO     Training average negative_sample_loss at step 1300: 0.663089
2025-12-12 20:38:57,378 INFO     Training average loss at step 1300: 0.748149
2025-12-12 20:39:04,593 INFO     Training average regularization at step 1400: 0.165030
2025-12-12 20:39:04,593 INFO     Training average positive_sample_loss at step 1400: 0.502695
2025-12-12 20:39:04,593 INFO     Training average negative_sample_loss at step 1400: 0.650049
2025-12-12 20:39:04,593 INFO     Training average loss at step 1400: 0.741402
2025-12-12 20:39:11,865 INFO     Training average regularization at step 1500: 0.170284
2025-12-12 20:39:11,865 INFO     Training average positive_sample_loss at step 1500: 0.504354
2025-12-12 20:39:11,865 INFO     Training average negative_sample_loss at step 1500: 0.638265
2025-12-12 20:39:11,865 INFO     Training average loss at step 1500: 0.741594
2025-12-12 20:39:19,142 INFO     Training average regularization at step 1600: 0.175148
2025-12-12 20:39:19,142 INFO     Training average positive_sample_loss at step 1600: 0.497431
2025-12-12 20:39:19,142 INFO     Training average negative_sample_loss at step 1600: 0.624563
2025-12-12 20:39:19,142 INFO     Training average loss at step 1600: 0.736145
2025-12-12 20:39:26,382 INFO     Training average regularization at step 1700: 0.179798
2025-12-12 20:39:26,383 INFO     Training average positive_sample_loss at step 1700: 0.490769
2025-12-12 20:39:26,383 INFO     Training average negative_sample_loss at step 1700: 0.616101
2025-12-12 20:39:26,383 INFO     Training average loss at step 1700: 0.733233
2025-12-12 20:39:33,628 INFO     Training average regularization at step 1800: 0.184108
2025-12-12 20:39:33,628 INFO     Training average positive_sample_loss at step 1800: 0.482273
2025-12-12 20:39:33,628 INFO     Training average negative_sample_loss at step 1800: 0.608024
2025-12-12 20:39:33,628 INFO     Training average loss at step 1800: 0.729256
2025-12-12 20:39:40,969 INFO     Training average regularization at step 1900: 0.188229
2025-12-12 20:39:40,969 INFO     Training average positive_sample_loss at step 1900: 0.476303
2025-12-12 20:39:40,970 INFO     Training average negative_sample_loss at step 1900: 0.592685
2025-12-12 20:39:40,970 INFO     Training average loss at step 1900: 0.722723
2025-12-12 20:39:48,315 INFO     Training average regularization at step 2000: 0.192064
2025-12-12 20:39:48,315 INFO     Training average positive_sample_loss at step 2000: 0.470762
2025-12-12 20:39:48,316 INFO     Training average negative_sample_loss at step 2000: 0.581200
2025-12-12 20:39:48,316 INFO     Training average loss at step 2000: 0.718045
2025-12-12 20:39:55,580 INFO     Training average regularization at step 2100: 0.195691
2025-12-12 20:39:55,581 INFO     Training average positive_sample_loss at step 2100: 0.465492
2025-12-12 20:39:55,581 INFO     Training average negative_sample_loss at step 2100: 0.576550
2025-12-12 20:39:55,581 INFO     Training average loss at step 2100: 0.716712
2025-12-12 20:40:02,825 INFO     Training average regularization at step 2200: 0.199174
2025-12-12 20:40:02,825 INFO     Training average positive_sample_loss at step 2200: 0.453647
2025-12-12 20:40:02,825 INFO     Training average negative_sample_loss at step 2200: 0.566022
2025-12-12 20:40:02,825 INFO     Training average loss at step 2200: 0.709008
2025-12-12 20:40:10,131 INFO     Training average regularization at step 2300: 0.202545
2025-12-12 20:40:10,131 INFO     Training average positive_sample_loss at step 2300: 0.458865
2025-12-12 20:40:10,131 INFO     Training average negative_sample_loss at step 2300: 0.554929
2025-12-12 20:40:10,131 INFO     Training average loss at step 2300: 0.709442
2025-12-12 20:40:17,409 INFO     Training average regularization at step 2400: 0.205846
2025-12-12 20:40:17,409 INFO     Training average positive_sample_loss at step 2400: 0.452850
2025-12-12 20:40:17,409 INFO     Training average negative_sample_loss at step 2400: 0.549083
2025-12-12 20:40:17,409 INFO     Training average loss at step 2400: 0.706812
2025-12-12 20:40:24,700 INFO     Training average regularization at step 2500: 0.209079
2025-12-12 20:40:24,700 INFO     Training average positive_sample_loss at step 2500: 0.449989
2025-12-12 20:40:24,700 INFO     Training average negative_sample_loss at step 2500: 0.545928
2025-12-12 20:40:24,700 INFO     Training average loss at step 2500: 0.707038
2025-12-12 20:40:31,976 INFO     Training average regularization at step 2600: 0.212187
2025-12-12 20:40:31,976 INFO     Training average positive_sample_loss at step 2600: 0.443797
2025-12-12 20:40:31,976 INFO     Training average negative_sample_loss at step 2600: 0.542287
2025-12-12 20:40:31,977 INFO     Training average loss at step 2600: 0.705229
2025-12-12 20:40:39,277 INFO     Training average regularization at step 2700: 0.215133
2025-12-12 20:40:39,277 INFO     Training average positive_sample_loss at step 2700: 0.436477
2025-12-12 20:40:39,277 INFO     Training average negative_sample_loss at step 2700: 0.527353
2025-12-12 20:40:39,277 INFO     Training average loss at step 2700: 0.697048
2025-12-12 20:40:46,572 INFO     Training average regularization at step 2800: 0.217924
2025-12-12 20:40:46,572 INFO     Training average positive_sample_loss at step 2800: 0.434216
2025-12-12 20:40:46,573 INFO     Training average negative_sample_loss at step 2800: 0.522025
2025-12-12 20:40:46,573 INFO     Training average loss at step 2800: 0.696045
2025-12-12 20:40:53,847 INFO     Training average regularization at step 2900: 0.220630
2025-12-12 20:40:53,847 INFO     Training average positive_sample_loss at step 2900: 0.420697
2025-12-12 20:40:53,847 INFO     Training average negative_sample_loss at step 2900: 0.523084
2025-12-12 20:40:53,847 INFO     Training average loss at step 2900: 0.692520
2025-12-12 20:41:01,100 INFO     Training average regularization at step 3000: 0.223235
2025-12-12 20:41:01,100 INFO     Training average positive_sample_loss at step 3000: 0.428150
2025-12-12 20:41:01,100 INFO     Training average negative_sample_loss at step 3000: 0.510442
2025-12-12 20:41:01,100 INFO     Training average loss at step 3000: 0.692531
2025-12-12 20:41:08,345 INFO     Training average regularization at step 3100: 0.225734
2025-12-12 20:41:08,345 INFO     Training average positive_sample_loss at step 3100: 0.419372
2025-12-12 20:41:08,345 INFO     Training average negative_sample_loss at step 3100: 0.504427
2025-12-12 20:41:08,345 INFO     Training average loss at step 3100: 0.687633
2025-12-12 20:41:15,575 INFO     Training average regularization at step 3200: 0.228139
2025-12-12 20:41:15,575 INFO     Training average positive_sample_loss at step 3200: 0.413759
2025-12-12 20:41:15,575 INFO     Training average negative_sample_loss at step 3200: 0.498102
2025-12-12 20:41:15,575 INFO     Training average loss at step 3200: 0.684070
2025-12-12 20:41:22,842 INFO     Training average regularization at step 3300: 0.230443
2025-12-12 20:41:22,842 INFO     Training average positive_sample_loss at step 3300: 0.411334
2025-12-12 20:41:22,842 INFO     Training average negative_sample_loss at step 3300: 0.491751
2025-12-12 20:41:22,842 INFO     Training average loss at step 3300: 0.681986
2025-12-12 20:41:30,106 INFO     Training average regularization at step 3400: 0.232742
2025-12-12 20:41:30,106 INFO     Training average positive_sample_loss at step 3400: 0.403967
2025-12-12 20:41:30,106 INFO     Training average negative_sample_loss at step 3400: 0.486619
2025-12-12 20:41:30,107 INFO     Training average loss at step 3400: 0.678034
2025-12-12 20:41:37,424 INFO     Training average regularization at step 3500: 0.234891
2025-12-12 20:41:37,424 INFO     Training average positive_sample_loss at step 3500: 0.403351
2025-12-12 20:41:37,424 INFO     Training average negative_sample_loss at step 3500: 0.471692
2025-12-12 20:41:37,425 INFO     Training average loss at step 3500: 0.672412
2025-12-12 20:41:44,794 INFO     Training average regularization at step 3600: 0.236992
2025-12-12 20:41:44,794 INFO     Training average positive_sample_loss at step 3600: 0.395451
2025-12-12 20:41:44,794 INFO     Training average negative_sample_loss at step 3600: 0.473701
2025-12-12 20:41:44,794 INFO     Training average loss at step 3600: 0.671568
2025-12-12 20:41:52,053 INFO     Training average regularization at step 3700: 0.239032
2025-12-12 20:41:52,054 INFO     Training average positive_sample_loss at step 3700: 0.393076
2025-12-12 20:41:52,054 INFO     Training average negative_sample_loss at step 3700: 0.467189
2025-12-12 20:41:52,054 INFO     Training average loss at step 3700: 0.669165
2025-12-12 20:41:59,327 INFO     Training average regularization at step 3800: 0.241027
2025-12-12 20:41:59,327 INFO     Training average positive_sample_loss at step 3800: 0.386956
2025-12-12 20:41:59,327 INFO     Training average negative_sample_loss at step 3800: 0.464795
2025-12-12 20:41:59,327 INFO     Training average loss at step 3800: 0.666902
2025-12-12 20:42:06,656 INFO     Training average regularization at step 3900: 0.242998
2025-12-12 20:42:06,656 INFO     Training average positive_sample_loss at step 3900: 0.385984
2025-12-12 20:42:06,656 INFO     Training average negative_sample_loss at step 3900: 0.460771
2025-12-12 20:42:06,656 INFO     Training average loss at step 3900: 0.666376
2025-12-12 20:42:20,618 INFO     Training average regularization at step 4000: 0.244852
2025-12-12 20:42:20,618 INFO     Training average positive_sample_loss at step 4000: 0.377419
2025-12-12 20:42:20,618 INFO     Training average negative_sample_loss at step 4000: 0.447667
2025-12-12 20:42:20,618 INFO     Training average loss at step 4000: 0.657395
2025-12-12 20:42:27,997 INFO     Training average regularization at step 4100: 0.246605
2025-12-12 20:42:27,998 INFO     Training average positive_sample_loss at step 4100: 0.378073
2025-12-12 20:42:27,998 INFO     Training average negative_sample_loss at step 4100: 0.442856
2025-12-12 20:42:27,998 INFO     Training average loss at step 4100: 0.657070
2025-12-12 20:42:35,336 INFO     Training average regularization at step 4200: 0.248361
2025-12-12 20:42:35,337 INFO     Training average positive_sample_loss at step 4200: 0.376367
2025-12-12 20:42:35,337 INFO     Training average negative_sample_loss at step 4200: 0.445304
2025-12-12 20:42:35,337 INFO     Training average loss at step 4200: 0.659196
2025-12-12 20:42:42,781 INFO     Training average regularization at step 4300: 0.250049
2025-12-12 20:42:42,781 INFO     Training average positive_sample_loss at step 4300: 0.371069
2025-12-12 20:42:42,781 INFO     Training average negative_sample_loss at step 4300: 0.435476
2025-12-12 20:42:42,781 INFO     Training average loss at step 4300: 0.653321
2025-12-12 20:42:50,129 INFO     Training average regularization at step 4400: 0.251688
2025-12-12 20:42:50,129 INFO     Training average positive_sample_loss at step 4400: 0.369603
2025-12-12 20:42:50,129 INFO     Training average negative_sample_loss at step 4400: 0.430456
2025-12-12 20:42:50,129 INFO     Training average loss at step 4400: 0.651717
2025-12-12 20:42:57,460 INFO     Training average regularization at step 4500: 0.253337
2025-12-12 20:42:57,460 INFO     Training average positive_sample_loss at step 4500: 0.369712
2025-12-12 20:42:57,460 INFO     Training average negative_sample_loss at step 4500: 0.430017
2025-12-12 20:42:57,460 INFO     Training average loss at step 4500: 0.653202
2025-12-12 20:43:04,796 INFO     Training average regularization at step 4600: 0.254947
2025-12-12 20:43:04,796 INFO     Training average positive_sample_loss at step 4600: 0.365832
2025-12-12 20:43:04,796 INFO     Training average negative_sample_loss at step 4600: 0.424908
2025-12-12 20:43:04,796 INFO     Training average loss at step 4600: 0.650317
2025-12-12 20:43:12,138 INFO     Training average regularization at step 4700: 0.256514
2025-12-12 20:43:12,138 INFO     Training average positive_sample_loss at step 4700: 0.357217
2025-12-12 20:43:12,138 INFO     Training average negative_sample_loss at step 4700: 0.414411
2025-12-12 20:43:12,138 INFO     Training average loss at step 4700: 0.642328
2025-12-12 20:43:19,474 INFO     Training average regularization at step 4800: 0.258029
2025-12-12 20:43:19,475 INFO     Training average positive_sample_loss at step 4800: 0.360284
2025-12-12 20:43:19,475 INFO     Training average negative_sample_loss at step 4800: 0.418534
2025-12-12 20:43:19,475 INFO     Training average loss at step 4800: 0.647438
2025-12-12 20:43:26,780 INFO     Training average regularization at step 4900: 0.259454
2025-12-12 20:43:26,780 INFO     Training average positive_sample_loss at step 4900: 0.351082
2025-12-12 20:43:26,780 INFO     Training average negative_sample_loss at step 4900: 0.402649
2025-12-12 20:43:26,780 INFO     Training average loss at step 4900: 0.636319
2025-12-12 20:43:34,105 INFO     Training average regularization at step 5000: 0.260891
2025-12-12 20:43:34,106 INFO     Training average positive_sample_loss at step 5000: 0.351858
2025-12-12 20:43:34,106 INFO     Training average negative_sample_loss at step 5000: 0.406828
2025-12-12 20:43:34,106 INFO     Training average loss at step 5000: 0.640234
2025-12-12 20:43:41,522 INFO     Training average regularization at step 5100: 0.262324
2025-12-12 20:43:41,523 INFO     Training average positive_sample_loss at step 5100: 0.347385
2025-12-12 20:43:41,523 INFO     Training average negative_sample_loss at step 5100: 0.404384
2025-12-12 20:43:41,523 INFO     Training average loss at step 5100: 0.638209
2025-12-12 20:43:48,929 INFO     Training average regularization at step 5200: 0.263694
2025-12-12 20:43:48,930 INFO     Training average positive_sample_loss at step 5200: 0.354873
2025-12-12 20:43:48,930 INFO     Training average negative_sample_loss at step 5200: 0.394780
2025-12-12 20:43:48,930 INFO     Training average loss at step 5200: 0.638520
2025-12-12 20:43:56,248 INFO     Training average regularization at step 5300: 0.265042
2025-12-12 20:43:56,248 INFO     Training average positive_sample_loss at step 5300: 0.335493
2025-12-12 20:43:56,249 INFO     Training average negative_sample_loss at step 5300: 0.395885
2025-12-12 20:43:56,249 INFO     Training average loss at step 5300: 0.630731
2025-12-12 20:44:03,579 INFO     Training average regularization at step 5400: 0.266321
2025-12-12 20:44:03,580 INFO     Training average positive_sample_loss at step 5400: 0.342382
2025-12-12 20:44:03,580 INFO     Training average negative_sample_loss at step 5400: 0.392419
2025-12-12 20:44:03,580 INFO     Training average loss at step 5400: 0.633721
2025-12-12 20:44:10,923 INFO     Training average regularization at step 5500: 0.267643
2025-12-12 20:44:10,924 INFO     Training average positive_sample_loss at step 5500: 0.344444
2025-12-12 20:44:10,924 INFO     Training average negative_sample_loss at step 5500: 0.384683
2025-12-12 20:44:10,924 INFO     Training average loss at step 5500: 0.632206
2025-12-12 20:44:18,200 INFO     Training average regularization at step 5600: 0.268907
2025-12-12 20:44:18,200 INFO     Training average positive_sample_loss at step 5600: 0.335709
2025-12-12 20:44:18,201 INFO     Training average negative_sample_loss at step 5600: 0.383852
2025-12-12 20:44:18,201 INFO     Training average loss at step 5600: 0.628687
2025-12-12 20:44:25,450 INFO     Training average regularization at step 5700: 0.270161
2025-12-12 20:44:25,450 INFO     Training average positive_sample_loss at step 5700: 0.335104
2025-12-12 20:44:25,450 INFO     Training average negative_sample_loss at step 5700: 0.382228
2025-12-12 20:44:25,450 INFO     Training average loss at step 5700: 0.628827
2025-12-12 20:44:32,668 INFO     Training average regularization at step 5800: 0.271334
2025-12-12 20:44:32,668 INFO     Training average positive_sample_loss at step 5800: 0.329834
2025-12-12 20:44:32,668 INFO     Training average negative_sample_loss at step 5800: 0.370051
2025-12-12 20:44:32,668 INFO     Training average loss at step 5800: 0.621276
2025-12-12 20:44:39,982 INFO     Training average regularization at step 5900: 0.272429
2025-12-12 20:44:39,982 INFO     Training average positive_sample_loss at step 5900: 0.332131
2025-12-12 20:44:39,982 INFO     Training average negative_sample_loss at step 5900: 0.370452
2025-12-12 20:44:39,982 INFO     Training average loss at step 5900: 0.623721
2025-12-12 20:44:47,369 INFO     Training average regularization at step 6000: 0.273537
2025-12-12 20:44:47,369 INFO     Training average positive_sample_loss at step 6000: 0.319396
2025-12-12 20:44:47,370 INFO     Training average negative_sample_loss at step 6000: 0.364375
2025-12-12 20:44:47,370 INFO     Training average loss at step 6000: 0.615422
2025-12-12 20:44:54,668 INFO     Training average regularization at step 6100: 0.274619
2025-12-12 20:44:54,669 INFO     Training average positive_sample_loss at step 6100: 0.323473
2025-12-12 20:44:54,669 INFO     Training average negative_sample_loss at step 6100: 0.365168
2025-12-12 20:44:54,669 INFO     Training average loss at step 6100: 0.618939
2025-12-12 20:45:01,952 INFO     Training average regularization at step 6200: 0.275776
2025-12-12 20:45:01,952 INFO     Training average positive_sample_loss at step 6200: 0.322404
2025-12-12 20:45:01,952 INFO     Training average negative_sample_loss at step 6200: 0.361717
2025-12-12 20:45:01,952 INFO     Training average loss at step 6200: 0.617837
2025-12-12 20:45:09,298 INFO     Training average regularization at step 6300: 0.276876
2025-12-12 20:45:09,298 INFO     Training average positive_sample_loss at step 6300: 0.319530
2025-12-12 20:45:09,298 INFO     Training average negative_sample_loss at step 6300: 0.362749
2025-12-12 20:45:09,298 INFO     Training average loss at step 6300: 0.618016
2025-12-12 20:45:16,605 INFO     Training average regularization at step 6400: 0.277929
2025-12-12 20:45:16,606 INFO     Training average positive_sample_loss at step 6400: 0.318490
2025-12-12 20:45:16,606 INFO     Training average negative_sample_loss at step 6400: 0.359359
2025-12-12 20:45:16,606 INFO     Training average loss at step 6400: 0.616854
2025-12-12 20:45:23,907 INFO     Training average regularization at step 6500: 0.278898
2025-12-12 20:45:23,907 INFO     Training average positive_sample_loss at step 6500: 0.307908
2025-12-12 20:45:23,907 INFO     Training average negative_sample_loss at step 6500: 0.354965
2025-12-12 20:45:23,907 INFO     Training average loss at step 6500: 0.610334
2025-12-12 20:45:31,184 INFO     Training average regularization at step 6600: 0.279831
2025-12-12 20:45:31,185 INFO     Training average positive_sample_loss at step 6600: 0.321688
2025-12-12 20:45:31,185 INFO     Training average negative_sample_loss at step 6600: 0.349086
2025-12-12 20:45:31,185 INFO     Training average loss at step 6600: 0.615218
2025-12-12 20:45:38,478 INFO     Training average regularization at step 6700: 0.280813
2025-12-12 20:45:38,478 INFO     Training average positive_sample_loss at step 6700: 0.298832
2025-12-12 20:45:38,478 INFO     Training average negative_sample_loss at step 6700: 0.343662
2025-12-12 20:45:38,478 INFO     Training average loss at step 6700: 0.602060
2025-12-12 20:45:45,902 INFO     Training average regularization at step 6800: 0.281747
2025-12-12 20:45:45,903 INFO     Training average positive_sample_loss at step 6800: 0.307524
2025-12-12 20:45:45,903 INFO     Training average negative_sample_loss at step 6800: 0.344764
2025-12-12 20:45:45,903 INFO     Training average loss at step 6800: 0.607890
2025-12-12 20:45:53,174 INFO     Training average regularization at step 6900: 0.282677
2025-12-12 20:45:53,175 INFO     Training average positive_sample_loss at step 6900: 0.307372
2025-12-12 20:45:53,175 INFO     Training average negative_sample_loss at step 6900: 0.341560
2025-12-12 20:45:53,175 INFO     Training average loss at step 6900: 0.607144
2025-12-12 20:46:00,459 INFO     Training average regularization at step 7000: 0.283563
2025-12-12 20:46:00,459 INFO     Training average positive_sample_loss at step 7000: 0.297943
2025-12-12 20:46:00,459 INFO     Training average negative_sample_loss at step 7000: 0.335242
2025-12-12 20:46:00,459 INFO     Training average loss at step 7000: 0.600156
2025-12-12 20:46:07,746 INFO     Training average regularization at step 7100: 0.284385
2025-12-12 20:46:07,746 INFO     Training average positive_sample_loss at step 7100: 0.304740
2025-12-12 20:46:07,746 INFO     Training average negative_sample_loss at step 7100: 0.331955
2025-12-12 20:46:07,746 INFO     Training average loss at step 7100: 0.602732
2025-12-12 20:46:14,978 INFO     Training average regularization at step 7200: 0.285196
2025-12-12 20:46:14,978 INFO     Training average positive_sample_loss at step 7200: 0.298208
2025-12-12 20:46:14,978 INFO     Training average negative_sample_loss at step 7200: 0.330802
2025-12-12 20:46:14,979 INFO     Training average loss at step 7200: 0.599701
2025-12-12 20:46:22,240 INFO     Training average regularization at step 7300: 0.286020
2025-12-12 20:46:22,242 INFO     Training average positive_sample_loss at step 7300: 0.291702
2025-12-12 20:46:22,242 INFO     Training average negative_sample_loss at step 7300: 0.324066
2025-12-12 20:46:22,242 INFO     Training average loss at step 7300: 0.593904
2025-12-12 20:46:29,498 INFO     Training average regularization at step 7400: 0.286850
2025-12-12 20:46:29,499 INFO     Training average positive_sample_loss at step 7400: 0.296793
2025-12-12 20:46:29,499 INFO     Training average negative_sample_loss at step 7400: 0.334900
2025-12-12 20:46:29,499 INFO     Training average loss at step 7400: 0.602696
2025-12-12 20:46:36,756 INFO     Training average regularization at step 7500: 0.287657
2025-12-12 20:46:36,756 INFO     Training average positive_sample_loss at step 7500: 0.298561
2025-12-12 20:46:36,756 INFO     Training average negative_sample_loss at step 7500: 0.320765
2025-12-12 20:46:36,756 INFO     Training average loss at step 7500: 0.597320
2025-12-12 20:46:44,162 INFO     Training average regularization at step 7600: 0.288470
2025-12-12 20:46:44,162 INFO     Training average positive_sample_loss at step 7600: 0.292042
2025-12-12 20:46:44,162 INFO     Training average negative_sample_loss at step 7600: 0.320040
2025-12-12 20:46:44,162 INFO     Training average loss at step 7600: 0.594511
2025-12-12 20:46:51,501 INFO     Training average regularization at step 7700: 0.289214
2025-12-12 20:46:51,502 INFO     Training average positive_sample_loss at step 7700: 0.289394
2025-12-12 20:46:51,502 INFO     Training average negative_sample_loss at step 7700: 0.320109
2025-12-12 20:46:51,502 INFO     Training average loss at step 7700: 0.593965
2025-12-12 20:46:58,836 INFO     Training average regularization at step 7800: 0.289906
2025-12-12 20:46:58,836 INFO     Training average positive_sample_loss at step 7800: 0.282804
2025-12-12 20:46:58,836 INFO     Training average negative_sample_loss at step 7800: 0.312941
2025-12-12 20:46:58,836 INFO     Training average loss at step 7800: 0.587778
2025-12-12 20:47:06,115 INFO     Training average regularization at step 7900: 0.290572
2025-12-12 20:47:06,116 INFO     Training average positive_sample_loss at step 7900: 0.282739
2025-12-12 20:47:06,116 INFO     Training average negative_sample_loss at step 7900: 0.317449
2025-12-12 20:47:06,116 INFO     Training average loss at step 7900: 0.590666
2025-12-12 20:47:20,963 INFO     Training average regularization at step 8000: 0.291233
2025-12-12 20:47:20,963 INFO     Training average positive_sample_loss at step 8000: 0.287896
2025-12-12 20:47:20,964 INFO     Training average negative_sample_loss at step 8000: 0.318684
2025-12-12 20:47:20,964 INFO     Training average loss at step 8000: 0.594522
2025-12-12 20:47:28,267 INFO     Training average regularization at step 8100: 0.291911
2025-12-12 20:47:28,268 INFO     Training average positive_sample_loss at step 8100: 0.280703
2025-12-12 20:47:28,268 INFO     Training average negative_sample_loss at step 8100: 0.307104
2025-12-12 20:47:28,268 INFO     Training average loss at step 8100: 0.585814
2025-12-12 20:47:35,628 INFO     Training average regularization at step 8200: 0.292545
2025-12-12 20:47:35,629 INFO     Training average positive_sample_loss at step 8200: 0.283957
2025-12-12 20:47:35,629 INFO     Training average negative_sample_loss at step 8200: 0.307459
2025-12-12 20:47:35,629 INFO     Training average loss at step 8200: 0.588253
2025-12-12 20:47:43,012 INFO     Training average regularization at step 8300: 0.293239
2025-12-12 20:47:43,012 INFO     Training average positive_sample_loss at step 8300: 0.274886
2025-12-12 20:47:43,012 INFO     Training average negative_sample_loss at step 8300: 0.309848
2025-12-12 20:47:43,012 INFO     Training average loss at step 8300: 0.585606
2025-12-12 20:47:50,279 INFO     Training average regularization at step 8400: 0.293876
2025-12-12 20:47:50,279 INFO     Training average positive_sample_loss at step 8400: 0.278325
2025-12-12 20:47:50,279 INFO     Training average negative_sample_loss at step 8400: 0.299966
2025-12-12 20:47:50,279 INFO     Training average loss at step 8400: 0.583021
2025-12-12 20:47:57,520 INFO     Training average regularization at step 8500: 0.294509
2025-12-12 20:47:57,537 INFO     Training average positive_sample_loss at step 8500: 0.282980
2025-12-12 20:47:57,537 INFO     Training average negative_sample_loss at step 8500: 0.301009
2025-12-12 20:47:57,537 INFO     Training average loss at step 8500: 0.586503
2025-12-12 20:48:04,763 INFO     Training average regularization at step 8600: 0.295138
2025-12-12 20:48:04,764 INFO     Training average positive_sample_loss at step 8600: 0.272715
2025-12-12 20:48:04,764 INFO     Training average negative_sample_loss at step 8600: 0.298543
2025-12-12 20:48:04,764 INFO     Training average loss at step 8600: 0.580767
2025-12-12 20:48:12,090 INFO     Training average regularization at step 8700: 0.295796
2025-12-12 20:48:12,091 INFO     Training average positive_sample_loss at step 8700: 0.270261
2025-12-12 20:48:12,091 INFO     Training average negative_sample_loss at step 8700: 0.302417
2025-12-12 20:48:12,091 INFO     Training average loss at step 8700: 0.582135
2025-12-12 20:48:19,394 INFO     Training average regularization at step 8800: 0.296400
2025-12-12 20:48:19,394 INFO     Training average positive_sample_loss at step 8800: 0.278728
2025-12-12 20:48:19,394 INFO     Training average negative_sample_loss at step 8800: 0.296499
2025-12-12 20:48:19,394 INFO     Training average loss at step 8800: 0.584014
2025-12-12 20:48:26,689 INFO     Training average regularization at step 8900: 0.296962
2025-12-12 20:48:26,690 INFO     Training average positive_sample_loss at step 8900: 0.275933
2025-12-12 20:48:26,690 INFO     Training average negative_sample_loss at step 8900: 0.301496
2025-12-12 20:48:26,690 INFO     Training average loss at step 8900: 0.585676
2025-12-12 20:48:34,031 INFO     Training average regularization at step 9000: 0.297603
2025-12-12 20:48:34,032 INFO     Training average positive_sample_loss at step 9000: 0.267094
2025-12-12 20:48:34,032 INFO     Training average negative_sample_loss at step 9000: 0.296289
2025-12-12 20:48:34,032 INFO     Training average loss at step 9000: 0.579295
2025-12-12 20:48:41,451 INFO     Training average regularization at step 9100: 0.298137
2025-12-12 20:48:41,452 INFO     Training average positive_sample_loss at step 9100: 0.264869
2025-12-12 20:48:41,452 INFO     Training average negative_sample_loss at step 9100: 0.294125
2025-12-12 20:48:41,452 INFO     Training average loss at step 9100: 0.577634
2025-12-12 20:48:48,810 INFO     Training average regularization at step 9200: 0.298692
2025-12-12 20:48:48,811 INFO     Training average positive_sample_loss at step 9200: 0.263967
2025-12-12 20:48:48,811 INFO     Training average negative_sample_loss at step 9200: 0.287235
2025-12-12 20:48:48,811 INFO     Training average loss at step 9200: 0.574293
2025-12-12 20:48:56,118 INFO     Training average regularization at step 9300: 0.299220
2025-12-12 20:48:56,119 INFO     Training average positive_sample_loss at step 9300: 0.262640
2025-12-12 20:48:56,119 INFO     Training average negative_sample_loss at step 9300: 0.288359
2025-12-12 20:48:56,119 INFO     Training average loss at step 9300: 0.574720
2025-12-12 20:49:03,400 INFO     Training average regularization at step 9400: 0.299782
2025-12-12 20:49:03,401 INFO     Training average positive_sample_loss at step 9400: 0.261934
2025-12-12 20:49:03,401 INFO     Training average negative_sample_loss at step 9400: 0.284081
2025-12-12 20:49:03,401 INFO     Training average loss at step 9400: 0.572789
2025-12-12 20:49:10,654 INFO     Training average regularization at step 9500: 0.300346
2025-12-12 20:49:10,654 INFO     Training average positive_sample_loss at step 9500: 0.257634
2025-12-12 20:49:10,655 INFO     Training average negative_sample_loss at step 9500: 0.282188
2025-12-12 20:49:10,655 INFO     Training average loss at step 9500: 0.570256
2025-12-12 20:49:17,916 INFO     Training average regularization at step 9600: 0.300870
2025-12-12 20:49:17,917 INFO     Training average positive_sample_loss at step 9600: 0.266068
2025-12-12 20:49:17,917 INFO     Training average negative_sample_loss at step 9600: 0.287434
2025-12-12 20:49:17,917 INFO     Training average loss at step 9600: 0.577621
2025-12-12 20:49:25,170 INFO     Training average regularization at step 9700: 0.301431
2025-12-12 20:49:25,170 INFO     Training average positive_sample_loss at step 9700: 0.256334
2025-12-12 20:49:25,170 INFO     Training average negative_sample_loss at step 9700: 0.283200
2025-12-12 20:49:25,170 INFO     Training average loss at step 9700: 0.571198
2025-12-12 20:49:32,395 INFO     Training average regularization at step 9800: 0.301871
2025-12-12 20:49:32,395 INFO     Training average positive_sample_loss at step 9800: 0.255887
2025-12-12 20:49:32,396 INFO     Training average negative_sample_loss at step 9800: 0.278550
2025-12-12 20:49:32,396 INFO     Training average loss at step 9800: 0.569090
2025-12-12 20:49:39,668 INFO     Training average regularization at step 9900: 0.302385
2025-12-12 20:49:39,668 INFO     Training average positive_sample_loss at step 9900: 0.253290
2025-12-12 20:49:39,669 INFO     Training average negative_sample_loss at step 9900: 0.275935
2025-12-12 20:49:39,669 INFO     Training average loss at step 9900: 0.566998
2025-12-12 20:49:47,017 INFO     Training average regularization at step 10000: 0.302814
2025-12-12 20:49:47,017 INFO     Training average positive_sample_loss at step 10000: 0.251007
2025-12-12 20:49:47,017 INFO     Training average negative_sample_loss at step 10000: 0.273628
2025-12-12 20:49:47,017 INFO     Training average loss at step 10000: 0.565131
2025-12-12 20:49:47,017 INFO     Evaluating on Valid Dataset...
2025-12-12 20:49:48,965 INFO     Evaluating the model... (0/5000)
2025-12-12 20:49:56,143 INFO     Evaluating the model... (100/5000)
2025-12-12 20:50:03,214 INFO     Evaluating the model... (200/5000)
2025-12-12 20:50:10,291 INFO     Evaluating the model... (300/5000)
2025-12-12 20:50:17,347 INFO     Evaluating the model... (400/5000)
2025-12-12 20:50:24,460 INFO     Evaluating the model... (500/5000)
2025-12-12 20:50:31,547 INFO     Evaluating the model... (600/5000)
2025-12-12 20:50:38,734 INFO     Evaluating the model... (700/5000)
2025-12-12 20:50:45,877 INFO     Evaluating the model... (800/5000)
2025-12-12 20:50:52,944 INFO     Evaluating the model... (900/5000)
2025-12-12 20:51:00,042 INFO     Evaluating the model... (1000/5000)
2025-12-12 20:51:07,093 INFO     Evaluating the model... (1100/5000)
2025-12-12 20:51:14,168 INFO     Evaluating the model... (1200/5000)
2025-12-12 20:51:21,287 INFO     Evaluating the model... (1300/5000)
2025-12-12 20:51:28,607 INFO     Evaluating the model... (1400/5000)
2025-12-12 20:51:35,709 INFO     Evaluating the model... (1500/5000)
2025-12-12 20:51:45,168 INFO     Evaluating the model... (1600/5000)
2025-12-12 20:51:52,259 INFO     Evaluating the model... (1700/5000)
2025-12-12 20:51:59,336 INFO     Evaluating the model... (1800/5000)
2025-12-12 20:52:06,395 INFO     Evaluating the model... (1900/5000)
2025-12-12 20:52:13,507 INFO     Evaluating the model... (2000/5000)
2025-12-12 20:52:20,624 INFO     Evaluating the model... (2100/5000)
2025-12-12 20:52:27,712 INFO     Evaluating the model... (2200/5000)
2025-12-12 20:52:34,797 INFO     Evaluating the model... (2300/5000)
2025-12-12 20:52:41,958 INFO     Evaluating the model... (2400/5000)
2025-12-12 20:52:49,863 INFO     Evaluating the model... (2500/5000)
2025-12-12 20:52:57,004 INFO     Evaluating the model... (2600/5000)
2025-12-12 20:53:04,084 INFO     Evaluating the model... (2700/5000)
2025-12-12 20:53:11,185 INFO     Evaluating the model... (2800/5000)
2025-12-12 20:53:18,216 INFO     Evaluating the model... (2900/5000)
2025-12-12 20:53:25,328 INFO     Evaluating the model... (3000/5000)
2025-12-12 20:53:32,407 INFO     Evaluating the model... (3100/5000)
2025-12-12 20:53:39,535 INFO     Evaluating the model... (3200/5000)
2025-12-12 20:53:46,719 INFO     Evaluating the model... (3300/5000)
2025-12-12 20:53:53,809 INFO     Evaluating the model... (3400/5000)
2025-12-12 20:54:00,848 INFO     Evaluating the model... (3500/5000)
2025-12-12 20:54:07,916 INFO     Evaluating the model... (3600/5000)
2025-12-12 20:54:14,987 INFO     Evaluating the model... (3700/5000)
2025-12-12 20:54:22,082 INFO     Evaluating the model... (3800/5000)
2025-12-12 20:54:29,135 INFO     Evaluating the model... (3900/5000)
2025-12-12 20:54:38,236 INFO     Evaluating the model... (4000/5000)
2025-12-12 20:54:45,434 INFO     Evaluating the model... (4100/5000)
2025-12-12 20:54:52,536 INFO     Evaluating the model... (4200/5000)
2025-12-12 20:54:59,641 INFO     Evaluating the model... (4300/5000)
2025-12-12 20:55:06,775 INFO     Evaluating the model... (4400/5000)
2025-12-12 20:55:13,891 INFO     Evaluating the model... (4500/5000)
2025-12-12 20:55:21,029 INFO     Evaluating the model... (4600/5000)
2025-12-12 20:55:28,185 INFO     Evaluating the model... (4700/5000)
2025-12-12 20:55:35,318 INFO     Evaluating the model... (4800/5000)
2025-12-12 20:55:42,530 INFO     Evaluating the model... (4900/5000)
2025-12-12 20:55:49,885 INFO     Valid MRR at step 10000: 0.301678
2025-12-12 20:55:49,885 INFO     Valid MR at step 10000: 5996.296800
2025-12-12 20:55:49,885 INFO     Valid HITS@1 at step 10000: 0.215700
2025-12-12 20:55:49,885 INFO     Valid HITS@3 at step 10000: 0.341200
2025-12-12 20:55:49,885 INFO     Valid HITS@10 at step 10000: 0.465400
2025-12-12 20:55:56,768 INFO     Evaluating on Test Dataset...
2025-12-12 20:55:58,492 INFO     Evaluating the model... (0/5000)
2025-12-12 20:56:05,708 INFO     Evaluating the model... (100/5000)
2025-12-12 20:56:13,074 INFO     Evaluating the model... (200/5000)
2025-12-12 20:56:20,184 INFO     Evaluating the model... (300/5000)
2025-12-12 20:56:27,341 INFO     Evaluating the model... (400/5000)
2025-12-12 20:56:34,442 INFO     Evaluating the model... (500/5000)
2025-12-12 20:56:41,657 INFO     Evaluating the model... (600/5000)
2025-12-12 20:56:48,814 INFO     Evaluating the model... (700/5000)
2025-12-12 20:56:55,940 INFO     Evaluating the model... (800/5000)
2025-12-12 20:57:03,037 INFO     Evaluating the model... (900/5000)
2025-12-12 20:57:10,155 INFO     Evaluating the model... (1000/5000)
2025-12-12 20:57:17,281 INFO     Evaluating the model... (1100/5000)
2025-12-12 20:57:24,494 INFO     Evaluating the model... (1200/5000)
2025-12-12 20:57:31,576 INFO     Evaluating the model... (1300/5000)
2025-12-12 20:57:41,164 INFO     Evaluating the model... (1400/5000)
2025-12-12 20:57:48,286 INFO     Evaluating the model... (1500/5000)
2025-12-12 20:57:55,410 INFO     Evaluating the model... (1600/5000)
2025-12-12 20:58:02,487 INFO     Evaluating the model... (1700/5000)
2025-12-12 20:58:09,555 INFO     Evaluating the model... (1800/5000)
2025-12-12 20:58:16,656 INFO     Evaluating the model... (1900/5000)
2025-12-12 20:58:23,735 INFO     Evaluating the model... (2000/5000)
2025-12-12 20:58:30,829 INFO     Evaluating the model... (2100/5000)
2025-12-12 20:58:37,963 INFO     Evaluating the model... (2200/5000)
2025-12-12 20:58:45,105 INFO     Evaluating the model... (2300/5000)
2025-12-12 20:58:52,244 INFO     Evaluating the model... (2400/5000)
2025-12-12 20:59:00,041 INFO     Evaluating the model... (2500/5000)
2025-12-12 20:59:07,222 INFO     Evaluating the model... (2600/5000)
2025-12-12 20:59:14,399 INFO     Evaluating the model... (2700/5000)
2025-12-12 20:59:21,588 INFO     Evaluating the model... (2800/5000)
2025-12-12 20:59:28,768 INFO     Evaluating the model... (2900/5000)
2025-12-12 20:59:35,895 INFO     Evaluating the model... (3000/5000)
2025-12-12 20:59:43,110 INFO     Evaluating the model... (3100/5000)
2025-12-12 20:59:50,252 INFO     Evaluating the model... (3200/5000)
2025-12-12 20:59:57,342 INFO     Evaluating the model... (3300/5000)
2025-12-12 21:00:04,491 INFO     Evaluating the model... (3400/5000)
2025-12-12 21:00:11,630 INFO     Evaluating the model... (3500/5000)
2025-12-12 21:00:18,715 INFO     Evaluating the model... (3600/5000)
2025-12-12 21:00:25,817 INFO     Evaluating the model... (3700/5000)
2025-12-12 21:00:32,913 INFO     Evaluating the model... (3800/5000)
2025-12-12 21:00:42,261 INFO     Evaluating the model... (3900/5000)
2025-12-12 21:00:49,424 INFO     Evaluating the model... (4000/5000)
2025-12-12 21:00:56,526 INFO     Evaluating the model... (4100/5000)
2025-12-12 21:01:03,646 INFO     Evaluating the model... (4200/5000)
2025-12-12 21:01:10,803 INFO     Evaluating the model... (4300/5000)
2025-12-12 21:01:17,933 INFO     Evaluating the model... (4400/5000)
2025-12-12 21:01:25,097 INFO     Evaluating the model... (4500/5000)
2025-12-12 21:01:32,179 INFO     Evaluating the model... (4600/5000)
2025-12-12 21:01:39,336 INFO     Evaluating the model... (4700/5000)
2025-12-12 21:01:46,483 INFO     Evaluating the model... (4800/5000)
2025-12-12 21:01:53,585 INFO     Evaluating the model... (4900/5000)
2025-12-12 21:02:00,956 INFO     Test MRR at step 10000: 0.296518
2025-12-12 21:02:00,956 INFO     Test MR at step 10000: 5443.156800
2025-12-12 21:02:00,956 INFO     Test HITS@1 at step 10000: 0.209500
2025-12-12 21:02:00,956 INFO     Test HITS@3 at step 10000: 0.337400
2025-12-12 21:02:00,956 INFO     Test HITS@10 at step 10000: 0.468600
2025-12-12 21:02:08,208 INFO     Training average regularization at step 10100: 0.303298
2025-12-12 21:02:08,209 INFO     Training average positive_sample_loss at step 10100: 0.249454
2025-12-12 21:02:08,209 INFO     Training average negative_sample_loss at step 10100: 0.276211
2025-12-12 21:02:08,209 INFO     Training average loss at step 10100: 0.566130
2025-12-12 21:02:15,472 INFO     Training average regularization at step 10200: 0.303756
2025-12-12 21:02:15,472 INFO     Training average positive_sample_loss at step 10200: 0.253231
2025-12-12 21:02:15,472 INFO     Training average negative_sample_loss at step 10200: 0.267028
2025-12-12 21:02:15,472 INFO     Training average loss at step 10200: 0.563886
2025-12-12 21:02:22,760 INFO     Training average regularization at step 10300: 0.304262
2025-12-12 21:02:22,761 INFO     Training average positive_sample_loss at step 10300: 0.250081
2025-12-12 21:02:22,761 INFO     Training average negative_sample_loss at step 10300: 0.272664
2025-12-12 21:02:22,761 INFO     Training average loss at step 10300: 0.565635
2025-12-12 21:02:30,044 INFO     Training average regularization at step 10400: 0.304751
2025-12-12 21:02:30,044 INFO     Training average positive_sample_loss at step 10400: 0.254342
2025-12-12 21:02:30,044 INFO     Training average negative_sample_loss at step 10400: 0.272126
2025-12-12 21:02:30,044 INFO     Training average loss at step 10400: 0.567985
2025-12-12 21:02:37,300 INFO     Training average regularization at step 10500: 0.305231
2025-12-12 21:02:37,301 INFO     Training average positive_sample_loss at step 10500: 0.243974
2025-12-12 21:02:37,301 INFO     Training average negative_sample_loss at step 10500: 0.267542
2025-12-12 21:02:37,301 INFO     Training average loss at step 10500: 0.560989
2025-12-12 21:02:44,648 INFO     Training average regularization at step 10600: 0.305690
2025-12-12 21:02:44,649 INFO     Training average positive_sample_loss at step 10600: 0.244835
2025-12-12 21:02:44,649 INFO     Training average negative_sample_loss at step 10600: 0.270872
2025-12-12 21:02:44,649 INFO     Training average loss at step 10600: 0.563543
2025-12-12 21:02:51,887 INFO     Training average regularization at step 10700: 0.306147
2025-12-12 21:02:51,887 INFO     Training average positive_sample_loss at step 10700: 0.245178
2025-12-12 21:02:51,887 INFO     Training average negative_sample_loss at step 10700: 0.266173
2025-12-12 21:02:51,887 INFO     Training average loss at step 10700: 0.561822
2025-12-12 21:03:00,731 INFO     Training average regularization at step 10800: 0.306583
2025-12-12 21:03:00,731 INFO     Training average positive_sample_loss at step 10800: 0.239965
2025-12-12 21:03:00,732 INFO     Training average negative_sample_loss at step 10800: 0.259213
2025-12-12 21:03:00,732 INFO     Training average loss at step 10800: 0.556172
2025-12-12 21:03:08,067 INFO     Training average regularization at step 10900: 0.306756
2025-12-12 21:03:08,068 INFO     Training average positive_sample_loss at step 10900: 0.193658
2025-12-12 21:03:08,068 INFO     Training average negative_sample_loss at step 10900: 0.227512
2025-12-12 21:03:08,068 INFO     Training average loss at step 10900: 0.517341
2025-12-12 21:03:15,353 INFO     Training average regularization at step 11000: 0.306715
2025-12-12 21:03:15,354 INFO     Training average positive_sample_loss at step 11000: 0.197205
2025-12-12 21:03:15,354 INFO     Training average negative_sample_loss at step 11000: 0.225752
2025-12-12 21:03:15,354 INFO     Training average loss at step 11000: 0.518193
2025-12-12 21:03:22,657 INFO     Training average regularization at step 11100: 0.306833
2025-12-12 21:03:22,657 INFO     Training average positive_sample_loss at step 11100: 0.199704
2025-12-12 21:03:22,657 INFO     Training average negative_sample_loss at step 11100: 0.226331
2025-12-12 21:03:22,657 INFO     Training average loss at step 11100: 0.519850
2025-12-12 21:03:29,945 INFO     Training average regularization at step 11200: 0.307022
2025-12-12 21:03:29,946 INFO     Training average positive_sample_loss at step 11200: 0.203196
2025-12-12 21:03:29,946 INFO     Training average negative_sample_loss at step 11200: 0.218108
2025-12-12 21:03:29,946 INFO     Training average loss at step 11200: 0.517674
2025-12-12 21:03:37,246 INFO     Training average regularization at step 11300: 0.307228
2025-12-12 21:03:37,246 INFO     Training average positive_sample_loss at step 11300: 0.207068
2025-12-12 21:03:37,246 INFO     Training average negative_sample_loss at step 11300: 0.224574
2025-12-12 21:03:37,246 INFO     Training average loss at step 11300: 0.523049
2025-12-12 21:03:44,658 INFO     Training average regularization at step 11400: 0.307471
2025-12-12 21:03:44,659 INFO     Training average positive_sample_loss at step 11400: 0.209292
2025-12-12 21:03:44,659 INFO     Training average negative_sample_loss at step 11400: 0.229396
2025-12-12 21:03:44,659 INFO     Training average loss at step 11400: 0.526815
2025-12-12 21:03:51,932 INFO     Training average regularization at step 11500: 0.307778
2025-12-12 21:03:51,932 INFO     Training average positive_sample_loss at step 11500: 0.208753
2025-12-12 21:03:51,932 INFO     Training average negative_sample_loss at step 11500: 0.223901
2025-12-12 21:03:51,932 INFO     Training average loss at step 11500: 0.524105
2025-12-12 21:03:59,204 INFO     Training average regularization at step 11600: 0.308044
2025-12-12 21:03:59,204 INFO     Training average positive_sample_loss at step 11600: 0.202663
2025-12-12 21:03:59,204 INFO     Training average negative_sample_loss at step 11600: 0.219819
2025-12-12 21:03:59,204 INFO     Training average loss at step 11600: 0.519285
2025-12-12 21:04:06,428 INFO     Training average regularization at step 11700: 0.308312
2025-12-12 21:04:06,428 INFO     Training average positive_sample_loss at step 11700: 0.212010
2025-12-12 21:04:06,428 INFO     Training average negative_sample_loss at step 11700: 0.227472
2025-12-12 21:04:06,428 INFO     Training average loss at step 11700: 0.528054
2025-12-12 21:04:13,787 INFO     Training average regularization at step 11800: 0.308697
2025-12-12 21:04:13,787 INFO     Training average positive_sample_loss at step 11800: 0.211597
2025-12-12 21:04:13,787 INFO     Training average negative_sample_loss at step 11800: 0.231512
2025-12-12 21:04:13,787 INFO     Training average loss at step 11800: 0.530252
2025-12-12 21:04:21,023 INFO     Training average regularization at step 11900: 0.309030
2025-12-12 21:04:21,023 INFO     Training average positive_sample_loss at step 11900: 0.216018
2025-12-12 21:04:21,023 INFO     Training average negative_sample_loss at step 11900: 0.230284
2025-12-12 21:04:21,023 INFO     Training average loss at step 11900: 0.532181
2025-12-12 21:04:35,583 INFO     Training average regularization at step 12000: 0.309473
2025-12-12 21:04:35,584 INFO     Training average positive_sample_loss at step 12000: 0.212552
2025-12-12 21:04:35,584 INFO     Training average negative_sample_loss at step 12000: 0.229690
2025-12-12 21:04:35,584 INFO     Training average loss at step 12000: 0.530594
2025-12-12 21:04:42,973 INFO     Training average regularization at step 12100: 0.309844
2025-12-12 21:04:42,974 INFO     Training average positive_sample_loss at step 12100: 0.216722
2025-12-12 21:04:42,974 INFO     Training average negative_sample_loss at step 12100: 0.229600
2025-12-12 21:04:42,974 INFO     Training average loss at step 12100: 0.533005
2025-12-12 21:04:50,278 INFO     Training average regularization at step 12200: 0.310252
2025-12-12 21:04:50,279 INFO     Training average positive_sample_loss at step 12200: 0.225522
2025-12-12 21:04:50,279 INFO     Training average negative_sample_loss at step 12200: 0.228415
2025-12-12 21:04:50,279 INFO     Training average loss at step 12200: 0.537221
2025-12-12 21:04:57,586 INFO     Training average regularization at step 12300: 0.310664
2025-12-12 21:04:57,586 INFO     Training average positive_sample_loss at step 12300: 0.215184
2025-12-12 21:04:57,586 INFO     Training average negative_sample_loss at step 12300: 0.229840
2025-12-12 21:04:57,586 INFO     Training average loss at step 12300: 0.533176
2025-12-12 21:05:04,844 INFO     Training average regularization at step 12400: 0.311041
2025-12-12 21:05:04,845 INFO     Training average positive_sample_loss at step 12400: 0.220162
2025-12-12 21:05:04,845 INFO     Training average negative_sample_loss at step 12400: 0.232326
2025-12-12 21:05:04,845 INFO     Training average loss at step 12400: 0.537285
2025-12-12 21:05:12,130 INFO     Training average regularization at step 12500: 0.311483
2025-12-12 21:05:12,131 INFO     Training average positive_sample_loss at step 12500: 0.223139
2025-12-12 21:05:12,131 INFO     Training average negative_sample_loss at step 12500: 0.234717
2025-12-12 21:05:12,131 INFO     Training average loss at step 12500: 0.540411
2025-12-12 21:05:19,382 INFO     Training average regularization at step 12600: 0.311966
2025-12-12 21:05:19,383 INFO     Training average positive_sample_loss at step 12600: 0.226857
2025-12-12 21:05:19,383 INFO     Training average negative_sample_loss at step 12600: 0.238471
2025-12-12 21:05:19,383 INFO     Training average loss at step 12600: 0.544630
2025-12-12 21:05:26,643 INFO     Training average regularization at step 12700: 0.312405
2025-12-12 21:05:26,643 INFO     Training average positive_sample_loss at step 12700: 0.220479
2025-12-12 21:05:26,643 INFO     Training average negative_sample_loss at step 12700: 0.238822
2025-12-12 21:05:26,643 INFO     Training average loss at step 12700: 0.542055
2025-12-12 21:05:33,858 INFO     Training average regularization at step 12800: 0.312820
2025-12-12 21:05:33,859 INFO     Training average positive_sample_loss at step 12800: 0.217704
2025-12-12 21:05:33,860 INFO     Training average negative_sample_loss at step 12800: 0.228273
2025-12-12 21:05:33,860 INFO     Training average loss at step 12800: 0.535808
2025-12-12 21:05:41,235 INFO     Training average regularization at step 12900: 0.313241
2025-12-12 21:05:41,236 INFO     Training average positive_sample_loss at step 12900: 0.232716
2025-12-12 21:05:41,236 INFO     Training average negative_sample_loss at step 12900: 0.234313
2025-12-12 21:05:41,236 INFO     Training average loss at step 12900: 0.546756
2025-12-12 21:05:48,577 INFO     Training average regularization at step 13000: 0.313745
2025-12-12 21:05:48,578 INFO     Training average positive_sample_loss at step 13000: 0.225026
2025-12-12 21:05:48,578 INFO     Training average negative_sample_loss at step 13000: 0.237862
2025-12-12 21:05:48,578 INFO     Training average loss at step 13000: 0.545189
2025-12-12 21:05:55,843 INFO     Training average regularization at step 13100: 0.314189
2025-12-12 21:05:55,844 INFO     Training average positive_sample_loss at step 13100: 0.223150
2025-12-12 21:05:55,844 INFO     Training average negative_sample_loss at step 13100: 0.229193
2025-12-12 21:05:55,844 INFO     Training average loss at step 13100: 0.540360
2025-12-12 21:06:03,115 INFO     Training average regularization at step 13200: 0.314570
2025-12-12 21:06:03,115 INFO     Training average positive_sample_loss at step 13200: 0.227025
2025-12-12 21:06:03,115 INFO     Training average negative_sample_loss at step 13200: 0.237186
2025-12-12 21:06:03,115 INFO     Training average loss at step 13200: 0.546675
2025-12-12 21:06:10,362 INFO     Training average regularization at step 13300: 0.314984
2025-12-12 21:06:10,363 INFO     Training average positive_sample_loss at step 13300: 0.227908
2025-12-12 21:06:10,363 INFO     Training average negative_sample_loss at step 13300: 0.237100
2025-12-12 21:06:10,363 INFO     Training average loss at step 13300: 0.547489
2025-12-12 21:06:17,622 INFO     Training average regularization at step 13400: 0.315488
2025-12-12 21:06:17,623 INFO     Training average positive_sample_loss at step 13400: 0.225985
2025-12-12 21:06:17,623 INFO     Training average negative_sample_loss at step 13400: 0.236057
2025-12-12 21:06:17,623 INFO     Training average loss at step 13400: 0.546509
2025-12-12 21:06:24,886 INFO     Training average regularization at step 13500: 0.315948
2025-12-12 21:06:24,887 INFO     Training average positive_sample_loss at step 13500: 0.225601
2025-12-12 21:06:24,887 INFO     Training average negative_sample_loss at step 13500: 0.240905
2025-12-12 21:06:24,887 INFO     Training average loss at step 13500: 0.549200
2025-12-12 21:06:32,155 INFO     Training average regularization at step 13600: 0.316420
2025-12-12 21:06:32,155 INFO     Training average positive_sample_loss at step 13600: 0.221013
2025-12-12 21:06:32,155 INFO     Training average negative_sample_loss at step 13600: 0.234285
2025-12-12 21:06:32,155 INFO     Training average loss at step 13600: 0.544069
2025-12-12 21:06:39,525 INFO     Training average regularization at step 13700: 0.316910
2025-12-12 21:06:39,526 INFO     Training average positive_sample_loss at step 13700: 0.229920
2025-12-12 21:06:39,526 INFO     Training average negative_sample_loss at step 13700: 0.235106
2025-12-12 21:06:39,526 INFO     Training average loss at step 13700: 0.549423
2025-12-12 21:06:46,902 INFO     Training average regularization at step 13800: 0.317361
2025-12-12 21:06:46,903 INFO     Training average positive_sample_loss at step 13800: 0.228345
2025-12-12 21:06:46,903 INFO     Training average negative_sample_loss at step 13800: 0.238494
2025-12-12 21:06:46,903 INFO     Training average loss at step 13800: 0.550780
2025-12-12 21:06:54,150 INFO     Training average regularization at step 13900: 0.317809
2025-12-12 21:06:54,151 INFO     Training average positive_sample_loss at step 13900: 0.236541
2025-12-12 21:06:54,151 INFO     Training average negative_sample_loss at step 13900: 0.246257
2025-12-12 21:06:54,151 INFO     Training average loss at step 13900: 0.559209
2025-12-12 21:07:01,405 INFO     Training average regularization at step 14000: 0.318326
2025-12-12 21:07:01,406 INFO     Training average positive_sample_loss at step 14000: 0.231221
2025-12-12 21:07:01,406 INFO     Training average negative_sample_loss at step 14000: 0.235549
2025-12-12 21:07:01,406 INFO     Training average loss at step 14000: 0.551711
2025-12-12 21:07:08,685 INFO     Training average regularization at step 14100: 0.318771
2025-12-12 21:07:08,685 INFO     Training average positive_sample_loss at step 14100: 0.223715
2025-12-12 21:07:08,685 INFO     Training average negative_sample_loss at step 14100: 0.237219
2025-12-12 21:07:08,685 INFO     Training average loss at step 14100: 0.549238
2025-12-12 21:07:15,984 INFO     Training average regularization at step 14200: 0.319205
2025-12-12 21:07:15,984 INFO     Training average positive_sample_loss at step 14200: 0.233546
2025-12-12 21:07:15,984 INFO     Training average negative_sample_loss at step 14200: 0.237609
2025-12-12 21:07:15,984 INFO     Training average loss at step 14200: 0.554782
2025-12-12 21:07:23,239 INFO     Training average regularization at step 14300: 0.319652
2025-12-12 21:07:23,239 INFO     Training average positive_sample_loss at step 14300: 0.235212
2025-12-12 21:07:23,239 INFO     Training average negative_sample_loss at step 14300: 0.240571
2025-12-12 21:07:23,239 INFO     Training average loss at step 14300: 0.557543
2025-12-12 21:07:30,469 INFO     Training average regularization at step 14400: 0.320055
2025-12-12 21:07:30,470 INFO     Training average positive_sample_loss at step 14400: 0.234301
2025-12-12 21:07:30,470 INFO     Training average negative_sample_loss at step 14400: 0.239322
2025-12-12 21:07:30,470 INFO     Training average loss at step 14400: 0.556866
2025-12-12 21:07:37,743 INFO     Training average regularization at step 14500: 0.320502
2025-12-12 21:07:37,743 INFO     Training average positive_sample_loss at step 14500: 0.232718
2025-12-12 21:07:37,743 INFO     Training average negative_sample_loss at step 14500: 0.236334
2025-12-12 21:07:37,743 INFO     Training average loss at step 14500: 0.555028
2025-12-12 21:07:45,089 INFO     Training average regularization at step 14600: 0.320919
2025-12-12 21:07:45,090 INFO     Training average positive_sample_loss at step 14600: 0.233979
2025-12-12 21:07:45,090 INFO     Training average negative_sample_loss at step 14600: 0.237756
2025-12-12 21:07:45,090 INFO     Training average loss at step 14600: 0.556787
2025-12-12 21:07:52,331 INFO     Training average regularization at step 14700: 0.321336
2025-12-12 21:07:52,331 INFO     Training average positive_sample_loss at step 14700: 0.229576
2025-12-12 21:07:52,332 INFO     Training average negative_sample_loss at step 14700: 0.242316
2025-12-12 21:07:52,332 INFO     Training average loss at step 14700: 0.557282
2025-12-12 21:07:59,612 INFO     Training average regularization at step 14800: 0.321749
2025-12-12 21:07:59,612 INFO     Training average positive_sample_loss at step 14800: 0.238050
2025-12-12 21:07:59,612 INFO     Training average negative_sample_loss at step 14800: 0.237426
2025-12-12 21:07:59,612 INFO     Training average loss at step 14800: 0.559487
2025-12-12 21:08:06,847 INFO     Training average regularization at step 14900: 0.322175
2025-12-12 21:08:06,847 INFO     Training average positive_sample_loss at step 14900: 0.236560
2025-12-12 21:08:06,848 INFO     Training average negative_sample_loss at step 14900: 0.240937
2025-12-12 21:08:06,848 INFO     Training average loss at step 14900: 0.560923
2025-12-12 21:08:14,060 INFO     Training average regularization at step 15000: 0.322591
2025-12-12 21:08:14,060 INFO     Training average positive_sample_loss at step 15000: 0.238975
2025-12-12 21:08:14,060 INFO     Training average negative_sample_loss at step 15000: 0.242082
2025-12-12 21:08:14,060 INFO     Training average loss at step 15000: 0.563119
2025-12-12 21:08:21,319 INFO     Training average regularization at step 15100: 0.323059
2025-12-12 21:08:21,319 INFO     Training average positive_sample_loss at step 15100: 0.232956
2025-12-12 21:08:21,320 INFO     Training average negative_sample_loss at step 15100: 0.238952
2025-12-12 21:08:21,320 INFO     Training average loss at step 15100: 0.559013
2025-12-12 21:08:28,569 INFO     Training average regularization at step 15200: 0.323471
2025-12-12 21:08:28,569 INFO     Training average positive_sample_loss at step 15200: 0.231680
2025-12-12 21:08:28,569 INFO     Training average negative_sample_loss at step 15200: 0.231140
2025-12-12 21:08:28,569 INFO     Training average loss at step 15200: 0.554880
2025-12-12 21:08:35,799 INFO     Training average regularization at step 15300: 0.323834
2025-12-12 21:08:35,800 INFO     Training average positive_sample_loss at step 15300: 0.228353
2025-12-12 21:08:35,800 INFO     Training average negative_sample_loss at step 15300: 0.241126
2025-12-12 21:08:35,800 INFO     Training average loss at step 15300: 0.558574
2025-12-12 21:08:43,148 INFO     Training average regularization at step 15400: 0.324209
2025-12-12 21:08:43,148 INFO     Training average positive_sample_loss at step 15400: 0.244748
2025-12-12 21:08:43,148 INFO     Training average negative_sample_loss at step 15400: 0.237481
2025-12-12 21:08:43,148 INFO     Training average loss at step 15400: 0.565323
2025-12-12 21:08:50,444 INFO     Training average regularization at step 15500: 0.324552
2025-12-12 21:08:50,444 INFO     Training average positive_sample_loss at step 15500: 0.230088
2025-12-12 21:08:50,444 INFO     Training average negative_sample_loss at step 15500: 0.232812
2025-12-12 21:08:50,444 INFO     Training average loss at step 15500: 0.556003
2025-12-12 21:08:57,704 INFO     Training average regularization at step 15600: 0.324917
2025-12-12 21:08:57,704 INFO     Training average positive_sample_loss at step 15600: 0.230385
2025-12-12 21:08:57,704 INFO     Training average negative_sample_loss at step 15600: 0.242093
2025-12-12 21:08:57,704 INFO     Training average loss at step 15600: 0.561156
2025-12-12 21:09:04,936 INFO     Training average regularization at step 15700: 0.325285
2025-12-12 21:09:04,936 INFO     Training average positive_sample_loss at step 15700: 0.240333
2025-12-12 21:09:04,936 INFO     Training average negative_sample_loss at step 15700: 0.233979
2025-12-12 21:09:04,936 INFO     Training average loss at step 15700: 0.562441
2025-12-12 21:09:12,231 INFO     Training average regularization at step 15800: 0.325656
2025-12-12 21:09:12,231 INFO     Training average positive_sample_loss at step 15800: 0.233871
2025-12-12 21:09:12,231 INFO     Training average negative_sample_loss at step 15800: 0.240312
2025-12-12 21:09:12,231 INFO     Training average loss at step 15800: 0.562747
2025-12-12 21:09:19,500 INFO     Training average regularization at step 15900: 0.325951
2025-12-12 21:09:19,500 INFO     Training average positive_sample_loss at step 15900: 0.233983
2025-12-12 21:09:19,500 INFO     Training average negative_sample_loss at step 15900: 0.238914
2025-12-12 21:09:19,500 INFO     Training average loss at step 15900: 0.562399
2025-12-12 21:09:34,725 INFO     Training average regularization at step 16000: 0.326282
2025-12-12 21:09:34,726 INFO     Training average positive_sample_loss at step 16000: 0.234788
2025-12-12 21:09:34,726 INFO     Training average negative_sample_loss at step 16000: 0.237346
2025-12-12 21:09:34,726 INFO     Training average loss at step 16000: 0.562349
2025-12-12 21:09:42,173 INFO     Training average regularization at step 16100: 0.326655
2025-12-12 21:09:42,173 INFO     Training average positive_sample_loss at step 16100: 0.236147
2025-12-12 21:09:42,173 INFO     Training average negative_sample_loss at step 16100: 0.235571
2025-12-12 21:09:42,173 INFO     Training average loss at step 16100: 0.562514
2025-12-12 21:09:49,469 INFO     Training average regularization at step 16200: 0.326984
2025-12-12 21:09:49,470 INFO     Training average positive_sample_loss at step 16200: 0.224453
2025-12-12 21:09:49,470 INFO     Training average negative_sample_loss at step 16200: 0.233207
2025-12-12 21:09:49,470 INFO     Training average loss at step 16200: 0.555815
2025-12-12 21:09:56,749 INFO     Training average regularization at step 16300: 0.327279
2025-12-12 21:09:56,750 INFO     Training average positive_sample_loss at step 16300: 0.235048
2025-12-12 21:09:56,750 INFO     Training average negative_sample_loss at step 16300: 0.232033
2025-12-12 21:09:56,750 INFO     Training average loss at step 16300: 0.560819
2025-12-12 21:10:03,998 INFO     Training average regularization at step 16400: 0.327644
2025-12-12 21:10:03,999 INFO     Training average positive_sample_loss at step 16400: 0.236390
2025-12-12 21:10:03,999 INFO     Training average negative_sample_loss at step 16400: 0.241135
2025-12-12 21:10:03,999 INFO     Training average loss at step 16400: 0.566407
2025-12-12 21:10:11,230 INFO     Training average regularization at step 16500: 0.327985
2025-12-12 21:10:11,233 INFO     Training average positive_sample_loss at step 16500: 0.235522
2025-12-12 21:10:11,233 INFO     Training average negative_sample_loss at step 16500: 0.236075
2025-12-12 21:10:11,233 INFO     Training average loss at step 16500: 0.563783
2025-12-12 21:10:18,477 INFO     Training average regularization at step 16600: 0.328316
2025-12-12 21:10:18,477 INFO     Training average positive_sample_loss at step 16600: 0.224551
2025-12-12 21:10:18,477 INFO     Training average negative_sample_loss at step 16600: 0.230507
2025-12-12 21:10:18,477 INFO     Training average loss at step 16600: 0.555845
2025-12-12 21:10:25,716 INFO     Training average regularization at step 16700: 0.328530
2025-12-12 21:10:25,717 INFO     Training average positive_sample_loss at step 16700: 0.223560
2025-12-12 21:10:25,717 INFO     Training average negative_sample_loss at step 16700: 0.231090
2025-12-12 21:10:25,717 INFO     Training average loss at step 16700: 0.555855
2025-12-12 21:10:32,931 INFO     Training average regularization at step 16800: 0.328755
2025-12-12 21:10:32,931 INFO     Training average positive_sample_loss at step 16800: 0.230195
2025-12-12 21:10:32,931 INFO     Training average negative_sample_loss at step 16800: 0.233778
2025-12-12 21:10:32,931 INFO     Training average loss at step 16800: 0.560742
2025-12-12 21:10:40,232 INFO     Training average regularization at step 16900: 0.329029
2025-12-12 21:10:40,233 INFO     Training average positive_sample_loss at step 16900: 0.224574
2025-12-12 21:10:40,233 INFO     Training average negative_sample_loss at step 16900: 0.228246
2025-12-12 21:10:40,233 INFO     Training average loss at step 16900: 0.555439
2025-12-12 21:10:47,602 INFO     Training average regularization at step 17000: 0.329243
2025-12-12 21:10:47,602 INFO     Training average positive_sample_loss at step 17000: 0.231409
2025-12-12 21:10:47,602 INFO     Training average negative_sample_loss at step 17000: 0.237077
2025-12-12 21:10:47,602 INFO     Training average loss at step 17000: 0.563486
2025-12-12 21:10:54,889 INFO     Training average regularization at step 17100: 0.329505
2025-12-12 21:10:54,890 INFO     Training average positive_sample_loss at step 17100: 0.230510
2025-12-12 21:10:54,890 INFO     Training average negative_sample_loss at step 17100: 0.234290
2025-12-12 21:10:54,890 INFO     Training average loss at step 17100: 0.561905
2025-12-12 21:11:02,194 INFO     Training average regularization at step 17200: 0.329755
2025-12-12 21:11:02,194 INFO     Training average positive_sample_loss at step 17200: 0.225600
2025-12-12 21:11:02,194 INFO     Training average negative_sample_loss at step 17200: 0.232727
2025-12-12 21:11:02,194 INFO     Training average loss at step 17200: 0.558918
2025-12-12 21:11:09,492 INFO     Training average regularization at step 17300: 0.329970
2025-12-12 21:11:09,492 INFO     Training average positive_sample_loss at step 17300: 0.227557
2025-12-12 21:11:09,492 INFO     Training average negative_sample_loss at step 17300: 0.226210
2025-12-12 21:11:09,492 INFO     Training average loss at step 17300: 0.556853
2025-12-12 21:11:16,795 INFO     Training average regularization at step 17400: 0.330164
2025-12-12 21:11:16,796 INFO     Training average positive_sample_loss at step 17400: 0.226393
2025-12-12 21:11:16,796 INFO     Training average negative_sample_loss at step 17400: 0.228864
2025-12-12 21:11:16,796 INFO     Training average loss at step 17400: 0.557792
2025-12-12 21:11:24,107 INFO     Training average regularization at step 17500: 0.330396
2025-12-12 21:11:24,107 INFO     Training average positive_sample_loss at step 17500: 0.223857
2025-12-12 21:11:24,107 INFO     Training average negative_sample_loss at step 17500: 0.230460
2025-12-12 21:11:24,107 INFO     Training average loss at step 17500: 0.557555
2025-12-12 21:11:31,381 INFO     Training average regularization at step 17600: 0.330609
2025-12-12 21:11:31,381 INFO     Training average positive_sample_loss at step 17600: 0.223603
2025-12-12 21:11:31,381 INFO     Training average negative_sample_loss at step 17600: 0.229241
2025-12-12 21:11:31,381 INFO     Training average loss at step 17600: 0.557031
2025-12-12 21:11:38,702 INFO     Training average regularization at step 17700: 0.330795
2025-12-12 21:11:38,703 INFO     Training average positive_sample_loss at step 17700: 0.229809
2025-12-12 21:11:38,703 INFO     Training average negative_sample_loss at step 17700: 0.226237
2025-12-12 21:11:38,703 INFO     Training average loss at step 17700: 0.558819
2025-12-12 21:11:46,172 INFO     Training average regularization at step 17800: 0.330963
2025-12-12 21:11:46,173 INFO     Training average positive_sample_loss at step 17800: 0.224125
2025-12-12 21:11:46,173 INFO     Training average negative_sample_loss at step 17800: 0.222017
2025-12-12 21:11:46,173 INFO     Training average loss at step 17800: 0.554034
2025-12-12 21:11:53,500 INFO     Training average regularization at step 17900: 0.331173
2025-12-12 21:11:53,500 INFO     Training average positive_sample_loss at step 17900: 0.222009
2025-12-12 21:11:53,500 INFO     Training average negative_sample_loss at step 17900: 0.229306
2025-12-12 21:11:53,500 INFO     Training average loss at step 17900: 0.556830
2025-12-12 21:12:00,750 INFO     Training average regularization at step 18000: 0.331404
2025-12-12 21:12:00,751 INFO     Training average positive_sample_loss at step 18000: 0.220543
2025-12-12 21:12:00,751 INFO     Training average negative_sample_loss at step 18000: 0.222608
2025-12-12 21:12:00,751 INFO     Training average loss at step 18000: 0.552980
2025-12-12 21:12:07,960 INFO     Training average regularization at step 18100: 0.331558
2025-12-12 21:12:07,960 INFO     Training average positive_sample_loss at step 18100: 0.222108
2025-12-12 21:12:07,960 INFO     Training average negative_sample_loss at step 18100: 0.228334
2025-12-12 21:12:07,960 INFO     Training average loss at step 18100: 0.556778
2025-12-12 21:12:15,162 INFO     Training average regularization at step 18200: 0.331742
2025-12-12 21:12:15,163 INFO     Training average positive_sample_loss at step 18200: 0.213743
2025-12-12 21:12:15,163 INFO     Training average negative_sample_loss at step 18200: 0.216358
2025-12-12 21:12:15,163 INFO     Training average loss at step 18200: 0.546793
2025-12-12 21:12:22,435 INFO     Training average regularization at step 18300: 0.331838
2025-12-12 21:12:22,435 INFO     Training average positive_sample_loss at step 18300: 0.225485
2025-12-12 21:12:22,435 INFO     Training average negative_sample_loss at step 18300: 0.229953
2025-12-12 21:12:22,435 INFO     Training average loss at step 18300: 0.559557
2025-12-12 21:12:29,656 INFO     Training average regularization at step 18400: 0.332010
2025-12-12 21:12:29,656 INFO     Training average positive_sample_loss at step 18400: 0.222233
2025-12-12 21:12:29,656 INFO     Training average negative_sample_loss at step 18400: 0.218143
2025-12-12 21:12:29,656 INFO     Training average loss at step 18400: 0.552198
2025-12-12 21:12:36,937 INFO     Training average regularization at step 18500: 0.332178
2025-12-12 21:12:36,938 INFO     Training average positive_sample_loss at step 18500: 0.222637
2025-12-12 21:12:36,938 INFO     Training average negative_sample_loss at step 18500: 0.223080
2025-12-12 21:12:36,938 INFO     Training average loss at step 18500: 0.555037
2025-12-12 21:12:44,334 INFO     Training average regularization at step 18600: 0.332323
2025-12-12 21:12:44,334 INFO     Training average positive_sample_loss at step 18600: 0.209418
2025-12-12 21:12:44,334 INFO     Training average negative_sample_loss at step 18600: 0.222719
2025-12-12 21:12:44,334 INFO     Training average loss at step 18600: 0.548392
2025-12-12 21:12:51,585 INFO     Training average regularization at step 18700: 0.332425
2025-12-12 21:12:51,586 INFO     Training average positive_sample_loss at step 18700: 0.218257
2025-12-12 21:12:51,586 INFO     Training average negative_sample_loss at step 18700: 0.227386
2025-12-12 21:12:51,586 INFO     Training average loss at step 18700: 0.555247
2025-12-12 21:12:58,812 INFO     Training average regularization at step 18800: 0.332569
2025-12-12 21:12:58,812 INFO     Training average positive_sample_loss at step 18800: 0.218470
2025-12-12 21:12:58,812 INFO     Training average negative_sample_loss at step 18800: 0.222264
2025-12-12 21:12:58,812 INFO     Training average loss at step 18800: 0.552936
2025-12-12 21:13:06,055 INFO     Training average regularization at step 18900: 0.332720
2025-12-12 21:13:06,058 INFO     Training average positive_sample_loss at step 18900: 0.224472
2025-12-12 21:13:06,058 INFO     Training average negative_sample_loss at step 18900: 0.216700
2025-12-12 21:13:06,058 INFO     Training average loss at step 18900: 0.553306
2025-12-12 21:13:13,264 INFO     Training average regularization at step 19000: 0.332842
2025-12-12 21:13:13,264 INFO     Training average positive_sample_loss at step 19000: 0.220984
2025-12-12 21:13:13,264 INFO     Training average negative_sample_loss at step 19000: 0.223364
2025-12-12 21:13:13,264 INFO     Training average loss at step 19000: 0.555016
2025-12-12 21:13:20,476 INFO     Training average regularization at step 19100: 0.332995
2025-12-12 21:13:20,477 INFO     Training average positive_sample_loss at step 19100: 0.221969
2025-12-12 21:13:20,477 INFO     Training average negative_sample_loss at step 19100: 0.215297
2025-12-12 21:13:20,477 INFO     Training average loss at step 19100: 0.551628
2025-12-12 21:13:27,745 INFO     Training average regularization at step 19200: 0.333135
2025-12-12 21:13:27,745 INFO     Training average positive_sample_loss at step 19200: 0.218970
2025-12-12 21:13:27,745 INFO     Training average negative_sample_loss at step 19200: 0.218340
2025-12-12 21:13:27,745 INFO     Training average loss at step 19200: 0.551790
2025-12-12 21:13:35,042 INFO     Training average regularization at step 19300: 0.333230
2025-12-12 21:13:35,042 INFO     Training average positive_sample_loss at step 19300: 0.213648
2025-12-12 21:13:35,042 INFO     Training average negative_sample_loss at step 19300: 0.221872
2025-12-12 21:13:35,042 INFO     Training average loss at step 19300: 0.550990
2025-12-12 21:13:42,492 INFO     Training average regularization at step 19400: 0.333307
2025-12-12 21:13:42,492 INFO     Training average positive_sample_loss at step 19400: 0.222869
2025-12-12 21:13:42,492 INFO     Training average negative_sample_loss at step 19400: 0.217431
2025-12-12 21:13:42,492 INFO     Training average loss at step 19400: 0.553457
2025-12-12 21:13:49,783 INFO     Training average regularization at step 19500: 0.333458
2025-12-12 21:13:49,783 INFO     Training average positive_sample_loss at step 19500: 0.220627
2025-12-12 21:13:49,783 INFO     Training average negative_sample_loss at step 19500: 0.216163
2025-12-12 21:13:49,783 INFO     Training average loss at step 19500: 0.551853
2025-12-12 21:13:57,047 INFO     Training average regularization at step 19600: 0.333580
2025-12-12 21:13:57,048 INFO     Training average positive_sample_loss at step 19600: 0.216210
2025-12-12 21:13:57,048 INFO     Training average negative_sample_loss at step 19600: 0.212919
2025-12-12 21:13:57,048 INFO     Training average loss at step 19600: 0.548145
2025-12-12 21:14:04,292 INFO     Training average regularization at step 19700: 0.333638
2025-12-12 21:14:04,292 INFO     Training average positive_sample_loss at step 19700: 0.211119
2025-12-12 21:14:04,292 INFO     Training average negative_sample_loss at step 19700: 0.208133
2025-12-12 21:14:04,292 INFO     Training average loss at step 19700: 0.543264
2025-12-12 21:14:11,550 INFO     Training average regularization at step 19800: 0.333644
2025-12-12 21:14:11,551 INFO     Training average positive_sample_loss at step 19800: 0.214278
2025-12-12 21:14:11,551 INFO     Training average negative_sample_loss at step 19800: 0.221236
2025-12-12 21:14:11,551 INFO     Training average loss at step 19800: 0.551401
2025-12-12 21:14:18,866 INFO     Training average regularization at step 19900: 0.333739
2025-12-12 21:14:18,866 INFO     Training average positive_sample_loss at step 19900: 0.221262
2025-12-12 21:14:18,866 INFO     Training average negative_sample_loss at step 19900: 0.217423
2025-12-12 21:14:18,866 INFO     Training average loss at step 19900: 0.553082
2025-12-12 21:14:26,122 INFO     Change learning_rate to 0.000259 at step 20000
2025-12-12 21:14:31,112 INFO     Training average regularization at step 20000: 0.333872
2025-12-12 21:14:31,113 INFO     Training average positive_sample_loss at step 20000: 0.208367
2025-12-12 21:14:31,113 INFO     Training average negative_sample_loss at step 20000: 0.210480
2025-12-12 21:14:31,113 INFO     Training average loss at step 20000: 0.543296
2025-12-12 21:14:31,114 INFO     Evaluating on Valid Dataset...
2025-12-12 21:14:32,847 INFO     Evaluating the model... (0/5000)
2025-12-12 21:14:40,238 INFO     Evaluating the model... (100/5000)
2025-12-12 21:14:47,396 INFO     Evaluating the model... (200/5000)
2025-12-12 21:14:54,527 INFO     Evaluating the model... (300/5000)
2025-12-12 21:15:01,698 INFO     Evaluating the model... (400/5000)
2025-12-12 21:15:08,788 INFO     Evaluating the model... (500/5000)
2025-12-12 21:15:15,891 INFO     Evaluating the model... (600/5000)
2025-12-12 21:15:23,152 INFO     Evaluating the model... (700/5000)
2025-12-12 21:15:30,277 INFO     Evaluating the model... (800/5000)
2025-12-12 21:15:37,396 INFO     Evaluating the model... (900/5000)
2025-12-12 21:15:44,629 INFO     Evaluating the model... (1000/5000)
2025-12-12 21:15:51,786 INFO     Evaluating the model... (1100/5000)
2025-12-12 21:16:00,725 INFO     Evaluating the model... (1200/5000)
2025-12-12 21:16:07,812 INFO     Evaluating the model... (1300/5000)
2025-12-12 21:16:14,897 INFO     Evaluating the model... (1400/5000)
2025-12-12 21:16:21,961 INFO     Evaluating the model... (1500/5000)
2025-12-12 21:16:29,111 INFO     Evaluating the model... (1600/5000)
2025-12-12 21:16:36,222 INFO     Evaluating the model... (1700/5000)
2025-12-12 21:16:43,368 INFO     Evaluating the model... (1800/5000)
2025-12-12 21:16:50,513 INFO     Evaluating the model... (1900/5000)
2025-12-12 21:16:57,690 INFO     Evaluating the model... (2000/5000)
2025-12-12 21:17:04,887 INFO     Evaluating the model... (2100/5000)
2025-12-12 21:17:12,086 INFO     Evaluating the model... (2200/5000)
2025-12-12 21:17:19,172 INFO     Evaluating the model... (2300/5000)
2025-12-12 21:17:26,337 INFO     Evaluating the model... (2400/5000)
2025-12-12 21:17:34,270 INFO     Evaluating the model... (2500/5000)
2025-12-12 21:17:41,536 INFO     Evaluating the model... (2600/5000)
2025-12-12 21:17:48,656 INFO     Evaluating the model... (2700/5000)
2025-12-12 21:17:55,827 INFO     Evaluating the model... (2800/5000)
2025-12-12 21:18:02,956 INFO     Evaluating the model... (2900/5000)
2025-12-12 21:18:10,064 INFO     Evaluating the model... (3000/5000)
2025-12-12 21:18:17,161 INFO     Evaluating the model... (3100/5000)
2025-12-12 21:18:24,247 INFO     Evaluating the model... (3200/5000)
2025-12-12 21:18:31,344 INFO     Evaluating the model... (3300/5000)
2025-12-12 21:18:38,460 INFO     Evaluating the model... (3400/5000)
2025-12-12 21:18:45,652 INFO     Evaluating the model... (3500/5000)
2025-12-12 21:18:54,356 INFO     Evaluating the model... (3600/5000)
2025-12-12 21:19:01,439 INFO     Evaluating the model... (3700/5000)
2025-12-12 21:19:08,534 INFO     Evaluating the model... (3800/5000)
2025-12-12 21:19:15,644 INFO     Evaluating the model... (3900/5000)
2025-12-12 21:19:22,748 INFO     Evaluating the model... (4000/5000)
2025-12-12 21:19:29,866 INFO     Evaluating the model... (4100/5000)
2025-12-12 21:19:37,059 INFO     Evaluating the model... (4200/5000)
2025-12-12 21:19:44,241 INFO     Evaluating the model... (4300/5000)
2025-12-12 21:19:51,331 INFO     Evaluating the model... (4400/5000)
2025-12-12 21:19:58,431 INFO     Evaluating the model... (4500/5000)
2025-12-12 21:20:05,512 INFO     Evaluating the model... (4600/5000)
2025-12-12 21:20:12,693 INFO     Evaluating the model... (4700/5000)
2025-12-12 21:20:19,866 INFO     Evaluating the model... (4800/5000)
2025-12-12 21:20:26,964 INFO     Evaluating the model... (4900/5000)
2025-12-12 21:20:34,520 INFO     Valid MRR at step 20000: 0.345315
2025-12-12 21:20:34,520 INFO     Valid MR at step 20000: 7483.400900
2025-12-12 21:20:34,520 INFO     Valid HITS@1 at step 20000: 0.256500
2025-12-12 21:20:34,520 INFO     Valid HITS@3 at step 20000: 0.389900
2025-12-12 21:20:34,520 INFO     Valid HITS@10 at step 20000: 0.520300
2025-12-12 21:20:38,413 INFO     Evaluating on Test Dataset...
2025-12-12 21:20:39,952 INFO     Evaluating the model... (0/5000)
2025-12-12 21:20:47,280 INFO     Evaluating the model... (100/5000)
2025-12-12 21:20:54,375 INFO     Evaluating the model... (200/5000)
2025-12-12 21:21:01,574 INFO     Evaluating the model... (300/5000)
2025-12-12 21:21:08,713 INFO     Evaluating the model... (400/5000)
2025-12-12 21:21:15,795 INFO     Evaluating the model... (500/5000)
2025-12-12 21:21:22,882 INFO     Evaluating the model... (600/5000)
2025-12-12 21:21:29,930 INFO     Evaluating the model... (700/5000)
2025-12-12 21:21:37,009 INFO     Evaluating the model... (800/5000)
2025-12-12 21:21:44,138 INFO     Evaluating the model... (900/5000)
2025-12-12 21:21:51,186 INFO     Evaluating the model... (1000/5000)
2025-12-12 21:22:00,802 INFO     Evaluating the model... (1100/5000)
2025-12-12 21:22:07,870 INFO     Evaluating the model... (1200/5000)
2025-12-12 21:22:14,946 INFO     Evaluating the model... (1300/5000)
2025-12-12 21:22:22,003 INFO     Evaluating the model... (1400/5000)
2025-12-12 21:22:29,051 INFO     Evaluating the model... (1500/5000)
2025-12-12 21:22:36,125 INFO     Evaluating the model... (1600/5000)
2025-12-12 21:22:43,297 INFO     Evaluating the model... (1700/5000)
2025-12-12 21:22:50,405 INFO     Evaluating the model... (1800/5000)
2025-12-12 21:22:57,541 INFO     Evaluating the model... (1900/5000)
2025-12-12 21:23:04,615 INFO     Evaluating the model... (2000/5000)
2025-12-12 21:23:11,669 INFO     Evaluating the model... (2100/5000)
2025-12-12 21:23:18,793 INFO     Evaluating the model... (2200/5000)
2025-12-12 21:23:25,867 INFO     Evaluating the model... (2300/5000)
2025-12-12 21:23:32,935 INFO     Evaluating the model... (2400/5000)
2025-12-12 21:23:40,907 INFO     Evaluating the model... (2500/5000)
2025-12-12 21:23:48,163 INFO     Evaluating the model... (2600/5000)
2025-12-12 21:23:55,290 INFO     Evaluating the model... (2700/5000)
2025-12-12 21:24:02,407 INFO     Evaluating the model... (2800/5000)
2025-12-12 21:24:09,547 INFO     Evaluating the model... (2900/5000)
2025-12-12 21:24:16,667 INFO     Evaluating the model... (3000/5000)
2025-12-12 21:24:23,853 INFO     Evaluating the model... (3100/5000)
2025-12-12 21:24:31,013 INFO     Evaluating the model... (3200/5000)
2025-12-12 21:24:38,185 INFO     Evaluating the model... (3300/5000)
2025-12-12 21:24:45,477 INFO     Evaluating the model... (3400/5000)
2025-12-12 21:24:55,114 INFO     Evaluating the model... (3500/5000)
2025-12-12 21:25:02,231 INFO     Evaluating the model... (3600/5000)
2025-12-12 21:25:09,372 INFO     Evaluating the model... (3700/5000)
2025-12-12 21:25:16,488 INFO     Evaluating the model... (3800/5000)
2025-12-12 21:25:23,609 INFO     Evaluating the model... (3900/5000)
2025-12-12 21:25:30,773 INFO     Evaluating the model... (4000/5000)
2025-12-12 21:25:37,893 INFO     Evaluating the model... (4100/5000)
2025-12-12 21:25:45,072 INFO     Evaluating the model... (4200/5000)
2025-12-12 21:25:52,175 INFO     Evaluating the model... (4300/5000)
2025-12-12 21:25:59,316 INFO     Evaluating the model... (4400/5000)
2025-12-12 21:26:06,453 INFO     Evaluating the model... (4500/5000)
2025-12-12 21:26:13,556 INFO     Evaluating the model... (4600/5000)
2025-12-12 21:26:20,700 INFO     Evaluating the model... (4700/5000)
2025-12-12 21:26:27,839 INFO     Evaluating the model... (4800/5000)
2025-12-12 21:26:34,957 INFO     Evaluating the model... (4900/5000)
2025-12-12 21:26:42,360 INFO     Test MRR at step 20000: 0.344655
2025-12-12 21:26:42,361 INFO     Test MR at step 20000: 8288.307300
2025-12-12 21:26:42,361 INFO     Test HITS@1 at step 20000: 0.257300
2025-12-12 21:26:42,361 INFO     Test HITS@3 at step 20000: 0.387400
2025-12-12 21:26:42,361 INFO     Test HITS@10 at step 20000: 0.514700
2025-12-12 21:26:49,805 INFO     Training average regularization at step 20100: 0.324016
2025-12-12 21:26:49,806 INFO     Training average positive_sample_loss at step 20100: 0.224255
2025-12-12 21:26:49,806 INFO     Training average negative_sample_loss at step 20100: 0.203067
2025-12-12 21:26:49,806 INFO     Training average loss at step 20100: 0.537677
2025-12-12 21:26:57,181 INFO     Training average regularization at step 20200: 0.312618
2025-12-12 21:26:57,182 INFO     Training average positive_sample_loss at step 20200: 0.231473
2025-12-12 21:26:57,182 INFO     Training average negative_sample_loss at step 20200: 0.189723
2025-12-12 21:26:57,182 INFO     Training average loss at step 20200: 0.523216
2025-12-12 21:27:04,543 INFO     Training average regularization at step 20300: 0.305757
2025-12-12 21:27:04,543 INFO     Training average positive_sample_loss at step 20300: 0.243958
2025-12-12 21:27:04,543 INFO     Training average negative_sample_loss at step 20300: 0.187463
2025-12-12 21:27:04,544 INFO     Training average loss at step 20300: 0.521467
2025-12-12 21:27:11,867 INFO     Training average regularization at step 20400: 0.300796
2025-12-12 21:27:11,868 INFO     Training average positive_sample_loss at step 20400: 0.240943
2025-12-12 21:27:11,868 INFO     Training average negative_sample_loss at step 20400: 0.182219
2025-12-12 21:27:11,868 INFO     Training average loss at step 20400: 0.512377
2025-12-12 21:27:19,164 INFO     Training average regularization at step 20500: 0.296936
2025-12-12 21:27:19,164 INFO     Training average positive_sample_loss at step 20500: 0.240793
2025-12-12 21:27:19,164 INFO     Training average negative_sample_loss at step 20500: 0.188600
2025-12-12 21:27:19,165 INFO     Training average loss at step 20500: 0.511632
2025-12-12 21:27:26,485 INFO     Training average regularization at step 20600: 0.293816
2025-12-12 21:27:26,485 INFO     Training average positive_sample_loss at step 20600: 0.243519
2025-12-12 21:27:26,486 INFO     Training average negative_sample_loss at step 20600: 0.198570
2025-12-12 21:27:26,486 INFO     Training average loss at step 20600: 0.514860
2025-12-12 21:27:33,769 INFO     Training average regularization at step 20700: 0.291231
2025-12-12 21:27:33,770 INFO     Training average positive_sample_loss at step 20700: 0.248508
2025-12-12 21:27:33,770 INFO     Training average negative_sample_loss at step 20700: 0.192810
2025-12-12 21:27:33,770 INFO     Training average loss at step 20700: 0.511890
2025-12-12 21:27:41,128 INFO     Training average regularization at step 20800: 0.289049
2025-12-12 21:27:41,129 INFO     Training average positive_sample_loss at step 20800: 0.239593
2025-12-12 21:27:41,129 INFO     Training average negative_sample_loss at step 20800: 0.196344
2025-12-12 21:27:41,129 INFO     Training average loss at step 20800: 0.507017
2025-12-12 21:27:48,466 INFO     Training average regularization at step 20900: 0.287164
2025-12-12 21:27:48,466 INFO     Training average positive_sample_loss at step 20900: 0.229746
2025-12-12 21:27:48,466 INFO     Training average negative_sample_loss at step 20900: 0.196819
2025-12-12 21:27:48,466 INFO     Training average loss at step 20900: 0.500447
2025-12-12 21:27:55,790 INFO     Training average regularization at step 21000: 0.285515
2025-12-12 21:27:55,791 INFO     Training average positive_sample_loss at step 21000: 0.239023
2025-12-12 21:27:55,791 INFO     Training average negative_sample_loss at step 21000: 0.189210
2025-12-12 21:27:55,791 INFO     Training average loss at step 21000: 0.499631
2025-12-12 21:28:03,144 INFO     Training average regularization at step 21100: 0.284055
2025-12-12 21:28:03,144 INFO     Training average positive_sample_loss at step 21100: 0.237146
2025-12-12 21:28:03,144 INFO     Training average negative_sample_loss at step 21100: 0.192360
2025-12-12 21:28:03,144 INFO     Training average loss at step 21100: 0.498808
2025-12-12 21:28:10,505 INFO     Training average regularization at step 21200: 0.282749
2025-12-12 21:28:10,505 INFO     Training average positive_sample_loss at step 21200: 0.227074
2025-12-12 21:28:10,505 INFO     Training average negative_sample_loss at step 21200: 0.193172
2025-12-12 21:28:10,505 INFO     Training average loss at step 21200: 0.492872
2025-12-12 21:28:17,830 INFO     Training average regularization at step 21300: 0.281568
2025-12-12 21:28:17,830 INFO     Training average positive_sample_loss at step 21300: 0.227188
2025-12-12 21:28:17,830 INFO     Training average negative_sample_loss at step 21300: 0.196286
2025-12-12 21:28:17,830 INFO     Training average loss at step 21300: 0.493305
2025-12-12 21:28:25,144 INFO     Training average regularization at step 21400: 0.280495
2025-12-12 21:28:25,145 INFO     Training average positive_sample_loss at step 21400: 0.232011
2025-12-12 21:28:25,145 INFO     Training average negative_sample_loss at step 21400: 0.187879
2025-12-12 21:28:25,145 INFO     Training average loss at step 21400: 0.490441
2025-12-12 21:28:32,469 INFO     Training average regularization at step 21500: 0.279511
2025-12-12 21:28:32,470 INFO     Training average positive_sample_loss at step 21500: 0.218040
2025-12-12 21:28:32,470 INFO     Training average negative_sample_loss at step 21500: 0.193602
2025-12-12 21:28:32,470 INFO     Training average loss at step 21500: 0.485332
2025-12-12 21:28:41,528 INFO     Training average regularization at step 21600: 0.278601
2025-12-12 21:28:41,529 INFO     Training average positive_sample_loss at step 21600: 0.217893
2025-12-12 21:28:41,529 INFO     Training average negative_sample_loss at step 21600: 0.192536
2025-12-12 21:28:41,529 INFO     Training average loss at step 21600: 0.483815
2025-12-12 21:28:48,937 INFO     Training average regularization at step 21700: 0.277746
2025-12-12 21:28:48,946 INFO     Training average positive_sample_loss at step 21700: 0.168286
2025-12-12 21:28:48,946 INFO     Training average negative_sample_loss at step 21700: 0.175837
2025-12-12 21:28:48,946 INFO     Training average loss at step 21700: 0.449808
2025-12-12 21:28:56,208 INFO     Training average regularization at step 21800: 0.276935
2025-12-12 21:28:56,208 INFO     Training average positive_sample_loss at step 21800: 0.175417
2025-12-12 21:28:56,208 INFO     Training average negative_sample_loss at step 21800: 0.172921
2025-12-12 21:28:56,208 INFO     Training average loss at step 21800: 0.451104
2025-12-12 21:29:03,519 INFO     Training average regularization at step 21900: 0.276163
2025-12-12 21:29:03,520 INFO     Training average positive_sample_loss at step 21900: 0.179066
2025-12-12 21:29:03,520 INFO     Training average negative_sample_loss at step 21900: 0.165904
2025-12-12 21:29:03,520 INFO     Training average loss at step 21900: 0.448648
2025-12-12 21:29:10,797 INFO     Training average regularization at step 22000: 0.275430
2025-12-12 21:29:10,798 INFO     Training average positive_sample_loss at step 22000: 0.174836
2025-12-12 21:29:10,798 INFO     Training average negative_sample_loss at step 22000: 0.165663
2025-12-12 21:29:10,798 INFO     Training average loss at step 22000: 0.445680
2025-12-12 21:29:18,064 INFO     Training average regularization at step 22100: 0.274734
2025-12-12 21:29:18,064 INFO     Training average positive_sample_loss at step 22100: 0.182664
2025-12-12 21:29:18,064 INFO     Training average negative_sample_loss at step 22100: 0.164479
2025-12-12 21:29:18,064 INFO     Training average loss at step 22100: 0.448305
2025-12-12 21:29:25,357 INFO     Training average regularization at step 22200: 0.274067
2025-12-12 21:29:25,357 INFO     Training average positive_sample_loss at step 22200: 0.177449
2025-12-12 21:29:25,357 INFO     Training average negative_sample_loss at step 22200: 0.162199
2025-12-12 21:29:25,357 INFO     Training average loss at step 22200: 0.443892
2025-12-12 21:29:32,600 INFO     Training average regularization at step 22300: 0.273427
2025-12-12 21:29:32,601 INFO     Training average positive_sample_loss at step 22300: 0.184200
2025-12-12 21:29:32,601 INFO     Training average negative_sample_loss at step 22300: 0.158464
2025-12-12 21:29:32,601 INFO     Training average loss at step 22300: 0.444760
2025-12-12 21:29:39,937 INFO     Training average regularization at step 22400: 0.272815
2025-12-12 21:29:39,938 INFO     Training average positive_sample_loss at step 22400: 0.171802
2025-12-12 21:29:39,938 INFO     Training average negative_sample_loss at step 22400: 0.152722
2025-12-12 21:29:39,938 INFO     Training average loss at step 22400: 0.435077
2025-12-12 21:29:47,326 INFO     Training average regularization at step 22500: 0.272219
2025-12-12 21:29:47,326 INFO     Training average positive_sample_loss at step 22500: 0.188243
2025-12-12 21:29:47,326 INFO     Training average negative_sample_loss at step 22500: 0.163449
2025-12-12 21:29:47,326 INFO     Training average loss at step 22500: 0.448065
2025-12-12 21:29:54,562 INFO     Training average regularization at step 22600: 0.271646
2025-12-12 21:29:54,562 INFO     Training average positive_sample_loss at step 22600: 0.182222
2025-12-12 21:29:54,562 INFO     Training average negative_sample_loss at step 22600: 0.149733
2025-12-12 21:29:54,562 INFO     Training average loss at step 22600: 0.437623
2025-12-12 21:30:01,844 INFO     Training average regularization at step 22700: 0.271090
2025-12-12 21:30:01,845 INFO     Training average positive_sample_loss at step 22700: 0.185369
2025-12-12 21:30:01,845 INFO     Training average negative_sample_loss at step 22700: 0.153942
2025-12-12 21:30:01,845 INFO     Training average loss at step 22700: 0.440746
2025-12-12 21:30:09,108 INFO     Training average regularization at step 22800: 0.270551
2025-12-12 21:30:09,108 INFO     Training average positive_sample_loss at step 22800: 0.183459
2025-12-12 21:30:09,108 INFO     Training average negative_sample_loss at step 22800: 0.153139
2025-12-12 21:30:09,108 INFO     Training average loss at step 22800: 0.438850
2025-12-12 21:30:16,357 INFO     Training average regularization at step 22900: 0.270026
2025-12-12 21:30:16,357 INFO     Training average positive_sample_loss at step 22900: 0.180420
2025-12-12 21:30:16,357 INFO     Training average negative_sample_loss at step 22900: 0.148750
2025-12-12 21:30:16,357 INFO     Training average loss at step 22900: 0.434611
2025-12-12 21:30:23,605 INFO     Training average regularization at step 23000: 0.269514
2025-12-12 21:30:23,606 INFO     Training average positive_sample_loss at step 23000: 0.176048
2025-12-12 21:30:23,606 INFO     Training average negative_sample_loss at step 23000: 0.149989
2025-12-12 21:30:23,606 INFO     Training average loss at step 23000: 0.432533
2025-12-12 21:30:30,831 INFO     Training average regularization at step 23100: 0.269018
2025-12-12 21:30:30,831 INFO     Training average positive_sample_loss at step 23100: 0.180944
2025-12-12 21:30:30,831 INFO     Training average negative_sample_loss at step 23100: 0.146680
2025-12-12 21:30:30,831 INFO     Training average loss at step 23100: 0.432829
2025-12-12 21:30:38,106 INFO     Training average regularization at step 23200: 0.268533
2025-12-12 21:30:38,107 INFO     Training average positive_sample_loss at step 23200: 0.168524
2025-12-12 21:30:38,107 INFO     Training average negative_sample_loss at step 23200: 0.149533
2025-12-12 21:30:38,107 INFO     Training average loss at step 23200: 0.427562
2025-12-12 21:30:45,495 INFO     Training average regularization at step 23300: 0.268048
2025-12-12 21:30:45,496 INFO     Training average positive_sample_loss at step 23300: 0.178689
2025-12-12 21:30:45,496 INFO     Training average negative_sample_loss at step 23300: 0.147145
2025-12-12 21:30:45,496 INFO     Training average loss at step 23300: 0.430965
2025-12-12 21:30:52,800 INFO     Training average regularization at step 23400: 0.267580
2025-12-12 21:30:52,801 INFO     Training average positive_sample_loss at step 23400: 0.173576
2025-12-12 21:30:52,801 INFO     Training average negative_sample_loss at step 23400: 0.136363
2025-12-12 21:30:52,801 INFO     Training average loss at step 23400: 0.422550
2025-12-12 21:31:00,048 INFO     Training average regularization at step 23500: 0.267122
2025-12-12 21:31:00,049 INFO     Training average positive_sample_loss at step 23500: 0.175239
2025-12-12 21:31:00,049 INFO     Training average negative_sample_loss at step 23500: 0.139257
2025-12-12 21:31:00,049 INFO     Training average loss at step 23500: 0.424370
2025-12-12 21:31:07,314 INFO     Training average regularization at step 23600: 0.266669
2025-12-12 21:31:07,315 INFO     Training average positive_sample_loss at step 23600: 0.168323
2025-12-12 21:31:07,315 INFO     Training average negative_sample_loss at step 23600: 0.151989
2025-12-12 21:31:07,315 INFO     Training average loss at step 23600: 0.426825
2025-12-12 21:31:14,583 INFO     Training average regularization at step 23700: 0.266223
2025-12-12 21:31:14,583 INFO     Training average positive_sample_loss at step 23700: 0.170862
2025-12-12 21:31:14,583 INFO     Training average negative_sample_loss at step 23700: 0.140092
2025-12-12 21:31:14,583 INFO     Training average loss at step 23700: 0.421700
2025-12-12 21:31:21,852 INFO     Training average regularization at step 23800: 0.265783
2025-12-12 21:31:21,852 INFO     Training average positive_sample_loss at step 23800: 0.168849
2025-12-12 21:31:21,852 INFO     Training average negative_sample_loss at step 23800: 0.129915
2025-12-12 21:31:21,852 INFO     Training average loss at step 23800: 0.415165
2025-12-12 21:31:29,141 INFO     Training average regularization at step 23900: 0.265349
2025-12-12 21:31:29,142 INFO     Training average positive_sample_loss at step 23900: 0.166486
2025-12-12 21:31:29,142 INFO     Training average negative_sample_loss at step 23900: 0.137264
2025-12-12 21:31:29,142 INFO     Training average loss at step 23900: 0.417224
2025-12-12 21:31:43,603 INFO     Training average regularization at step 24000: 0.264924
2025-12-12 21:31:43,603 INFO     Training average positive_sample_loss at step 24000: 0.172487
2025-12-12 21:31:43,603 INFO     Training average negative_sample_loss at step 24000: 0.129829
2025-12-12 21:31:43,603 INFO     Training average loss at step 24000: 0.416082
2025-12-12 21:31:50,873 INFO     Training average regularization at step 24100: 0.264504
2025-12-12 21:31:50,874 INFO     Training average positive_sample_loss at step 24100: 0.162576
2025-12-12 21:31:50,874 INFO     Training average negative_sample_loss at step 24100: 0.138049
2025-12-12 21:31:50,874 INFO     Training average loss at step 24100: 0.414816
2025-12-12 21:31:58,244 INFO     Training average regularization at step 24200: 0.264085
2025-12-12 21:31:58,245 INFO     Training average positive_sample_loss at step 24200: 0.163219
2025-12-12 21:31:58,245 INFO     Training average negative_sample_loss at step 24200: 0.141498
2025-12-12 21:31:58,245 INFO     Training average loss at step 24200: 0.416444
2025-12-12 21:32:05,496 INFO     Training average regularization at step 24300: 0.263673
2025-12-12 21:32:05,496 INFO     Training average positive_sample_loss at step 24300: 0.160255
2025-12-12 21:32:05,497 INFO     Training average negative_sample_loss at step 24300: 0.134517
2025-12-12 21:32:05,497 INFO     Training average loss at step 24300: 0.411059
2025-12-12 21:32:12,745 INFO     Training average regularization at step 24400: 0.263266
2025-12-12 21:32:12,745 INFO     Training average positive_sample_loss at step 24400: 0.165111
2025-12-12 21:32:12,745 INFO     Training average negative_sample_loss at step 24400: 0.132073
2025-12-12 21:32:12,745 INFO     Training average loss at step 24400: 0.411858
2025-12-12 21:32:19,990 INFO     Training average regularization at step 24500: 0.262859
2025-12-12 21:32:19,990 INFO     Training average positive_sample_loss at step 24500: 0.161726
2025-12-12 21:32:19,990 INFO     Training average negative_sample_loss at step 24500: 0.131425
2025-12-12 21:32:19,990 INFO     Training average loss at step 24500: 0.409434
2025-12-12 21:32:27,216 INFO     Training average regularization at step 24600: 0.262456
2025-12-12 21:32:27,216 INFO     Training average positive_sample_loss at step 24600: 0.154361
2025-12-12 21:32:27,217 INFO     Training average negative_sample_loss at step 24600: 0.132637
2025-12-12 21:32:27,217 INFO     Training average loss at step 24600: 0.405955
2025-12-12 21:32:34,452 INFO     Training average regularization at step 24700: 0.262055
2025-12-12 21:32:34,453 INFO     Training average positive_sample_loss at step 24700: 0.165281
2025-12-12 21:32:34,453 INFO     Training average negative_sample_loss at step 24700: 0.128961
2025-12-12 21:32:34,453 INFO     Training average loss at step 24700: 0.409176
2025-12-12 21:32:41,795 INFO     Training average regularization at step 24800: 0.261658
2025-12-12 21:32:41,795 INFO     Training average positive_sample_loss at step 24800: 0.147664
2025-12-12 21:32:41,795 INFO     Training average negative_sample_loss at step 24800: 0.134266
2025-12-12 21:32:41,795 INFO     Training average loss at step 24800: 0.402623
2025-12-12 21:32:49,145 INFO     Training average regularization at step 24900: 0.261258
2025-12-12 21:32:49,145 INFO     Training average positive_sample_loss at step 24900: 0.154373
2025-12-12 21:32:49,145 INFO     Training average negative_sample_loss at step 24900: 0.128333
2025-12-12 21:32:49,145 INFO     Training average loss at step 24900: 0.402611
2025-12-12 21:32:56,405 INFO     Training average regularization at step 25000: 0.260861
2025-12-12 21:32:56,406 INFO     Training average positive_sample_loss at step 25000: 0.150606
2025-12-12 21:32:56,406 INFO     Training average negative_sample_loss at step 25000: 0.126274
2025-12-12 21:32:56,406 INFO     Training average loss at step 25000: 0.399301
2025-12-12 21:33:03,636 INFO     Training average regularization at step 25100: 0.260468
2025-12-12 21:33:03,636 INFO     Training average positive_sample_loss at step 25100: 0.146165
2025-12-12 21:33:03,636 INFO     Training average negative_sample_loss at step 25100: 0.130016
2025-12-12 21:33:03,636 INFO     Training average loss at step 25100: 0.398559
2025-12-12 21:33:10,952 INFO     Training average regularization at step 25200: 0.260075
2025-12-12 21:33:10,953 INFO     Training average positive_sample_loss at step 25200: 0.153685
2025-12-12 21:33:10,953 INFO     Training average negative_sample_loss at step 25200: 0.129159
2025-12-12 21:33:10,953 INFO     Training average loss at step 25200: 0.401498
2025-12-12 21:33:18,243 INFO     Training average regularization at step 25300: 0.259683
2025-12-12 21:33:18,243 INFO     Training average positive_sample_loss at step 25300: 0.148666
2025-12-12 21:33:18,243 INFO     Training average negative_sample_loss at step 25300: 0.123088
2025-12-12 21:33:18,243 INFO     Training average loss at step 25300: 0.395560
2025-12-12 21:33:25,474 INFO     Training average regularization at step 25400: 0.259292
2025-12-12 21:33:25,474 INFO     Training average positive_sample_loss at step 25400: 0.143185
2025-12-12 21:33:25,474 INFO     Training average negative_sample_loss at step 25400: 0.121801
2025-12-12 21:33:25,474 INFO     Training average loss at step 25400: 0.391785
2025-12-12 21:33:32,714 INFO     Training average regularization at step 25500: 0.258905
2025-12-12 21:33:32,714 INFO     Training average positive_sample_loss at step 25500: 0.148035
2025-12-12 21:33:32,714 INFO     Training average negative_sample_loss at step 25500: 0.119671
2025-12-12 21:33:32,714 INFO     Training average loss at step 25500: 0.392758
2025-12-12 21:33:40,055 INFO     Training average regularization at step 25600: 0.258518
2025-12-12 21:33:40,056 INFO     Training average positive_sample_loss at step 25600: 0.141075
2025-12-12 21:33:40,056 INFO     Training average negative_sample_loss at step 25600: 0.113371
2025-12-12 21:33:40,056 INFO     Training average loss at step 25600: 0.385741
2025-12-12 21:33:47,380 INFO     Training average regularization at step 25700: 0.258128
2025-12-12 21:33:47,380 INFO     Training average positive_sample_loss at step 25700: 0.146461
2025-12-12 21:33:47,380 INFO     Training average negative_sample_loss at step 25700: 0.117192
2025-12-12 21:33:47,380 INFO     Training average loss at step 25700: 0.389955
2025-12-12 21:33:54,664 INFO     Training average regularization at step 25800: 0.257743
2025-12-12 21:33:54,664 INFO     Training average positive_sample_loss at step 25800: 0.146505
2025-12-12 21:33:54,665 INFO     Training average negative_sample_loss at step 25800: 0.119587
2025-12-12 21:33:54,665 INFO     Training average loss at step 25800: 0.390788
2025-12-12 21:34:01,894 INFO     Training average regularization at step 25900: 0.257358
2025-12-12 21:34:01,894 INFO     Training average positive_sample_loss at step 25900: 0.143871
2025-12-12 21:34:01,894 INFO     Training average negative_sample_loss at step 25900: 0.117476
2025-12-12 21:34:01,894 INFO     Training average loss at step 25900: 0.388031
2025-12-12 21:34:09,187 INFO     Training average regularization at step 26000: 0.256970
2025-12-12 21:34:09,188 INFO     Training average positive_sample_loss at step 26000: 0.141134
2025-12-12 21:34:09,188 INFO     Training average negative_sample_loss at step 26000: 0.111917
2025-12-12 21:34:09,188 INFO     Training average loss at step 26000: 0.383495
2025-12-12 21:34:16,427 INFO     Training average regularization at step 26100: 0.256584
2025-12-12 21:34:16,428 INFO     Training average positive_sample_loss at step 26100: 0.139116
2025-12-12 21:34:16,428 INFO     Training average negative_sample_loss at step 26100: 0.117125
2025-12-12 21:34:16,428 INFO     Training average loss at step 26100: 0.384704
2025-12-12 21:34:23,710 INFO     Training average regularization at step 26200: 0.256198
2025-12-12 21:34:23,710 INFO     Training average positive_sample_loss at step 26200: 0.138961
2025-12-12 21:34:23,710 INFO     Training average negative_sample_loss at step 26200: 0.122260
2025-12-12 21:34:23,710 INFO     Training average loss at step 26200: 0.386809
2025-12-12 21:34:31,039 INFO     Training average regularization at step 26300: 0.255813
2025-12-12 21:34:31,039 INFO     Training average positive_sample_loss at step 26300: 0.140329
2025-12-12 21:34:31,040 INFO     Training average negative_sample_loss at step 26300: 0.117202
2025-12-12 21:34:31,040 INFO     Training average loss at step 26300: 0.384579
2025-12-12 21:34:38,372 INFO     Training average regularization at step 26400: 0.255431
2025-12-12 21:34:38,372 INFO     Training average positive_sample_loss at step 26400: 0.144436
2025-12-12 21:34:38,372 INFO     Training average negative_sample_loss at step 26400: 0.110954
2025-12-12 21:34:38,372 INFO     Training average loss at step 26400: 0.383126
2025-12-12 21:34:45,765 INFO     Training average regularization at step 26500: 0.255052
2025-12-12 21:34:45,765 INFO     Training average positive_sample_loss at step 26500: 0.141101
2025-12-12 21:34:45,766 INFO     Training average negative_sample_loss at step 26500: 0.114073
2025-12-12 21:34:45,766 INFO     Training average loss at step 26500: 0.382639
2025-12-12 21:34:53,002 INFO     Training average regularization at step 26600: 0.254665
2025-12-12 21:34:53,002 INFO     Training average positive_sample_loss at step 26600: 0.131300
2025-12-12 21:34:53,002 INFO     Training average negative_sample_loss at step 26600: 0.114214
2025-12-12 21:34:53,002 INFO     Training average loss at step 26600: 0.377422
2025-12-12 21:35:00,266 INFO     Training average regularization at step 26700: 0.254279
2025-12-12 21:35:00,266 INFO     Training average positive_sample_loss at step 26700: 0.136931
2025-12-12 21:35:00,266 INFO     Training average negative_sample_loss at step 26700: 0.113025
2025-12-12 21:35:00,266 INFO     Training average loss at step 26700: 0.379257
2025-12-12 21:35:07,492 INFO     Training average regularization at step 26800: 0.253900
2025-12-12 21:35:07,492 INFO     Training average positive_sample_loss at step 26800: 0.134181
2025-12-12 21:35:07,492 INFO     Training average negative_sample_loss at step 26800: 0.112860
2025-12-12 21:35:07,492 INFO     Training average loss at step 26800: 0.377421
2025-12-12 21:35:14,748 INFO     Training average regularization at step 26900: 0.253518
2025-12-12 21:35:14,749 INFO     Training average positive_sample_loss at step 26900: 0.126080
2025-12-12 21:35:14,749 INFO     Training average negative_sample_loss at step 26900: 0.104648
2025-12-12 21:35:14,749 INFO     Training average loss at step 26900: 0.368882
2025-12-12 21:35:21,969 INFO     Training average regularization at step 27000: 0.253134
2025-12-12 21:35:21,969 INFO     Training average positive_sample_loss at step 27000: 0.132867
2025-12-12 21:35:21,969 INFO     Training average negative_sample_loss at step 27000: 0.117380
2025-12-12 21:35:21,969 INFO     Training average loss at step 27000: 0.378258
2025-12-12 21:35:29,170 INFO     Training average regularization at step 27100: 0.252748
2025-12-12 21:35:29,171 INFO     Training average positive_sample_loss at step 27100: 0.129521
2025-12-12 21:35:29,171 INFO     Training average negative_sample_loss at step 27100: 0.101682
2025-12-12 21:35:29,171 INFO     Training average loss at step 27100: 0.368350
2025-12-12 21:35:36,402 INFO     Training average regularization at step 27200: 0.252367
2025-12-12 21:35:36,403 INFO     Training average positive_sample_loss at step 27200: 0.136069
2025-12-12 21:35:36,403 INFO     Training average negative_sample_loss at step 27200: 0.107300
2025-12-12 21:35:36,403 INFO     Training average loss at step 27200: 0.374051
2025-12-12 21:35:43,783 INFO     Training average regularization at step 27300: 0.251985
2025-12-12 21:35:43,784 INFO     Training average positive_sample_loss at step 27300: 0.127917
2025-12-12 21:35:43,784 INFO     Training average negative_sample_loss at step 27300: 0.106624
2025-12-12 21:35:43,784 INFO     Training average loss at step 27300: 0.369256
2025-12-12 21:35:51,045 INFO     Training average regularization at step 27400: 0.251606
2025-12-12 21:35:51,045 INFO     Training average positive_sample_loss at step 27400: 0.124034
2025-12-12 21:35:51,045 INFO     Training average negative_sample_loss at step 27400: 0.104219
2025-12-12 21:35:51,045 INFO     Training average loss at step 27400: 0.365733
2025-12-12 21:35:58,289 INFO     Training average regularization at step 27500: 0.251225
2025-12-12 21:35:58,289 INFO     Training average positive_sample_loss at step 27500: 0.130283
2025-12-12 21:35:58,289 INFO     Training average negative_sample_loss at step 27500: 0.105332
2025-12-12 21:35:58,289 INFO     Training average loss at step 27500: 0.369033
2025-12-12 21:36:05,510 INFO     Training average regularization at step 27600: 0.250841
2025-12-12 21:36:05,511 INFO     Training average positive_sample_loss at step 27600: 0.124177
2025-12-12 21:36:05,511 INFO     Training average negative_sample_loss at step 27600: 0.099910
2025-12-12 21:36:05,511 INFO     Training average loss at step 27600: 0.362885
2025-12-12 21:36:12,795 INFO     Training average regularization at step 27700: 0.250458
2025-12-12 21:36:12,795 INFO     Training average positive_sample_loss at step 27700: 0.125360
2025-12-12 21:36:12,795 INFO     Training average negative_sample_loss at step 27700: 0.098883
2025-12-12 21:36:12,795 INFO     Training average loss at step 27700: 0.362579
2025-12-12 21:36:20,137 INFO     Training average regularization at step 27800: 0.250075
2025-12-12 21:36:20,138 INFO     Training average positive_sample_loss at step 27800: 0.127153
2025-12-12 21:36:20,138 INFO     Training average negative_sample_loss at step 27800: 0.103667
2025-12-12 21:36:20,138 INFO     Training average loss at step 27800: 0.365485
2025-12-12 21:36:27,491 INFO     Training average regularization at step 27900: 0.249689
2025-12-12 21:36:27,491 INFO     Training average positive_sample_loss at step 27900: 0.126036
2025-12-12 21:36:27,491 INFO     Training average negative_sample_loss at step 27900: 0.103156
2025-12-12 21:36:27,491 INFO     Training average loss at step 27900: 0.364285
2025-12-12 21:36:42,185 INFO     Training average regularization at step 28000: 0.249304
2025-12-12 21:36:42,185 INFO     Training average positive_sample_loss at step 28000: 0.115858
2025-12-12 21:36:42,185 INFO     Training average negative_sample_loss at step 28000: 0.102716
2025-12-12 21:36:42,185 INFO     Training average loss at step 28000: 0.358591
2025-12-12 21:36:49,523 INFO     Training average regularization at step 28100: 0.248920
2025-12-12 21:36:49,523 INFO     Training average positive_sample_loss at step 28100: 0.122278
2025-12-12 21:36:49,523 INFO     Training average negative_sample_loss at step 28100: 0.094795
2025-12-12 21:36:49,523 INFO     Training average loss at step 28100: 0.357456
2025-12-12 21:36:56,791 INFO     Training average regularization at step 28200: 0.248534
2025-12-12 21:36:56,791 INFO     Training average positive_sample_loss at step 28200: 0.116960
2025-12-12 21:36:56,791 INFO     Training average negative_sample_loss at step 28200: 0.096803
2025-12-12 21:36:56,791 INFO     Training average loss at step 28200: 0.355416
2025-12-12 21:37:04,009 INFO     Training average regularization at step 28300: 0.248148
2025-12-12 21:37:04,010 INFO     Training average positive_sample_loss at step 28300: 0.115675
2025-12-12 21:37:04,010 INFO     Training average negative_sample_loss at step 28300: 0.098271
2025-12-12 21:37:04,010 INFO     Training average loss at step 28300: 0.355121
2025-12-12 21:37:11,209 INFO     Training average regularization at step 28400: 0.247759
2025-12-12 21:37:11,209 INFO     Training average positive_sample_loss at step 28400: 0.117867
2025-12-12 21:37:11,209 INFO     Training average negative_sample_loss at step 28400: 0.097913
2025-12-12 21:37:11,209 INFO     Training average loss at step 28400: 0.355649
2025-12-12 21:37:18,493 INFO     Training average regularization at step 28500: 0.247371
2025-12-12 21:37:18,493 INFO     Training average positive_sample_loss at step 28500: 0.116921
2025-12-12 21:37:18,493 INFO     Training average negative_sample_loss at step 28500: 0.100845
2025-12-12 21:37:18,493 INFO     Training average loss at step 28500: 0.356254
2025-12-12 21:37:25,739 INFO     Training average regularization at step 28600: 0.246985
2025-12-12 21:37:25,740 INFO     Training average positive_sample_loss at step 28600: 0.113017
2025-12-12 21:37:25,740 INFO     Training average negative_sample_loss at step 28600: 0.097648
2025-12-12 21:37:25,740 INFO     Training average loss at step 28600: 0.352317
2025-12-12 21:37:32,989 INFO     Training average regularization at step 28700: 0.246596
2025-12-12 21:37:32,989 INFO     Training average positive_sample_loss at step 28700: 0.114127
2025-12-12 21:37:32,989 INFO     Training average negative_sample_loss at step 28700: 0.095832
2025-12-12 21:37:32,989 INFO     Training average loss at step 28700: 0.351575
2025-12-12 21:37:40,317 INFO     Training average regularization at step 28800: 0.246203
2025-12-12 21:37:40,318 INFO     Training average positive_sample_loss at step 28800: 0.109230
2025-12-12 21:37:40,318 INFO     Training average negative_sample_loss at step 28800: 0.092245
2025-12-12 21:37:40,318 INFO     Training average loss at step 28800: 0.346941
2025-12-12 21:37:47,648 INFO     Training average regularization at step 28900: 0.245813
2025-12-12 21:37:47,648 INFO     Training average positive_sample_loss at step 28900: 0.115542
2025-12-12 21:37:47,648 INFO     Training average negative_sample_loss at step 28900: 0.089149
2025-12-12 21:37:47,648 INFO     Training average loss at step 28900: 0.348158
2025-12-12 21:37:54,939 INFO     Training average regularization at step 29000: 0.245420
2025-12-12 21:37:54,963 INFO     Training average positive_sample_loss at step 29000: 0.118111
2025-12-12 21:37:54,963 INFO     Training average negative_sample_loss at step 29000: 0.091832
2025-12-12 21:37:54,963 INFO     Training average loss at step 29000: 0.350392
2025-12-12 21:38:02,250 INFO     Training average regularization at step 29100: 0.245026
2025-12-12 21:38:02,250 INFO     Training average positive_sample_loss at step 29100: 0.112412
2025-12-12 21:38:02,250 INFO     Training average negative_sample_loss at step 29100: 0.090329
2025-12-12 21:38:02,250 INFO     Training average loss at step 29100: 0.346397
2025-12-12 21:38:09,578 INFO     Training average regularization at step 29200: 0.244635
2025-12-12 21:38:09,578 INFO     Training average positive_sample_loss at step 29200: 0.105179
2025-12-12 21:38:09,578 INFO     Training average negative_sample_loss at step 29200: 0.095431
2025-12-12 21:38:09,578 INFO     Training average loss at step 29200: 0.344940
2025-12-12 21:38:16,950 INFO     Training average regularization at step 29300: 0.244241
2025-12-12 21:38:16,951 INFO     Training average positive_sample_loss at step 29300: 0.110376
2025-12-12 21:38:16,951 INFO     Training average negative_sample_loss at step 29300: 0.092556
2025-12-12 21:38:16,951 INFO     Training average loss at step 29300: 0.345707
2025-12-12 21:38:24,240 INFO     Training average regularization at step 29400: 0.243850
2025-12-12 21:38:24,240 INFO     Training average positive_sample_loss at step 29400: 0.103260
2025-12-12 21:38:24,240 INFO     Training average negative_sample_loss at step 29400: 0.091506
2025-12-12 21:38:24,240 INFO     Training average loss at step 29400: 0.341233
2025-12-12 21:38:31,557 INFO     Training average regularization at step 29500: 0.243455
2025-12-12 21:38:31,557 INFO     Training average positive_sample_loss at step 29500: 0.109522
2025-12-12 21:38:31,557 INFO     Training average negative_sample_loss at step 29500: 0.089740
2025-12-12 21:38:31,557 INFO     Training average loss at step 29500: 0.343085
2025-12-12 21:38:38,911 INFO     Training average regularization at step 29600: 0.243058
2025-12-12 21:38:38,912 INFO     Training average positive_sample_loss at step 29600: 0.110042
2025-12-12 21:38:38,912 INFO     Training average negative_sample_loss at step 29600: 0.091377
2025-12-12 21:38:38,912 INFO     Training average loss at step 29600: 0.343767
2025-12-12 21:38:46,335 INFO     Training average regularization at step 29700: 0.242665
2025-12-12 21:38:46,335 INFO     Training average positive_sample_loss at step 29700: 0.107101
2025-12-12 21:38:46,335 INFO     Training average negative_sample_loss at step 29700: 0.092762
2025-12-12 21:38:46,335 INFO     Training average loss at step 29700: 0.342596
2025-12-12 21:38:53,577 INFO     Training average regularization at step 29800: 0.242273
2025-12-12 21:38:53,578 INFO     Training average positive_sample_loss at step 29800: 0.107195
2025-12-12 21:38:53,578 INFO     Training average negative_sample_loss at step 29800: 0.091413
2025-12-12 21:38:53,578 INFO     Training average loss at step 29800: 0.341577
2025-12-12 21:39:00,853 INFO     Training average regularization at step 29900: 0.241878
2025-12-12 21:39:00,853 INFO     Training average positive_sample_loss at step 29900: 0.105255
2025-12-12 21:39:00,853 INFO     Training average negative_sample_loss at step 29900: 0.088903
2025-12-12 21:39:00,853 INFO     Training average loss at step 29900: 0.338958
2025-12-12 21:39:08,129 INFO     Training average regularization at step 30000: 0.241480
2025-12-12 21:39:08,130 INFO     Training average positive_sample_loss at step 30000: 0.101689
2025-12-12 21:39:08,130 INFO     Training average negative_sample_loss at step 30000: 0.085716
2025-12-12 21:39:08,130 INFO     Training average loss at step 30000: 0.335183
2025-12-12 21:39:08,130 INFO     Evaluating on Valid Dataset...
2025-12-12 21:39:09,737 INFO     Evaluating the model... (0/5000)
2025-12-12 21:39:17,202 INFO     Evaluating the model... (100/5000)
2025-12-12 21:39:24,275 INFO     Evaluating the model... (200/5000)
2025-12-12 21:39:31,427 INFO     Evaluating the model... (300/5000)
2025-12-12 21:39:38,592 INFO     Evaluating the model... (400/5000)
2025-12-12 21:39:45,766 INFO     Evaluating the model... (500/5000)
2025-12-12 21:39:52,857 INFO     Evaluating the model... (600/5000)
2025-12-12 21:39:59,958 INFO     Evaluating the model... (700/5000)
2025-12-12 21:40:08,726 INFO     Evaluating the model... (800/5000)
2025-12-12 21:40:15,851 INFO     Evaluating the model... (900/5000)
2025-12-12 21:40:23,037 INFO     Evaluating the model... (1000/5000)
2025-12-12 21:40:30,146 INFO     Evaluating the model... (1100/5000)
2025-12-12 21:40:37,271 INFO     Evaluating the model... (1200/5000)
2025-12-12 21:40:44,450 INFO     Evaluating the model... (1300/5000)
2025-12-12 21:40:51,523 INFO     Evaluating the model... (1400/5000)
2025-12-12 21:40:58,604 INFO     Evaluating the model... (1500/5000)
2025-12-12 21:41:05,649 INFO     Evaluating the model... (1600/5000)
2025-12-12 21:41:12,728 INFO     Evaluating the model... (1700/5000)
2025-12-12 21:41:19,832 INFO     Evaluating the model... (1800/5000)
2025-12-12 21:41:26,886 INFO     Evaluating the model... (1900/5000)
2025-12-12 21:41:34,006 INFO     Evaluating the model... (2000/5000)
2025-12-12 21:41:41,365 INFO     Evaluating the model... (2100/5000)
2025-12-12 21:41:48,540 INFO     Evaluating the model... (2200/5000)
2025-12-12 21:41:55,644 INFO     Evaluating the model... (2300/5000)
2025-12-12 21:42:02,747 INFO     Evaluating the model... (2400/5000)
2025-12-12 21:42:10,709 INFO     Evaluating the model... (2500/5000)
2025-12-12 21:42:17,973 INFO     Evaluating the model... (2600/5000)
2025-12-12 21:42:25,131 INFO     Evaluating the model... (2700/5000)
2025-12-12 21:42:32,339 INFO     Evaluating the model... (2800/5000)
2025-12-12 21:42:39,602 INFO     Evaluating the model... (2900/5000)
2025-12-12 21:42:46,797 INFO     Evaluating the model... (3000/5000)
2025-12-12 21:42:53,905 INFO     Evaluating the model... (3100/5000)
2025-12-12 21:43:03,202 INFO     Evaluating the model... (3200/5000)
2025-12-12 21:43:10,292 INFO     Evaluating the model... (3300/5000)
2025-12-12 21:43:17,386 INFO     Evaluating the model... (3400/5000)
2025-12-12 21:43:24,471 INFO     Evaluating the model... (3500/5000)
2025-12-12 21:43:31,618 INFO     Evaluating the model... (3600/5000)
2025-12-12 21:43:38,736 INFO     Evaluating the model... (3700/5000)
2025-12-12 21:43:45,864 INFO     Evaluating the model... (3800/5000)
2025-12-12 21:43:52,925 INFO     Evaluating the model... (3900/5000)
2025-12-12 21:44:00,024 INFO     Evaluating the model... (4000/5000)
2025-12-12 21:44:07,088 INFO     Evaluating the model... (4100/5000)
2025-12-12 21:44:14,156 INFO     Evaluating the model... (4200/5000)
2025-12-12 21:44:21,243 INFO     Evaluating the model... (4300/5000)
2025-12-12 21:44:28,286 INFO     Evaluating the model... (4400/5000)
2025-12-12 21:44:35,358 INFO     Evaluating the model... (4500/5000)
2025-12-12 21:44:42,607 INFO     Evaluating the model... (4600/5000)
2025-12-12 21:44:49,711 INFO     Evaluating the model... (4700/5000)
2025-12-12 21:44:56,796 INFO     Evaluating the model... (4800/5000)
2025-12-12 21:45:03,873 INFO     Evaluating the model... (4900/5000)
2025-12-12 21:45:11,272 INFO     Valid MRR at step 30000: 0.406162
2025-12-12 21:45:11,272 INFO     Valid MR at step 30000: 5907.286200
2025-12-12 21:45:11,272 INFO     Valid HITS@1 at step 30000: 0.307400
2025-12-12 21:45:11,272 INFO     Valid HITS@3 at step 30000: 0.464900
2025-12-12 21:45:11,272 INFO     Valid HITS@10 at step 30000: 0.588300
2025-12-12 21:45:18,712 INFO     Evaluating on Test Dataset...
2025-12-12 21:45:20,395 INFO     Evaluating the model... (0/5000)
2025-12-12 21:45:27,672 INFO     Evaluating the model... (100/5000)
2025-12-12 21:45:34,752 INFO     Evaluating the model... (200/5000)
2025-12-12 21:45:41,916 INFO     Evaluating the model... (300/5000)
2025-12-12 21:45:49,015 INFO     Evaluating the model... (400/5000)
2025-12-12 21:45:56,114 INFO     Evaluating the model... (500/5000)
2025-12-12 21:46:05,063 INFO     Evaluating the model... (600/5000)
2025-12-12 21:46:12,151 INFO     Evaluating the model... (700/5000)
2025-12-12 21:46:19,228 INFO     Evaluating the model... (800/5000)
2025-12-12 21:46:26,347 INFO     Evaluating the model... (900/5000)
2025-12-12 21:46:33,429 INFO     Evaluating the model... (1000/5000)
2025-12-12 21:46:40,584 INFO     Evaluating the model... (1100/5000)
2025-12-12 21:46:47,693 INFO     Evaluating the model... (1200/5000)
2025-12-12 21:46:54,758 INFO     Evaluating the model... (1300/5000)
2025-12-12 21:47:01,828 INFO     Evaluating the model... (1400/5000)
2025-12-12 21:47:08,920 INFO     Evaluating the model... (1500/5000)
2025-12-12 21:47:16,001 INFO     Evaluating the model... (1600/5000)
2025-12-12 21:47:23,245 INFO     Evaluating the model... (1700/5000)
2025-12-12 21:47:30,327 INFO     Evaluating the model... (1800/5000)
2025-12-12 21:47:37,435 INFO     Evaluating the model... (1900/5000)
2025-12-12 21:47:44,573 INFO     Evaluating the model... (2000/5000)
2025-12-12 21:47:51,659 INFO     Evaluating the model... (2100/5000)
2025-12-12 21:47:58,746 INFO     Evaluating the model... (2200/5000)
2025-12-12 21:48:05,815 INFO     Evaluating the model... (2300/5000)
2025-12-12 21:48:12,901 INFO     Evaluating the model... (2400/5000)
2025-12-12 21:48:20,837 INFO     Evaluating the model... (2500/5000)
2025-12-12 21:48:28,089 INFO     Evaluating the model... (2600/5000)
2025-12-12 21:48:35,187 INFO     Evaluating the model... (2700/5000)
2025-12-12 21:48:42,436 INFO     Evaluating the model... (2800/5000)
2025-12-12 21:48:49,561 INFO     Evaluating the model... (2900/5000)
2025-12-12 21:48:58,275 INFO     Evaluating the model... (3000/5000)
2025-12-12 21:49:05,384 INFO     Evaluating the model... (3100/5000)
2025-12-12 21:49:12,496 INFO     Evaluating the model... (3200/5000)
2025-12-12 21:49:19,591 INFO     Evaluating the model... (3300/5000)
2025-12-12 21:49:26,682 INFO     Evaluating the model... (3400/5000)
2025-12-12 21:49:33,775 INFO     Evaluating the model... (3500/5000)
2025-12-12 21:49:40,949 INFO     Evaluating the model... (3600/5000)
2025-12-12 21:49:48,127 INFO     Evaluating the model... (3700/5000)
2025-12-12 21:49:55,236 INFO     Evaluating the model... (3800/5000)
2025-12-12 21:50:02,364 INFO     Evaluating the model... (3900/5000)
2025-12-12 21:50:09,517 INFO     Evaluating the model... (4000/5000)
2025-12-12 21:50:16,733 INFO     Evaluating the model... (4100/5000)
2025-12-12 21:50:23,882 INFO     Evaluating the model... (4200/5000)
2025-12-12 21:50:31,023 INFO     Evaluating the model... (4300/5000)
2025-12-12 21:50:38,156 INFO     Evaluating the model... (4400/5000)
2025-12-12 21:50:45,356 INFO     Evaluating the model... (4500/5000)
2025-12-12 21:50:52,489 INFO     Evaluating the model... (4600/5000)
2025-12-12 21:50:59,620 INFO     Evaluating the model... (4700/5000)
2025-12-12 21:51:06,709 INFO     Evaluating the model... (4800/5000)
2025-12-12 21:51:13,790 INFO     Evaluating the model... (4900/5000)
2025-12-12 21:51:21,191 INFO     Test MRR at step 30000: 0.402644
2025-12-12 21:51:21,191 INFO     Test MR at step 30000: 6440.585700
2025-12-12 21:51:21,191 INFO     Test HITS@1 at step 30000: 0.301000
2025-12-12 21:51:21,191 INFO     Test HITS@3 at step 30000: 0.464200
2025-12-12 21:51:21,191 INFO     Test HITS@10 at step 30000: 0.588100
2025-12-12 21:51:28,464 INFO     Training average regularization at step 30100: 0.241080
2025-12-12 21:51:28,464 INFO     Training average positive_sample_loss at step 30100: 0.102126
2025-12-12 21:51:28,464 INFO     Training average negative_sample_loss at step 30100: 0.082435
2025-12-12 21:51:28,464 INFO     Training average loss at step 30100: 0.333361
2025-12-12 21:51:35,881 INFO     Training average regularization at step 30200: 0.240677
2025-12-12 21:51:35,883 INFO     Training average positive_sample_loss at step 30200: 0.101331
2025-12-12 21:51:35,883 INFO     Training average negative_sample_loss at step 30200: 0.085346
2025-12-12 21:51:35,883 INFO     Training average loss at step 30200: 0.334016
2025-12-12 21:51:43,261 INFO     Training average regularization at step 30300: 0.240274
2025-12-12 21:51:43,262 INFO     Training average positive_sample_loss at step 30300: 0.099652
2025-12-12 21:51:43,262 INFO     Training average negative_sample_loss at step 30300: 0.079888
2025-12-12 21:51:43,262 INFO     Training average loss at step 30300: 0.330044
2025-12-12 21:51:50,587 INFO     Training average regularization at step 30400: 0.239872
2025-12-12 21:51:50,587 INFO     Training average positive_sample_loss at step 30400: 0.098226
2025-12-12 21:51:50,588 INFO     Training average negative_sample_loss at step 30400: 0.090035
2025-12-12 21:51:50,588 INFO     Training average loss at step 30400: 0.334002
2025-12-12 21:51:57,936 INFO     Training average regularization at step 30500: 0.239466
2025-12-12 21:51:57,937 INFO     Training average positive_sample_loss at step 30500: 0.095049
2025-12-12 21:51:57,937 INFO     Training average negative_sample_loss at step 30500: 0.085844
2025-12-12 21:51:57,937 INFO     Training average loss at step 30500: 0.329912
2025-12-12 21:52:05,187 INFO     Training average regularization at step 30600: 0.239061
2025-12-12 21:52:05,187 INFO     Training average positive_sample_loss at step 30600: 0.104077
2025-12-12 21:52:05,187 INFO     Training average negative_sample_loss at step 30600: 0.082577
2025-12-12 21:52:05,187 INFO     Training average loss at step 30600: 0.332388
2025-12-12 21:52:12,477 INFO     Training average regularization at step 30700: 0.238655
2025-12-12 21:52:12,478 INFO     Training average positive_sample_loss at step 30700: 0.097471
2025-12-12 21:52:12,478 INFO     Training average negative_sample_loss at step 30700: 0.087521
2025-12-12 21:52:12,478 INFO     Training average loss at step 30700: 0.331151
2025-12-12 21:52:19,749 INFO     Training average regularization at step 30800: 0.238251
2025-12-12 21:52:19,749 INFO     Training average positive_sample_loss at step 30800: 0.094758
2025-12-12 21:52:19,749 INFO     Training average negative_sample_loss at step 30800: 0.086837
2025-12-12 21:52:19,749 INFO     Training average loss at step 30800: 0.329048
2025-12-12 21:52:26,993 INFO     Training average regularization at step 30900: 0.237844
2025-12-12 21:52:26,994 INFO     Training average positive_sample_loss at step 30900: 0.095448
2025-12-12 21:52:26,994 INFO     Training average negative_sample_loss at step 30900: 0.085551
2025-12-12 21:52:26,994 INFO     Training average loss at step 30900: 0.328343
2025-12-12 21:52:34,230 INFO     Training average regularization at step 31000: 0.237438
2025-12-12 21:52:34,231 INFO     Training average positive_sample_loss at step 31000: 0.094727
2025-12-12 21:52:34,231 INFO     Training average negative_sample_loss at step 31000: 0.078948
2025-12-12 21:52:34,231 INFO     Training average loss at step 31000: 0.324276
2025-12-12 21:52:41,567 INFO     Training average regularization at step 31100: 0.237033
2025-12-12 21:52:41,570 INFO     Training average positive_sample_loss at step 31100: 0.095834
2025-12-12 21:52:41,570 INFO     Training average negative_sample_loss at step 31100: 0.081474
2025-12-12 21:52:41,571 INFO     Training average loss at step 31100: 0.325687
2025-12-12 21:52:48,893 INFO     Training average regularization at step 31200: 0.236625
2025-12-12 21:52:48,893 INFO     Training average positive_sample_loss at step 31200: 0.089952
2025-12-12 21:52:48,893 INFO     Training average negative_sample_loss at step 31200: 0.085148
2025-12-12 21:52:48,893 INFO     Training average loss at step 31200: 0.324176
2025-12-12 21:52:56,171 INFO     Training average regularization at step 31300: 0.236216
2025-12-12 21:52:56,171 INFO     Training average positive_sample_loss at step 31300: 0.091667
2025-12-12 21:52:56,171 INFO     Training average negative_sample_loss at step 31300: 0.083637
2025-12-12 21:52:56,171 INFO     Training average loss at step 31300: 0.323868
2025-12-12 21:53:03,431 INFO     Training average regularization at step 31400: 0.235805
2025-12-12 21:53:03,431 INFO     Training average positive_sample_loss at step 31400: 0.094365
2025-12-12 21:53:03,431 INFO     Training average negative_sample_loss at step 31400: 0.084706
2025-12-12 21:53:03,431 INFO     Training average loss at step 31400: 0.325341
2025-12-12 21:53:10,679 INFO     Training average regularization at step 31500: 0.235397
2025-12-12 21:53:10,680 INFO     Training average positive_sample_loss at step 31500: 0.094097
2025-12-12 21:53:10,680 INFO     Training average negative_sample_loss at step 31500: 0.082586
2025-12-12 21:53:10,680 INFO     Training average loss at step 31500: 0.323739
2025-12-12 21:53:17,979 INFO     Training average regularization at step 31600: 0.234986
2025-12-12 21:53:17,980 INFO     Training average positive_sample_loss at step 31600: 0.089454
2025-12-12 21:53:17,980 INFO     Training average negative_sample_loss at step 31600: 0.076878
2025-12-12 21:53:17,980 INFO     Training average loss at step 31600: 0.318153
2025-12-12 21:53:25,200 INFO     Training average regularization at step 31700: 0.234576
2025-12-12 21:53:25,200 INFO     Training average positive_sample_loss at step 31700: 0.085933
2025-12-12 21:53:25,200 INFO     Training average negative_sample_loss at step 31700: 0.078456
2025-12-12 21:53:25,200 INFO     Training average loss at step 31700: 0.316770
2025-12-12 21:53:32,450 INFO     Training average regularization at step 31800: 0.234162
2025-12-12 21:53:32,450 INFO     Training average positive_sample_loss at step 31800: 0.089506
2025-12-12 21:53:32,450 INFO     Training average negative_sample_loss at step 31800: 0.077079
2025-12-12 21:53:32,450 INFO     Training average loss at step 31800: 0.317455
2025-12-12 21:53:39,756 INFO     Training average regularization at step 31900: 0.233747
2025-12-12 21:53:39,756 INFO     Training average positive_sample_loss at step 31900: 0.089204
2025-12-12 21:53:39,756 INFO     Training average negative_sample_loss at step 31900: 0.078747
2025-12-12 21:53:39,756 INFO     Training average loss at step 31900: 0.317723
2025-12-12 21:53:54,687 INFO     Training average regularization at step 32000: 0.233329
2025-12-12 21:53:54,688 INFO     Training average positive_sample_loss at step 32000: 0.086153
2025-12-12 21:53:54,688 INFO     Training average negative_sample_loss at step 32000: 0.072637
2025-12-12 21:53:54,688 INFO     Training average loss at step 32000: 0.312723
2025-12-12 21:54:01,984 INFO     Training average regularization at step 32100: 0.232909
2025-12-12 21:54:01,985 INFO     Training average positive_sample_loss at step 32100: 0.082942
2025-12-12 21:54:01,985 INFO     Training average negative_sample_loss at step 32100: 0.075018
2025-12-12 21:54:01,985 INFO     Training average loss at step 32100: 0.311889
2025-12-12 21:54:09,216 INFO     Training average regularization at step 32200: 0.232490
2025-12-12 21:54:09,217 INFO     Training average positive_sample_loss at step 32200: 0.081974
2025-12-12 21:54:09,217 INFO     Training average negative_sample_loss at step 32200: 0.074512
2025-12-12 21:54:09,217 INFO     Training average loss at step 32200: 0.310733
2025-12-12 21:54:16,481 INFO     Training average regularization at step 32300: 0.232069
2025-12-12 21:54:16,482 INFO     Training average positive_sample_loss at step 32300: 0.081518
2025-12-12 21:54:16,482 INFO     Training average negative_sample_loss at step 32300: 0.078869
2025-12-12 21:54:16,482 INFO     Training average loss at step 32300: 0.312263
2025-12-12 21:54:25,395 INFO     Training average regularization at step 32400: 0.231645
2025-12-12 21:54:25,400 INFO     Training average positive_sample_loss at step 32400: 0.068484
2025-12-12 21:54:25,401 INFO     Training average negative_sample_loss at step 32400: 0.079057
2025-12-12 21:54:25,401 INFO     Training average loss at step 32400: 0.305415
2025-12-12 21:54:32,764 INFO     Training average regularization at step 32500: 0.231204
2025-12-12 21:54:32,764 INFO     Training average positive_sample_loss at step 32500: 0.041075
2025-12-12 21:54:32,764 INFO     Training average negative_sample_loss at step 32500: 0.064041
2025-12-12 21:54:32,764 INFO     Training average loss at step 32500: 0.283762
2025-12-12 21:54:40,210 INFO     Training average regularization at step 32600: 0.230761
2025-12-12 21:54:40,211 INFO     Training average positive_sample_loss at step 32600: 0.045601
2025-12-12 21:54:40,211 INFO     Training average negative_sample_loss at step 32600: 0.062495
2025-12-12 21:54:40,211 INFO     Training average loss at step 32600: 0.284809
2025-12-12 21:54:47,561 INFO     Training average regularization at step 32700: 0.230318
2025-12-12 21:54:47,562 INFO     Training average positive_sample_loss at step 32700: 0.044888
2025-12-12 21:54:47,562 INFO     Training average negative_sample_loss at step 32700: 0.053854
2025-12-12 21:54:47,562 INFO     Training average loss at step 32700: 0.279689
2025-12-12 21:54:54,831 INFO     Training average regularization at step 32800: 0.229874
2025-12-12 21:54:54,831 INFO     Training average positive_sample_loss at step 32800: 0.044743
2025-12-12 21:54:54,831 INFO     Training average negative_sample_loss at step 32800: 0.056388
2025-12-12 21:54:54,831 INFO     Training average loss at step 32800: 0.280440
2025-12-12 21:55:02,123 INFO     Training average regularization at step 32900: 0.229421
2025-12-12 21:55:02,123 INFO     Training average positive_sample_loss at step 32900: 0.042766
2025-12-12 21:55:02,124 INFO     Training average negative_sample_loss at step 32900: 0.052281
2025-12-12 21:55:02,124 INFO     Training average loss at step 32900: 0.276945
2025-12-12 21:55:09,447 INFO     Training average regularization at step 33000: 0.228967
2025-12-12 21:55:09,447 INFO     Training average positive_sample_loss at step 33000: 0.047030
2025-12-12 21:55:09,447 INFO     Training average negative_sample_loss at step 33000: 0.057472
2025-12-12 21:55:09,447 INFO     Training average loss at step 33000: 0.281218
2025-12-12 21:55:16,699 INFO     Training average regularization at step 33100: 0.228507
2025-12-12 21:55:16,701 INFO     Training average positive_sample_loss at step 33100: 0.049822
2025-12-12 21:55:16,701 INFO     Training average negative_sample_loss at step 33100: 0.048257
2025-12-12 21:55:16,701 INFO     Training average loss at step 33100: 0.277546
2025-12-12 21:55:23,998 INFO     Training average regularization at step 33200: 0.228040
2025-12-12 21:55:23,998 INFO     Training average positive_sample_loss at step 33200: 0.044744
2025-12-12 21:55:23,998 INFO     Training average negative_sample_loss at step 33200: 0.058253
2025-12-12 21:55:23,998 INFO     Training average loss at step 33200: 0.279539
2025-12-12 21:55:31,294 INFO     Training average regularization at step 33300: 0.227571
2025-12-12 21:55:31,295 INFO     Training average positive_sample_loss at step 33300: 0.052146
2025-12-12 21:55:31,295 INFO     Training average negative_sample_loss at step 33300: 0.054833
2025-12-12 21:55:31,295 INFO     Training average loss at step 33300: 0.281061
2025-12-12 21:55:38,593 INFO     Training average regularization at step 33400: 0.227104
2025-12-12 21:55:38,593 INFO     Training average positive_sample_loss at step 33400: 0.049033
2025-12-12 21:55:38,593 INFO     Training average negative_sample_loss at step 33400: 0.052182
2025-12-12 21:55:38,594 INFO     Training average loss at step 33400: 0.277711
2025-12-12 21:55:45,952 INFO     Training average regularization at step 33500: 0.226633
2025-12-12 21:55:45,953 INFO     Training average positive_sample_loss at step 33500: 0.052396
2025-12-12 21:55:45,953 INFO     Training average negative_sample_loss at step 33500: 0.051605
2025-12-12 21:55:45,953 INFO     Training average loss at step 33500: 0.278634
2025-12-12 21:55:53,208 INFO     Training average regularization at step 33600: 0.226159
2025-12-12 21:55:53,208 INFO     Training average positive_sample_loss at step 33600: 0.048609
2025-12-12 21:55:53,208 INFO     Training average negative_sample_loss at step 33600: 0.056370
2025-12-12 21:55:53,208 INFO     Training average loss at step 33600: 0.278649
2025-12-12 21:56:00,498 INFO     Training average regularization at step 33700: 0.225678
2025-12-12 21:56:00,498 INFO     Training average positive_sample_loss at step 33700: 0.047995
2025-12-12 21:56:00,499 INFO     Training average negative_sample_loss at step 33700: 0.052772
2025-12-12 21:56:00,499 INFO     Training average loss at step 33700: 0.276061
2025-12-12 21:56:07,764 INFO     Training average regularization at step 33800: 0.225194
2025-12-12 21:56:07,765 INFO     Training average positive_sample_loss at step 33800: 0.046677
2025-12-12 21:56:07,765 INFO     Training average negative_sample_loss at step 33800: 0.046964
2025-12-12 21:56:07,765 INFO     Training average loss at step 33800: 0.272014
2025-12-12 21:56:15,019 INFO     Training average regularization at step 33900: 0.224709
2025-12-12 21:56:15,020 INFO     Training average positive_sample_loss at step 33900: 0.048121
2025-12-12 21:56:15,020 INFO     Training average negative_sample_loss at step 33900: 0.050354
2025-12-12 21:56:15,020 INFO     Training average loss at step 33900: 0.273947
2025-12-12 21:56:22,253 INFO     Training average regularization at step 34000: 0.224223
2025-12-12 21:56:22,253 INFO     Training average positive_sample_loss at step 34000: 0.054554
2025-12-12 21:56:22,253 INFO     Training average negative_sample_loss at step 34000: 0.052587
2025-12-12 21:56:22,254 INFO     Training average loss at step 34000: 0.277793
2025-12-12 21:56:29,516 INFO     Training average regularization at step 34100: 0.223729
2025-12-12 21:56:29,517 INFO     Training average positive_sample_loss at step 34100: 0.051957
2025-12-12 21:56:29,517 INFO     Training average negative_sample_loss at step 34100: 0.054922
2025-12-12 21:56:29,517 INFO     Training average loss at step 34100: 0.277168
2025-12-12 21:56:36,796 INFO     Training average regularization at step 34200: 0.223233
2025-12-12 21:56:36,798 INFO     Training average positive_sample_loss at step 34200: 0.054928
2025-12-12 21:56:36,798 INFO     Training average negative_sample_loss at step 34200: 0.053429
2025-12-12 21:56:36,798 INFO     Training average loss at step 34200: 0.277412
2025-12-12 21:56:44,173 INFO     Training average regularization at step 34300: 0.222739
2025-12-12 21:56:44,174 INFO     Training average positive_sample_loss at step 34300: 0.048802
2025-12-12 21:56:44,174 INFO     Training average negative_sample_loss at step 34300: 0.055752
2025-12-12 21:56:44,174 INFO     Training average loss at step 34300: 0.275016
2025-12-12 21:56:51,483 INFO     Training average regularization at step 34400: 0.222243
2025-12-12 21:56:51,483 INFO     Training average positive_sample_loss at step 34400: 0.049155
2025-12-12 21:56:51,483 INFO     Training average negative_sample_loss at step 34400: 0.055683
2025-12-12 21:56:51,483 INFO     Training average loss at step 34400: 0.274662
2025-12-12 21:56:58,703 INFO     Training average regularization at step 34500: 0.221744
2025-12-12 21:56:58,704 INFO     Training average positive_sample_loss at step 34500: 0.054937
2025-12-12 21:56:58,704 INFO     Training average negative_sample_loss at step 34500: 0.054645
2025-12-12 21:56:58,704 INFO     Training average loss at step 34500: 0.276536
2025-12-12 21:57:05,972 INFO     Training average regularization at step 34600: 0.221247
2025-12-12 21:57:05,972 INFO     Training average positive_sample_loss at step 34600: 0.049180
2025-12-12 21:57:05,972 INFO     Training average negative_sample_loss at step 34600: 0.057095
2025-12-12 21:57:05,972 INFO     Training average loss at step 34600: 0.274384
2025-12-12 21:57:13,216 INFO     Training average regularization at step 34700: 0.220747
2025-12-12 21:57:13,217 INFO     Training average positive_sample_loss at step 34700: 0.055470
2025-12-12 21:57:13,217 INFO     Training average negative_sample_loss at step 34700: 0.052340
2025-12-12 21:57:13,217 INFO     Training average loss at step 34700: 0.274652
2025-12-12 21:57:20,447 INFO     Training average regularization at step 34800: 0.220247
2025-12-12 21:57:20,447 INFO     Training average positive_sample_loss at step 34800: 0.057177
2025-12-12 21:57:20,447 INFO     Training average negative_sample_loss at step 34800: 0.052579
2025-12-12 21:57:20,447 INFO     Training average loss at step 34800: 0.275125
2025-12-12 21:57:27,700 INFO     Training average regularization at step 34900: 0.219742
2025-12-12 21:57:27,701 INFO     Training average positive_sample_loss at step 34900: 0.054695
2025-12-12 21:57:27,701 INFO     Training average negative_sample_loss at step 34900: 0.052505
2025-12-12 21:57:27,701 INFO     Training average loss at step 34900: 0.273342
2025-12-12 21:57:34,984 INFO     Training average regularization at step 35000: 0.219238
2025-12-12 21:57:34,985 INFO     Training average positive_sample_loss at step 35000: 0.056809
2025-12-12 21:57:34,985 INFO     Training average negative_sample_loss at step 35000: 0.049980
2025-12-12 21:57:34,985 INFO     Training average loss at step 35000: 0.272633
2025-12-12 21:57:42,390 INFO     Training average regularization at step 35100: 0.218735
2025-12-12 21:57:42,391 INFO     Training average positive_sample_loss at step 35100: 0.055411
2025-12-12 21:57:42,391 INFO     Training average negative_sample_loss at step 35100: 0.060541
2025-12-12 21:57:42,391 INFO     Training average loss at step 35100: 0.276711
2025-12-12 21:57:49,774 INFO     Training average regularization at step 35200: 0.218230
2025-12-12 21:57:49,775 INFO     Training average positive_sample_loss at step 35200: 0.058488
2025-12-12 21:57:49,775 INFO     Training average negative_sample_loss at step 35200: 0.054397
2025-12-12 21:57:49,775 INFO     Training average loss at step 35200: 0.274673
2025-12-12 21:57:57,101 INFO     Training average regularization at step 35300: 0.217727
2025-12-12 21:57:57,102 INFO     Training average positive_sample_loss at step 35300: 0.053632
2025-12-12 21:57:57,102 INFO     Training average negative_sample_loss at step 35300: 0.047314
2025-12-12 21:57:57,102 INFO     Training average loss at step 35300: 0.268200
2025-12-12 21:58:04,370 INFO     Training average regularization at step 35400: 0.217221
2025-12-12 21:58:04,371 INFO     Training average positive_sample_loss at step 35400: 0.052377
2025-12-12 21:58:04,371 INFO     Training average negative_sample_loss at step 35400: 0.054596
2025-12-12 21:58:04,371 INFO     Training average loss at step 35400: 0.270708
2025-12-12 21:58:11,629 INFO     Training average regularization at step 35500: 0.216715
2025-12-12 21:58:11,636 INFO     Training average positive_sample_loss at step 35500: 0.048855
2025-12-12 21:58:11,636 INFO     Training average negative_sample_loss at step 35500: 0.055484
2025-12-12 21:58:11,636 INFO     Training average loss at step 35500: 0.268885
2025-12-12 21:58:18,931 INFO     Training average regularization at step 35600: 0.216211
2025-12-12 21:58:18,931 INFO     Training average positive_sample_loss at step 35600: 0.055816
2025-12-12 21:58:18,931 INFO     Training average negative_sample_loss at step 35600: 0.058449
2025-12-12 21:58:18,931 INFO     Training average loss at step 35600: 0.273343
2025-12-12 21:58:26,152 INFO     Training average regularization at step 35700: 0.215710
2025-12-12 21:58:26,152 INFO     Training average positive_sample_loss at step 35700: 0.054891
2025-12-12 21:58:26,152 INFO     Training average negative_sample_loss at step 35700: 0.056484
2025-12-12 21:58:26,152 INFO     Training average loss at step 35700: 0.271398
2025-12-12 21:58:33,415 INFO     Training average regularization at step 35800: 0.215208
2025-12-12 21:58:33,415 INFO     Training average positive_sample_loss at step 35800: 0.052501
2025-12-12 21:58:33,415 INFO     Training average negative_sample_loss at step 35800: 0.058610
2025-12-12 21:58:33,415 INFO     Training average loss at step 35800: 0.270764
2025-12-12 21:58:40,697 INFO     Training average regularization at step 35900: 0.214702
2025-12-12 21:58:40,697 INFO     Training average positive_sample_loss at step 35900: 0.056599
2025-12-12 21:58:40,697 INFO     Training average negative_sample_loss at step 35900: 0.050982
2025-12-12 21:58:40,698 INFO     Training average loss at step 35900: 0.268492
2025-12-12 21:58:55,267 INFO     Training average regularization at step 36000: 0.214196
2025-12-12 21:58:55,267 INFO     Training average positive_sample_loss at step 36000: 0.050987
2025-12-12 21:58:55,267 INFO     Training average negative_sample_loss at step 36000: 0.054307
2025-12-12 21:58:55,267 INFO     Training average loss at step 36000: 0.266843
2025-12-12 21:59:02,583 INFO     Training average regularization at step 36100: 0.213688
2025-12-12 21:59:02,584 INFO     Training average positive_sample_loss at step 36100: 0.056094
2025-12-12 21:59:02,584 INFO     Training average negative_sample_loss at step 36100: 0.061575
2025-12-12 21:59:02,584 INFO     Training average loss at step 36100: 0.272522
2025-12-12 21:59:09,884 INFO     Training average regularization at step 36200: 0.213187
2025-12-12 21:59:09,885 INFO     Training average positive_sample_loss at step 36200: 0.053380
2025-12-12 21:59:09,885 INFO     Training average negative_sample_loss at step 36200: 0.051618
2025-12-12 21:59:09,885 INFO     Training average loss at step 36200: 0.265686
2025-12-12 21:59:17,146 INFO     Training average regularization at step 36300: 0.212684
2025-12-12 21:59:17,147 INFO     Training average positive_sample_loss at step 36300: 0.057820
2025-12-12 21:59:17,147 INFO     Training average negative_sample_loss at step 36300: 0.054180
2025-12-12 21:59:17,147 INFO     Training average loss at step 36300: 0.268684
2025-12-12 21:59:24,458 INFO     Training average regularization at step 36400: 0.212177
2025-12-12 21:59:24,458 INFO     Training average positive_sample_loss at step 36400: 0.055609
2025-12-12 21:59:24,458 INFO     Training average negative_sample_loss at step 36400: 0.053195
2025-12-12 21:59:24,458 INFO     Training average loss at step 36400: 0.266579
2025-12-12 21:59:31,800 INFO     Training average regularization at step 36500: 0.211673
2025-12-12 21:59:31,801 INFO     Training average positive_sample_loss at step 36500: 0.062120
2025-12-12 21:59:31,801 INFO     Training average negative_sample_loss at step 36500: 0.055281
2025-12-12 21:59:31,801 INFO     Training average loss at step 36500: 0.270374
2025-12-12 21:59:39,126 INFO     Training average regularization at step 36600: 0.211173
2025-12-12 21:59:39,127 INFO     Training average positive_sample_loss at step 36600: 0.054146
2025-12-12 21:59:39,127 INFO     Training average negative_sample_loss at step 36600: 0.054885
2025-12-12 21:59:39,127 INFO     Training average loss at step 36600: 0.265689
2025-12-12 21:59:46,497 INFO     Training average regularization at step 36700: 0.210670
2025-12-12 21:59:46,498 INFO     Training average positive_sample_loss at step 36700: 0.062559
2025-12-12 21:59:46,498 INFO     Training average negative_sample_loss at step 36700: 0.054937
2025-12-12 21:59:46,498 INFO     Training average loss at step 36700: 0.269418
2025-12-12 21:59:53,811 INFO     Training average regularization at step 36800: 0.210170
2025-12-12 21:59:53,811 INFO     Training average positive_sample_loss at step 36800: 0.054268
2025-12-12 21:59:53,811 INFO     Training average negative_sample_loss at step 36800: 0.055214
2025-12-12 21:59:53,811 INFO     Training average loss at step 36800: 0.264911
2025-12-12 22:00:01,050 INFO     Training average regularization at step 36900: 0.209673
2025-12-12 22:00:01,050 INFO     Training average positive_sample_loss at step 36900: 0.058534
2025-12-12 22:00:01,050 INFO     Training average negative_sample_loss at step 36900: 0.053631
2025-12-12 22:00:01,050 INFO     Training average loss at step 36900: 0.265756
2025-12-12 22:00:08,326 INFO     Training average regularization at step 37000: 0.209173
2025-12-12 22:00:08,326 INFO     Training average positive_sample_loss at step 37000: 0.058276
2025-12-12 22:00:08,326 INFO     Training average negative_sample_loss at step 37000: 0.057548
2025-12-12 22:00:08,326 INFO     Training average loss at step 37000: 0.267085
2025-12-12 22:00:15,592 INFO     Training average regularization at step 37100: 0.208678
2025-12-12 22:00:15,593 INFO     Training average positive_sample_loss at step 37100: 0.054663
2025-12-12 22:00:15,593 INFO     Training average negative_sample_loss at step 37100: 0.051653
2025-12-12 22:00:15,593 INFO     Training average loss at step 37100: 0.261836
2025-12-12 22:00:22,848 INFO     Training average regularization at step 37200: 0.208180
2025-12-12 22:00:22,849 INFO     Training average positive_sample_loss at step 37200: 0.062830
2025-12-12 22:00:22,849 INFO     Training average negative_sample_loss at step 37200: 0.056279
2025-12-12 22:00:22,849 INFO     Training average loss at step 37200: 0.267735
2025-12-12 22:00:30,114 INFO     Training average regularization at step 37300: 0.207690
2025-12-12 22:00:30,115 INFO     Training average positive_sample_loss at step 37300: 0.060488
2025-12-12 22:00:30,115 INFO     Training average negative_sample_loss at step 37300: 0.055858
2025-12-12 22:00:30,115 INFO     Training average loss at step 37300: 0.265863
2025-12-12 22:00:37,410 INFO     Training average regularization at step 37400: 0.207201
2025-12-12 22:00:37,411 INFO     Training average positive_sample_loss at step 37400: 0.054818
2025-12-12 22:00:37,411 INFO     Training average negative_sample_loss at step 37400: 0.058666
2025-12-12 22:00:37,411 INFO     Training average loss at step 37400: 0.263943
2025-12-12 22:00:44,824 INFO     Training average regularization at step 37500: 0.206715
2025-12-12 22:00:44,825 INFO     Training average positive_sample_loss at step 37500: 0.058837
2025-12-12 22:00:44,825 INFO     Training average negative_sample_loss at step 37500: 0.055093
2025-12-12 22:00:44,825 INFO     Training average loss at step 37500: 0.263680
2025-12-12 22:00:52,054 INFO     Training average regularization at step 37600: 0.206232
2025-12-12 22:00:52,054 INFO     Training average positive_sample_loss at step 37600: 0.061741
2025-12-12 22:00:52,054 INFO     Training average negative_sample_loss at step 37600: 0.054880
2025-12-12 22:00:52,054 INFO     Training average loss at step 37600: 0.264542
2025-12-12 22:00:59,304 INFO     Training average regularization at step 37700: 0.205746
2025-12-12 22:00:59,304 INFO     Training average positive_sample_loss at step 37700: 0.056503
2025-12-12 22:00:59,304 INFO     Training average negative_sample_loss at step 37700: 0.058213
2025-12-12 22:00:59,304 INFO     Training average loss at step 37700: 0.263104
2025-12-12 22:01:06,601 INFO     Training average regularization at step 37800: 0.205264
2025-12-12 22:01:06,602 INFO     Training average positive_sample_loss at step 37800: 0.055826
2025-12-12 22:01:06,602 INFO     Training average negative_sample_loss at step 37800: 0.053416
2025-12-12 22:01:06,602 INFO     Training average loss at step 37800: 0.259885
2025-12-12 22:01:13,821 INFO     Training average regularization at step 37900: 0.204786
2025-12-12 22:01:13,826 INFO     Training average positive_sample_loss at step 37900: 0.059923
2025-12-12 22:01:13,826 INFO     Training average negative_sample_loss at step 37900: 0.061239
2025-12-12 22:01:13,826 INFO     Training average loss at step 37900: 0.265367
2025-12-12 22:01:21,074 INFO     Training average regularization at step 38000: 0.204308
2025-12-12 22:01:21,074 INFO     Training average positive_sample_loss at step 38000: 0.058430
2025-12-12 22:01:21,074 INFO     Training average negative_sample_loss at step 38000: 0.053117
2025-12-12 22:01:21,074 INFO     Training average loss at step 38000: 0.260081
2025-12-12 22:01:28,283 INFO     Training average regularization at step 38100: 0.203832
2025-12-12 22:01:28,284 INFO     Training average positive_sample_loss at step 38100: 0.055814
2025-12-12 22:01:28,284 INFO     Training average negative_sample_loss at step 38100: 0.052711
2025-12-12 22:01:28,284 INFO     Training average loss at step 38100: 0.258094
2025-12-12 22:01:35,490 INFO     Training average regularization at step 38200: 0.203352
2025-12-12 22:01:35,490 INFO     Training average positive_sample_loss at step 38200: 0.053058
2025-12-12 22:01:35,490 INFO     Training average negative_sample_loss at step 38200: 0.052599
2025-12-12 22:01:35,490 INFO     Training average loss at step 38200: 0.256180
2025-12-12 22:01:42,863 INFO     Training average regularization at step 38300: 0.202872
2025-12-12 22:01:42,864 INFO     Training average positive_sample_loss at step 38300: 0.062959
2025-12-12 22:01:42,864 INFO     Training average negative_sample_loss at step 38300: 0.055157
2025-12-12 22:01:42,864 INFO     Training average loss at step 38300: 0.261930
2025-12-12 22:01:50,113 INFO     Training average regularization at step 38400: 0.202398
2025-12-12 22:01:50,113 INFO     Training average positive_sample_loss at step 38400: 0.057577
2025-12-12 22:01:50,113 INFO     Training average negative_sample_loss at step 38400: 0.053466
2025-12-12 22:01:50,113 INFO     Training average loss at step 38400: 0.257919
2025-12-12 22:01:57,342 INFO     Training average regularization at step 38500: 0.201924
2025-12-12 22:01:57,342 INFO     Training average positive_sample_loss at step 38500: 0.062732
2025-12-12 22:01:57,342 INFO     Training average negative_sample_loss at step 38500: 0.055526
2025-12-12 22:01:57,342 INFO     Training average loss at step 38500: 0.261053
2025-12-12 22:02:04,622 INFO     Training average regularization at step 38600: 0.201451
2025-12-12 22:02:04,622 INFO     Training average positive_sample_loss at step 38600: 0.050831
2025-12-12 22:02:04,622 INFO     Training average negative_sample_loss at step 38600: 0.053337
2025-12-12 22:02:04,622 INFO     Training average loss at step 38600: 0.253535
2025-12-12 22:02:11,867 INFO     Training average regularization at step 38700: 0.200983
2025-12-12 22:02:11,867 INFO     Training average positive_sample_loss at step 38700: 0.056651
2025-12-12 22:02:11,868 INFO     Training average negative_sample_loss at step 38700: 0.055520
2025-12-12 22:02:11,868 INFO     Training average loss at step 38700: 0.257069
2025-12-12 22:02:19,105 INFO     Training average regularization at step 38800: 0.200514
2025-12-12 22:02:19,105 INFO     Training average positive_sample_loss at step 38800: 0.057001
2025-12-12 22:02:19,105 INFO     Training average negative_sample_loss at step 38800: 0.054622
2025-12-12 22:02:19,105 INFO     Training average loss at step 38800: 0.256325
2025-12-12 22:02:26,351 INFO     Training average regularization at step 38900: 0.200044
2025-12-12 22:02:26,351 INFO     Training average positive_sample_loss at step 38900: 0.058532
2025-12-12 22:02:26,351 INFO     Training average negative_sample_loss at step 38900: 0.050263
2025-12-12 22:02:26,351 INFO     Training average loss at step 38900: 0.254442
2025-12-12 22:02:33,628 INFO     Training average regularization at step 39000: 0.199575
2025-12-12 22:02:33,629 INFO     Training average positive_sample_loss at step 39000: 0.061315
2025-12-12 22:02:33,629 INFO     Training average negative_sample_loss at step 39000: 0.058816
2025-12-12 22:02:33,629 INFO     Training average loss at step 39000: 0.259640
2025-12-12 22:02:40,952 INFO     Training average regularization at step 39100: 0.199109
2025-12-12 22:02:40,953 INFO     Training average positive_sample_loss at step 39100: 0.057908
2025-12-12 22:02:40,953 INFO     Training average negative_sample_loss at step 39100: 0.055207
2025-12-12 22:02:40,953 INFO     Training average loss at step 39100: 0.255666
2025-12-12 22:02:48,275 INFO     Training average regularization at step 39200: 0.198645
2025-12-12 22:02:48,275 INFO     Training average positive_sample_loss at step 39200: 0.057253
2025-12-12 22:02:48,275 INFO     Training average negative_sample_loss at step 39200: 0.054604
2025-12-12 22:02:48,276 INFO     Training average loss at step 39200: 0.254573
2025-12-12 22:02:55,537 INFO     Training average regularization at step 39300: 0.198180
2025-12-12 22:02:55,537 INFO     Training average positive_sample_loss at step 39300: 0.058476
2025-12-12 22:02:55,537 INFO     Training average negative_sample_loss at step 39300: 0.055948
2025-12-12 22:02:55,537 INFO     Training average loss at step 39300: 0.255393
2025-12-12 22:03:02,831 INFO     Training average regularization at step 39400: 0.197725
2025-12-12 22:03:02,832 INFO     Training average positive_sample_loss at step 39400: 0.060890
2025-12-12 22:03:02,832 INFO     Training average negative_sample_loss at step 39400: 0.054417
2025-12-12 22:03:02,832 INFO     Training average loss at step 39400: 0.255378
2025-12-12 22:03:10,084 INFO     Training average regularization at step 39500: 0.197271
2025-12-12 22:03:10,084 INFO     Training average positive_sample_loss at step 39500: 0.055200
2025-12-12 22:03:10,085 INFO     Training average negative_sample_loss at step 39500: 0.052132
2025-12-12 22:03:10,085 INFO     Training average loss at step 39500: 0.250937
2025-12-12 22:03:17,361 INFO     Training average regularization at step 39600: 0.196815
2025-12-12 22:03:17,362 INFO     Training average positive_sample_loss at step 39600: 0.056467
2025-12-12 22:03:17,362 INFO     Training average negative_sample_loss at step 39600: 0.048083
2025-12-12 22:03:17,362 INFO     Training average loss at step 39600: 0.249090
2025-12-12 22:03:24,565 INFO     Training average regularization at step 39700: 0.196360
2025-12-12 22:03:24,565 INFO     Training average positive_sample_loss at step 39700: 0.053249
2025-12-12 22:03:24,565 INFO     Training average negative_sample_loss at step 39700: 0.059020
2025-12-12 22:03:24,565 INFO     Training average loss at step 39700: 0.252494
2025-12-12 22:03:31,764 INFO     Training average regularization at step 39800: 0.195907
2025-12-12 22:03:31,765 INFO     Training average positive_sample_loss at step 39800: 0.057377
2025-12-12 22:03:31,765 INFO     Training average negative_sample_loss at step 39800: 0.054960
2025-12-12 22:03:31,765 INFO     Training average loss at step 39800: 0.252076
2025-12-12 22:03:39,112 INFO     Training average regularization at step 39900: 0.195454
2025-12-12 22:03:39,113 INFO     Training average positive_sample_loss at step 39900: 0.059005
2025-12-12 22:03:39,113 INFO     Training average negative_sample_loss at step 39900: 0.055512
2025-12-12 22:03:39,113 INFO     Training average loss at step 39900: 0.252712
2025-12-12 22:03:46,446 INFO     Change learning_rate to 0.000026 at step 40000
2025-12-12 22:03:50,893 INFO     Training average regularization at step 40000: 0.195010
2025-12-12 22:03:50,893 INFO     Training average positive_sample_loss at step 40000: 0.057970
2025-12-12 22:03:50,893 INFO     Training average negative_sample_loss at step 40000: 0.049765
2025-12-12 22:03:50,893 INFO     Training average loss at step 40000: 0.248877
2025-12-12 22:03:50,894 INFO     Evaluating on Valid Dataset...
2025-12-12 22:03:52,734 INFO     Evaluating the model... (0/5000)
2025-12-12 22:04:00,094 INFO     Evaluating the model... (100/5000)
2025-12-12 22:04:07,087 INFO     Evaluating the model... (200/5000)
2025-12-12 22:04:14,186 INFO     Evaluating the model... (300/5000)
2025-12-12 22:04:22,935 INFO     Evaluating the model... (400/5000)
2025-12-12 22:04:30,005 INFO     Evaluating the model... (500/5000)
2025-12-12 22:04:37,054 INFO     Evaluating the model... (600/5000)
2025-12-12 22:04:44,245 INFO     Evaluating the model... (700/5000)
2025-12-12 22:04:51,284 INFO     Evaluating the model... (800/5000)
2025-12-12 22:04:58,340 INFO     Evaluating the model... (900/5000)
2025-12-12 22:05:05,427 INFO     Evaluating the model... (1000/5000)
2025-12-12 22:05:12,768 INFO     Evaluating the model... (1100/5000)
2025-12-12 22:05:19,853 INFO     Evaluating the model... (1200/5000)
2025-12-12 22:05:26,986 INFO     Evaluating the model... (1300/5000)
2025-12-12 22:05:34,178 INFO     Evaluating the model... (1400/5000)
2025-12-12 22:05:41,422 INFO     Evaluating the model... (1500/5000)
2025-12-12 22:05:48,571 INFO     Evaluating the model... (1600/5000)
2025-12-12 22:05:55,648 INFO     Evaluating the model... (1700/5000)
2025-12-12 22:06:02,740 INFO     Evaluating the model... (1800/5000)
2025-12-12 22:06:09,843 INFO     Evaluating the model... (1900/5000)
2025-12-12 22:06:16,918 INFO     Evaluating the model... (2000/5000)
2025-12-12 22:06:24,039 INFO     Evaluating the model... (2100/5000)
2025-12-12 22:06:31,110 INFO     Evaluating the model... (2200/5000)
2025-12-12 22:06:38,197 INFO     Evaluating the model... (2300/5000)
2025-12-12 22:06:45,341 INFO     Evaluating the model... (2400/5000)
2025-12-12 22:06:53,155 INFO     Evaluating the model... (2500/5000)
2025-12-12 22:07:00,429 INFO     Evaluating the model... (2600/5000)
2025-12-12 22:07:07,541 INFO     Evaluating the model... (2700/5000)
2025-12-12 22:07:16,821 INFO     Evaluating the model... (2800/5000)
2025-12-12 22:07:23,934 INFO     Evaluating the model... (2900/5000)
2025-12-12 22:07:31,033 INFO     Evaluating the model... (3000/5000)
2025-12-12 22:07:38,145 INFO     Evaluating the model... (3100/5000)
2025-12-12 22:07:45,315 INFO     Evaluating the model... (3200/5000)
2025-12-12 22:07:52,399 INFO     Evaluating the model... (3300/5000)
2025-12-12 22:07:59,511 INFO     Evaluating the model... (3400/5000)
2025-12-12 22:08:06,612 INFO     Evaluating the model... (3500/5000)
2025-12-12 22:08:13,725 INFO     Evaluating the model... (3600/5000)
2025-12-12 22:08:20,832 INFO     Evaluating the model... (3700/5000)
2025-12-12 22:08:28,002 INFO     Evaluating the model... (3800/5000)
2025-12-12 22:08:35,139 INFO     Evaluating the model... (3900/5000)
2025-12-12 22:08:42,344 INFO     Evaluating the model... (4000/5000)
2025-12-12 22:08:49,461 INFO     Evaluating the model... (4100/5000)
2025-12-12 22:08:56,637 INFO     Evaluating the model... (4200/5000)
2025-12-12 22:09:03,772 INFO     Evaluating the model... (4300/5000)
2025-12-12 22:09:10,935 INFO     Evaluating the model... (4400/5000)
2025-12-12 22:09:18,074 INFO     Evaluating the model... (4500/5000)
2025-12-12 22:09:25,229 INFO     Evaluating the model... (4600/5000)
2025-12-12 22:09:32,364 INFO     Evaluating the model... (4700/5000)
2025-12-12 22:09:39,516 INFO     Evaluating the model... (4800/5000)
2025-12-12 22:09:46,688 INFO     Evaluating the model... (4900/5000)
2025-12-12 22:09:54,025 INFO     Valid MRR at step 40000: 0.408690
2025-12-12 22:09:54,025 INFO     Valid MR at step 40000: 8378.156800
2025-12-12 22:09:54,025 INFO     Valid HITS@1 at step 40000: 0.314500
2025-12-12 22:09:54,025 INFO     Valid HITS@3 at step 40000: 0.464100
2025-12-12 22:09:54,025 INFO     Valid HITS@10 at step 40000: 0.582400
2025-12-12 22:09:58,347 INFO     Evaluating on Test Dataset...
2025-12-12 22:09:59,908 INFO     Evaluating the model... (0/5000)
2025-12-12 22:10:07,193 INFO     Evaluating the model... (100/5000)
2025-12-12 22:10:16,658 INFO     Evaluating the model... (200/5000)
2025-12-12 22:10:23,752 INFO     Evaluating the model... (300/5000)
2025-12-12 22:10:30,869 INFO     Evaluating the model... (400/5000)
2025-12-12 22:10:37,991 INFO     Evaluating the model... (500/5000)
2025-12-12 22:10:45,223 INFO     Evaluating the model... (600/5000)
2025-12-12 22:10:52,330 INFO     Evaluating the model... (700/5000)
2025-12-12 22:10:59,404 INFO     Evaluating the model... (800/5000)
2025-12-12 22:11:06,625 INFO     Evaluating the model... (900/5000)
2025-12-12 22:11:13,726 INFO     Evaluating the model... (1000/5000)
2025-12-12 22:11:20,817 INFO     Evaluating the model... (1100/5000)
2025-12-12 22:11:27,893 INFO     Evaluating the model... (1200/5000)
2025-12-12 22:11:34,991 INFO     Evaluating the model... (1300/5000)
2025-12-12 22:11:42,160 INFO     Evaluating the model... (1400/5000)
2025-12-12 22:11:49,290 INFO     Evaluating the model... (1500/5000)
2025-12-12 22:11:56,415 INFO     Evaluating the model... (1600/5000)
2025-12-12 22:12:03,521 INFO     Evaluating the model... (1700/5000)
2025-12-12 22:12:10,637 INFO     Evaluating the model... (1800/5000)
2025-12-12 22:12:17,689 INFO     Evaluating the model... (1900/5000)
2025-12-12 22:12:24,752 INFO     Evaluating the model... (2000/5000)
2025-12-12 22:12:31,826 INFO     Evaluating the model... (2100/5000)
2025-12-12 22:12:38,947 INFO     Evaluating the model... (2200/5000)
2025-12-12 22:12:46,136 INFO     Evaluating the model... (2300/5000)
2025-12-12 22:12:53,242 INFO     Evaluating the model... (2400/5000)
2025-12-12 22:13:01,271 INFO     Evaluating the model... (2500/5000)
2025-12-12 22:13:08,472 INFO     Evaluating the model... (2600/5000)
2025-12-12 22:13:17,860 INFO     Evaluating the model... (2700/5000)
2025-12-12 22:13:24,958 INFO     Evaluating the model... (2800/5000)
2025-12-12 22:13:32,110 INFO     Evaluating the model... (2900/5000)
2025-12-12 22:13:39,231 INFO     Evaluating the model... (3000/5000)
2025-12-12 22:13:46,392 INFO     Evaluating the model... (3100/5000)
2025-12-12 22:13:53,489 INFO     Evaluating the model... (3200/5000)
2025-12-12 22:14:00,615 INFO     Evaluating the model... (3300/5000)
2025-12-12 22:14:07,699 INFO     Evaluating the model... (3400/5000)
2025-12-12 22:14:14,802 INFO     Evaluating the model... (3500/5000)
2025-12-12 22:14:21,891 INFO     Evaluating the model... (3600/5000)
2025-12-12 22:14:29,032 INFO     Evaluating the model... (3700/5000)
2025-12-12 22:14:36,117 INFO     Evaluating the model... (3800/5000)
2025-12-12 22:14:43,312 INFO     Evaluating the model... (3900/5000)
2025-12-12 22:14:50,414 INFO     Evaluating the model... (4000/5000)
2025-12-12 22:14:57,506 INFO     Evaluating the model... (4100/5000)
2025-12-12 22:15:04,616 INFO     Evaluating the model... (4200/5000)
2025-12-12 22:15:11,753 INFO     Evaluating the model... (4300/5000)
2025-12-12 22:15:18,906 INFO     Evaluating the model... (4400/5000)
2025-12-12 22:15:25,985 INFO     Evaluating the model... (4500/5000)
2025-12-12 22:15:33,093 INFO     Evaluating the model... (4600/5000)
2025-12-12 22:15:40,260 INFO     Evaluating the model... (4700/5000)
2025-12-12 22:15:47,384 INFO     Evaluating the model... (4800/5000)
2025-12-12 22:15:54,482 INFO     Evaluating the model... (4900/5000)
2025-12-12 22:16:01,847 INFO     Test MRR at step 40000: 0.414034
2025-12-12 22:16:01,847 INFO     Test MR at step 40000: 8732.190100
2025-12-12 22:16:01,847 INFO     Test HITS@1 at step 40000: 0.320800
2025-12-12 22:16:01,847 INFO     Test HITS@3 at step 40000: 0.472600
2025-12-12 22:16:01,847 INFO     Test HITS@10 at step 40000: 0.583100
2025-12-12 22:16:09,083 INFO     Training average regularization at step 40100: 0.193651
2025-12-12 22:16:09,084 INFO     Training average positive_sample_loss at step 40100: 0.060038
2025-12-12 22:16:09,084 INFO     Training average negative_sample_loss at step 40100: 0.057349
2025-12-12 22:16:09,084 INFO     Training average loss at step 40100: 0.252345
2025-12-12 22:16:16,383 INFO     Training average regularization at step 40200: 0.191886
2025-12-12 22:16:16,383 INFO     Training average positive_sample_loss at step 40200: 0.060076
2025-12-12 22:16:16,383 INFO     Training average negative_sample_loss at step 40200: 0.053471
2025-12-12 22:16:16,383 INFO     Training average loss at step 40200: 0.248659
2025-12-12 22:16:23,638 INFO     Training average regularization at step 40300: 0.190555
2025-12-12 22:16:23,639 INFO     Training average positive_sample_loss at step 40300: 0.064885
2025-12-12 22:16:23,639 INFO     Training average negative_sample_loss at step 40300: 0.045835
2025-12-12 22:16:23,639 INFO     Training average loss at step 40300: 0.245915
2025-12-12 22:16:30,971 INFO     Training average regularization at step 40400: 0.189492
2025-12-12 22:16:30,973 INFO     Training average positive_sample_loss at step 40400: 0.064317
2025-12-12 22:16:30,973 INFO     Training average negative_sample_loss at step 40400: 0.052276
2025-12-12 22:16:30,973 INFO     Training average loss at step 40400: 0.247789
2025-12-12 22:16:38,325 INFO     Training average regularization at step 40500: 0.188615
2025-12-12 22:16:38,325 INFO     Training average positive_sample_loss at step 40500: 0.073089
2025-12-12 22:16:38,325 INFO     Training average negative_sample_loss at step 40500: 0.055029
2025-12-12 22:16:38,325 INFO     Training average loss at step 40500: 0.252674
2025-12-12 22:16:45,742 INFO     Training average regularization at step 40600: 0.187881
2025-12-12 22:16:45,742 INFO     Training average positive_sample_loss at step 40600: 0.067859
2025-12-12 22:16:45,742 INFO     Training average negative_sample_loss at step 40600: 0.048199
2025-12-12 22:16:45,742 INFO     Training average loss at step 40600: 0.245910
2025-12-12 22:16:53,005 INFO     Training average regularization at step 40700: 0.187253
2025-12-12 22:16:53,006 INFO     Training average positive_sample_loss at step 40700: 0.069510
2025-12-12 22:16:53,006 INFO     Training average negative_sample_loss at step 40700: 0.052299
2025-12-12 22:16:53,006 INFO     Training average loss at step 40700: 0.248158
2025-12-12 22:17:00,245 INFO     Training average regularization at step 40800: 0.186711
2025-12-12 22:17:00,245 INFO     Training average positive_sample_loss at step 40800: 0.072196
2025-12-12 22:17:00,246 INFO     Training average negative_sample_loss at step 40800: 0.049837
2025-12-12 22:17:00,246 INFO     Training average loss at step 40800: 0.247727
2025-12-12 22:17:07,508 INFO     Training average regularization at step 40900: 0.186238
2025-12-12 22:17:07,508 INFO     Training average positive_sample_loss at step 40900: 0.072445
2025-12-12 22:17:07,508 INFO     Training average negative_sample_loss at step 40900: 0.054959
2025-12-12 22:17:07,508 INFO     Training average loss at step 40900: 0.249940
2025-12-12 22:17:14,729 INFO     Training average regularization at step 41000: 0.185821
2025-12-12 22:17:14,729 INFO     Training average positive_sample_loss at step 41000: 0.071017
2025-12-12 22:17:14,729 INFO     Training average negative_sample_loss at step 41000: 0.050120
2025-12-12 22:17:14,730 INFO     Training average loss at step 41000: 0.246390
2025-12-12 22:17:21,967 INFO     Training average regularization at step 41100: 0.185451
2025-12-12 22:17:21,968 INFO     Training average positive_sample_loss at step 41100: 0.074859
2025-12-12 22:17:21,968 INFO     Training average negative_sample_loss at step 41100: 0.055184
2025-12-12 22:17:21,968 INFO     Training average loss at step 41100: 0.250473
2025-12-12 22:17:29,171 INFO     Training average regularization at step 41200: 0.185119
2025-12-12 22:17:29,171 INFO     Training average positive_sample_loss at step 41200: 0.071351
2025-12-12 22:17:29,171 INFO     Training average negative_sample_loss at step 41200: 0.052135
2025-12-12 22:17:29,171 INFO     Training average loss at step 41200: 0.246862
2025-12-12 22:17:36,420 INFO     Training average regularization at step 41300: 0.184820
2025-12-12 22:17:36,420 INFO     Training average positive_sample_loss at step 41300: 0.076009
2025-12-12 22:17:36,420 INFO     Training average negative_sample_loss at step 41300: 0.051515
2025-12-12 22:17:36,420 INFO     Training average loss at step 41300: 0.248582
2025-12-12 22:17:43,837 INFO     Training average regularization at step 41400: 0.184550
2025-12-12 22:17:43,837 INFO     Training average positive_sample_loss at step 41400: 0.072339
2025-12-12 22:17:43,837 INFO     Training average negative_sample_loss at step 41400: 0.047812
2025-12-12 22:17:43,838 INFO     Training average loss at step 41400: 0.244626
2025-12-12 22:17:51,131 INFO     Training average regularization at step 41500: 0.184305
2025-12-12 22:17:51,132 INFO     Training average positive_sample_loss at step 41500: 0.068357
2025-12-12 22:17:51,132 INFO     Training average negative_sample_loss at step 41500: 0.051282
2025-12-12 22:17:51,132 INFO     Training average loss at step 41500: 0.244124
2025-12-12 22:17:58,402 INFO     Training average regularization at step 41600: 0.184080
2025-12-12 22:17:58,402 INFO     Training average positive_sample_loss at step 41600: 0.071076
2025-12-12 22:17:58,403 INFO     Training average negative_sample_loss at step 41600: 0.054999
2025-12-12 22:17:58,403 INFO     Training average loss at step 41600: 0.247117
2025-12-12 22:18:05,663 INFO     Training average regularization at step 41700: 0.183872
2025-12-12 22:18:05,664 INFO     Training average positive_sample_loss at step 41700: 0.074430
2025-12-12 22:18:05,664 INFO     Training average negative_sample_loss at step 41700: 0.054863
2025-12-12 22:18:05,664 INFO     Training average loss at step 41700: 0.248519
2025-12-12 22:18:12,935 INFO     Training average regularization at step 41800: 0.183681
2025-12-12 22:18:12,937 INFO     Training average positive_sample_loss at step 41800: 0.068172
2025-12-12 22:18:12,937 INFO     Training average negative_sample_loss at step 41800: 0.056398
2025-12-12 22:18:12,937 INFO     Training average loss at step 41800: 0.245966
2025-12-12 22:18:20,220 INFO     Training average regularization at step 41900: 0.183503
2025-12-12 22:18:20,222 INFO     Training average positive_sample_loss at step 41900: 0.071220
2025-12-12 22:18:20,222 INFO     Training average negative_sample_loss at step 41900: 0.050241
2025-12-12 22:18:20,222 INFO     Training average loss at step 41900: 0.244234
2025-12-12 22:18:27,489 INFO     Training average regularization at step 42000: 0.183337
2025-12-12 22:18:27,490 INFO     Training average positive_sample_loss at step 42000: 0.070663
2025-12-12 22:18:27,490 INFO     Training average negative_sample_loss at step 42000: 0.054132
2025-12-12 22:18:27,490 INFO     Training average loss at step 42000: 0.245735
2025-12-12 22:18:34,799 INFO     Training average regularization at step 42100: 0.183182
2025-12-12 22:18:34,800 INFO     Training average positive_sample_loss at step 42100: 0.075178
2025-12-12 22:18:34,800 INFO     Training average negative_sample_loss at step 42100: 0.054447
2025-12-12 22:18:34,800 INFO     Training average loss at step 42100: 0.247995
2025-12-12 22:18:42,133 INFO     Training average regularization at step 42200: 0.183036
2025-12-12 22:18:42,133 INFO     Training average positive_sample_loss at step 42200: 0.071373
2025-12-12 22:18:42,134 INFO     Training average negative_sample_loss at step 42200: 0.048977
2025-12-12 22:18:42,134 INFO     Training average loss at step 42200: 0.243211
2025-12-12 22:18:49,483 INFO     Training average regularization at step 42300: 0.182898
2025-12-12 22:18:49,483 INFO     Training average positive_sample_loss at step 42300: 0.073632
2025-12-12 22:18:49,483 INFO     Training average negative_sample_loss at step 42300: 0.058163
2025-12-12 22:18:49,483 INFO     Training average loss at step 42300: 0.248796
2025-12-12 22:18:56,768 INFO     Training average regularization at step 42400: 0.182768
2025-12-12 22:18:56,768 INFO     Training average positive_sample_loss at step 42400: 0.075422
2025-12-12 22:18:56,768 INFO     Training average negative_sample_loss at step 42400: 0.056339
2025-12-12 22:18:56,768 INFO     Training average loss at step 42400: 0.248649
2025-12-12 22:19:04,068 INFO     Training average regularization at step 42500: 0.182643
2025-12-12 22:19:04,069 INFO     Training average positive_sample_loss at step 42500: 0.064254
2025-12-12 22:19:04,069 INFO     Training average negative_sample_loss at step 42500: 0.051685
2025-12-12 22:19:04,069 INFO     Training average loss at step 42500: 0.240612
2025-12-12 22:19:11,329 INFO     Training average regularization at step 42600: 0.182523
2025-12-12 22:19:11,332 INFO     Training average positive_sample_loss at step 42600: 0.071033
2025-12-12 22:19:11,332 INFO     Training average negative_sample_loss at step 42600: 0.058913
2025-12-12 22:19:11,332 INFO     Training average loss at step 42600: 0.247496
2025-12-12 22:19:18,704 INFO     Training average regularization at step 42700: 0.182408
2025-12-12 22:19:18,708 INFO     Training average positive_sample_loss at step 42700: 0.073707
2025-12-12 22:19:18,708 INFO     Training average negative_sample_loss at step 42700: 0.065999
2025-12-12 22:19:18,708 INFO     Training average loss at step 42700: 0.252261
2025-12-12 22:19:25,984 INFO     Training average regularization at step 42800: 0.182298
2025-12-12 22:19:25,985 INFO     Training average positive_sample_loss at step 42800: 0.070186
2025-12-12 22:19:25,985 INFO     Training average negative_sample_loss at step 42800: 0.057060
2025-12-12 22:19:25,985 INFO     Training average loss at step 42800: 0.245921
2025-12-12 22:19:33,251 INFO     Training average regularization at step 42900: 0.182192
2025-12-12 22:19:33,251 INFO     Training average positive_sample_loss at step 42900: 0.073833
2025-12-12 22:19:33,251 INFO     Training average negative_sample_loss at step 42900: 0.059877
2025-12-12 22:19:33,251 INFO     Training average loss at step 42900: 0.249048
2025-12-12 22:19:40,566 INFO     Training average regularization at step 43000: 0.182090
2025-12-12 22:19:40,566 INFO     Training average positive_sample_loss at step 43000: 0.069972
2025-12-12 22:19:40,566 INFO     Training average negative_sample_loss at step 43000: 0.053519
2025-12-12 22:19:40,567 INFO     Training average loss at step 43000: 0.243836
2025-12-12 22:19:47,966 INFO     Training average regularization at step 43100: 0.181991
2025-12-12 22:19:47,966 INFO     Training average positive_sample_loss at step 43100: 0.068218
2025-12-12 22:19:47,966 INFO     Training average negative_sample_loss at step 43100: 0.057037
2025-12-12 22:19:47,966 INFO     Training average loss at step 43100: 0.244619
2025-12-12 22:19:56,882 INFO     Training average regularization at step 43200: 0.181895
2025-12-12 22:19:56,882 INFO     Training average positive_sample_loss at step 43200: 0.061971
2025-12-12 22:19:56,883 INFO     Training average negative_sample_loss at step 43200: 0.053071
2025-12-12 22:19:56,883 INFO     Training average loss at step 43200: 0.239415
2025-12-12 22:20:04,178 INFO     Training average regularization at step 43300: 0.181800
2025-12-12 22:20:04,179 INFO     Training average positive_sample_loss at step 43300: 0.038083
2025-12-12 22:20:04,179 INFO     Training average negative_sample_loss at step 43300: 0.050729
2025-12-12 22:20:04,179 INFO     Training average loss at step 43300: 0.226206
2025-12-12 22:20:11,462 INFO     Training average regularization at step 43400: 0.181706
2025-12-12 22:20:11,462 INFO     Training average positive_sample_loss at step 43400: 0.038286
2025-12-12 22:20:11,462 INFO     Training average negative_sample_loss at step 43400: 0.063488
2025-12-12 22:20:11,462 INFO     Training average loss at step 43400: 0.232593
2025-12-12 22:20:18,770 INFO     Training average regularization at step 43500: 0.181615
2025-12-12 22:20:18,770 INFO     Training average positive_sample_loss at step 43500: 0.037085
2025-12-12 22:20:18,770 INFO     Training average negative_sample_loss at step 43500: 0.050617
2025-12-12 22:20:18,770 INFO     Training average loss at step 43500: 0.225466
2025-12-12 22:20:26,005 INFO     Training average regularization at step 43600: 0.181525
2025-12-12 22:20:26,006 INFO     Training average positive_sample_loss at step 43600: 0.035703
2025-12-12 22:20:26,006 INFO     Training average negative_sample_loss at step 43600: 0.050455
2025-12-12 22:20:26,006 INFO     Training average loss at step 43600: 0.224604
2025-12-12 22:20:33,284 INFO     Training average regularization at step 43700: 0.181437
2025-12-12 22:20:33,284 INFO     Training average positive_sample_loss at step 43700: 0.039195
2025-12-12 22:20:33,284 INFO     Training average negative_sample_loss at step 43700: 0.050913
2025-12-12 22:20:33,284 INFO     Training average loss at step 43700: 0.226491
2025-12-12 22:20:40,689 INFO     Training average regularization at step 43800: 0.181349
2025-12-12 22:20:40,690 INFO     Training average positive_sample_loss at step 43800: 0.036796
2025-12-12 22:20:40,690 INFO     Training average negative_sample_loss at step 43800: 0.046960
2025-12-12 22:20:40,693 INFO     Training average loss at step 43800: 0.223227
2025-12-12 22:20:48,108 INFO     Training average regularization at step 43900: 0.181264
2025-12-12 22:20:48,109 INFO     Training average positive_sample_loss at step 43900: 0.034687
2025-12-12 22:20:48,109 INFO     Training average negative_sample_loss at step 43900: 0.050728
2025-12-12 22:20:48,109 INFO     Training average loss at step 43900: 0.223972
2025-12-12 22:21:03,179 INFO     Training average regularization at step 44000: 0.181180
2025-12-12 22:21:03,179 INFO     Training average positive_sample_loss at step 44000: 0.040061
2025-12-12 22:21:03,179 INFO     Training average negative_sample_loss at step 44000: 0.049758
2025-12-12 22:21:03,179 INFO     Training average loss at step 44000: 0.226089
2025-12-12 22:21:10,473 INFO     Training average regularization at step 44100: 0.181098
2025-12-12 22:21:10,474 INFO     Training average positive_sample_loss at step 44100: 0.041001
2025-12-12 22:21:10,474 INFO     Training average negative_sample_loss at step 44100: 0.050476
2025-12-12 22:21:10,474 INFO     Training average loss at step 44100: 0.226836
2025-12-12 22:21:17,765 INFO     Training average regularization at step 44200: 0.181017
2025-12-12 22:21:17,765 INFO     Training average positive_sample_loss at step 44200: 0.041949
2025-12-12 22:21:17,765 INFO     Training average negative_sample_loss at step 44200: 0.054339
2025-12-12 22:21:17,766 INFO     Training average loss at step 44200: 0.229161
2025-12-12 22:21:25,029 INFO     Training average regularization at step 44300: 0.180937
2025-12-12 22:21:25,030 INFO     Training average positive_sample_loss at step 44300: 0.042923
2025-12-12 22:21:25,030 INFO     Training average negative_sample_loss at step 44300: 0.048413
2025-12-12 22:21:25,030 INFO     Training average loss at step 44300: 0.226605
2025-12-12 22:21:32,329 INFO     Training average regularization at step 44400: 0.180858
2025-12-12 22:21:32,329 INFO     Training average positive_sample_loss at step 44400: 0.042103
2025-12-12 22:21:32,329 INFO     Training average negative_sample_loss at step 44400: 0.046729
2025-12-12 22:21:32,329 INFO     Training average loss at step 44400: 0.225274
2025-12-12 22:21:39,700 INFO     Training average regularization at step 44500: 0.180780
2025-12-12 22:21:39,701 INFO     Training average positive_sample_loss at step 44500: 0.043114
2025-12-12 22:21:39,701 INFO     Training average negative_sample_loss at step 44500: 0.052133
2025-12-12 22:21:39,701 INFO     Training average loss at step 44500: 0.228403
2025-12-12 22:21:47,066 INFO     Training average regularization at step 44600: 0.180703
2025-12-12 22:21:47,066 INFO     Training average positive_sample_loss at step 44600: 0.040297
2025-12-12 22:21:47,066 INFO     Training average negative_sample_loss at step 44600: 0.047768
2025-12-12 22:21:47,066 INFO     Training average loss at step 44600: 0.224736
2025-12-12 22:21:54,314 INFO     Training average regularization at step 44700: 0.180627
2025-12-12 22:21:54,315 INFO     Training average positive_sample_loss at step 44700: 0.042782
2025-12-12 22:21:54,315 INFO     Training average negative_sample_loss at step 44700: 0.055481
2025-12-12 22:21:54,315 INFO     Training average loss at step 44700: 0.229758
2025-12-12 22:22:01,546 INFO     Training average regularization at step 44800: 0.180552
2025-12-12 22:22:01,546 INFO     Training average positive_sample_loss at step 44800: 0.041520
2025-12-12 22:22:01,546 INFO     Training average negative_sample_loss at step 44800: 0.049244
2025-12-12 22:22:01,546 INFO     Training average loss at step 44800: 0.225934
2025-12-12 22:22:08,800 INFO     Training average regularization at step 44900: 0.180478
2025-12-12 22:22:08,801 INFO     Training average positive_sample_loss at step 44900: 0.044240
2025-12-12 22:22:08,801 INFO     Training average negative_sample_loss at step 44900: 0.046524
2025-12-12 22:22:08,801 INFO     Training average loss at step 44900: 0.225860
2025-12-12 22:22:16,048 INFO     Training average regularization at step 45000: 0.180406
2025-12-12 22:22:16,048 INFO     Training average positive_sample_loss at step 45000: 0.042808
2025-12-12 22:22:16,048 INFO     Training average negative_sample_loss at step 45000: 0.044491
2025-12-12 22:22:16,049 INFO     Training average loss at step 45000: 0.224055
2025-12-12 22:22:23,260 INFO     Training average regularization at step 45100: 0.180334
2025-12-12 22:22:23,260 INFO     Training average positive_sample_loss at step 45100: 0.043381
2025-12-12 22:22:23,260 INFO     Training average negative_sample_loss at step 45100: 0.051445
2025-12-12 22:22:23,260 INFO     Training average loss at step 45100: 0.227747
2025-12-12 22:22:30,513 INFO     Training average regularization at step 45200: 0.180263
2025-12-12 22:22:30,514 INFO     Training average positive_sample_loss at step 45200: 0.045719
2025-12-12 22:22:30,514 INFO     Training average negative_sample_loss at step 45200: 0.044280
2025-12-12 22:22:30,514 INFO     Training average loss at step 45200: 0.225262
2025-12-12 22:22:37,841 INFO     Training average regularization at step 45300: 0.180192
2025-12-12 22:22:37,841 INFO     Training average positive_sample_loss at step 45300: 0.048953
2025-12-12 22:22:37,841 INFO     Training average negative_sample_loss at step 45300: 0.048903
2025-12-12 22:22:37,841 INFO     Training average loss at step 45300: 0.229120
2025-12-12 22:22:45,172 INFO     Training average regularization at step 45400: 0.180122
2025-12-12 22:22:45,172 INFO     Training average positive_sample_loss at step 45400: 0.048918
2025-12-12 22:22:45,172 INFO     Training average negative_sample_loss at step 45400: 0.045249
2025-12-12 22:22:45,172 INFO     Training average loss at step 45400: 0.227206
2025-12-12 22:22:52,425 INFO     Training average regularization at step 45500: 0.180053
2025-12-12 22:22:52,426 INFO     Training average positive_sample_loss at step 45500: 0.045464
2025-12-12 22:22:52,426 INFO     Training average negative_sample_loss at step 45500: 0.047034
2025-12-12 22:22:52,426 INFO     Training average loss at step 45500: 0.226302
2025-12-12 22:22:59,745 INFO     Training average regularization at step 45600: 0.179984
2025-12-12 22:22:59,745 INFO     Training average positive_sample_loss at step 45600: 0.043364
2025-12-12 22:22:59,745 INFO     Training average negative_sample_loss at step 45600: 0.048665
2025-12-12 22:22:59,745 INFO     Training average loss at step 45600: 0.225999
2025-12-12 22:23:07,049 INFO     Training average regularization at step 45700: 0.179916
2025-12-12 22:23:07,049 INFO     Training average positive_sample_loss at step 45700: 0.042207
2025-12-12 22:23:07,049 INFO     Training average negative_sample_loss at step 45700: 0.048049
2025-12-12 22:23:07,049 INFO     Training average loss at step 45700: 0.225044
2025-12-12 22:23:14,253 INFO     Training average regularization at step 45800: 0.179847
2025-12-12 22:23:14,254 INFO     Training average positive_sample_loss at step 45800: 0.044112
2025-12-12 22:23:14,254 INFO     Training average negative_sample_loss at step 45800: 0.045512
2025-12-12 22:23:14,254 INFO     Training average loss at step 45800: 0.224659
2025-12-12 22:23:21,500 INFO     Training average regularization at step 45900: 0.179780
2025-12-12 22:23:21,500 INFO     Training average positive_sample_loss at step 45900: 0.041758
2025-12-12 22:23:21,500 INFO     Training average negative_sample_loss at step 45900: 0.050254
2025-12-12 22:23:21,500 INFO     Training average loss at step 45900: 0.225786
2025-12-12 22:23:28,757 INFO     Training average regularization at step 46000: 0.179713
2025-12-12 22:23:28,758 INFO     Training average positive_sample_loss at step 46000: 0.041089
2025-12-12 22:23:28,758 INFO     Training average negative_sample_loss at step 46000: 0.048864
2025-12-12 22:23:28,758 INFO     Training average loss at step 46000: 0.224690
2025-12-12 22:23:36,024 INFO     Training average regularization at step 46100: 0.179646
2025-12-12 22:23:36,024 INFO     Training average positive_sample_loss at step 46100: 0.040252
2025-12-12 22:23:36,024 INFO     Training average negative_sample_loss at step 46100: 0.041109
2025-12-12 22:23:36,024 INFO     Training average loss at step 46100: 0.220327
2025-12-12 22:23:43,375 INFO     Training average regularization at step 46200: 0.179580
2025-12-12 22:23:43,376 INFO     Training average positive_sample_loss at step 46200: 0.045887
2025-12-12 22:23:43,376 INFO     Training average negative_sample_loss at step 46200: 0.050006
2025-12-12 22:23:43,376 INFO     Training average loss at step 46200: 0.227527
2025-12-12 22:23:50,653 INFO     Training average regularization at step 46300: 0.179514
2025-12-12 22:23:50,653 INFO     Training average positive_sample_loss at step 46300: 0.043033
2025-12-12 22:23:50,653 INFO     Training average negative_sample_loss at step 46300: 0.044410
2025-12-12 22:23:50,653 INFO     Training average loss at step 46300: 0.223236
2025-12-12 22:23:57,932 INFO     Training average regularization at step 46400: 0.179448
2025-12-12 22:23:57,934 INFO     Training average positive_sample_loss at step 46400: 0.046133
2025-12-12 22:23:57,935 INFO     Training average negative_sample_loss at step 46400: 0.046270
2025-12-12 22:23:57,935 INFO     Training average loss at step 46400: 0.225649
2025-12-12 22:24:05,261 INFO     Training average regularization at step 46500: 0.179383
2025-12-12 22:24:05,262 INFO     Training average positive_sample_loss at step 46500: 0.046825
2025-12-12 22:24:05,262 INFO     Training average negative_sample_loss at step 46500: 0.047442
2025-12-12 22:24:05,262 INFO     Training average loss at step 46500: 0.226517
2025-12-12 22:24:12,536 INFO     Training average regularization at step 46600: 0.179318
2025-12-12 22:24:12,536 INFO     Training average positive_sample_loss at step 46600: 0.044405
2025-12-12 22:24:12,536 INFO     Training average negative_sample_loss at step 46600: 0.047202
2025-12-12 22:24:12,536 INFO     Training average loss at step 46600: 0.225121
2025-12-12 22:24:19,795 INFO     Training average regularization at step 46700: 0.179253
2025-12-12 22:24:19,796 INFO     Training average positive_sample_loss at step 46700: 0.047056
2025-12-12 22:24:19,796 INFO     Training average negative_sample_loss at step 46700: 0.052520
2025-12-12 22:24:19,796 INFO     Training average loss at step 46700: 0.229041
2025-12-12 22:24:27,048 INFO     Training average regularization at step 46800: 0.179189
2025-12-12 22:24:27,049 INFO     Training average positive_sample_loss at step 46800: 0.043905
2025-12-12 22:24:27,049 INFO     Training average negative_sample_loss at step 46800: 0.042063
2025-12-12 22:24:27,049 INFO     Training average loss at step 46800: 0.222173
2025-12-12 22:24:34,319 INFO     Training average regularization at step 46900: 0.179124
2025-12-12 22:24:34,319 INFO     Training average positive_sample_loss at step 46900: 0.041801
2025-12-12 22:24:34,320 INFO     Training average negative_sample_loss at step 46900: 0.041376
2025-12-12 22:24:34,320 INFO     Training average loss at step 46900: 0.220713
2025-12-12 22:24:41,664 INFO     Training average regularization at step 47000: 0.179060
2025-12-12 22:24:41,665 INFO     Training average positive_sample_loss at step 47000: 0.044317
2025-12-12 22:24:41,665 INFO     Training average negative_sample_loss at step 47000: 0.048788
2025-12-12 22:24:41,665 INFO     Training average loss at step 47000: 0.225613
2025-12-12 22:24:48,995 INFO     Training average regularization at step 47100: 0.178997
2025-12-12 22:24:48,996 INFO     Training average positive_sample_loss at step 47100: 0.044982
2025-12-12 22:24:48,996 INFO     Training average negative_sample_loss at step 47100: 0.047817
2025-12-12 22:24:48,996 INFO     Training average loss at step 47100: 0.225396
2025-12-12 22:24:56,283 INFO     Training average regularization at step 47200: 0.178933
2025-12-12 22:24:56,284 INFO     Training average positive_sample_loss at step 47200: 0.045616
2025-12-12 22:24:56,284 INFO     Training average negative_sample_loss at step 47200: 0.046217
2025-12-12 22:24:56,284 INFO     Training average loss at step 47200: 0.224849
2025-12-12 22:25:03,570 INFO     Training average regularization at step 47300: 0.178869
2025-12-12 22:25:03,570 INFO     Training average positive_sample_loss at step 47300: 0.047182
2025-12-12 22:25:03,570 INFO     Training average negative_sample_loss at step 47300: 0.040035
2025-12-12 22:25:03,570 INFO     Training average loss at step 47300: 0.222477
2025-12-12 22:25:10,815 INFO     Training average regularization at step 47400: 0.178806
2025-12-12 22:25:10,816 INFO     Training average positive_sample_loss at step 47400: 0.048492
2025-12-12 22:25:10,816 INFO     Training average negative_sample_loss at step 47400: 0.043877
2025-12-12 22:25:10,816 INFO     Training average loss at step 47400: 0.224991
2025-12-12 22:25:18,087 INFO     Training average regularization at step 47500: 0.178743
2025-12-12 22:25:18,087 INFO     Training average positive_sample_loss at step 47500: 0.042806
2025-12-12 22:25:18,087 INFO     Training average negative_sample_loss at step 47500: 0.049360
2025-12-12 22:25:18,087 INFO     Training average loss at step 47500: 0.224826
2025-12-12 22:25:25,328 INFO     Training average regularization at step 47600: 0.178680
2025-12-12 22:25:25,333 INFO     Training average positive_sample_loss at step 47600: 0.042339
2025-12-12 22:25:25,333 INFO     Training average negative_sample_loss at step 47600: 0.050373
2025-12-12 22:25:25,333 INFO     Training average loss at step 47600: 0.225036
2025-12-12 22:25:32,554 INFO     Training average regularization at step 47700: 0.178618
2025-12-12 22:25:32,555 INFO     Training average positive_sample_loss at step 47700: 0.044885
2025-12-12 22:25:32,555 INFO     Training average negative_sample_loss at step 47700: 0.051199
2025-12-12 22:25:32,555 INFO     Training average loss at step 47700: 0.226660
2025-12-12 22:25:39,843 INFO     Training average regularization at step 47800: 0.178555
2025-12-12 22:25:39,843 INFO     Training average positive_sample_loss at step 47800: 0.044789
2025-12-12 22:25:39,843 INFO     Training average negative_sample_loss at step 47800: 0.046352
2025-12-12 22:25:39,843 INFO     Training average loss at step 47800: 0.224126
2025-12-12 22:25:47,185 INFO     Training average regularization at step 47900: 0.178493
2025-12-12 22:25:47,185 INFO     Training average positive_sample_loss at step 47900: 0.047280
2025-12-12 22:25:47,185 INFO     Training average negative_sample_loss at step 47900: 0.044317
2025-12-12 22:25:47,186 INFO     Training average loss at step 47900: 0.224292
2025-12-12 22:26:02,036 INFO     Training average regularization at step 48000: 0.178431
2025-12-12 22:26:02,037 INFO     Training average positive_sample_loss at step 48000: 0.043791
2025-12-12 22:26:02,037 INFO     Training average negative_sample_loss at step 48000: 0.040118
2025-12-12 22:26:02,037 INFO     Training average loss at step 48000: 0.220385
2025-12-12 22:26:09,297 INFO     Training average regularization at step 48100: 0.178369
2025-12-12 22:26:09,298 INFO     Training average positive_sample_loss at step 48100: 0.043558
2025-12-12 22:26:09,298 INFO     Training average negative_sample_loss at step 48100: 0.042798
2025-12-12 22:26:09,298 INFO     Training average loss at step 48100: 0.221547
2025-12-12 22:26:16,561 INFO     Training average regularization at step 48200: 0.178306
2025-12-12 22:26:16,562 INFO     Training average positive_sample_loss at step 48200: 0.042237
2025-12-12 22:26:16,562 INFO     Training average negative_sample_loss at step 48200: 0.048483
2025-12-12 22:26:16,562 INFO     Training average loss at step 48200: 0.223666
2025-12-12 22:26:23,785 INFO     Training average regularization at step 48300: 0.178244
2025-12-12 22:26:23,786 INFO     Training average positive_sample_loss at step 48300: 0.046220
2025-12-12 22:26:23,786 INFO     Training average negative_sample_loss at step 48300: 0.044123
2025-12-12 22:26:23,786 INFO     Training average loss at step 48300: 0.223416
2025-12-12 22:26:30,998 INFO     Training average regularization at step 48400: 0.178182
2025-12-12 22:26:30,999 INFO     Training average positive_sample_loss at step 48400: 0.044170
2025-12-12 22:26:30,999 INFO     Training average negative_sample_loss at step 48400: 0.047344
2025-12-12 22:26:30,999 INFO     Training average loss at step 48400: 0.223939
2025-12-12 22:26:38,257 INFO     Training average regularization at step 48500: 0.178120
2025-12-12 22:26:38,257 INFO     Training average positive_sample_loss at step 48500: 0.043807
2025-12-12 22:26:38,257 INFO     Training average negative_sample_loss at step 48500: 0.041139
2025-12-12 22:26:38,257 INFO     Training average loss at step 48500: 0.220594
2025-12-12 22:26:45,616 INFO     Training average regularization at step 48600: 0.178058
2025-12-12 22:26:45,616 INFO     Training average positive_sample_loss at step 48600: 0.043808
2025-12-12 22:26:45,616 INFO     Training average negative_sample_loss at step 48600: 0.042628
2025-12-12 22:26:45,616 INFO     Training average loss at step 48600: 0.221276
2025-12-12 22:26:52,873 INFO     Training average regularization at step 48700: 0.177996
2025-12-12 22:26:52,873 INFO     Training average positive_sample_loss at step 48700: 0.046683
2025-12-12 22:26:52,873 INFO     Training average negative_sample_loss at step 48700: 0.043928
2025-12-12 22:26:52,873 INFO     Training average loss at step 48700: 0.223302
2025-12-12 22:27:00,122 INFO     Training average regularization at step 48800: 0.177934
2025-12-12 22:27:00,123 INFO     Training average positive_sample_loss at step 48800: 0.043985
2025-12-12 22:27:00,123 INFO     Training average negative_sample_loss at step 48800: 0.051978
2025-12-12 22:27:00,123 INFO     Training average loss at step 48800: 0.225916
2025-12-12 22:27:07,380 INFO     Training average regularization at step 48900: 0.177872
2025-12-12 22:27:07,380 INFO     Training average positive_sample_loss at step 48900: 0.043717
2025-12-12 22:27:07,380 INFO     Training average negative_sample_loss at step 48900: 0.054043
2025-12-12 22:27:07,380 INFO     Training average loss at step 48900: 0.226752
2025-12-12 22:27:14,604 INFO     Training average regularization at step 49000: 0.177810
2025-12-12 22:27:14,605 INFO     Training average positive_sample_loss at step 49000: 0.046297
2025-12-12 22:27:14,605 INFO     Training average negative_sample_loss at step 49000: 0.048218
2025-12-12 22:27:14,605 INFO     Training average loss at step 49000: 0.225068
2025-12-12 22:27:21,847 INFO     Training average regularization at step 49100: 0.177748
2025-12-12 22:27:21,848 INFO     Training average positive_sample_loss at step 49100: 0.041777
2025-12-12 22:27:21,848 INFO     Training average negative_sample_loss at step 49100: 0.042257
2025-12-12 22:27:21,848 INFO     Training average loss at step 49100: 0.219765
2025-12-12 22:27:29,102 INFO     Training average regularization at step 49200: 0.177686
2025-12-12 22:27:29,102 INFO     Training average positive_sample_loss at step 49200: 0.049221
2025-12-12 22:27:29,102 INFO     Training average negative_sample_loss at step 49200: 0.047264
2025-12-12 22:27:29,102 INFO     Training average loss at step 49200: 0.225928
2025-12-12 22:27:36,344 INFO     Training average regularization at step 49300: 0.177625
2025-12-12 22:27:36,344 INFO     Training average positive_sample_loss at step 49300: 0.046105
2025-12-12 22:27:36,344 INFO     Training average negative_sample_loss at step 49300: 0.040913
2025-12-12 22:27:36,344 INFO     Training average loss at step 49300: 0.221133
2025-12-12 22:27:43,754 INFO     Training average regularization at step 49400: 0.177563
2025-12-12 22:27:43,754 INFO     Training average positive_sample_loss at step 49400: 0.041550
2025-12-12 22:27:43,754 INFO     Training average negative_sample_loss at step 49400: 0.040146
2025-12-12 22:27:43,755 INFO     Training average loss at step 49400: 0.218411
2025-12-12 22:27:51,038 INFO     Training average regularization at step 49500: 0.177502
2025-12-12 22:27:51,039 INFO     Training average positive_sample_loss at step 49500: 0.044285
2025-12-12 22:27:51,039 INFO     Training average negative_sample_loss at step 49500: 0.038371
2025-12-12 22:27:51,039 INFO     Training average loss at step 49500: 0.218830
2025-12-12 22:27:58,299 INFO     Training average regularization at step 49600: 0.177441
2025-12-12 22:27:58,299 INFO     Training average positive_sample_loss at step 49600: 0.044023
2025-12-12 22:27:58,299 INFO     Training average negative_sample_loss at step 49600: 0.043344
2025-12-12 22:27:58,300 INFO     Training average loss at step 49600: 0.221125
2025-12-12 22:28:05,577 INFO     Training average regularization at step 49700: 0.177379
2025-12-12 22:28:05,577 INFO     Training average positive_sample_loss at step 49700: 0.043720
2025-12-12 22:28:05,577 INFO     Training average negative_sample_loss at step 49700: 0.047224
2025-12-12 22:28:05,577 INFO     Training average loss at step 49700: 0.222851
2025-12-12 22:28:12,851 INFO     Training average regularization at step 49800: 0.177318
2025-12-12 22:28:12,852 INFO     Training average positive_sample_loss at step 49800: 0.044275
2025-12-12 22:28:12,852 INFO     Training average negative_sample_loss at step 49800: 0.046557
2025-12-12 22:28:12,852 INFO     Training average loss at step 49800: 0.222734
2025-12-12 22:28:20,136 INFO     Training average regularization at step 49900: 0.177257
2025-12-12 22:28:20,136 INFO     Training average positive_sample_loss at step 49900: 0.040769
2025-12-12 22:28:20,136 INFO     Training average negative_sample_loss at step 49900: 0.044396
2025-12-12 22:28:20,137 INFO     Training average loss at step 49900: 0.219839
2025-12-12 22:28:27,410 INFO     Training average regularization at step 50000: 0.177194
2025-12-12 22:28:27,411 INFO     Training average positive_sample_loss at step 50000: 0.043260
2025-12-12 22:28:27,411 INFO     Training average negative_sample_loss at step 50000: 0.043747
2025-12-12 22:28:27,411 INFO     Training average loss at step 50000: 0.220698
2025-12-12 22:28:27,411 INFO     Evaluating on Valid Dataset...
2025-12-12 22:28:29,856 INFO     Evaluating the model... (0/5000)
2025-12-12 22:28:37,799 INFO     Evaluating the model... (100/5000)
2025-12-12 22:28:45,047 INFO     Evaluating the model... (200/5000)
2025-12-12 22:28:52,482 INFO     Evaluating the model... (300/5000)
2025-12-12 22:28:59,557 INFO     Evaluating the model... (400/5000)
2025-12-12 22:29:07,231 INFO     Evaluating the model... (500/5000)
2025-12-12 22:29:14,394 INFO     Evaluating the model... (600/5000)
2025-12-12 22:29:21,489 INFO     Evaluating the model... (700/5000)
2025-12-12 22:29:28,571 INFO     Evaluating the model... (800/5000)
2025-12-12 22:29:35,639 INFO     Evaluating the model... (900/5000)
2025-12-12 22:29:42,854 INFO     Evaluating the model... (1000/5000)
2025-12-12 22:29:50,006 INFO     Evaluating the model... (1100/5000)
2025-12-12 22:29:57,130 INFO     Evaluating the model... (1200/5000)
2025-12-12 22:30:04,215 INFO     Evaluating the model... (1300/5000)
2025-12-12 22:30:11,271 INFO     Evaluating the model... (1400/5000)
2025-12-12 22:30:18,320 INFO     Evaluating the model... (1500/5000)
2025-12-12 22:30:25,376 INFO     Evaluating the model... (1600/5000)
2025-12-12 22:30:32,422 INFO     Evaluating the model... (1700/5000)
2025-12-12 22:30:39,544 INFO     Evaluating the model... (1800/5000)
2025-12-12 22:30:46,693 INFO     Evaluating the model... (1900/5000)
2025-12-12 22:30:53,811 INFO     Evaluating the model... (2000/5000)
2025-12-12 22:31:00,870 INFO     Evaluating the model... (2100/5000)
2025-12-12 22:31:07,917 INFO     Evaluating the model... (2200/5000)
2025-12-12 22:31:14,991 INFO     Evaluating the model... (2300/5000)
2025-12-12 22:31:22,037 INFO     Evaluating the model... (2400/5000)
2025-12-12 22:31:31,869 INFO     Evaluating the model... (2500/5000)
2025-12-12 22:31:39,054 INFO     Evaluating the model... (2600/5000)
2025-12-12 22:31:46,249 INFO     Evaluating the model... (2700/5000)
2025-12-12 22:31:53,340 INFO     Evaluating the model... (2800/5000)
2025-12-12 22:32:00,475 INFO     Evaluating the model... (2900/5000)
2025-12-12 22:32:07,610 INFO     Evaluating the model... (3000/5000)
2025-12-12 22:32:14,820 INFO     Evaluating the model... (3100/5000)
2025-12-12 22:32:21,937 INFO     Evaluating the model... (3200/5000)
2025-12-12 22:32:29,032 INFO     Evaluating the model... (3300/5000)
2025-12-12 22:32:36,134 INFO     Evaluating the model... (3400/5000)
2025-12-12 22:32:43,297 INFO     Evaluating the model... (3500/5000)
2025-12-12 22:32:50,451 INFO     Evaluating the model... (3600/5000)
2025-12-12 22:32:57,601 INFO     Evaluating the model... (3700/5000)
2025-12-12 22:33:04,742 INFO     Evaluating the model... (3800/5000)
2025-12-12 22:33:11,877 INFO     Evaluating the model... (3900/5000)
2025-12-12 22:33:19,041 INFO     Evaluating the model... (4000/5000)
2025-12-12 22:33:26,204 INFO     Evaluating the model... (4100/5000)
2025-12-12 22:33:33,332 INFO     Evaluating the model... (4200/5000)
2025-12-12 22:33:40,551 INFO     Evaluating the model... (4300/5000)
2025-12-12 22:33:47,715 INFO     Evaluating the model... (4400/5000)
2025-12-12 22:33:54,849 INFO     Evaluating the model... (4500/5000)
2025-12-12 22:34:01,965 INFO     Evaluating the model... (4600/5000)
2025-12-12 22:34:09,068 INFO     Evaluating the model... (4700/5000)
2025-12-12 22:34:16,163 INFO     Evaluating the model... (4800/5000)
2025-12-12 22:34:23,299 INFO     Evaluating the model... (4900/5000)
2025-12-12 22:34:32,206 INFO     Valid MRR at step 50000: 0.406224
2025-12-12 22:34:32,206 INFO     Valid MR at step 50000: 8970.602600
2025-12-12 22:34:32,206 INFO     Valid HITS@1 at step 50000: 0.312300
2025-12-12 22:34:32,206 INFO     Valid HITS@3 at step 50000: 0.463600
2025-12-12 22:34:32,207 INFO     Valid HITS@10 at step 50000: 0.576700
2025-12-12 22:34:32,207 INFO     Evaluating on Test Dataset...
2025-12-12 22:34:33,454 INFO     Evaluating the model... (0/5000)
2025-12-12 22:34:40,781 INFO     Evaluating the model... (100/5000)
2025-12-12 22:34:47,946 INFO     Evaluating the model... (200/5000)
2025-12-12 22:34:55,034 INFO     Evaluating the model... (300/5000)
2025-12-12 22:35:02,104 INFO     Evaluating the model... (400/5000)
2025-12-12 22:35:09,206 INFO     Evaluating the model... (500/5000)
2025-12-12 22:35:16,269 INFO     Evaluating the model... (600/5000)
2025-12-12 22:35:23,373 INFO     Evaluating the model... (700/5000)
2025-12-12 22:35:30,444 INFO     Evaluating the model... (800/5000)
2025-12-12 22:35:37,548 INFO     Evaluating the model... (900/5000)
2025-12-12 22:35:44,727 INFO     Evaluating the model... (1000/5000)
2025-12-12 22:35:51,787 INFO     Evaluating the model... (1100/5000)
2025-12-12 22:35:58,844 INFO     Evaluating the model... (1200/5000)
2025-12-12 22:36:05,972 INFO     Evaluating the model... (1300/5000)
2025-12-12 22:36:13,065 INFO     Evaluating the model... (1400/5000)
2025-12-12 22:36:20,178 INFO     Evaluating the model... (1500/5000)
2025-12-12 22:36:27,250 INFO     Evaluating the model... (1600/5000)
2025-12-12 22:36:34,326 INFO     Evaluating the model... (1700/5000)
2025-12-12 22:36:41,499 INFO     Evaluating the model... (1800/5000)
2025-12-12 22:36:48,613 INFO     Evaluating the model... (1900/5000)
2025-12-12 22:36:55,701 INFO     Evaluating the model... (2000/5000)
2025-12-12 22:37:02,785 INFO     Evaluating the model... (2100/5000)
2025-12-12 22:37:09,889 INFO     Evaluating the model... (2200/5000)
2025-12-12 22:37:17,016 INFO     Evaluating the model... (2300/5000)
2025-12-12 22:37:25,526 INFO     Evaluating the model... (2400/5000)
2025-12-12 22:37:33,388 INFO     Evaluating the model... (2500/5000)
2025-12-12 22:37:40,650 INFO     Evaluating the model... (2600/5000)
2025-12-12 22:37:47,790 INFO     Evaluating the model... (2700/5000)
2025-12-12 22:37:54,900 INFO     Evaluating the model... (2800/5000)
2025-12-12 22:38:02,003 INFO     Evaluating the model... (2900/5000)
2025-12-12 22:38:09,133 INFO     Evaluating the model... (3000/5000)
2025-12-12 22:38:16,303 INFO     Evaluating the model... (3100/5000)
2025-12-12 22:38:23,458 INFO     Evaluating the model... (3200/5000)
2025-12-12 22:38:30,613 INFO     Evaluating the model... (3300/5000)
2025-12-12 22:38:37,761 INFO     Evaluating the model... (3400/5000)
2025-12-12 22:38:45,023 INFO     Evaluating the model... (3500/5000)
2025-12-12 22:38:52,172 INFO     Evaluating the model... (3600/5000)
2025-12-12 22:38:59,276 INFO     Evaluating the model... (3700/5000)
2025-12-12 22:39:06,393 INFO     Evaluating the model... (3800/5000)
2025-12-12 22:39:13,504 INFO     Evaluating the model... (3900/5000)
2025-12-12 22:39:20,599 INFO     Evaluating the model... (4000/5000)
2025-12-12 22:39:27,687 INFO     Evaluating the model... (4100/5000)
2025-12-12 22:39:34,793 INFO     Evaluating the model... (4200/5000)
2025-12-12 22:39:41,980 INFO     Evaluating the model... (4300/5000)
2025-12-12 22:39:49,099 INFO     Evaluating the model... (4400/5000)
2025-12-12 22:39:56,224 INFO     Evaluating the model... (4500/5000)
2025-12-12 22:40:03,352 INFO     Evaluating the model... (4600/5000)
2025-12-12 22:40:10,503 INFO     Evaluating the model... (4700/5000)
2025-12-12 22:40:19,913 INFO     Evaluating the model... (4800/5000)
2025-12-12 22:40:27,009 INFO     Evaluating the model... (4900/5000)
2025-12-12 22:40:34,511 INFO     Test MRR at step 50000: 0.414222
2025-12-12 22:40:34,512 INFO     Test MR at step 50000: 9374.144300
2025-12-12 22:40:34,512 INFO     Test HITS@1 at step 50000: 0.323000
2025-12-12 22:40:34,512 INFO     Test HITS@3 at step 50000: 0.471700
2025-12-12 22:40:34,512 INFO     Test HITS@10 at step 50000: 0.578600
2025-12-12 22:40:41,873 INFO     Training average regularization at step 50100: 0.177133
2025-12-12 22:40:41,881 INFO     Training average positive_sample_loss at step 50100: 0.044080
2025-12-12 22:40:41,881 INFO     Training average negative_sample_loss at step 50100: 0.044990
2025-12-12 22:40:41,881 INFO     Training average loss at step 50100: 0.221668
2025-12-12 22:40:49,171 INFO     Training average regularization at step 50200: 0.177071
2025-12-12 22:40:49,172 INFO     Training average positive_sample_loss at step 50200: 0.043066
2025-12-12 22:40:49,172 INFO     Training average negative_sample_loss at step 50200: 0.042545
2025-12-12 22:40:49,172 INFO     Training average loss at step 50200: 0.219876
2025-12-12 22:40:56,413 INFO     Training average regularization at step 50300: 0.177009
2025-12-12 22:40:56,413 INFO     Training average positive_sample_loss at step 50300: 0.044370
2025-12-12 22:40:56,414 INFO     Training average negative_sample_loss at step 50300: 0.055524
2025-12-12 22:40:56,414 INFO     Training average loss at step 50300: 0.226956
2025-12-12 22:41:03,674 INFO     Training average regularization at step 50400: 0.176947
2025-12-12 22:41:03,674 INFO     Training average positive_sample_loss at step 50400: 0.043605
2025-12-12 22:41:03,675 INFO     Training average negative_sample_loss at step 50400: 0.047476
2025-12-12 22:41:03,675 INFO     Training average loss at step 50400: 0.222488
2025-12-12 22:41:10,895 INFO     Training average regularization at step 50500: 0.176886
2025-12-12 22:41:10,896 INFO     Training average positive_sample_loss at step 50500: 0.048996
2025-12-12 22:41:10,896 INFO     Training average negative_sample_loss at step 50500: 0.047789
2025-12-12 22:41:10,896 INFO     Training average loss at step 50500: 0.225279
2025-12-12 22:41:18,122 INFO     Training average regularization at step 50600: 0.176825
2025-12-12 22:41:18,122 INFO     Training average positive_sample_loss at step 50600: 0.045725
2025-12-12 22:41:18,122 INFO     Training average negative_sample_loss at step 50600: 0.040789
2025-12-12 22:41:18,122 INFO     Training average loss at step 50600: 0.220082
2025-12-12 22:41:25,353 INFO     Training average regularization at step 50700: 0.176764
2025-12-12 22:41:25,353 INFO     Training average positive_sample_loss at step 50700: 0.041902
2025-12-12 22:41:25,353 INFO     Training average negative_sample_loss at step 50700: 0.046995
2025-12-12 22:41:25,353 INFO     Training average loss at step 50700: 0.221212
2025-12-12 22:41:32,604 INFO     Training average regularization at step 50800: 0.176702
2025-12-12 22:41:32,605 INFO     Training average positive_sample_loss at step 50800: 0.043651
2025-12-12 22:41:32,605 INFO     Training average negative_sample_loss at step 50800: 0.041761
2025-12-12 22:41:32,605 INFO     Training average loss at step 50800: 0.219408
2025-12-12 22:41:39,967 INFO     Training average regularization at step 50900: 0.176641
2025-12-12 22:41:39,967 INFO     Training average positive_sample_loss at step 50900: 0.044744
2025-12-12 22:41:39,967 INFO     Training average negative_sample_loss at step 50900: 0.044703
2025-12-12 22:41:39,968 INFO     Training average loss at step 50900: 0.221365
2025-12-12 22:41:47,287 INFO     Training average regularization at step 51000: 0.176580
2025-12-12 22:41:47,287 INFO     Training average positive_sample_loss at step 51000: 0.044167
2025-12-12 22:41:47,287 INFO     Training average negative_sample_loss at step 51000: 0.046067
2025-12-12 22:41:47,287 INFO     Training average loss at step 51000: 0.221697
2025-12-12 22:41:54,553 INFO     Training average regularization at step 51100: 0.176519
2025-12-12 22:41:54,553 INFO     Training average positive_sample_loss at step 51100: 0.042561
2025-12-12 22:41:54,553 INFO     Training average negative_sample_loss at step 51100: 0.044583
2025-12-12 22:41:54,553 INFO     Training average loss at step 51100: 0.220091
2025-12-12 22:42:01,788 INFO     Training average regularization at step 51200: 0.176458
2025-12-12 22:42:01,789 INFO     Training average positive_sample_loss at step 51200: 0.045003
2025-12-12 22:42:01,789 INFO     Training average negative_sample_loss at step 51200: 0.043240
2025-12-12 22:42:01,789 INFO     Training average loss at step 51200: 0.220579
2025-12-12 22:42:09,029 INFO     Training average regularization at step 51300: 0.176397
2025-12-12 22:42:09,030 INFO     Training average positive_sample_loss at step 51300: 0.042014
2025-12-12 22:42:09,030 INFO     Training average negative_sample_loss at step 51300: 0.043829
2025-12-12 22:42:09,030 INFO     Training average loss at step 51300: 0.219318
2025-12-12 22:42:16,344 INFO     Training average regularization at step 51400: 0.176335
2025-12-12 22:42:16,344 INFO     Training average positive_sample_loss at step 51400: 0.041570
2025-12-12 22:42:16,344 INFO     Training average negative_sample_loss at step 51400: 0.041652
2025-12-12 22:42:16,344 INFO     Training average loss at step 51400: 0.217946
2025-12-12 22:42:23,695 INFO     Training average regularization at step 51500: 0.176273
2025-12-12 22:42:23,695 INFO     Training average positive_sample_loss at step 51500: 0.044098
2025-12-12 22:42:23,695 INFO     Training average negative_sample_loss at step 51500: 0.042481
2025-12-12 22:42:23,695 INFO     Training average loss at step 51500: 0.219563
2025-12-12 22:42:31,040 INFO     Training average regularization at step 51600: 0.176212
2025-12-12 22:42:31,041 INFO     Training average positive_sample_loss at step 51600: 0.044471
2025-12-12 22:42:31,041 INFO     Training average negative_sample_loss at step 51600: 0.039264
2025-12-12 22:42:31,041 INFO     Training average loss at step 51600: 0.218080
2025-12-12 22:42:38,370 INFO     Training average regularization at step 51700: 0.176151
2025-12-12 22:42:38,370 INFO     Training average positive_sample_loss at step 51700: 0.042124
2025-12-12 22:42:38,370 INFO     Training average negative_sample_loss at step 51700: 0.039238
2025-12-12 22:42:38,370 INFO     Training average loss at step 51700: 0.216831
2025-12-12 22:42:45,772 INFO     Training average regularization at step 51800: 0.176089
2025-12-12 22:42:45,773 INFO     Training average positive_sample_loss at step 51800: 0.041942
2025-12-12 22:42:45,773 INFO     Training average negative_sample_loss at step 51800: 0.049623
2025-12-12 22:42:45,773 INFO     Training average loss at step 51800: 0.221871
2025-12-12 22:42:53,053 INFO     Training average regularization at step 51900: 0.176027
2025-12-12 22:42:53,054 INFO     Training average positive_sample_loss at step 51900: 0.047642
2025-12-12 22:42:53,054 INFO     Training average negative_sample_loss at step 51900: 0.048680
2025-12-12 22:42:53,054 INFO     Training average loss at step 51900: 0.224188
2025-12-12 22:43:08,196 INFO     Training average regularization at step 52000: 0.175966
2025-12-12 22:43:08,196 INFO     Training average positive_sample_loss at step 52000: 0.041243
2025-12-12 22:43:08,196 INFO     Training average negative_sample_loss at step 52000: 0.042941
2025-12-12 22:43:08,196 INFO     Training average loss at step 52000: 0.218058
2025-12-12 22:43:15,575 INFO     Training average regularization at step 52100: 0.175904
2025-12-12 22:43:15,576 INFO     Training average positive_sample_loss at step 52100: 0.044488
2025-12-12 22:43:15,576 INFO     Training average negative_sample_loss at step 52100: 0.040958
2025-12-12 22:43:15,576 INFO     Training average loss at step 52100: 0.218627
2025-12-12 22:43:22,931 INFO     Training average regularization at step 52200: 0.175843
2025-12-12 22:43:22,932 INFO     Training average positive_sample_loss at step 52200: 0.043221
2025-12-12 22:43:22,932 INFO     Training average negative_sample_loss at step 52200: 0.039628
2025-12-12 22:43:22,932 INFO     Training average loss at step 52200: 0.217267
2025-12-12 22:43:30,251 INFO     Training average regularization at step 52300: 0.175781
2025-12-12 22:43:30,253 INFO     Training average positive_sample_loss at step 52300: 0.042138
2025-12-12 22:43:30,253 INFO     Training average negative_sample_loss at step 52300: 0.040262
2025-12-12 22:43:30,253 INFO     Training average loss at step 52300: 0.216981
2025-12-12 22:43:37,559 INFO     Training average regularization at step 52400: 0.175720
2025-12-12 22:43:37,560 INFO     Training average positive_sample_loss at step 52400: 0.042995
2025-12-12 22:43:37,560 INFO     Training average negative_sample_loss at step 52400: 0.045103
2025-12-12 22:43:37,560 INFO     Training average loss at step 52400: 0.219769
2025-12-12 22:43:44,999 INFO     Training average regularization at step 52500: 0.175658
2025-12-12 22:43:45,000 INFO     Training average positive_sample_loss at step 52500: 0.046031
2025-12-12 22:43:45,000 INFO     Training average negative_sample_loss at step 52500: 0.048194
2025-12-12 22:43:45,000 INFO     Training average loss at step 52500: 0.222771
2025-12-12 22:43:52,240 INFO     Training average regularization at step 52600: 0.175596
2025-12-12 22:43:52,240 INFO     Training average positive_sample_loss at step 52600: 0.044797
2025-12-12 22:43:52,240 INFO     Training average negative_sample_loss at step 52600: 0.043965
2025-12-12 22:43:52,240 INFO     Training average loss at step 52600: 0.219977
2025-12-12 22:43:59,478 INFO     Training average regularization at step 52700: 0.175535
2025-12-12 22:43:59,479 INFO     Training average positive_sample_loss at step 52700: 0.047209
2025-12-12 22:43:59,479 INFO     Training average negative_sample_loss at step 52700: 0.043677
2025-12-12 22:43:59,479 INFO     Training average loss at step 52700: 0.220978
2025-12-12 22:44:06,772 INFO     Training average regularization at step 52800: 0.175473
2025-12-12 22:44:06,773 INFO     Training average positive_sample_loss at step 52800: 0.042726
2025-12-12 22:44:06,773 INFO     Training average negative_sample_loss at step 52800: 0.050467
2025-12-12 22:44:06,773 INFO     Training average loss at step 52800: 0.222069
2025-12-12 22:44:14,136 INFO     Training average regularization at step 52900: 0.175412
2025-12-12 22:44:14,142 INFO     Training average positive_sample_loss at step 52900: 0.043214
2025-12-12 22:44:14,142 INFO     Training average negative_sample_loss at step 52900: 0.042213
2025-12-12 22:44:14,142 INFO     Training average loss at step 52900: 0.218125
2025-12-12 22:44:21,419 INFO     Training average regularization at step 53000: 0.175350
2025-12-12 22:44:21,420 INFO     Training average positive_sample_loss at step 53000: 0.041495
2025-12-12 22:44:21,420 INFO     Training average negative_sample_loss at step 53000: 0.043536
2025-12-12 22:44:21,420 INFO     Training average loss at step 53000: 0.217866
2025-12-12 22:44:28,635 INFO     Training average regularization at step 53100: 0.175288
2025-12-12 22:44:28,635 INFO     Training average positive_sample_loss at step 53100: 0.045890
2025-12-12 22:44:28,635 INFO     Training average negative_sample_loss at step 53100: 0.042849
2025-12-12 22:44:28,635 INFO     Training average loss at step 53100: 0.219657
2025-12-12 22:44:35,870 INFO     Training average regularization at step 53200: 0.175226
2025-12-12 22:44:35,870 INFO     Training average positive_sample_loss at step 53200: 0.042881
2025-12-12 22:44:35,870 INFO     Training average negative_sample_loss at step 53200: 0.036953
2025-12-12 22:44:35,870 INFO     Training average loss at step 53200: 0.215143
2025-12-12 22:44:43,247 INFO     Training average regularization at step 53300: 0.175164
2025-12-12 22:44:43,248 INFO     Training average positive_sample_loss at step 53300: 0.044370
2025-12-12 22:44:43,248 INFO     Training average negative_sample_loss at step 53300: 0.040191
2025-12-12 22:44:43,248 INFO     Training average loss at step 53300: 0.217445
2025-12-12 22:44:50,554 INFO     Training average regularization at step 53400: 0.175103
2025-12-12 22:44:50,554 INFO     Training average positive_sample_loss at step 53400: 0.044473
2025-12-12 22:44:50,554 INFO     Training average negative_sample_loss at step 53400: 0.042139
2025-12-12 22:44:50,554 INFO     Training average loss at step 53400: 0.218409
2025-12-12 22:44:57,786 INFO     Training average regularization at step 53500: 0.175041
2025-12-12 22:44:57,787 INFO     Training average positive_sample_loss at step 53500: 0.043774
2025-12-12 22:44:57,787 INFO     Training average negative_sample_loss at step 53500: 0.042951
2025-12-12 22:44:57,787 INFO     Training average loss at step 53500: 0.218404
2025-12-12 22:45:04,998 INFO     Training average regularization at step 53600: 0.174980
2025-12-12 22:45:04,999 INFO     Training average positive_sample_loss at step 53600: 0.042622
2025-12-12 22:45:04,999 INFO     Training average negative_sample_loss at step 53600: 0.041471
2025-12-12 22:45:04,999 INFO     Training average loss at step 53600: 0.217026
2025-12-12 22:45:12,250 INFO     Training average regularization at step 53700: 0.174918
2025-12-12 22:45:12,251 INFO     Training average positive_sample_loss at step 53700: 0.041707
2025-12-12 22:45:12,251 INFO     Training average negative_sample_loss at step 53700: 0.045892
2025-12-12 22:45:12,251 INFO     Training average loss at step 53700: 0.218717
2025-12-12 22:45:19,488 INFO     Training average regularization at step 53800: 0.174856
2025-12-12 22:45:19,489 INFO     Training average positive_sample_loss at step 53800: 0.042093
2025-12-12 22:45:19,489 INFO     Training average negative_sample_loss at step 53800: 0.046051
2025-12-12 22:45:19,489 INFO     Training average loss at step 53800: 0.218928
2025-12-12 22:45:26,774 INFO     Training average regularization at step 53900: 0.174794
2025-12-12 22:45:26,774 INFO     Training average positive_sample_loss at step 53900: 0.047041
2025-12-12 22:45:26,774 INFO     Training average negative_sample_loss at step 53900: 0.045819
2025-12-12 22:45:26,774 INFO     Training average loss at step 53900: 0.221224
2025-12-12 22:45:35,648 INFO     Training average regularization at step 54000: 0.174732
2025-12-12 22:45:35,655 INFO     Training average positive_sample_loss at step 54000: 0.040885
2025-12-12 22:45:35,655 INFO     Training average negative_sample_loss at step 54000: 0.042948
2025-12-12 22:45:35,655 INFO     Training average loss at step 54000: 0.216649
2025-12-12 22:45:43,050 INFO     Training average regularization at step 54100: 0.174669
2025-12-12 22:45:43,050 INFO     Training average positive_sample_loss at step 54100: 0.034611
2025-12-12 22:45:43,050 INFO     Training average negative_sample_loss at step 54100: 0.041828
2025-12-12 22:45:43,050 INFO     Training average loss at step 54100: 0.212888
2025-12-12 22:45:50,369 INFO     Training average regularization at step 54200: 0.174605
2025-12-12 22:45:50,370 INFO     Training average positive_sample_loss at step 54200: 0.032489
2025-12-12 22:45:50,370 INFO     Training average negative_sample_loss at step 54200: 0.045335
2025-12-12 22:45:50,370 INFO     Training average loss at step 54200: 0.213517
2025-12-12 22:45:57,634 INFO     Training average regularization at step 54300: 0.174542
2025-12-12 22:45:57,635 INFO     Training average positive_sample_loss at step 54300: 0.031037
2025-12-12 22:45:57,635 INFO     Training average negative_sample_loss at step 54300: 0.038911
2025-12-12 22:45:57,635 INFO     Training average loss at step 54300: 0.209515
2025-12-12 22:46:04,939 INFO     Training average regularization at step 54400: 0.174477
2025-12-12 22:46:04,940 INFO     Training average positive_sample_loss at step 54400: 0.032508
2025-12-12 22:46:04,940 INFO     Training average negative_sample_loss at step 54400: 0.041341
2025-12-12 22:46:04,940 INFO     Training average loss at step 54400: 0.211402
2025-12-12 22:46:12,194 INFO     Training average regularization at step 54500: 0.174413
2025-12-12 22:46:12,195 INFO     Training average positive_sample_loss at step 54500: 0.031908
2025-12-12 22:46:12,195 INFO     Training average negative_sample_loss at step 54500: 0.041500
2025-12-12 22:46:12,195 INFO     Training average loss at step 54500: 0.211117
2025-12-12 22:46:19,446 INFO     Training average regularization at step 54600: 0.174349
2025-12-12 22:46:19,447 INFO     Training average positive_sample_loss at step 54600: 0.038535
2025-12-12 22:46:19,447 INFO     Training average negative_sample_loss at step 54600: 0.038432
2025-12-12 22:46:19,447 INFO     Training average loss at step 54600: 0.212832
2025-12-12 22:46:26,686 INFO     Training average regularization at step 54700: 0.174284
2025-12-12 22:46:26,686 INFO     Training average positive_sample_loss at step 54700: 0.034756
2025-12-12 22:46:26,687 INFO     Training average negative_sample_loss at step 54700: 0.042056
2025-12-12 22:46:26,687 INFO     Training average loss at step 54700: 0.212690
2025-12-12 22:46:33,904 INFO     Training average regularization at step 54800: 0.174219
2025-12-12 22:46:33,905 INFO     Training average positive_sample_loss at step 54800: 0.032510
2025-12-12 22:46:33,905 INFO     Training average negative_sample_loss at step 54800: 0.044479
2025-12-12 22:46:33,905 INFO     Training average loss at step 54800: 0.212714
2025-12-12 22:46:41,253 INFO     Training average regularization at step 54900: 0.174154
2025-12-12 22:46:41,291 INFO     Training average positive_sample_loss at step 54900: 0.035675
2025-12-12 22:46:41,291 INFO     Training average negative_sample_loss at step 54900: 0.036466
2025-12-12 22:46:41,291 INFO     Training average loss at step 54900: 0.210225
2025-12-12 22:46:48,590 INFO     Training average regularization at step 55000: 0.174089
2025-12-12 22:46:48,591 INFO     Training average positive_sample_loss at step 55000: 0.035844
2025-12-12 22:46:48,591 INFO     Training average negative_sample_loss at step 55000: 0.045757
2025-12-12 22:46:48,591 INFO     Training average loss at step 55000: 0.214889
2025-12-12 22:46:55,863 INFO     Training average regularization at step 55100: 0.174024
2025-12-12 22:46:55,864 INFO     Training average positive_sample_loss at step 55100: 0.036331
2025-12-12 22:46:55,864 INFO     Training average negative_sample_loss at step 55100: 0.041293
2025-12-12 22:46:55,864 INFO     Training average loss at step 55100: 0.212835
2025-12-12 22:47:03,164 INFO     Training average regularization at step 55200: 0.173958
2025-12-12 22:47:03,165 INFO     Training average positive_sample_loss at step 55200: 0.034684
2025-12-12 22:47:03,165 INFO     Training average negative_sample_loss at step 55200: 0.043147
2025-12-12 22:47:03,165 INFO     Training average loss at step 55200: 0.212874
2025-12-12 22:47:10,429 INFO     Training average regularization at step 55300: 0.173893
2025-12-12 22:47:10,429 INFO     Training average positive_sample_loss at step 55300: 0.034747
2025-12-12 22:47:10,429 INFO     Training average negative_sample_loss at step 55300: 0.036011
2025-12-12 22:47:10,429 INFO     Training average loss at step 55300: 0.209272
2025-12-12 22:47:17,710 INFO     Training average regularization at step 55400: 0.173828
2025-12-12 22:47:17,711 INFO     Training average positive_sample_loss at step 55400: 0.034802
2025-12-12 22:47:17,711 INFO     Training average negative_sample_loss at step 55400: 0.038723
2025-12-12 22:47:17,711 INFO     Training average loss at step 55400: 0.210591
2025-12-12 22:47:24,955 INFO     Training average regularization at step 55500: 0.173762
2025-12-12 22:47:24,956 INFO     Training average positive_sample_loss at step 55500: 0.036430
2025-12-12 22:47:24,956 INFO     Training average negative_sample_loss at step 55500: 0.046057
2025-12-12 22:47:24,956 INFO     Training average loss at step 55500: 0.215006
2025-12-12 22:47:32,220 INFO     Training average regularization at step 55600: 0.173696
2025-12-12 22:47:32,220 INFO     Training average positive_sample_loss at step 55600: 0.031826
2025-12-12 22:47:32,220 INFO     Training average negative_sample_loss at step 55600: 0.033553
2025-12-12 22:47:32,220 INFO     Training average loss at step 55600: 0.206386
2025-12-12 22:47:39,530 INFO     Training average regularization at step 55700: 0.173630
2025-12-12 22:47:39,530 INFO     Training average positive_sample_loss at step 55700: 0.032843
2025-12-12 22:47:39,530 INFO     Training average negative_sample_loss at step 55700: 0.041556
2025-12-12 22:47:39,530 INFO     Training average loss at step 55700: 0.210829
2025-12-12 22:47:46,934 INFO     Training average regularization at step 55800: 0.173564
2025-12-12 22:47:46,935 INFO     Training average positive_sample_loss at step 55800: 0.038948
2025-12-12 22:47:46,935 INFO     Training average negative_sample_loss at step 55800: 0.040520
2025-12-12 22:47:46,935 INFO     Training average loss at step 55800: 0.213298
2025-12-12 22:47:54,242 INFO     Training average regularization at step 55900: 0.173499
2025-12-12 22:47:54,242 INFO     Training average positive_sample_loss at step 55900: 0.036627
2025-12-12 22:47:54,242 INFO     Training average negative_sample_loss at step 55900: 0.045453
2025-12-12 22:47:54,242 INFO     Training average loss at step 55900: 0.214539
2025-12-12 22:48:09,001 INFO     Training average regularization at step 56000: 0.173434
2025-12-12 22:48:09,002 INFO     Training average positive_sample_loss at step 56000: 0.031936
2025-12-12 22:48:09,003 INFO     Training average negative_sample_loss at step 56000: 0.036130
2025-12-12 22:48:09,003 INFO     Training average loss at step 56000: 0.207466
2025-12-12 22:48:16,300 INFO     Training average regularization at step 56100: 0.173368
2025-12-12 22:48:16,301 INFO     Training average positive_sample_loss at step 56100: 0.032773
2025-12-12 22:48:16,301 INFO     Training average negative_sample_loss at step 56100: 0.033722
2025-12-12 22:48:16,301 INFO     Training average loss at step 56100: 0.206616
2025-12-12 22:48:23,565 INFO     Training average regularization at step 56200: 0.173303
2025-12-12 22:48:23,565 INFO     Training average positive_sample_loss at step 56200: 0.034775
2025-12-12 22:48:23,565 INFO     Training average negative_sample_loss at step 56200: 0.042319
2025-12-12 22:48:23,565 INFO     Training average loss at step 56200: 0.211850
2025-12-12 22:48:30,820 INFO     Training average regularization at step 56300: 0.173237
2025-12-12 22:48:30,821 INFO     Training average positive_sample_loss at step 56300: 0.033500
2025-12-12 22:48:30,821 INFO     Training average negative_sample_loss at step 56300: 0.039902
2025-12-12 22:48:30,821 INFO     Training average loss at step 56300: 0.209939
2025-12-12 22:48:38,130 INFO     Training average regularization at step 56400: 0.173172
2025-12-12 22:48:38,140 INFO     Training average positive_sample_loss at step 56400: 0.033517
2025-12-12 22:48:38,140 INFO     Training average negative_sample_loss at step 56400: 0.039663
2025-12-12 22:48:38,140 INFO     Training average loss at step 56400: 0.209761
2025-12-12 22:48:45,572 INFO     Training average regularization at step 56500: 0.173106
2025-12-12 22:48:45,572 INFO     Training average positive_sample_loss at step 56500: 0.035246
2025-12-12 22:48:45,572 INFO     Training average negative_sample_loss at step 56500: 0.036930
2025-12-12 22:48:45,572 INFO     Training average loss at step 56500: 0.209194
2025-12-12 22:48:52,845 INFO     Training average regularization at step 56600: 0.173041
2025-12-12 22:48:52,845 INFO     Training average positive_sample_loss at step 56600: 0.034988
2025-12-12 22:48:52,845 INFO     Training average negative_sample_loss at step 56600: 0.039803
2025-12-12 22:48:52,845 INFO     Training average loss at step 56600: 0.210436
2025-12-12 22:49:00,125 INFO     Training average regularization at step 56700: 0.172976
2025-12-12 22:49:00,125 INFO     Training average positive_sample_loss at step 56700: 0.032568
2025-12-12 22:49:00,125 INFO     Training average negative_sample_loss at step 56700: 0.038372
2025-12-12 22:49:00,125 INFO     Training average loss at step 56700: 0.208446
2025-12-12 22:49:07,365 INFO     Training average regularization at step 56800: 0.172911
2025-12-12 22:49:07,366 INFO     Training average positive_sample_loss at step 56800: 0.036090
2025-12-12 22:49:07,366 INFO     Training average negative_sample_loss at step 56800: 0.036609
2025-12-12 22:49:07,366 INFO     Training average loss at step 56800: 0.209260
2025-12-12 22:49:14,612 INFO     Training average regularization at step 56900: 0.172846
2025-12-12 22:49:14,613 INFO     Training average positive_sample_loss at step 56900: 0.035838
2025-12-12 22:49:14,613 INFO     Training average negative_sample_loss at step 56900: 0.036681
2025-12-12 22:49:14,613 INFO     Training average loss at step 56900: 0.209105
2025-12-12 22:49:21,844 INFO     Training average regularization at step 57000: 0.172781
2025-12-12 22:49:21,844 INFO     Training average positive_sample_loss at step 57000: 0.032859
2025-12-12 22:49:21,844 INFO     Training average negative_sample_loss at step 57000: 0.034258
2025-12-12 22:49:21,844 INFO     Training average loss at step 57000: 0.206339
2025-12-12 22:49:29,104 INFO     Training average regularization at step 57100: 0.172715
2025-12-12 22:49:29,105 INFO     Training average positive_sample_loss at step 57100: 0.034519
2025-12-12 22:49:29,105 INFO     Training average negative_sample_loss at step 57100: 0.036012
2025-12-12 22:49:29,105 INFO     Training average loss at step 57100: 0.207981
2025-12-12 22:49:36,377 INFO     Training average regularization at step 57200: 0.172650
2025-12-12 22:49:36,377 INFO     Training average positive_sample_loss at step 57200: 0.032173
2025-12-12 22:49:36,378 INFO     Training average negative_sample_loss at step 57200: 0.041819
2025-12-12 22:49:36,378 INFO     Training average loss at step 57200: 0.209646
2025-12-12 22:49:43,745 INFO     Training average regularization at step 57300: 0.172585
2025-12-12 22:49:43,746 INFO     Training average positive_sample_loss at step 57300: 0.031024
2025-12-12 22:49:43,746 INFO     Training average negative_sample_loss at step 57300: 0.038696
2025-12-12 22:49:43,746 INFO     Training average loss at step 57300: 0.207445
2025-12-12 22:49:50,971 INFO     Training average regularization at step 57400: 0.172520
2025-12-12 22:49:50,971 INFO     Training average positive_sample_loss at step 57400: 0.036908
2025-12-12 22:49:50,971 INFO     Training average negative_sample_loss at step 57400: 0.040339
2025-12-12 22:49:50,971 INFO     Training average loss at step 57400: 0.211143
2025-12-12 22:49:58,205 INFO     Training average regularization at step 57500: 0.172454
2025-12-12 22:49:58,206 INFO     Training average positive_sample_loss at step 57500: 0.031711
2025-12-12 22:49:58,206 INFO     Training average negative_sample_loss at step 57500: 0.038995
2025-12-12 22:49:58,206 INFO     Training average loss at step 57500: 0.207807
2025-12-12 22:50:05,438 INFO     Training average regularization at step 57600: 0.172389
2025-12-12 22:50:05,439 INFO     Training average positive_sample_loss at step 57600: 0.035982
2025-12-12 22:50:05,439 INFO     Training average negative_sample_loss at step 57600: 0.037814
2025-12-12 22:50:05,439 INFO     Training average loss at step 57600: 0.209288
2025-12-12 22:50:12,669 INFO     Training average regularization at step 57700: 0.172325
2025-12-12 22:50:12,669 INFO     Training average positive_sample_loss at step 57700: 0.037357
2025-12-12 22:50:12,669 INFO     Training average negative_sample_loss at step 57700: 0.036338
2025-12-12 22:50:12,669 INFO     Training average loss at step 57700: 0.209172
Traceback (most recent call last):
  File "/home/25171213997/ITI/codes/run.py", line 469, in <module>
    accuracy = objective()
  File "/home/25171213997/ITI/codes/run.py", line 376, in objective
    log = kge_model.train_step(kge_model, optimizer, train_iterator, args)
  File "/home/25171213997/ITI/codes/mult.py", line 926, in train_step
    
  File "/apps/software/anaconda3/envs/pytorch1.12-cuda11.3/lib/python3.10/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/apps/software/anaconda3/envs/pytorch1.12-cuda11.3/lib/python3.10/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
