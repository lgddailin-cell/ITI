2025-12-12 23:25:26,931 INFO     Parameters: Namespace(cuda='True', seed=10, do_train='True', do_valid='True', do_test='True', evaluate_train=False, countries=False, regions=None, data_path='/home/25171213997/ITI/data/FB15k/', model='ComplEx', double_entity_embedding=False, double_relation_embedding=False, negative_sample_size=300, hidden_dim=1000, house_dim=2, house_num=2, housd_num=2, types_num=2, thred=0.7, gamma=26.0, negative_adversarial_sampling=True, adversarial_temperature=1.16010547465235, batch_size=200, regularization=0.0881968094660471, ent_reg=0.0, rel_reg=0.0, test_batch_size=2, uni_weight=False, learning_rate=0.00258708538141072, cpu_num=10, init_checkpoint=None, save_path='/home/25171213997/ITI/FB15k/ComplEx-1/', max_steps=250000, warm_up_steps=20000, save_checkpoint_steps=20000, valid_steps=10000, log_steps=100, test_log_steps=500, nentity=14951, nrelation=1345)
2025-12-12 23:25:26,932 INFO     Model: ComplEx
2025-12-12 23:25:26,932 INFO     Data Path: /home/25171213997/ITI/data/FB15k/
2025-12-12 23:25:26,932 INFO     #entity: 14951
2025-12-12 23:25:26,932 INFO     #relation: 1345
2025-12-12 23:25:27,304 INFO     #train: 483142
2025-12-12 23:25:27,343 INFO     #valid: 50000
2025-12-12 23:25:27,389 INFO     #test: 59071
2025-12-12 23:25:27,841 INFO     Model Parameter Configuration:
2025-12-12 23:25:27,841 INFO     Parameter gamma: torch.Size([1]), require_grad = False
2025-12-12 23:25:27,841 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False
2025-12-12 23:25:27,841 INFO     Parameter entity_embedding: torch.Size([14951, 500, 2]), require_grad = True
2025-12-12 23:25:27,841 INFO     Parameter head_type_vec: torch.Size([14951]), require_grad = False
2025-12-12 23:25:27,841 INFO     Parameter head_type_mat: torch.Size([571, 500, 2]), require_grad = True
2025-12-12 23:25:27,841 INFO     Parameter tail_type_mat: torch.Size([571, 500, 2]), require_grad = True
2025-12-12 23:25:27,841 INFO     Parameter relation_embedding: torch.Size([1345, 500, 4]), require_grad = True
2025-12-12 23:25:27,841 INFO     Parameter r1_dir_head: torch.Size([571, 1, 1]), require_grad = True
2025-12-12 23:25:27,841 INFO     Parameter r2_dir_tail: torch.Size([571, 1, 1]), require_grad = True
2025-12-12 23:25:27,841 INFO     Parameter r1_scale_head: torch.Size([571, 500, 1]), require_grad = True
2025-12-12 23:25:27,841 INFO     Parameter r2_scale_tail: torch.Size([571, 500, 1]), require_grad = True
2025-12-12 23:25:27,841 INFO     Parameter k_dir_head: torch.Size([1345, 1, 2]), require_grad = True
2025-12-12 23:25:27,841 INFO     Parameter k_dir_tail: torch.Size([1345, 1, 2]), require_grad = True
2025-12-12 23:25:27,841 INFO     Parameter k_scale_head: torch.Size([1345, 500, 2]), require_grad = True
2025-12-12 23:25:27,841 INFO     Parameter k_scale_tail: torch.Size([1345, 500, 2]), require_grad = True
2025-12-12 23:25:27,841 INFO     Parameter relation_weight: torch.Size([1345, 500, 2]), require_grad = True
2025-12-12 23:25:32,762 INFO     Ramdomly Initializing ComplEx Model...
2025-12-12 23:25:32,768 INFO     Start Training...
2025-12-12 23:25:32,768 INFO     init_step = 1
2025-12-12 23:25:32,768 INFO     batch_size = 200
2025-12-12 23:25:32,768 INFO     negative_adversarial_sampling = 1
2025-12-12 23:25:32,769 INFO     hidden_dim = 1000
2025-12-12 23:25:32,769 INFO     gamma = 26.000000
2025-12-12 23:25:32,769 INFO     negative_adversarial_sampling = True
2025-12-12 23:25:32,769 INFO     adversarial_temperature = 1.160105
2025-12-12 23:25:32,769 INFO     learning_rate = 0
2025-12-12 23:25:35,610 INFO     Training average regularization at step 100: 0.018196
2025-12-12 23:25:35,610 INFO     Training average positive_sample_loss at step 100: 0.692686
2025-12-12 23:25:35,610 INFO     Training average negative_sample_loss at step 100: 0.693153
2025-12-12 23:25:35,610 INFO     Training average loss at step 100: 0.711115
2025-12-12 23:25:37,828 INFO     Training average regularization at step 200: 0.022463
2025-12-12 23:25:37,829 INFO     Training average positive_sample_loss at step 200: 0.689147
2025-12-12 23:25:37,829 INFO     Training average negative_sample_loss at step 200: 0.693164
2025-12-12 23:25:37,829 INFO     Training average loss at step 200: 0.713618
2025-12-12 23:25:40,052 INFO     Training average regularization at step 300: 0.040548
2025-12-12 23:25:40,053 INFO     Training average positive_sample_loss at step 300: 0.664323
2025-12-12 23:25:40,053 INFO     Training average negative_sample_loss at step 300: 0.693563
2025-12-12 23:25:40,053 INFO     Training average loss at step 300: 0.719491
2025-12-12 23:25:42,268 INFO     Training average regularization at step 400: 0.065986
2025-12-12 23:25:42,269 INFO     Training average positive_sample_loss at step 400: 0.593585
2025-12-12 23:25:42,269 INFO     Training average negative_sample_loss at step 400: 0.700534
2025-12-12 23:25:42,269 INFO     Training average loss at step 400: 0.713046
2025-12-12 23:25:44,489 INFO     Training average regularization at step 500: 0.091310
2025-12-12 23:25:44,489 INFO     Training average positive_sample_loss at step 500: 0.482540
2025-12-12 23:25:44,489 INFO     Training average negative_sample_loss at step 500: 0.723411
2025-12-12 23:25:44,489 INFO     Training average loss at step 500: 0.694286
2025-12-12 23:25:46,679 INFO     Training average regularization at step 600: 0.110248
2025-12-12 23:25:46,679 INFO     Training average positive_sample_loss at step 600: 0.388943
2025-12-12 23:25:46,679 INFO     Training average negative_sample_loss at step 600: 0.751081
2025-12-12 23:25:46,679 INFO     Training average loss at step 600: 0.680260
2025-12-12 23:25:48,845 INFO     Training average regularization at step 700: 0.123503
2025-12-12 23:25:48,845 INFO     Training average positive_sample_loss at step 700: 0.332731
2025-12-12 23:25:48,845 INFO     Training average negative_sample_loss at step 700: 0.768492
2025-12-12 23:25:48,845 INFO     Training average loss at step 700: 0.674115
2025-12-12 23:25:51,016 INFO     Training average regularization at step 800: 0.133438
2025-12-12 23:25:51,016 INFO     Training average positive_sample_loss at step 800: 0.295399
2025-12-12 23:25:51,016 INFO     Training average negative_sample_loss at step 800: 0.776420
2025-12-12 23:25:51,016 INFO     Training average loss at step 800: 0.669348
2025-12-12 23:25:53,166 INFO     Training average regularization at step 900: 0.140780
2025-12-12 23:25:53,167 INFO     Training average positive_sample_loss at step 900: 0.263718
2025-12-12 23:25:53,167 INFO     Training average negative_sample_loss at step 900: 0.781449
2025-12-12 23:25:53,167 INFO     Training average loss at step 900: 0.663363
2025-12-12 23:25:55,372 INFO     Training average regularization at step 1000: 0.146793
2025-12-12 23:25:55,372 INFO     Training average positive_sample_loss at step 1000: 0.245094
2025-12-12 23:25:55,372 INFO     Training average negative_sample_loss at step 1000: 0.779977
2025-12-12 23:25:55,372 INFO     Training average loss at step 1000: 0.659328
2025-12-12 23:25:57,543 INFO     Training average regularization at step 1100: 0.152631
2025-12-12 23:25:57,543 INFO     Training average positive_sample_loss at step 1100: 0.233027
2025-12-12 23:25:57,543 INFO     Training average negative_sample_loss at step 1100: 0.770618
2025-12-12 23:25:57,543 INFO     Training average loss at step 1100: 0.654454
2025-12-12 23:25:59,697 INFO     Training average regularization at step 1200: 0.158533
2025-12-12 23:25:59,697 INFO     Training average positive_sample_loss at step 1200: 0.221922
2025-12-12 23:25:59,697 INFO     Training average negative_sample_loss at step 1200: 0.757162
2025-12-12 23:25:59,697 INFO     Training average loss at step 1200: 0.648075
2025-12-12 23:26:01,854 INFO     Training average regularization at step 1300: 0.166058
2025-12-12 23:26:01,854 INFO     Training average positive_sample_loss at step 1300: 0.220642
2025-12-12 23:26:01,854 INFO     Training average negative_sample_loss at step 1300: 0.730422
2025-12-12 23:26:01,854 INFO     Training average loss at step 1300: 0.641590
2025-12-12 23:26:04,015 INFO     Training average regularization at step 1400: 0.175985
2025-12-12 23:26:04,016 INFO     Training average positive_sample_loss at step 1400: 0.223841
2025-12-12 23:26:04,016 INFO     Training average negative_sample_loss at step 1400: 0.686213
2025-12-12 23:26:04,016 INFO     Training average loss at step 1400: 0.631012
2025-12-12 23:26:06,171 INFO     Training average regularization at step 1500: 0.188810
2025-12-12 23:26:06,171 INFO     Training average positive_sample_loss at step 1500: 0.243108
2025-12-12 23:26:06,171 INFO     Training average negative_sample_loss at step 1500: 0.629737
2025-12-12 23:26:06,171 INFO     Training average loss at step 1500: 0.625233
2025-12-12 23:26:08,325 INFO     Training average regularization at step 1600: 0.203210
2025-12-12 23:26:08,325 INFO     Training average positive_sample_loss at step 1600: 0.258727
2025-12-12 23:26:08,325 INFO     Training average negative_sample_loss at step 1600: 0.571803
2025-12-12 23:26:08,325 INFO     Training average loss at step 1600: 0.618475
2025-12-12 23:26:10,505 INFO     Training average regularization at step 1700: 0.216925
2025-12-12 23:26:10,505 INFO     Training average positive_sample_loss at step 1700: 0.272357
2025-12-12 23:26:10,505 INFO     Training average negative_sample_loss at step 1700: 0.531345
2025-12-12 23:26:10,505 INFO     Training average loss at step 1700: 0.618776
2025-12-12 23:26:12,654 INFO     Training average regularization at step 1800: 0.229101
2025-12-12 23:26:12,654 INFO     Training average positive_sample_loss at step 1800: 0.276241
2025-12-12 23:26:12,654 INFO     Training average negative_sample_loss at step 1800: 0.500255
2025-12-12 23:26:12,654 INFO     Training average loss at step 1800: 0.617349
2025-12-12 23:26:14,821 INFO     Training average regularization at step 1900: 0.239824
2025-12-12 23:26:14,822 INFO     Training average positive_sample_loss at step 1900: 0.280749
2025-12-12 23:26:14,822 INFO     Training average negative_sample_loss at step 1900: 0.478317
2025-12-12 23:26:14,822 INFO     Training average loss at step 1900: 0.619356
2025-12-12 23:26:17,007 INFO     Training average regularization at step 2000: 0.248959
2025-12-12 23:26:17,007 INFO     Training average positive_sample_loss at step 2000: 0.278400
2025-12-12 23:26:17,007 INFO     Training average negative_sample_loss at step 2000: 0.463488
2025-12-12 23:26:17,007 INFO     Training average loss at step 2000: 0.619903
2025-12-12 23:26:19,152 INFO     Training average regularization at step 2100: 0.256665
2025-12-12 23:26:19,152 INFO     Training average positive_sample_loss at step 2100: 0.282249
2025-12-12 23:26:19,152 INFO     Training average negative_sample_loss at step 2100: 0.451052
2025-12-12 23:26:19,152 INFO     Training average loss at step 2100: 0.623316
2025-12-12 23:26:21,304 INFO     Training average regularization at step 2200: 0.263455
2025-12-12 23:26:21,305 INFO     Training average positive_sample_loss at step 2200: 0.278466
2025-12-12 23:26:21,305 INFO     Training average negative_sample_loss at step 2200: 0.443087
2025-12-12 23:26:21,305 INFO     Training average loss at step 2200: 0.624232
2025-12-12 23:26:23,461 INFO     Training average regularization at step 2300: 0.269443
2025-12-12 23:26:23,461 INFO     Training average positive_sample_loss at step 2300: 0.272201
2025-12-12 23:26:23,461 INFO     Training average negative_sample_loss at step 2300: 0.427900
2025-12-12 23:26:23,461 INFO     Training average loss at step 2300: 0.619493
2025-12-12 23:26:25,629 INFO     Training average regularization at step 2400: 0.274766
2025-12-12 23:26:25,630 INFO     Training average positive_sample_loss at step 2400: 0.271406
2025-12-12 23:26:25,630 INFO     Training average negative_sample_loss at step 2400: 0.424461
2025-12-12 23:26:25,630 INFO     Training average loss at step 2400: 0.622700
2025-12-12 23:26:27,814 INFO     Training average regularization at step 2500: 0.279245
2025-12-12 23:26:27,814 INFO     Training average positive_sample_loss at step 2500: 0.265227
2025-12-12 23:26:27,814 INFO     Training average negative_sample_loss at step 2500: 0.411761
2025-12-12 23:26:27,814 INFO     Training average loss at step 2500: 0.617739
2025-12-12 23:26:29,972 INFO     Training average regularization at step 2600: 0.283497
2025-12-12 23:26:29,972 INFO     Training average positive_sample_loss at step 2600: 0.264165
2025-12-12 23:26:29,972 INFO     Training average negative_sample_loss at step 2600: 0.405117
2025-12-12 23:26:29,972 INFO     Training average loss at step 2600: 0.618138
2025-12-12 23:26:32,127 INFO     Training average regularization at step 2700: 0.287462
2025-12-12 23:26:32,127 INFO     Training average positive_sample_loss at step 2700: 0.257445
2025-12-12 23:26:32,127 INFO     Training average negative_sample_loss at step 2700: 0.399079
2025-12-12 23:26:32,127 INFO     Training average loss at step 2700: 0.615725
2025-12-12 23:26:34,283 INFO     Training average regularization at step 2800: 0.290942
2025-12-12 23:26:34,283 INFO     Training average positive_sample_loss at step 2800: 0.249528
2025-12-12 23:26:34,283 INFO     Training average negative_sample_loss at step 2800: 0.387489
2025-12-12 23:26:34,284 INFO     Training average loss at step 2800: 0.609450
2025-12-12 23:26:36,452 INFO     Training average regularization at step 2900: 0.294054
2025-12-12 23:26:36,452 INFO     Training average positive_sample_loss at step 2900: 0.248210
2025-12-12 23:26:36,452 INFO     Training average negative_sample_loss at step 2900: 0.387531
2025-12-12 23:26:36,452 INFO     Training average loss at step 2900: 0.611925
2025-12-12 23:26:38,691 INFO     Training average regularization at step 3000: 0.296980
2025-12-12 23:26:38,691 INFO     Training average positive_sample_loss at step 3000: 0.244774
2025-12-12 23:26:38,691 INFO     Training average negative_sample_loss at step 3000: 0.371861
2025-12-12 23:26:38,691 INFO     Training average loss at step 3000: 0.605297
2025-12-12 23:26:40,865 INFO     Training average regularization at step 3100: 0.299620
2025-12-12 23:26:40,865 INFO     Training average positive_sample_loss at step 3100: 0.241438
2025-12-12 23:26:40,865 INFO     Training average negative_sample_loss at step 3100: 0.366551
2025-12-12 23:26:40,865 INFO     Training average loss at step 3100: 0.603615
2025-12-12 23:26:43,088 INFO     Training average regularization at step 3200: 0.302056
2025-12-12 23:26:43,088 INFO     Training average positive_sample_loss at step 3200: 0.237247
2025-12-12 23:26:43,088 INFO     Training average negative_sample_loss at step 3200: 0.360973
2025-12-12 23:26:43,088 INFO     Training average loss at step 3200: 0.601166
2025-12-12 23:26:45,259 INFO     Training average regularization at step 3300: 0.304207
2025-12-12 23:26:45,259 INFO     Training average positive_sample_loss at step 3300: 0.233977
2025-12-12 23:26:45,259 INFO     Training average negative_sample_loss at step 3300: 0.358550
2025-12-12 23:26:45,259 INFO     Training average loss at step 3300: 0.600471
2025-12-12 23:26:47,398 INFO     Training average regularization at step 3400: 0.306348
2025-12-12 23:26:47,398 INFO     Training average positive_sample_loss at step 3400: 0.232516
2025-12-12 23:26:47,398 INFO     Training average negative_sample_loss at step 3400: 0.353470
2025-12-12 23:26:47,398 INFO     Training average loss at step 3400: 0.599341
2025-12-12 23:26:49,567 INFO     Training average regularization at step 3500: 0.308302
2025-12-12 23:26:49,567 INFO     Training average positive_sample_loss at step 3500: 0.224074
2025-12-12 23:26:49,567 INFO     Training average negative_sample_loss at step 3500: 0.345600
2025-12-12 23:26:49,567 INFO     Training average loss at step 3500: 0.593139
2025-12-12 23:26:51,738 INFO     Training average regularization at step 3600: 0.310130
2025-12-12 23:26:51,738 INFO     Training average positive_sample_loss at step 3600: 0.222751
2025-12-12 23:26:51,738 INFO     Training average negative_sample_loss at step 3600: 0.337224
2025-12-12 23:26:51,738 INFO     Training average loss at step 3600: 0.590117
2025-12-12 23:26:53,881 INFO     Training average regularization at step 3700: 0.311767
2025-12-12 23:26:53,881 INFO     Training average positive_sample_loss at step 3700: 0.220121
2025-12-12 23:26:53,881 INFO     Training average negative_sample_loss at step 3700: 0.336712
2025-12-12 23:26:53,881 INFO     Training average loss at step 3700: 0.590184
2025-12-12 23:26:56,026 INFO     Training average regularization at step 3800: 0.313330
2025-12-12 23:26:56,026 INFO     Training average positive_sample_loss at step 3800: 0.214575
2025-12-12 23:26:56,026 INFO     Training average negative_sample_loss at step 3800: 0.332791
2025-12-12 23:26:56,026 INFO     Training average loss at step 3800: 0.587013
2025-12-12 23:26:58,172 INFO     Training average regularization at step 3900: 0.314874
2025-12-12 23:26:58,172 INFO     Training average positive_sample_loss at step 3900: 0.218399
2025-12-12 23:26:58,172 INFO     Training average negative_sample_loss at step 3900: 0.322178
2025-12-12 23:26:58,172 INFO     Training average loss at step 3900: 0.585163
2025-12-12 23:27:00,348 INFO     Training average regularization at step 4000: 0.316445
2025-12-12 23:27:00,349 INFO     Training average positive_sample_loss at step 4000: 0.209935
2025-12-12 23:27:00,349 INFO     Training average negative_sample_loss at step 4000: 0.325380
2025-12-12 23:27:00,349 INFO     Training average loss at step 4000: 0.584103
2025-12-12 23:27:02,509 INFO     Training average regularization at step 4100: 0.317823
2025-12-12 23:27:02,510 INFO     Training average positive_sample_loss at step 4100: 0.217261
2025-12-12 23:27:02,510 INFO     Training average negative_sample_loss at step 4100: 0.323418
2025-12-12 23:27:02,510 INFO     Training average loss at step 4100: 0.588163
2025-12-12 23:27:04,674 INFO     Training average regularization at step 4200: 0.319191
2025-12-12 23:27:04,675 INFO     Training average positive_sample_loss at step 4200: 0.206588
2025-12-12 23:27:04,675 INFO     Training average negative_sample_loss at step 4200: 0.324100
2025-12-12 23:27:04,675 INFO     Training average loss at step 4200: 0.584535
2025-12-12 23:27:06,828 INFO     Training average regularization at step 4300: 0.320395
2025-12-12 23:27:06,829 INFO     Training average positive_sample_loss at step 4300: 0.205988
2025-12-12 23:27:06,829 INFO     Training average negative_sample_loss at step 4300: 0.308846
2025-12-12 23:27:06,829 INFO     Training average loss at step 4300: 0.577812
2025-12-12 23:27:08,985 INFO     Training average regularization at step 4400: 0.321740
2025-12-12 23:27:08,986 INFO     Training average positive_sample_loss at step 4400: 0.199928
2025-12-12 23:27:08,986 INFO     Training average negative_sample_loss at step 4400: 0.311448
2025-12-12 23:27:08,986 INFO     Training average loss at step 4400: 0.577427
2025-12-12 23:27:11,152 INFO     Training average regularization at step 4500: 0.322714
2025-12-12 23:27:11,152 INFO     Training average positive_sample_loss at step 4500: 0.198606
2025-12-12 23:27:11,152 INFO     Training average negative_sample_loss at step 4500: 0.307771
2025-12-12 23:27:11,152 INFO     Training average loss at step 4500: 0.575902
2025-12-12 23:27:13,375 INFO     Training average regularization at step 4600: 0.323798
2025-12-12 23:27:13,376 INFO     Training average positive_sample_loss at step 4600: 0.199692
2025-12-12 23:27:13,376 INFO     Training average negative_sample_loss at step 4600: 0.301274
2025-12-12 23:27:13,376 INFO     Training average loss at step 4600: 0.574281
2025-12-12 23:27:15,535 INFO     Training average regularization at step 4700: 0.324872
2025-12-12 23:27:15,535 INFO     Training average positive_sample_loss at step 4700: 0.197518
2025-12-12 23:27:15,535 INFO     Training average negative_sample_loss at step 4700: 0.305960
2025-12-12 23:27:15,535 INFO     Training average loss at step 4700: 0.576611
2025-12-12 23:27:17,679 INFO     Training average regularization at step 4800: 0.325900
2025-12-12 23:27:17,679 INFO     Training average positive_sample_loss at step 4800: 0.192975
2025-12-12 23:27:17,679 INFO     Training average negative_sample_loss at step 4800: 0.292325
2025-12-12 23:27:17,679 INFO     Training average loss at step 4800: 0.568551
2025-12-12 23:27:20,792 INFO     Training average regularization at step 4900: 0.326737
2025-12-12 23:27:20,792 INFO     Training average positive_sample_loss at step 4900: 0.162211
2025-12-12 23:27:20,792 INFO     Training average negative_sample_loss at step 4900: 0.281046
2025-12-12 23:27:20,792 INFO     Training average loss at step 4900: 0.548366
2025-12-12 23:27:22,958 INFO     Training average regularization at step 5000: 0.326936
2025-12-12 23:27:22,958 INFO     Training average positive_sample_loss at step 5000: 0.160118
2025-12-12 23:27:22,959 INFO     Training average negative_sample_loss at step 5000: 0.257007
2025-12-12 23:27:22,959 INFO     Training average loss at step 5000: 0.535499
2025-12-12 23:27:25,110 INFO     Training average regularization at step 5100: 0.327492
2025-12-12 23:27:25,110 INFO     Training average positive_sample_loss at step 5100: 0.166450
2025-12-12 23:27:25,110 INFO     Training average negative_sample_loss at step 5100: 0.263106
2025-12-12 23:27:25,110 INFO     Training average loss at step 5100: 0.542270
2025-12-12 23:27:27,254 INFO     Training average regularization at step 5200: 0.328241
2025-12-12 23:27:27,254 INFO     Training average positive_sample_loss at step 5200: 0.165744
2025-12-12 23:27:27,254 INFO     Training average negative_sample_loss at step 5200: 0.256338
2025-12-12 23:27:27,254 INFO     Training average loss at step 5200: 0.539282
2025-12-12 23:27:29,402 INFO     Training average regularization at step 5300: 0.329039
2025-12-12 23:27:29,403 INFO     Training average positive_sample_loss at step 5300: 0.164991
2025-12-12 23:27:29,403 INFO     Training average negative_sample_loss at step 5300: 0.253917
2025-12-12 23:27:29,403 INFO     Training average loss at step 5300: 0.538493
2025-12-12 23:27:31,573 INFO     Training average regularization at step 5400: 0.329832
2025-12-12 23:27:31,573 INFO     Training average positive_sample_loss at step 5400: 0.165460
2025-12-12 23:27:31,573 INFO     Training average negative_sample_loss at step 5400: 0.259599
2025-12-12 23:27:31,573 INFO     Training average loss at step 5400: 0.542362
2025-12-12 23:27:33,774 INFO     Training average regularization at step 5500: 0.330543
2025-12-12 23:27:33,775 INFO     Training average positive_sample_loss at step 5500: 0.169400
2025-12-12 23:27:33,775 INFO     Training average negative_sample_loss at step 5500: 0.260816
2025-12-12 23:27:33,775 INFO     Training average loss at step 5500: 0.545651
2025-12-12 23:27:35,947 INFO     Training average regularization at step 5600: 0.331561
2025-12-12 23:27:35,948 INFO     Training average positive_sample_loss at step 5600: 0.173416
2025-12-12 23:27:35,948 INFO     Training average negative_sample_loss at step 5600: 0.252592
2025-12-12 23:27:35,948 INFO     Training average loss at step 5600: 0.544565
2025-12-12 23:27:38,143 INFO     Training average regularization at step 5700: 0.332485
2025-12-12 23:27:38,143 INFO     Training average positive_sample_loss at step 5700: 0.164245
2025-12-12 23:27:38,143 INFO     Training average negative_sample_loss at step 5700: 0.252351
2025-12-12 23:27:38,143 INFO     Training average loss at step 5700: 0.540783
2025-12-12 23:27:40,339 INFO     Training average regularization at step 5800: 0.333207
2025-12-12 23:27:40,339 INFO     Training average positive_sample_loss at step 5800: 0.166715
2025-12-12 23:27:40,339 INFO     Training average negative_sample_loss at step 5800: 0.251829
2025-12-12 23:27:40,339 INFO     Training average loss at step 5800: 0.542479
2025-12-12 23:27:42,545 INFO     Training average regularization at step 5900: 0.334134
2025-12-12 23:27:42,545 INFO     Training average positive_sample_loss at step 5900: 0.163982
2025-12-12 23:27:42,545 INFO     Training average negative_sample_loss at step 5900: 0.256393
2025-12-12 23:27:42,545 INFO     Training average loss at step 5900: 0.544322
2025-12-12 23:27:44,784 INFO     Training average regularization at step 6000: 0.334976
2025-12-12 23:27:44,784 INFO     Training average positive_sample_loss at step 6000: 0.169085
2025-12-12 23:27:44,784 INFO     Training average negative_sample_loss at step 6000: 0.256816
2025-12-12 23:27:44,784 INFO     Training average loss at step 6000: 0.547927
2025-12-12 23:27:46,925 INFO     Training average regularization at step 6100: 0.335910
2025-12-12 23:27:46,925 INFO     Training average positive_sample_loss at step 6100: 0.169245
2025-12-12 23:27:46,925 INFO     Training average negative_sample_loss at step 6100: 0.252719
2025-12-12 23:27:46,925 INFO     Training average loss at step 6100: 0.546892
2025-12-12 23:27:49,085 INFO     Training average regularization at step 6200: 0.336826
2025-12-12 23:27:49,085 INFO     Training average positive_sample_loss at step 6200: 0.167092
2025-12-12 23:27:49,085 INFO     Training average negative_sample_loss at step 6200: 0.259098
2025-12-12 23:27:49,085 INFO     Training average loss at step 6200: 0.549921
2025-12-12 23:27:51,247 INFO     Training average regularization at step 6300: 0.337642
2025-12-12 23:27:51,247 INFO     Training average positive_sample_loss at step 6300: 0.168126
2025-12-12 23:27:51,247 INFO     Training average negative_sample_loss at step 6300: 0.256470
2025-12-12 23:27:51,247 INFO     Training average loss at step 6300: 0.549940
2025-12-12 23:27:53,410 INFO     Training average regularization at step 6400: 0.338471
2025-12-12 23:27:53,411 INFO     Training average positive_sample_loss at step 6400: 0.170122
2025-12-12 23:27:53,411 INFO     Training average negative_sample_loss at step 6400: 0.250908
2025-12-12 23:27:53,411 INFO     Training average loss at step 6400: 0.548986
2025-12-12 23:27:55,595 INFO     Training average regularization at step 6500: 0.339249
2025-12-12 23:27:55,595 INFO     Training average positive_sample_loss at step 6500: 0.170810
2025-12-12 23:27:55,595 INFO     Training average negative_sample_loss at step 6500: 0.254358
2025-12-12 23:27:55,595 INFO     Training average loss at step 6500: 0.551834
2025-12-12 23:27:57,738 INFO     Training average regularization at step 6600: 0.340028
2025-12-12 23:27:57,738 INFO     Training average positive_sample_loss at step 6600: 0.169869
2025-12-12 23:27:57,738 INFO     Training average negative_sample_loss at step 6600: 0.260502
2025-12-12 23:27:57,738 INFO     Training average loss at step 6600: 0.555214
2025-12-12 23:27:59,890 INFO     Training average regularization at step 6700: 0.340817
2025-12-12 23:27:59,890 INFO     Training average positive_sample_loss at step 6700: 0.167537
2025-12-12 23:27:59,890 INFO     Training average negative_sample_loss at step 6700: 0.246875
2025-12-12 23:27:59,890 INFO     Training average loss at step 6700: 0.548023
2025-12-12 23:28:02,042 INFO     Training average regularization at step 6800: 0.341558
2025-12-12 23:28:02,042 INFO     Training average positive_sample_loss at step 6800: 0.167399
2025-12-12 23:28:02,042 INFO     Training average negative_sample_loss at step 6800: 0.254904
2025-12-12 23:28:02,042 INFO     Training average loss at step 6800: 0.552709
2025-12-12 23:28:04,201 INFO     Training average regularization at step 6900: 0.342296
2025-12-12 23:28:04,202 INFO     Training average positive_sample_loss at step 6900: 0.164169
2025-12-12 23:28:04,202 INFO     Training average negative_sample_loss at step 6900: 0.251320
2025-12-12 23:28:04,202 INFO     Training average loss at step 6900: 0.550040
2025-12-12 23:28:06,389 INFO     Training average regularization at step 7000: 0.342957
2025-12-12 23:28:06,389 INFO     Training average positive_sample_loss at step 7000: 0.166967
2025-12-12 23:28:06,389 INFO     Training average negative_sample_loss at step 7000: 0.257871
2025-12-12 23:28:06,389 INFO     Training average loss at step 7000: 0.555376
2025-12-12 23:28:08,578 INFO     Training average regularization at step 7100: 0.343726
2025-12-12 23:28:08,579 INFO     Training average positive_sample_loss at step 7100: 0.170890
2025-12-12 23:28:08,579 INFO     Training average negative_sample_loss at step 7100: 0.253143
2025-12-12 23:28:08,579 INFO     Training average loss at step 7100: 0.555742
2025-12-12 23:28:10,750 INFO     Training average regularization at step 7200: 0.344351
2025-12-12 23:28:10,751 INFO     Training average positive_sample_loss at step 7200: 0.169682
2025-12-12 23:28:10,751 INFO     Training average negative_sample_loss at step 7200: 0.251110
2025-12-12 23:28:10,751 INFO     Training average loss at step 7200: 0.554748
2025-12-12 23:28:12,920 INFO     Training average regularization at step 7300: 0.344981
2025-12-12 23:28:12,920 INFO     Training average positive_sample_loss at step 7300: 0.165602
2025-12-12 23:28:12,920 INFO     Training average negative_sample_loss at step 7300: 0.249568
2025-12-12 23:28:12,920 INFO     Training average loss at step 7300: 0.552566
2025-12-12 23:28:15,070 INFO     Training average regularization at step 7400: 0.345578
2025-12-12 23:28:15,070 INFO     Training average positive_sample_loss at step 7400: 0.163861
2025-12-12 23:28:15,070 INFO     Training average negative_sample_loss at step 7400: 0.240837
2025-12-12 23:28:15,070 INFO     Training average loss at step 7400: 0.547926
2025-12-12 23:28:17,224 INFO     Training average regularization at step 7500: 0.346071
2025-12-12 23:28:17,224 INFO     Training average positive_sample_loss at step 7500: 0.158885
2025-12-12 23:28:17,224 INFO     Training average negative_sample_loss at step 7500: 0.246736
2025-12-12 23:28:17,224 INFO     Training average loss at step 7500: 0.548882
2025-12-12 23:28:19,422 INFO     Training average regularization at step 7600: 0.346609
2025-12-12 23:28:19,422 INFO     Training average positive_sample_loss at step 7600: 0.162069
2025-12-12 23:28:19,422 INFO     Training average negative_sample_loss at step 7600: 0.244734
2025-12-12 23:28:19,423 INFO     Training average loss at step 7600: 0.550011
2025-12-12 23:28:21,576 INFO     Training average regularization at step 7700: 0.347079
2025-12-12 23:28:21,576 INFO     Training average positive_sample_loss at step 7700: 0.172655
2025-12-12 23:28:21,576 INFO     Training average negative_sample_loss at step 7700: 0.248263
2025-12-12 23:28:21,576 INFO     Training average loss at step 7700: 0.557538
2025-12-12 23:28:23,731 INFO     Training average regularization at step 7800: 0.347557
2025-12-12 23:28:23,733 INFO     Training average positive_sample_loss at step 7800: 0.167111
2025-12-12 23:28:23,733 INFO     Training average negative_sample_loss at step 7800: 0.250678
2025-12-12 23:28:23,733 INFO     Training average loss at step 7800: 0.556451
2025-12-12 23:28:25,898 INFO     Training average regularization at step 7900: 0.347860
2025-12-12 23:28:25,898 INFO     Training average positive_sample_loss at step 7900: 0.169657
2025-12-12 23:28:25,898 INFO     Training average negative_sample_loss at step 7900: 0.248490
2025-12-12 23:28:25,898 INFO     Training average loss at step 7900: 0.556933
2025-12-12 23:28:28,072 INFO     Training average regularization at step 8000: 0.348508
2025-12-12 23:28:28,072 INFO     Training average positive_sample_loss at step 8000: 0.163880
2025-12-12 23:28:28,072 INFO     Training average negative_sample_loss at step 8000: 0.242096
2025-12-12 23:28:28,073 INFO     Training average loss at step 8000: 0.551496
2025-12-12 23:28:30,239 INFO     Training average regularization at step 8100: 0.349008
2025-12-12 23:28:30,240 INFO     Training average positive_sample_loss at step 8100: 0.159703
2025-12-12 23:28:30,240 INFO     Training average negative_sample_loss at step 8100: 0.238176
2025-12-12 23:28:30,240 INFO     Training average loss at step 8100: 0.547947
2025-12-12 23:28:32,380 INFO     Training average regularization at step 8200: 0.349358
2025-12-12 23:28:32,380 INFO     Training average positive_sample_loss at step 8200: 0.161432
2025-12-12 23:28:32,380 INFO     Training average negative_sample_loss at step 8200: 0.247412
2025-12-12 23:28:32,380 INFO     Training average loss at step 8200: 0.553780
2025-12-12 23:28:34,536 INFO     Training average regularization at step 8300: 0.349885
2025-12-12 23:28:34,538 INFO     Training average positive_sample_loss at step 8300: 0.159815
2025-12-12 23:28:34,538 INFO     Training average negative_sample_loss at step 8300: 0.239789
2025-12-12 23:28:34,538 INFO     Training average loss at step 8300: 0.549687
2025-12-12 23:28:36,707 INFO     Training average regularization at step 8400: 0.350450
2025-12-12 23:28:36,708 INFO     Training average positive_sample_loss at step 8400: 0.159099
2025-12-12 23:28:36,708 INFO     Training average negative_sample_loss at step 8400: 0.235526
2025-12-12 23:28:36,708 INFO     Training average loss at step 8400: 0.547762
2025-12-12 23:28:38,868 INFO     Training average regularization at step 8500: 0.350881
2025-12-12 23:28:38,869 INFO     Training average positive_sample_loss at step 8500: 0.159622
2025-12-12 23:28:38,869 INFO     Training average negative_sample_loss at step 8500: 0.239837
2025-12-12 23:28:38,869 INFO     Training average loss at step 8500: 0.550610
2025-12-12 23:28:41,082 INFO     Training average regularization at step 8600: 0.351302
2025-12-12 23:28:41,083 INFO     Training average positive_sample_loss at step 8600: 0.159375
2025-12-12 23:28:41,083 INFO     Training average negative_sample_loss at step 8600: 0.234690
2025-12-12 23:28:41,083 INFO     Training average loss at step 8600: 0.548335
2025-12-12 23:28:43,328 INFO     Training average regularization at step 8700: 0.351597
2025-12-12 23:28:43,328 INFO     Training average positive_sample_loss at step 8700: 0.152311
2025-12-12 23:28:43,328 INFO     Training average negative_sample_loss at step 8700: 0.234744
2025-12-12 23:28:43,328 INFO     Training average loss at step 8700: 0.545124
2025-12-12 23:28:45,511 INFO     Training average regularization at step 8800: 0.351760
2025-12-12 23:28:45,512 INFO     Training average positive_sample_loss at step 8800: 0.156158
2025-12-12 23:28:45,512 INFO     Training average negative_sample_loss at step 8800: 0.232695
2025-12-12 23:28:45,512 INFO     Training average loss at step 8800: 0.546187
2025-12-12 23:28:47,646 INFO     Training average regularization at step 8900: 0.352090
2025-12-12 23:28:47,647 INFO     Training average positive_sample_loss at step 8900: 0.153994
2025-12-12 23:28:47,647 INFO     Training average negative_sample_loss at step 8900: 0.233783
2025-12-12 23:28:47,647 INFO     Training average loss at step 8900: 0.545978
2025-12-12 23:28:49,800 INFO     Training average regularization at step 9000: 0.352475
2025-12-12 23:28:49,800 INFO     Training average positive_sample_loss at step 9000: 0.158694
2025-12-12 23:28:49,800 INFO     Training average negative_sample_loss at step 9000: 0.229949
2025-12-12 23:28:49,800 INFO     Training average loss at step 9000: 0.546797
2025-12-12 23:28:51,948 INFO     Training average regularization at step 9100: 0.352994
2025-12-12 23:28:51,949 INFO     Training average positive_sample_loss at step 9100: 0.153643
2025-12-12 23:28:51,949 INFO     Training average negative_sample_loss at step 9100: 0.230935
2025-12-12 23:28:51,949 INFO     Training average loss at step 9100: 0.545283
2025-12-12 23:28:54,103 INFO     Training average regularization at step 9200: 0.353336
2025-12-12 23:28:54,103 INFO     Training average positive_sample_loss at step 9200: 0.155412
2025-12-12 23:28:54,103 INFO     Training average negative_sample_loss at step 9200: 0.223306
2025-12-12 23:28:54,103 INFO     Training average loss at step 9200: 0.542695
2025-12-12 23:28:56,272 INFO     Training average regularization at step 9300: 0.353588
2025-12-12 23:28:56,272 INFO     Training average positive_sample_loss at step 9300: 0.152873
2025-12-12 23:28:56,272 INFO     Training average negative_sample_loss at step 9300: 0.225947
2025-12-12 23:28:56,272 INFO     Training average loss at step 9300: 0.542998
2025-12-12 23:28:58,423 INFO     Training average regularization at step 9400: 0.353852
2025-12-12 23:28:58,429 INFO     Training average positive_sample_loss at step 9400: 0.148957
2025-12-12 23:28:58,430 INFO     Training average negative_sample_loss at step 9400: 0.217066
2025-12-12 23:28:58,430 INFO     Training average loss at step 9400: 0.536863
2025-12-12 23:29:00,597 INFO     Training average regularization at step 9500: 0.354044
2025-12-12 23:29:00,597 INFO     Training average positive_sample_loss at step 9500: 0.145105
2025-12-12 23:29:00,597 INFO     Training average negative_sample_loss at step 9500: 0.220272
2025-12-12 23:29:00,597 INFO     Training average loss at step 9500: 0.536732
2025-12-12 23:29:02,753 INFO     Training average regularization at step 9600: 0.354267
2025-12-12 23:29:02,753 INFO     Training average positive_sample_loss at step 9600: 0.148283
2025-12-12 23:29:02,753 INFO     Training average negative_sample_loss at step 9600: 0.223245
2025-12-12 23:29:02,753 INFO     Training average loss at step 9600: 0.540031
2025-12-12 23:29:05,915 INFO     Training average regularization at step 9700: 0.354676
2025-12-12 23:29:05,916 INFO     Training average positive_sample_loss at step 9700: 0.136986
2025-12-12 23:29:05,916 INFO     Training average negative_sample_loss at step 9700: 0.221783
2025-12-12 23:29:05,916 INFO     Training average loss at step 9700: 0.534061
2025-12-12 23:29:08,076 INFO     Training average regularization at step 9800: 0.354379
2025-12-12 23:29:08,076 INFO     Training average positive_sample_loss at step 9800: 0.123945
2025-12-12 23:29:08,076 INFO     Training average negative_sample_loss at step 9800: 0.193444
2025-12-12 23:29:08,077 INFO     Training average loss at step 9800: 0.513074
2025-12-12 23:29:10,240 INFO     Training average regularization at step 9900: 0.354074
2025-12-12 23:29:10,240 INFO     Training average positive_sample_loss at step 9900: 0.130738
2025-12-12 23:29:10,240 INFO     Training average negative_sample_loss at step 9900: 0.199511
2025-12-12 23:29:10,240 INFO     Training average loss at step 9900: 0.519198
2025-12-12 23:29:12,423 INFO     Training average regularization at step 10000: 0.353967
2025-12-12 23:29:12,423 INFO     Training average positive_sample_loss at step 10000: 0.133388
2025-12-12 23:29:12,423 INFO     Training average negative_sample_loss at step 10000: 0.196707
2025-12-12 23:29:12,423 INFO     Training average loss at step 10000: 0.519015
2025-12-12 23:29:12,423 INFO     Evaluating on Valid Dataset...
2025-12-12 23:29:12,962 INFO     Evaluating the model... (0/50000)
2025-12-12 23:29:15,636 INFO     Evaluating the model... (500/50000)
2025-12-12 23:29:18,113 INFO     Evaluating the model... (1000/50000)
2025-12-12 23:29:20,542 INFO     Evaluating the model... (1500/50000)
2025-12-12 23:29:23,057 INFO     Evaluating the model... (2000/50000)
2025-12-12 23:29:25,791 INFO     Evaluating the model... (2500/50000)
2025-12-12 23:29:28,163 INFO     Evaluating the model... (3000/50000)
2025-12-12 23:29:30,623 INFO     Evaluating the model... (3500/50000)
2025-12-12 23:29:34,084 INFO     Evaluating the model... (4000/50000)
2025-12-12 23:29:36,930 INFO     Evaluating the model... (4500/50000)
2025-12-12 23:29:39,671 INFO     Evaluating the model... (5000/50000)
2025-12-12 23:29:42,310 INFO     Evaluating the model... (5500/50000)
2025-12-12 23:29:45,484 INFO     Evaluating the model... (6000/50000)
2025-12-12 23:29:48,466 INFO     Evaluating the model... (6500/50000)
2025-12-12 23:29:50,948 INFO     Evaluating the model... (7000/50000)
2025-12-12 23:29:53,403 INFO     Evaluating the model... (7500/50000)
2025-12-12 23:29:55,956 INFO     Evaluating the model... (8000/50000)
2025-12-12 23:29:58,794 INFO     Evaluating the model... (8500/50000)
2025-12-12 23:30:01,263 INFO     Evaluating the model... (9000/50000)
2025-12-12 23:30:03,740 INFO     Evaluating the model... (9500/50000)
2025-12-12 23:30:06,261 INFO     Evaluating the model... (10000/50000)
2025-12-12 23:30:08,690 INFO     Evaluating the model... (10500/50000)
2025-12-12 23:30:12,005 INFO     Evaluating the model... (11000/50000)
2025-12-12 23:30:14,566 INFO     Evaluating the model... (11500/50000)
2025-12-12 23:30:17,115 INFO     Evaluating the model... (12000/50000)
2025-12-12 23:30:19,636 INFO     Evaluating the model... (12500/50000)
2025-12-12 23:30:22,340 INFO     Evaluating the model... (13000/50000)
2025-12-12 23:30:25,767 INFO     Evaluating the model... (13500/50000)
2025-12-12 23:30:28,183 INFO     Evaluating the model... (14000/50000)
2025-12-12 23:30:30,693 INFO     Evaluating the model... (14500/50000)
2025-12-12 23:30:33,226 INFO     Evaluating the model... (15000/50000)
2025-12-12 23:30:35,864 INFO     Evaluating the model... (15500/50000)
2025-12-12 23:30:39,381 INFO     Evaluating the model... (16000/50000)
2025-12-12 23:30:42,015 INFO     Evaluating the model... (16500/50000)
2025-12-12 23:30:44,778 INFO     Evaluating the model... (17000/50000)
2025-12-12 23:30:47,405 INFO     Evaluating the model... (17500/50000)
2025-12-12 23:30:49,784 INFO     Evaluating the model... (18000/50000)
2025-12-12 23:30:53,281 INFO     Evaluating the model... (18500/50000)
2025-12-12 23:30:55,804 INFO     Evaluating the model... (19000/50000)
2025-12-12 23:30:58,300 INFO     Evaluating the model... (19500/50000)
2025-12-12 23:31:00,671 INFO     Evaluating the model... (20000/50000)
2025-12-12 23:31:03,026 INFO     Evaluating the model... (20500/50000)
2025-12-12 23:31:06,199 INFO     Evaluating the model... (21000/50000)
2025-12-12 23:31:08,857 INFO     Evaluating the model... (21500/50000)
2025-12-12 23:31:11,300 INFO     Evaluating the model... (22000/50000)
2025-12-12 23:31:13,719 INFO     Evaluating the model... (22500/50000)
2025-12-12 23:31:16,195 INFO     Evaluating the model... (23000/50000)
2025-12-12 23:31:19,517 INFO     Evaluating the model... (23500/50000)
2025-12-12 23:31:21,930 INFO     Evaluating the model... (24000/50000)
2025-12-12 23:31:24,316 INFO     Evaluating the model... (24500/50000)
2025-12-12 23:31:27,103 INFO     Evaluating the model... (25000/50000)
2025-12-12 23:31:29,690 INFO     Evaluating the model... (25500/50000)
2025-12-12 23:31:32,418 INFO     Evaluating the model... (26000/50000)
2025-12-12 23:31:34,909 INFO     Evaluating the model... (26500/50000)
2025-12-12 23:31:37,566 INFO     Evaluating the model... (27000/50000)
2025-12-12 23:31:40,231 INFO     Evaluating the model... (27500/50000)
2025-12-12 23:31:43,178 INFO     Evaluating the model... (28000/50000)
2025-12-12 23:31:46,719 INFO     Evaluating the model... (28500/50000)
2025-12-12 23:31:49,258 INFO     Evaluating the model... (29000/50000)
2025-12-12 23:31:51,706 INFO     Evaluating the model... (29500/50000)
2025-12-12 23:31:54,467 INFO     Evaluating the model... (30000/50000)
2025-12-12 23:31:57,071 INFO     Evaluating the model... (30500/50000)
2025-12-12 23:32:00,080 INFO     Evaluating the model... (31000/50000)
2025-12-12 23:32:02,504 INFO     Evaluating the model... (31500/50000)
2025-12-12 23:32:04,989 INFO     Evaluating the model... (32000/50000)
2025-12-12 23:32:07,553 INFO     Evaluating the model... (32500/50000)
2025-12-12 23:32:09,989 INFO     Evaluating the model... (33000/50000)
2025-12-12 23:32:12,959 INFO     Evaluating the model... (33500/50000)
2025-12-12 23:32:15,460 INFO     Evaluating the model... (34000/50000)
2025-12-12 23:32:18,144 INFO     Evaluating the model... (34500/50000)
2025-12-12 23:32:20,639 INFO     Evaluating the model... (35000/50000)
2025-12-12 23:32:23,751 INFO     Evaluating the model... (35500/50000)
2025-12-12 23:32:26,218 INFO     Evaluating the model... (36000/50000)
2025-12-12 23:32:28,872 INFO     Evaluating the model... (36500/50000)
2025-12-12 23:32:31,401 INFO     Evaluating the model... (37000/50000)
2025-12-12 23:32:33,923 INFO     Evaluating the model... (37500/50000)
2025-12-12 23:32:37,506 INFO     Evaluating the model... (38000/50000)
2025-12-12 23:32:40,324 INFO     Evaluating the model... (38500/50000)
2025-12-12 23:32:43,036 INFO     Evaluating the model... (39000/50000)
2025-12-12 23:32:45,653 INFO     Evaluating the model... (39500/50000)
2025-12-12 23:32:48,166 INFO     Evaluating the model... (40000/50000)
2025-12-12 23:32:51,607 INFO     Evaluating the model... (40500/50000)
2025-12-12 23:32:54,040 INFO     Evaluating the model... (41000/50000)
2025-12-12 23:32:56,541 INFO     Evaluating the model... (41500/50000)
2025-12-12 23:32:58,983 INFO     Evaluating the model... (42000/50000)
2025-12-12 23:33:01,535 INFO     Evaluating the model... (42500/50000)
2025-12-12 23:33:05,096 INFO     Evaluating the model... (43000/50000)
2025-12-12 23:33:07,680 INFO     Evaluating the model... (43500/50000)
2025-12-12 23:33:10,233 INFO     Evaluating the model... (44000/50000)
2025-12-12 23:33:12,671 INFO     Evaluating the model... (44500/50000)
2025-12-12 23:33:15,448 INFO     Evaluating the model... (45000/50000)
2025-12-12 23:33:18,855 INFO     Evaluating the model... (45500/50000)
2025-12-12 23:33:21,342 INFO     Evaluating the model... (46000/50000)
2025-12-12 23:33:23,760 INFO     Evaluating the model... (46500/50000)
2025-12-12 23:33:26,595 INFO     Evaluating the model... (47000/50000)
2025-12-12 23:33:29,054 INFO     Evaluating the model... (47500/50000)
2025-12-12 23:33:32,419 INFO     Evaluating the model... (48000/50000)
2025-12-12 23:33:34,892 INFO     Evaluating the model... (48500/50000)
2025-12-12 23:33:37,798 INFO     Evaluating the model... (49000/50000)
2025-12-12 23:33:40,474 INFO     Evaluating the model... (49500/50000)
2025-12-12 23:33:43,459 INFO     Valid MRR at step 10000: 0.474775
2025-12-12 23:33:43,459 INFO     Valid MR at step 10000: 760.498060
2025-12-12 23:33:43,459 INFO     Valid HITS@1 at step 10000: 0.390820
2025-12-12 23:33:43,459 INFO     Valid HITS@3 at step 10000: 0.522670
2025-12-12 23:33:43,459 INFO     Valid HITS@10 at step 10000: 0.624110
2025-12-12 23:33:44,607 INFO     Evaluating on Test Dataset...
2025-12-12 23:33:45,251 INFO     Evaluating the model... (0/59072)
2025-12-12 23:33:48,015 INFO     Evaluating the model... (500/59072)
2025-12-12 23:33:50,524 INFO     Evaluating the model... (1000/59072)
2025-12-12 23:33:53,152 INFO     Evaluating the model... (1500/59072)
2025-12-12 23:33:55,671 INFO     Evaluating the model... (2000/59072)
2025-12-12 23:33:58,131 INFO     Evaluating the model... (2500/59072)
2025-12-12 23:34:01,659 INFO     Evaluating the model... (3000/59072)
2025-12-12 23:34:03,928 INFO     Evaluating the model... (3500/59072)
2025-12-12 23:34:06,370 INFO     Evaluating the model... (4000/59072)
2025-12-12 23:34:08,726 INFO     Evaluating the model... (4500/59072)
2025-12-12 23:34:11,335 INFO     Evaluating the model... (5000/59072)
2025-12-12 23:34:14,554 INFO     Evaluating the model... (5500/59072)
2025-12-12 23:34:17,065 INFO     Evaluating the model... (6000/59072)
2025-12-12 23:34:19,365 INFO     Evaluating the model... (6500/59072)
2025-12-12 23:34:21,903 INFO     Evaluating the model... (7000/59072)
2025-12-12 23:34:24,578 INFO     Evaluating the model... (7500/59072)
2025-12-12 23:34:27,636 INFO     Evaluating the model... (8000/59072)
2025-12-12 23:34:30,115 INFO     Evaluating the model... (8500/59072)
2025-12-12 23:34:32,672 INFO     Evaluating the model... (9000/59072)
2025-12-12 23:34:35,336 INFO     Evaluating the model... (9500/59072)
2025-12-12 23:34:38,074 INFO     Evaluating the model... (10000/59072)
2025-12-12 23:34:41,645 INFO     Evaluating the model... (10500/59072)
2025-12-12 23:34:44,271 INFO     Evaluating the model... (11000/59072)
2025-12-12 23:34:46,975 INFO     Evaluating the model... (11500/59072)
2025-12-12 23:34:49,328 INFO     Evaluating the model... (12000/59072)
2025-12-12 23:34:52,363 INFO     Evaluating the model... (12500/59072)
2025-12-12 23:34:54,791 INFO     Evaluating the model... (13000/59072)
2025-12-12 23:34:57,531 INFO     Evaluating the model... (13500/59072)
2025-12-12 23:34:59,967 INFO     Evaluating the model... (14000/59072)
2025-12-12 23:35:02,450 INFO     Evaluating the model... (14500/59072)
2025-12-12 23:35:05,512 INFO     Evaluating the model... (15000/59072)
2025-12-12 23:35:08,093 INFO     Evaluating the model... (15500/59072)
2025-12-12 23:35:10,675 INFO     Evaluating the model... (16000/59072)
2025-12-12 23:35:13,171 INFO     Evaluating the model... (16500/59072)
2025-12-12 23:35:15,543 INFO     Evaluating the model... (17000/59072)
2025-12-12 23:35:18,589 INFO     Evaluating the model... (17500/59072)
2025-12-12 23:35:21,238 INFO     Evaluating the model... (18000/59072)
2025-12-12 23:35:23,693 INFO     Evaluating the model... (18500/59072)
2025-12-12 23:35:26,161 INFO     Evaluating the model... (19000/59072)
2025-12-12 23:35:28,590 INFO     Evaluating the model... (19500/59072)
2025-12-12 23:35:31,985 INFO     Evaluating the model... (20000/59072)
2025-12-12 23:35:34,507 INFO     Evaluating the model... (20500/59072)
2025-12-12 23:35:37,164 INFO     Evaluating the model... (21000/59072)
2025-12-12 23:35:39,737 INFO     Evaluating the model... (21500/59072)
2025-12-12 23:35:42,533 INFO     Evaluating the model... (22000/59072)
2025-12-12 23:35:46,044 INFO     Evaluating the model... (22500/59072)
2025-12-12 23:35:48,440 INFO     Evaluating the model... (23000/59072)
2025-12-12 23:35:50,843 INFO     Evaluating the model... (23500/59072)
2025-12-12 23:35:53,227 INFO     Evaluating the model... (24000/59072)
2025-12-12 23:35:55,844 INFO     Evaluating the model... (24500/59072)
2025-12-12 23:35:59,164 INFO     Evaluating the model... (25000/59072)
2025-12-12 23:36:01,629 INFO     Evaluating the model... (25500/59072)
2025-12-12 23:36:04,131 INFO     Evaluating the model... (26000/59072)
2025-12-12 23:36:06,922 INFO     Evaluating the model... (26500/59072)
2025-12-12 23:36:09,496 INFO     Evaluating the model... (27000/59072)
2025-12-12 23:36:12,713 INFO     Evaluating the model... (27500/59072)
2025-12-12 23:36:15,084 INFO     Evaluating the model... (28000/59072)
2025-12-12 23:36:17,744 INFO     Evaluating the model... (28500/59072)
2025-12-12 23:36:20,169 INFO     Evaluating the model... (29000/59072)
2025-12-12 23:36:22,605 INFO     Evaluating the model... (29500/59072)
2025-12-12 23:36:25,565 INFO     Evaluating the model... (30000/59072)
2025-12-12 23:36:28,121 INFO     Evaluating the model... (30500/59072)
2025-12-12 23:36:30,869 INFO     Evaluating the model... (31000/59072)
2025-12-12 23:36:33,342 INFO     Evaluating the model... (31500/59072)
2025-12-12 23:36:37,089 INFO     Evaluating the model... (32000/59072)
2025-12-12 23:36:39,975 INFO     Evaluating the model... (32500/59072)
2025-12-12 23:36:42,894 INFO     Evaluating the model... (33000/59072)
2025-12-12 23:36:45,610 INFO     Evaluating the model... (33500/59072)
2025-12-12 23:36:48,081 INFO     Evaluating the model... (34000/59072)
2025-12-12 23:36:51,505 INFO     Evaluating the model... (34500/59072)
2025-12-12 23:36:54,004 INFO     Evaluating the model... (35000/59072)
2025-12-12 23:36:56,533 INFO     Evaluating the model... (35500/59072)
2025-12-12 23:36:59,024 INFO     Evaluating the model... (36000/59072)
2025-12-12 23:37:01,482 INFO     Evaluating the model... (36500/59072)
2025-12-12 23:37:05,040 INFO     Evaluating the model... (37000/59072)
2025-12-12 23:37:07,501 INFO     Evaluating the model... (37500/59072)
2025-12-12 23:37:09,928 INFO     Evaluating the model... (38000/59072)
2025-12-12 23:37:12,368 INFO     Evaluating the model... (38500/59072)
2025-12-12 23:37:14,996 INFO     Evaluating the model... (39000/59072)
2025-12-12 23:37:18,317 INFO     Evaluating the model... (39500/59072)
2025-12-12 23:37:20,951 INFO     Evaluating the model... (40000/59072)
2025-12-12 23:37:23,527 INFO     Evaluating the model... (40500/59072)
2025-12-12 23:37:26,223 INFO     Evaluating the model... (41000/59072)
2025-12-12 23:37:28,835 INFO     Evaluating the model... (41500/59072)
2025-12-12 23:37:32,161 INFO     Evaluating the model... (42000/59072)
2025-12-12 23:37:34,730 INFO     Evaluating the model... (42500/59072)
2025-12-12 23:37:37,666 INFO     Evaluating the model... (43000/59072)
2025-12-12 23:37:40,335 INFO     Evaluating the model... (43500/59072)
2025-12-12 23:37:43,878 INFO     Evaluating the model... (44000/59072)
2025-12-12 23:37:46,438 INFO     Evaluating the model... (44500/59072)
2025-12-12 23:37:49,071 INFO     Evaluating the model... (45000/59072)
2025-12-12 23:37:51,673 INFO     Evaluating the model... (45500/59072)
2025-12-12 23:37:54,208 INFO     Evaluating the model... (46000/59072)
2025-12-12 23:37:57,409 INFO     Evaluating the model... (46500/59072)
2025-12-12 23:37:59,950 INFO     Evaluating the model... (47000/59072)
2025-12-12 23:38:02,526 INFO     Evaluating the model... (47500/59072)
2025-12-12 23:38:04,942 INFO     Evaluating the model... (48000/59072)
2025-12-12 23:38:07,391 INFO     Evaluating the model... (48500/59072)
2025-12-12 23:38:10,488 INFO     Evaluating the model... (49000/59072)
2025-12-12 23:38:13,149 INFO     Evaluating the model... (49500/59072)
2025-12-12 23:38:15,677 INFO     Evaluating the model... (50000/59072)
2025-12-12 23:38:18,161 INFO     Evaluating the model... (50500/59072)
2025-12-12 23:38:20,615 INFO     Evaluating the model... (51000/59072)
2025-12-12 23:38:23,939 INFO     Evaluating the model... (51500/59072)
2025-12-12 23:38:26,483 INFO     Evaluating the model... (52000/59072)
2025-12-12 23:38:28,927 INFO     Evaluating the model... (52500/59072)
2025-12-12 23:38:31,453 INFO     Evaluating the model... (53000/59072)
2025-12-12 23:38:33,977 INFO     Evaluating the model... (53500/59072)
2025-12-12 23:38:37,359 INFO     Evaluating the model... (54000/59072)
2025-12-12 23:38:40,104 INFO     Evaluating the model... (54500/59072)
2025-12-12 23:38:42,669 INFO     Evaluating the model... (55000/59072)
2025-12-12 23:38:45,300 INFO     Evaluating the model... (55500/59072)
2025-12-12 23:38:48,067 INFO     Evaluating the model... (56000/59072)
2025-12-12 23:38:51,336 INFO     Evaluating the model... (56500/59072)
2025-12-12 23:38:53,835 INFO     Evaluating the model... (57000/59072)
2025-12-12 23:38:56,307 INFO     Evaluating the model... (57500/59072)
2025-12-12 23:38:58,964 INFO     Evaluating the model... (58000/59072)
2025-12-12 23:39:01,524 INFO     Evaluating the model... (58500/59072)
2025-12-12 23:39:04,821 INFO     Evaluating the model... (59000/59072)
2025-12-12 23:39:05,459 INFO     Test MRR at step 10000: 0.473382
2025-12-12 23:39:05,459 INFO     Test MR at step 10000: 779.188587
2025-12-12 23:39:05,459 INFO     Test HITS@1 at step 10000: 0.389785
2025-12-12 23:39:05,459 INFO     Test HITS@3 at step 10000: 0.520992
2025-12-12 23:39:05,459 INFO     Test HITS@10 at step 10000: 0.620998
2025-12-12 23:39:07,626 INFO     Training average regularization at step 10100: 0.354071
2025-12-12 23:39:07,626 INFO     Training average positive_sample_loss at step 10100: 0.140278
2025-12-12 23:39:07,626 INFO     Training average negative_sample_loss at step 10100: 0.194007
2025-12-12 23:39:07,626 INFO     Training average loss at step 10100: 0.521214
2025-12-12 23:39:09,838 INFO     Training average regularization at step 10200: 0.354355
2025-12-12 23:39:09,839 INFO     Training average positive_sample_loss at step 10200: 0.133612
2025-12-12 23:39:09,839 INFO     Training average negative_sample_loss at step 10200: 0.193658
2025-12-12 23:39:09,839 INFO     Training average loss at step 10200: 0.517990
2025-12-12 23:39:12,020 INFO     Training average regularization at step 10300: 0.354446
2025-12-12 23:39:12,020 INFO     Training average positive_sample_loss at step 10300: 0.134473
2025-12-12 23:39:12,020 INFO     Training average negative_sample_loss at step 10300: 0.193659
2025-12-12 23:39:12,020 INFO     Training average loss at step 10300: 0.518512
2025-12-12 23:39:14,191 INFO     Training average regularization at step 10400: 0.354589
2025-12-12 23:39:14,192 INFO     Training average positive_sample_loss at step 10400: 0.136163
2025-12-12 23:39:14,192 INFO     Training average negative_sample_loss at step 10400: 0.196601
2025-12-12 23:39:14,192 INFO     Training average loss at step 10400: 0.520971
2025-12-12 23:39:16,354 INFO     Training average regularization at step 10500: 0.355059
2025-12-12 23:39:16,355 INFO     Training average positive_sample_loss at step 10500: 0.136297
2025-12-12 23:39:16,355 INFO     Training average negative_sample_loss at step 10500: 0.192723
2025-12-12 23:39:16,355 INFO     Training average loss at step 10500: 0.519569
2025-12-12 23:39:18,502 INFO     Training average regularization at step 10600: 0.355482
2025-12-12 23:39:18,502 INFO     Training average positive_sample_loss at step 10600: 0.135246
2025-12-12 23:39:18,502 INFO     Training average negative_sample_loss at step 10600: 0.199754
2025-12-12 23:39:18,502 INFO     Training average loss at step 10600: 0.522982
2025-12-12 23:39:20,678 INFO     Training average regularization at step 10700: 0.355874
2025-12-12 23:39:20,679 INFO     Training average positive_sample_loss at step 10700: 0.138846
2025-12-12 23:39:20,679 INFO     Training average negative_sample_loss at step 10700: 0.200792
2025-12-12 23:39:20,679 INFO     Training average loss at step 10700: 0.525693
2025-12-12 23:39:22,840 INFO     Training average regularization at step 10800: 0.356412
2025-12-12 23:39:22,840 INFO     Training average positive_sample_loss at step 10800: 0.141454
2025-12-12 23:39:22,840 INFO     Training average negative_sample_loss at step 10800: 0.200704
2025-12-12 23:39:22,840 INFO     Training average loss at step 10800: 0.527491
2025-12-12 23:39:25,001 INFO     Training average regularization at step 10900: 0.356719
2025-12-12 23:39:25,002 INFO     Training average positive_sample_loss at step 10900: 0.144150
2025-12-12 23:39:25,002 INFO     Training average negative_sample_loss at step 10900: 0.202558
2025-12-12 23:39:25,002 INFO     Training average loss at step 10900: 0.530073
2025-12-12 23:39:27,198 INFO     Training average regularization at step 11000: 0.357193
2025-12-12 23:39:27,198 INFO     Training average positive_sample_loss at step 11000: 0.135778
2025-12-12 23:39:27,198 INFO     Training average negative_sample_loss at step 11000: 0.207143
2025-12-12 23:39:27,198 INFO     Training average loss at step 11000: 0.528653
2025-12-12 23:39:29,359 INFO     Training average regularization at step 11100: 0.357714
2025-12-12 23:39:29,359 INFO     Training average positive_sample_loss at step 11100: 0.138443
2025-12-12 23:39:29,359 INFO     Training average negative_sample_loss at step 11100: 0.196439
2025-12-12 23:39:29,359 INFO     Training average loss at step 11100: 0.525155
2025-12-12 23:39:31,522 INFO     Training average regularization at step 11200: 0.358252
2025-12-12 23:39:31,522 INFO     Training average positive_sample_loss at step 11200: 0.141680
2025-12-12 23:39:31,522 INFO     Training average negative_sample_loss at step 11200: 0.203620
2025-12-12 23:39:31,522 INFO     Training average loss at step 11200: 0.530902
2025-12-12 23:39:33,668 INFO     Training average regularization at step 11300: 0.358736
2025-12-12 23:39:33,669 INFO     Training average positive_sample_loss at step 11300: 0.143579
2025-12-12 23:39:33,669 INFO     Training average negative_sample_loss at step 11300: 0.207950
2025-12-12 23:39:33,669 INFO     Training average loss at step 11300: 0.534501
2025-12-12 23:39:35,830 INFO     Training average regularization at step 11400: 0.359035
2025-12-12 23:39:35,831 INFO     Training average positive_sample_loss at step 11400: 0.137948
2025-12-12 23:39:35,831 INFO     Training average negative_sample_loss at step 11400: 0.203533
2025-12-12 23:39:35,831 INFO     Training average loss at step 11400: 0.529775
2025-12-12 23:39:38,012 INFO     Training average regularization at step 11500: 0.359394
2025-12-12 23:39:38,012 INFO     Training average positive_sample_loss at step 11500: 0.143625
2025-12-12 23:39:38,012 INFO     Training average negative_sample_loss at step 11500: 0.206640
2025-12-12 23:39:38,012 INFO     Training average loss at step 11500: 0.534527
2025-12-12 23:39:40,181 INFO     Training average regularization at step 11600: 0.359853
2025-12-12 23:39:40,181 INFO     Training average positive_sample_loss at step 11600: 0.141024
2025-12-12 23:39:40,181 INFO     Training average negative_sample_loss at step 11600: 0.208268
2025-12-12 23:39:40,181 INFO     Training average loss at step 11600: 0.534500
2025-12-12 23:39:42,432 INFO     Training average regularization at step 11700: 0.360297
2025-12-12 23:39:42,432 INFO     Training average positive_sample_loss at step 11700: 0.139608
2025-12-12 23:39:42,432 INFO     Training average negative_sample_loss at step 11700: 0.198419
2025-12-12 23:39:42,432 INFO     Training average loss at step 11700: 0.529311
2025-12-12 23:39:44,613 INFO     Training average regularization at step 11800: 0.360669
2025-12-12 23:39:44,614 INFO     Training average positive_sample_loss at step 11800: 0.141639
2025-12-12 23:39:44,614 INFO     Training average negative_sample_loss at step 11800: 0.204720
2025-12-12 23:39:44,614 INFO     Training average loss at step 11800: 0.533848
2025-12-12 23:39:46,752 INFO     Training average regularization at step 11900: 0.361078
2025-12-12 23:39:46,752 INFO     Training average positive_sample_loss at step 11900: 0.137180
2025-12-12 23:39:46,752 INFO     Training average negative_sample_loss at step 11900: 0.194759
2025-12-12 23:39:46,752 INFO     Training average loss at step 11900: 0.527047
2025-12-12 23:39:48,915 INFO     Training average regularization at step 12000: 0.361427
2025-12-12 23:39:48,915 INFO     Training average positive_sample_loss at step 12000: 0.142187
2025-12-12 23:39:48,915 INFO     Training average negative_sample_loss at step 12000: 0.206915
2025-12-12 23:39:48,915 INFO     Training average loss at step 12000: 0.535978
2025-12-12 23:39:51,071 INFO     Training average regularization at step 12100: 0.361702
2025-12-12 23:39:51,071 INFO     Training average positive_sample_loss at step 12100: 0.140128
2025-12-12 23:39:51,071 INFO     Training average negative_sample_loss at step 12100: 0.204130
2025-12-12 23:39:51,071 INFO     Training average loss at step 12100: 0.533831
2025-12-12 23:39:53,277 INFO     Training average regularization at step 12200: 0.362053
2025-12-12 23:39:53,277 INFO     Training average positive_sample_loss at step 12200: 0.148473
2025-12-12 23:39:53,277 INFO     Training average negative_sample_loss at step 12200: 0.202281
2025-12-12 23:39:53,278 INFO     Training average loss at step 12200: 0.537430
2025-12-12 23:39:55,429 INFO     Training average regularization at step 12300: 0.362540
2025-12-12 23:39:55,429 INFO     Training average positive_sample_loss at step 12300: 0.139984
2025-12-12 23:39:55,429 INFO     Training average negative_sample_loss at step 12300: 0.204295
2025-12-12 23:39:55,429 INFO     Training average loss at step 12300: 0.534679
2025-12-12 23:39:57,619 INFO     Training average regularization at step 12400: 0.362903
2025-12-12 23:39:57,619 INFO     Training average positive_sample_loss at step 12400: 0.138335
2025-12-12 23:39:57,619 INFO     Training average negative_sample_loss at step 12400: 0.204589
2025-12-12 23:39:57,619 INFO     Training average loss at step 12400: 0.534365
2025-12-12 23:39:59,764 INFO     Training average regularization at step 12500: 0.363369
2025-12-12 23:39:59,765 INFO     Training average positive_sample_loss at step 12500: 0.136646
2025-12-12 23:39:59,765 INFO     Training average negative_sample_loss at step 12500: 0.201498
2025-12-12 23:39:59,765 INFO     Training average loss at step 12500: 0.532440
2025-12-12 23:40:01,898 INFO     Training average regularization at step 12600: 0.363636
2025-12-12 23:40:01,898 INFO     Training average positive_sample_loss at step 12600: 0.145252
2025-12-12 23:40:01,898 INFO     Training average negative_sample_loss at step 12600: 0.207455
2025-12-12 23:40:01,898 INFO     Training average loss at step 12600: 0.539990
2025-12-12 23:40:04,032 INFO     Training average regularization at step 12700: 0.363997
2025-12-12 23:40:04,033 INFO     Training average positive_sample_loss at step 12700: 0.143198
2025-12-12 23:40:04,033 INFO     Training average negative_sample_loss at step 12700: 0.206539
2025-12-12 23:40:04,033 INFO     Training average loss at step 12700: 0.538865
2025-12-12 23:40:06,199 INFO     Training average regularization at step 12800: 0.364215
2025-12-12 23:40:06,199 INFO     Training average positive_sample_loss at step 12800: 0.144504
2025-12-12 23:40:06,199 INFO     Training average negative_sample_loss at step 12800: 0.203943
2025-12-12 23:40:06,199 INFO     Training average loss at step 12800: 0.538438
2025-12-12 23:40:08,337 INFO     Training average regularization at step 12900: 0.364619
2025-12-12 23:40:08,337 INFO     Training average positive_sample_loss at step 12900: 0.144562
2025-12-12 23:40:08,338 INFO     Training average negative_sample_loss at step 12900: 0.201747
2025-12-12 23:40:08,338 INFO     Training average loss at step 12900: 0.537774
2025-12-12 23:40:10,485 INFO     Training average regularization at step 13000: 0.365040
2025-12-12 23:40:10,485 INFO     Training average positive_sample_loss at step 13000: 0.142272
2025-12-12 23:40:10,485 INFO     Training average negative_sample_loss at step 13000: 0.203112
2025-12-12 23:40:10,485 INFO     Training average loss at step 13000: 0.537732
2025-12-12 23:40:12,626 INFO     Training average regularization at step 13100: 0.365310
2025-12-12 23:40:12,627 INFO     Training average positive_sample_loss at step 13100: 0.140719
2025-12-12 23:40:12,627 INFO     Training average negative_sample_loss at step 13100: 0.202817
2025-12-12 23:40:12,627 INFO     Training average loss at step 13100: 0.537078
2025-12-12 23:40:14,795 INFO     Training average regularization at step 13200: 0.365654
2025-12-12 23:40:14,796 INFO     Training average positive_sample_loss at step 13200: 0.135370
2025-12-12 23:40:14,796 INFO     Training average negative_sample_loss at step 13200: 0.195387
2025-12-12 23:40:14,796 INFO     Training average loss at step 13200: 0.531033
2025-12-12 23:40:16,931 INFO     Training average regularization at step 13300: 0.365778
2025-12-12 23:40:16,931 INFO     Training average positive_sample_loss at step 13300: 0.134106
2025-12-12 23:40:16,931 INFO     Training average negative_sample_loss at step 13300: 0.206081
2025-12-12 23:40:16,931 INFO     Training average loss at step 13300: 0.535871
2025-12-12 23:40:19,061 INFO     Training average regularization at step 13400: 0.365869
2025-12-12 23:40:19,061 INFO     Training average positive_sample_loss at step 13400: 0.140259
2025-12-12 23:40:19,061 INFO     Training average negative_sample_loss at step 13400: 0.196128
2025-12-12 23:40:19,061 INFO     Training average loss at step 13400: 0.534062
2025-12-12 23:40:21,189 INFO     Training average regularization at step 13500: 0.365997
2025-12-12 23:40:21,190 INFO     Training average positive_sample_loss at step 13500: 0.138916
2025-12-12 23:40:21,190 INFO     Training average negative_sample_loss at step 13500: 0.192043
2025-12-12 23:40:21,190 INFO     Training average loss at step 13500: 0.531477
2025-12-12 23:40:23,323 INFO     Training average regularization at step 13600: 0.366201
2025-12-12 23:40:23,323 INFO     Training average positive_sample_loss at step 13600: 0.139275
2025-12-12 23:40:23,323 INFO     Training average negative_sample_loss at step 13600: 0.198712
2025-12-12 23:40:23,323 INFO     Training average loss at step 13600: 0.535195
2025-12-12 23:40:25,460 INFO     Training average regularization at step 13700: 0.366286
2025-12-12 23:40:25,460 INFO     Training average positive_sample_loss at step 13700: 0.131359
2025-12-12 23:40:25,460 INFO     Training average negative_sample_loss at step 13700: 0.197595
2025-12-12 23:40:25,460 INFO     Training average loss at step 13700: 0.530763
2025-12-12 23:40:27,647 INFO     Training average regularization at step 13800: 0.366346
2025-12-12 23:40:27,647 INFO     Training average positive_sample_loss at step 13800: 0.130180
2025-12-12 23:40:27,647 INFO     Training average negative_sample_loss at step 13800: 0.198660
2025-12-12 23:40:27,647 INFO     Training average loss at step 13800: 0.530766
2025-12-12 23:40:29,827 INFO     Training average regularization at step 13900: 0.366497
2025-12-12 23:40:29,827 INFO     Training average positive_sample_loss at step 13900: 0.140681
2025-12-12 23:40:29,827 INFO     Training average negative_sample_loss at step 13900: 0.192756
2025-12-12 23:40:29,827 INFO     Training average loss at step 13900: 0.533215
2025-12-12 23:40:31,965 INFO     Training average regularization at step 14000: 0.366728
2025-12-12 23:40:31,965 INFO     Training average positive_sample_loss at step 14000: 0.139686
2025-12-12 23:40:31,965 INFO     Training average negative_sample_loss at step 14000: 0.196267
2025-12-12 23:40:31,965 INFO     Training average loss at step 14000: 0.534705
2025-12-12 23:40:34,097 INFO     Training average regularization at step 14100: 0.366747
2025-12-12 23:40:34,098 INFO     Training average positive_sample_loss at step 14100: 0.139729
2025-12-12 23:40:34,098 INFO     Training average negative_sample_loss at step 14100: 0.198512
2025-12-12 23:40:34,098 INFO     Training average loss at step 14100: 0.535868
2025-12-12 23:40:36,244 INFO     Training average regularization at step 14200: 0.366933
2025-12-12 23:40:36,244 INFO     Training average positive_sample_loss at step 14200: 0.136146
2025-12-12 23:40:36,244 INFO     Training average negative_sample_loss at step 14200: 0.191774
2025-12-12 23:40:36,244 INFO     Training average loss at step 14200: 0.530893
2025-12-12 23:40:38,427 INFO     Training average regularization at step 14300: 0.367119
2025-12-12 23:40:38,427 INFO     Training average positive_sample_loss at step 14300: 0.131983
2025-12-12 23:40:38,427 INFO     Training average negative_sample_loss at step 14300: 0.191508
2025-12-12 23:40:38,427 INFO     Training average loss at step 14300: 0.528864
2025-12-12 23:40:40,610 INFO     Training average regularization at step 14400: 0.367275
2025-12-12 23:40:40,610 INFO     Training average positive_sample_loss at step 14400: 0.133551
2025-12-12 23:40:40,610 INFO     Training average negative_sample_loss at step 14400: 0.192150
2025-12-12 23:40:40,610 INFO     Training average loss at step 14400: 0.530126
2025-12-12 23:40:43,916 INFO     Training average regularization at step 14500: 0.367439
2025-12-12 23:40:43,916 INFO     Training average positive_sample_loss at step 14500: 0.132635
2025-12-12 23:40:43,917 INFO     Training average negative_sample_loss at step 14500: 0.193999
2025-12-12 23:40:43,917 INFO     Training average loss at step 14500: 0.530756
2025-12-12 23:40:46,052 INFO     Training average regularization at step 14600: 0.367037
2025-12-12 23:40:46,052 INFO     Training average positive_sample_loss at step 14600: 0.105882
2025-12-12 23:40:46,052 INFO     Training average negative_sample_loss at step 14600: 0.179066
2025-12-12 23:40:46,052 INFO     Training average loss at step 14600: 0.509511
2025-12-12 23:40:48,230 INFO     Training average regularization at step 14700: 0.366337
2025-12-12 23:40:48,230 INFO     Training average positive_sample_loss at step 14700: 0.115512
2025-12-12 23:40:48,230 INFO     Training average negative_sample_loss at step 14700: 0.167502
2025-12-12 23:40:48,230 INFO     Training average loss at step 14700: 0.507844
2025-12-12 23:40:50,380 INFO     Training average regularization at step 14800: 0.365960
2025-12-12 23:40:50,380 INFO     Training average positive_sample_loss at step 14800: 0.118060
2025-12-12 23:40:50,380 INFO     Training average negative_sample_loss at step 14800: 0.169746
2025-12-12 23:40:50,380 INFO     Training average loss at step 14800: 0.509863
2025-12-12 23:40:52,532 INFO     Training average regularization at step 14900: 0.365759
2025-12-12 23:40:52,534 INFO     Training average positive_sample_loss at step 14900: 0.116240
2025-12-12 23:40:52,534 INFO     Training average negative_sample_loss at step 14900: 0.172183
2025-12-12 23:40:52,534 INFO     Training average loss at step 14900: 0.509970
2025-12-12 23:40:54,693 INFO     Training average regularization at step 15000: 0.365696
2025-12-12 23:40:54,693 INFO     Training average positive_sample_loss at step 15000: 0.118340
2025-12-12 23:40:54,693 INFO     Training average negative_sample_loss at step 15000: 0.167490
2025-12-12 23:40:54,693 INFO     Training average loss at step 15000: 0.508611
2025-12-12 23:40:56,860 INFO     Training average regularization at step 15100: 0.365759
2025-12-12 23:40:56,860 INFO     Training average positive_sample_loss at step 15100: 0.119172
2025-12-12 23:40:56,860 INFO     Training average negative_sample_loss at step 15100: 0.169353
2025-12-12 23:40:56,860 INFO     Training average loss at step 15100: 0.510021
2025-12-12 23:40:59,037 INFO     Training average regularization at step 15200: 0.365879
2025-12-12 23:40:59,037 INFO     Training average positive_sample_loss at step 15200: 0.122694
2025-12-12 23:40:59,037 INFO     Training average negative_sample_loss at step 15200: 0.171248
2025-12-12 23:40:59,037 INFO     Training average loss at step 15200: 0.512850
2025-12-12 23:41:01,204 INFO     Training average regularization at step 15300: 0.365910
2025-12-12 23:41:01,205 INFO     Training average positive_sample_loss at step 15300: 0.123441
2025-12-12 23:41:01,205 INFO     Training average negative_sample_loss at step 15300: 0.169799
2025-12-12 23:41:01,205 INFO     Training average loss at step 15300: 0.512530
2025-12-12 23:41:03,345 INFO     Training average regularization at step 15400: 0.366000
2025-12-12 23:41:03,345 INFO     Training average positive_sample_loss at step 15400: 0.118615
2025-12-12 23:41:03,345 INFO     Training average negative_sample_loss at step 15400: 0.170341
2025-12-12 23:41:03,345 INFO     Training average loss at step 15400: 0.510479
2025-12-12 23:41:05,479 INFO     Training average regularization at step 15500: 0.366220
2025-12-12 23:41:05,480 INFO     Training average positive_sample_loss at step 15500: 0.125905
2025-12-12 23:41:05,480 INFO     Training average negative_sample_loss at step 15500: 0.169434
2025-12-12 23:41:05,480 INFO     Training average loss at step 15500: 0.513889
2025-12-12 23:41:07,645 INFO     Training average regularization at step 15600: 0.366531
2025-12-12 23:41:07,645 INFO     Training average positive_sample_loss at step 15600: 0.124696
2025-12-12 23:41:07,645 INFO     Training average negative_sample_loss at step 15600: 0.168514
2025-12-12 23:41:07,645 INFO     Training average loss at step 15600: 0.513136
2025-12-12 23:41:09,803 INFO     Training average regularization at step 15700: 0.366811
2025-12-12 23:41:09,804 INFO     Training average positive_sample_loss at step 15700: 0.120699
2025-12-12 23:41:09,804 INFO     Training average negative_sample_loss at step 15700: 0.172597
2025-12-12 23:41:09,804 INFO     Training average loss at step 15700: 0.513459
2025-12-12 23:41:11,959 INFO     Training average regularization at step 15800: 0.367069
2025-12-12 23:41:11,959 INFO     Training average positive_sample_loss at step 15800: 0.125797
2025-12-12 23:41:11,959 INFO     Training average negative_sample_loss at step 15800: 0.176004
2025-12-12 23:41:11,959 INFO     Training average loss at step 15800: 0.517969
2025-12-12 23:41:14,104 INFO     Training average regularization at step 15900: 0.367433
2025-12-12 23:41:14,104 INFO     Training average positive_sample_loss at step 15900: 0.126549
2025-12-12 23:41:14,104 INFO     Training average negative_sample_loss at step 15900: 0.175526
2025-12-12 23:41:14,104 INFO     Training average loss at step 15900: 0.518470
2025-12-12 23:41:16,252 INFO     Training average regularization at step 16000: 0.367681
2025-12-12 23:41:16,253 INFO     Training average positive_sample_loss at step 16000: 0.126661
2025-12-12 23:41:16,253 INFO     Training average negative_sample_loss at step 16000: 0.177270
2025-12-12 23:41:16,253 INFO     Training average loss at step 16000: 0.519646
2025-12-12 23:41:18,410 INFO     Training average regularization at step 16100: 0.367799
2025-12-12 23:41:18,410 INFO     Training average positive_sample_loss at step 16100: 0.121705
2025-12-12 23:41:18,410 INFO     Training average negative_sample_loss at step 16100: 0.179654
2025-12-12 23:41:18,410 INFO     Training average loss at step 16100: 0.518479
2025-12-12 23:41:20,553 INFO     Training average regularization at step 16200: 0.368135
2025-12-12 23:41:20,554 INFO     Training average positive_sample_loss at step 16200: 0.130690
2025-12-12 23:41:20,554 INFO     Training average negative_sample_loss at step 16200: 0.177446
2025-12-12 23:41:20,554 INFO     Training average loss at step 16200: 0.522203
2025-12-12 23:41:22,711 INFO     Training average regularization at step 16300: 0.368390
2025-12-12 23:41:22,712 INFO     Training average positive_sample_loss at step 16300: 0.126997
2025-12-12 23:41:22,712 INFO     Training average negative_sample_loss at step 16300: 0.180849
2025-12-12 23:41:22,712 INFO     Training average loss at step 16300: 0.522313
2025-12-12 23:41:24,854 INFO     Training average regularization at step 16400: 0.368638
2025-12-12 23:41:24,854 INFO     Training average positive_sample_loss at step 16400: 0.124843
2025-12-12 23:41:24,854 INFO     Training average negative_sample_loss at step 16400: 0.176424
2025-12-12 23:41:24,854 INFO     Training average loss at step 16400: 0.519271
2025-12-12 23:41:27,016 INFO     Training average regularization at step 16500: 0.368978
2025-12-12 23:41:27,016 INFO     Training average positive_sample_loss at step 16500: 0.131213
2025-12-12 23:41:27,016 INFO     Training average negative_sample_loss at step 16500: 0.181426
2025-12-12 23:41:27,016 INFO     Training average loss at step 16500: 0.525297
2025-12-12 23:41:29,171 INFO     Training average regularization at step 16600: 0.369333
2025-12-12 23:41:29,171 INFO     Training average positive_sample_loss at step 16600: 0.128812
2025-12-12 23:41:29,171 INFO     Training average negative_sample_loss at step 16600: 0.176360
2025-12-12 23:41:29,171 INFO     Training average loss at step 16600: 0.521919
2025-12-12 23:41:31,345 INFO     Training average regularization at step 16700: 0.369600
2025-12-12 23:41:31,345 INFO     Training average positive_sample_loss at step 16700: 0.129067
2025-12-12 23:41:31,346 INFO     Training average negative_sample_loss at step 16700: 0.190110
2025-12-12 23:41:31,346 INFO     Training average loss at step 16700: 0.529189
2025-12-12 23:41:33,570 INFO     Training average regularization at step 16800: 0.369862
2025-12-12 23:41:33,570 INFO     Training average positive_sample_loss at step 16800: 0.130656
2025-12-12 23:41:33,570 INFO     Training average negative_sample_loss at step 16800: 0.182844
2025-12-12 23:41:33,570 INFO     Training average loss at step 16800: 0.526612
2025-12-12 23:41:35,755 INFO     Training average regularization at step 16900: 0.370178
2025-12-12 23:41:35,755 INFO     Training average positive_sample_loss at step 16900: 0.133418
2025-12-12 23:41:35,755 INFO     Training average negative_sample_loss at step 16900: 0.187282
2025-12-12 23:41:35,755 INFO     Training average loss at step 16900: 0.530528
2025-12-12 23:41:37,960 INFO     Training average regularization at step 17000: 0.370461
2025-12-12 23:41:37,961 INFO     Training average positive_sample_loss at step 17000: 0.130530
2025-12-12 23:41:37,961 INFO     Training average negative_sample_loss at step 17000: 0.189695
2025-12-12 23:41:37,961 INFO     Training average loss at step 17000: 0.530574
2025-12-12 23:41:40,198 INFO     Training average regularization at step 17100: 0.370916
2025-12-12 23:41:40,198 INFO     Training average positive_sample_loss at step 17100: 0.131224
2025-12-12 23:41:40,198 INFO     Training average negative_sample_loss at step 17100: 0.175674
2025-12-12 23:41:40,198 INFO     Training average loss at step 17100: 0.524365
2025-12-12 23:41:42,364 INFO     Training average regularization at step 17200: 0.371205
2025-12-12 23:41:42,365 INFO     Training average positive_sample_loss at step 17200: 0.130141
2025-12-12 23:41:42,365 INFO     Training average negative_sample_loss at step 17200: 0.177761
2025-12-12 23:41:42,365 INFO     Training average loss at step 17200: 0.525156
2025-12-12 23:41:44,619 INFO     Training average regularization at step 17300: 0.371412
2025-12-12 23:41:44,620 INFO     Training average positive_sample_loss at step 17300: 0.129544
2025-12-12 23:41:44,620 INFO     Training average negative_sample_loss at step 17300: 0.190533
2025-12-12 23:41:44,620 INFO     Training average loss at step 17300: 0.531451
2025-12-12 23:41:46,788 INFO     Training average regularization at step 17400: 0.371597
2025-12-12 23:41:46,789 INFO     Training average positive_sample_loss at step 17400: 0.128506
2025-12-12 23:41:46,789 INFO     Training average negative_sample_loss at step 17400: 0.183595
2025-12-12 23:41:46,789 INFO     Training average loss at step 17400: 0.527647
2025-12-12 23:41:48,937 INFO     Training average regularization at step 17500: 0.371844
2025-12-12 23:41:48,937 INFO     Training average positive_sample_loss at step 17500: 0.129401
2025-12-12 23:41:48,937 INFO     Training average negative_sample_loss at step 17500: 0.180146
2025-12-12 23:41:48,937 INFO     Training average loss at step 17500: 0.526618
2025-12-12 23:41:51,076 INFO     Training average regularization at step 17600: 0.372076
2025-12-12 23:41:51,077 INFO     Training average positive_sample_loss at step 17600: 0.126392
2025-12-12 23:41:51,077 INFO     Training average negative_sample_loss at step 17600: 0.180905
2025-12-12 23:41:51,077 INFO     Training average loss at step 17600: 0.525724
2025-12-12 23:41:53,252 INFO     Training average regularization at step 17700: 0.372228
2025-12-12 23:41:53,252 INFO     Training average positive_sample_loss at step 17700: 0.131129
2025-12-12 23:41:53,252 INFO     Training average negative_sample_loss at step 17700: 0.183374
2025-12-12 23:41:53,252 INFO     Training average loss at step 17700: 0.529479
2025-12-12 23:41:55,437 INFO     Training average regularization at step 17800: 0.372427
2025-12-12 23:41:55,437 INFO     Training average positive_sample_loss at step 17800: 0.133268
2025-12-12 23:41:55,438 INFO     Training average negative_sample_loss at step 17800: 0.184140
2025-12-12 23:41:55,438 INFO     Training average loss at step 17800: 0.531132
2025-12-12 23:41:57,619 INFO     Training average regularization at step 17900: 0.372657
2025-12-12 23:41:57,619 INFO     Training average positive_sample_loss at step 17900: 0.124758
2025-12-12 23:41:57,619 INFO     Training average negative_sample_loss at step 17900: 0.182579
2025-12-12 23:41:57,619 INFO     Training average loss at step 17900: 0.526326
2025-12-12 23:41:59,777 INFO     Training average regularization at step 18000: 0.372822
2025-12-12 23:41:59,777 INFO     Training average positive_sample_loss at step 18000: 0.134217
2025-12-12 23:41:59,777 INFO     Training average negative_sample_loss at step 18000: 0.185682
2025-12-12 23:41:59,777 INFO     Training average loss at step 18000: 0.532772
2025-12-12 23:42:01,939 INFO     Training average regularization at step 18100: 0.373215
2025-12-12 23:42:01,939 INFO     Training average positive_sample_loss at step 18100: 0.129587
2025-12-12 23:42:01,939 INFO     Training average negative_sample_loss at step 18100: 0.180313
2025-12-12 23:42:01,939 INFO     Training average loss at step 18100: 0.528164
2025-12-12 23:42:04,093 INFO     Training average regularization at step 18200: 0.373445
2025-12-12 23:42:04,093 INFO     Training average positive_sample_loss at step 18200: 0.128456
2025-12-12 23:42:04,093 INFO     Training average negative_sample_loss at step 18200: 0.180679
2025-12-12 23:42:04,093 INFO     Training average loss at step 18200: 0.528013
2025-12-12 23:42:06,257 INFO     Training average regularization at step 18300: 0.373519
2025-12-12 23:42:06,257 INFO     Training average positive_sample_loss at step 18300: 0.124393
2025-12-12 23:42:06,257 INFO     Training average negative_sample_loss at step 18300: 0.183414
2025-12-12 23:42:06,257 INFO     Training average loss at step 18300: 0.527423
2025-12-12 23:42:08,411 INFO     Training average regularization at step 18400: 0.373513
2025-12-12 23:42:08,411 INFO     Training average positive_sample_loss at step 18400: 0.123044
2025-12-12 23:42:08,411 INFO     Training average negative_sample_loss at step 18400: 0.175617
2025-12-12 23:42:08,411 INFO     Training average loss at step 18400: 0.522844
2025-12-12 23:42:10,561 INFO     Training average regularization at step 18500: 0.373647
2025-12-12 23:42:10,561 INFO     Training average positive_sample_loss at step 18500: 0.126641
2025-12-12 23:42:10,561 INFO     Training average negative_sample_loss at step 18500: 0.177031
2025-12-12 23:42:10,561 INFO     Training average loss at step 18500: 0.525483
2025-12-12 23:42:12,713 INFO     Training average regularization at step 18600: 0.373725
2025-12-12 23:42:12,713 INFO     Training average positive_sample_loss at step 18600: 0.121334
2025-12-12 23:42:12,713 INFO     Training average negative_sample_loss at step 18600: 0.168722
2025-12-12 23:42:12,713 INFO     Training average loss at step 18600: 0.518753
2025-12-12 23:42:14,880 INFO     Training average regularization at step 18700: 0.373676
2025-12-12 23:42:14,880 INFO     Training average positive_sample_loss at step 18700: 0.122402
2025-12-12 23:42:14,880 INFO     Training average negative_sample_loss at step 18700: 0.173981
2025-12-12 23:42:14,881 INFO     Training average loss at step 18700: 0.521868
2025-12-12 23:42:17,043 INFO     Training average regularization at step 18800: 0.373676
2025-12-12 23:42:17,043 INFO     Training average positive_sample_loss at step 18800: 0.124904
2025-12-12 23:42:17,043 INFO     Training average negative_sample_loss at step 18800: 0.180686
2025-12-12 23:42:17,043 INFO     Training average loss at step 18800: 0.526471
2025-12-12 23:42:19,208 INFO     Training average regularization at step 18900: 0.373854
2025-12-12 23:42:19,209 INFO     Training average positive_sample_loss at step 18900: 0.124964
2025-12-12 23:42:19,209 INFO     Training average negative_sample_loss at step 18900: 0.175290
2025-12-12 23:42:19,209 INFO     Training average loss at step 18900: 0.523981
2025-12-12 23:42:21,374 INFO     Training average regularization at step 19000: 0.373887
2025-12-12 23:42:21,374 INFO     Training average positive_sample_loss at step 19000: 0.123148
2025-12-12 23:42:21,374 INFO     Training average negative_sample_loss at step 19000: 0.174861
2025-12-12 23:42:21,374 INFO     Training average loss at step 19000: 0.522892
2025-12-12 23:42:23,536 INFO     Training average regularization at step 19100: 0.373998
2025-12-12 23:42:23,536 INFO     Training average positive_sample_loss at step 19100: 0.120651
2025-12-12 23:42:23,536 INFO     Training average negative_sample_loss at step 19100: 0.168008
2025-12-12 23:42:23,536 INFO     Training average loss at step 19100: 0.518328
2025-12-12 23:42:25,686 INFO     Training average regularization at step 19200: 0.373948
2025-12-12 23:42:25,686 INFO     Training average positive_sample_loss at step 19200: 0.122184
2025-12-12 23:42:25,686 INFO     Training average negative_sample_loss at step 19200: 0.173264
2025-12-12 23:42:25,686 INFO     Training average loss at step 19200: 0.521672
2025-12-12 23:42:27,896 INFO     Training average regularization at step 19300: 0.373859
2025-12-12 23:42:27,897 INFO     Training average positive_sample_loss at step 19300: 0.121984
2025-12-12 23:42:27,897 INFO     Training average negative_sample_loss at step 19300: 0.170513
2025-12-12 23:42:27,897 INFO     Training average loss at step 19300: 0.520107
2025-12-12 23:42:31,015 INFO     Training average regularization at step 19400: 0.373553
2025-12-12 23:42:31,015 INFO     Training average positive_sample_loss at step 19400: 0.100650
2025-12-12 23:42:31,016 INFO     Training average negative_sample_loss at step 19400: 0.164648
2025-12-12 23:42:31,016 INFO     Training average loss at step 19400: 0.506202
2025-12-12 23:42:33,178 INFO     Training average regularization at step 19500: 0.372751
2025-12-12 23:42:33,179 INFO     Training average positive_sample_loss at step 19500: 0.104456
2025-12-12 23:42:33,179 INFO     Training average negative_sample_loss at step 19500: 0.152008
2025-12-12 23:42:33,179 INFO     Training average loss at step 19500: 0.500984
2025-12-12 23:42:35,360 INFO     Training average regularization at step 19600: 0.372328
2025-12-12 23:42:35,360 INFO     Training average positive_sample_loss at step 19600: 0.109390
2025-12-12 23:42:35,360 INFO     Training average negative_sample_loss at step 19600: 0.150929
2025-12-12 23:42:35,360 INFO     Training average loss at step 19600: 0.502487
2025-12-12 23:42:37,558 INFO     Training average regularization at step 19700: 0.371926
2025-12-12 23:42:37,558 INFO     Training average positive_sample_loss at step 19700: 0.102836
2025-12-12 23:42:37,558 INFO     Training average negative_sample_loss at step 19700: 0.151147
2025-12-12 23:42:37,558 INFO     Training average loss at step 19700: 0.498917
2025-12-12 23:42:39,850 INFO     Training average regularization at step 19800: 0.371675
2025-12-12 23:42:39,851 INFO     Training average positive_sample_loss at step 19800: 0.110904
2025-12-12 23:42:39,851 INFO     Training average negative_sample_loss at step 19800: 0.154116
2025-12-12 23:42:39,851 INFO     Training average loss at step 19800: 0.504185
2025-12-12 23:42:42,033 INFO     Training average regularization at step 19900: 0.371550
2025-12-12 23:42:42,033 INFO     Training average positive_sample_loss at step 19900: 0.108785
2025-12-12 23:42:42,033 INFO     Training average negative_sample_loss at step 19900: 0.150578
2025-12-12 23:42:42,034 INFO     Training average loss at step 19900: 0.501232
2025-12-12 23:42:44,210 INFO     Change learning_rate to 0.000259 at step 20000
2025-12-12 23:42:44,971 INFO     Training average regularization at step 20000: 0.371392
2025-12-12 23:42:44,971 INFO     Training average positive_sample_loss at step 20000: 0.111334
2025-12-12 23:42:44,971 INFO     Training average negative_sample_loss at step 20000: 0.157262
2025-12-12 23:42:44,971 INFO     Training average loss at step 20000: 0.505690
2025-12-12 23:42:44,972 INFO     Evaluating on Valid Dataset...
2025-12-12 23:42:45,653 INFO     Evaluating the model... (0/50000)
2025-12-12 23:42:48,424 INFO     Evaluating the model... (500/50000)
2025-12-12 23:42:51,187 INFO     Evaluating the model... (1000/50000)
2025-12-12 23:42:53,669 INFO     Evaluating the model... (1500/50000)
2025-12-12 23:42:56,906 INFO     Evaluating the model... (2000/50000)
2025-12-12 23:42:59,354 INFO     Evaluating the model... (2500/50000)
2025-12-12 23:43:01,999 INFO     Evaluating the model... (3000/50000)
2025-12-12 23:43:04,419 INFO     Evaluating the model... (3500/50000)
2025-12-12 23:43:06,900 INFO     Evaluating the model... (4000/50000)
2025-12-12 23:43:09,712 INFO     Evaluating the model... (4500/50000)
2025-12-12 23:43:12,102 INFO     Evaluating the model... (5000/50000)
2025-12-12 23:43:14,710 INFO     Evaluating the model... (5500/50000)
2025-12-12 23:43:17,283 INFO     Evaluating the model... (6000/50000)
2025-12-12 23:43:19,774 INFO     Evaluating the model... (6500/50000)
2025-12-12 23:43:22,711 INFO     Evaluating the model... (7000/50000)
2025-12-12 23:43:25,382 INFO     Evaluating the model... (7500/50000)
2025-12-12 23:43:27,856 INFO     Evaluating the model... (8000/50000)
2025-12-12 23:43:30,292 INFO     Evaluating the model... (8500/50000)
2025-12-12 23:43:33,440 INFO     Evaluating the model... (9000/50000)
2025-12-12 23:43:36,228 INFO     Evaluating the model... (9500/50000)
2025-12-12 23:43:38,872 INFO     Evaluating the model... (10000/50000)
2025-12-12 23:43:41,399 INFO     Evaluating the model... (10500/50000)
2025-12-12 23:43:43,947 INFO     Evaluating the model... (11000/50000)
2025-12-12 23:43:47,064 INFO     Evaluating the model... (11500/50000)
2025-12-12 23:43:49,667 INFO     Evaluating the model... (12000/50000)
2025-12-12 23:43:51,992 INFO     Evaluating the model... (12500/50000)
2025-12-12 23:43:54,412 INFO     Evaluating the model... (13000/50000)
2025-12-12 23:43:56,886 INFO     Evaluating the model... (13500/50000)
2025-12-12 23:44:00,189 INFO     Evaluating the model... (14000/50000)
2025-12-12 23:44:02,588 INFO     Evaluating the model... (14500/50000)
2025-12-12 23:44:05,096 INFO     Evaluating the model... (15000/50000)
2025-12-12 23:44:07,555 INFO     Evaluating the model... (15500/50000)
2025-12-12 23:44:10,130 INFO     Evaluating the model... (16000/50000)
2025-12-12 23:44:13,213 INFO     Evaluating the model... (16500/50000)
2025-12-12 23:44:15,636 INFO     Evaluating the model... (17000/50000)
2025-12-12 23:44:18,044 INFO     Evaluating the model... (17500/50000)
2025-12-12 23:44:20,437 INFO     Evaluating the model... (18000/50000)
2025-12-12 23:44:23,047 INFO     Evaluating the model... (18500/50000)
2025-12-12 23:44:26,318 INFO     Evaluating the model... (19000/50000)
2025-12-12 23:44:28,793 INFO     Evaluating the model... (19500/50000)
2025-12-12 23:44:31,279 INFO     Evaluating the model... (20000/50000)
2025-12-12 23:44:33,868 INFO     Evaluating the model... (20500/50000)
2025-12-12 23:44:36,421 INFO     Evaluating the model... (21000/50000)
2025-12-12 23:44:39,957 INFO     Evaluating the model... (21500/50000)
2025-12-12 23:44:42,544 INFO     Evaluating the model... (22000/50000)
2025-12-12 23:44:45,415 INFO     Evaluating the model... (22500/50000)
2025-12-12 23:44:47,822 INFO     Evaluating the model... (23000/50000)
2025-12-12 23:44:50,197 INFO     Evaluating the model... (23500/50000)
2025-12-12 23:44:53,343 INFO     Evaluating the model... (24000/50000)
2025-12-12 23:44:55,787 INFO     Evaluating the model... (24500/50000)
2025-12-12 23:44:58,661 INFO     Evaluating the model... (25000/50000)
2025-12-12 23:45:01,208 INFO     Evaluating the model... (25500/50000)
2025-12-12 23:45:03,779 INFO     Evaluating the model... (26000/50000)
2025-12-12 23:45:07,982 INFO     Evaluating the model... (26500/50000)
2025-12-12 23:45:10,641 INFO     Evaluating the model... (27000/50000)
2025-12-12 23:45:13,343 INFO     Evaluating the model... (27500/50000)
2025-12-12 23:45:15,986 INFO     Evaluating the model... (28000/50000)
2025-12-12 23:45:18,482 INFO     Evaluating the model... (28500/50000)
2025-12-12 23:45:21,857 INFO     Evaluating the model... (29000/50000)
2025-12-12 23:45:24,325 INFO     Evaluating the model... (29500/50000)
2025-12-12 23:45:26,952 INFO     Evaluating the model... (30000/50000)
2025-12-12 23:45:29,480 INFO     Evaluating the model... (30500/50000)
2025-12-12 23:45:32,172 INFO     Evaluating the model... (31000/50000)
2025-12-12 23:45:35,332 INFO     Evaluating the model... (31500/50000)
2025-12-12 23:45:38,062 INFO     Evaluating the model... (32000/50000)
2025-12-12 23:45:40,653 INFO     Evaluating the model... (32500/50000)
2025-12-12 23:45:43,632 INFO     Evaluating the model... (33000/50000)
2025-12-12 23:45:46,170 INFO     Evaluating the model... (33500/50000)
2025-12-12 23:45:49,252 INFO     Evaluating the model... (34000/50000)
2025-12-12 23:45:51,725 INFO     Evaluating the model... (34500/50000)
2025-12-12 23:45:54,601 INFO     Evaluating the model... (35000/50000)
2025-12-12 23:45:57,104 INFO     Evaluating the model... (35500/50000)
2025-12-12 23:46:00,301 INFO     Evaluating the model... (36000/50000)
2025-12-12 23:46:02,819 INFO     Evaluating the model... (36500/50000)
2025-12-12 23:46:05,508 INFO     Evaluating the model... (37000/50000)
2025-12-12 23:46:08,133 INFO     Evaluating the model... (37500/50000)
2025-12-12 23:46:10,656 INFO     Evaluating the model... (38000/50000)
2025-12-12 23:46:13,741 INFO     Evaluating the model... (38500/50000)
2025-12-12 23:46:16,333 INFO     Evaluating the model... (39000/50000)
2025-12-12 23:46:18,944 INFO     Evaluating the model... (39500/50000)
2025-12-12 23:46:21,552 INFO     Evaluating the model... (40000/50000)
2025-12-12 23:46:24,024 INFO     Evaluating the model... (40500/50000)
2025-12-12 23:46:27,095 INFO     Evaluating the model... (41000/50000)
2025-12-12 23:46:29,799 INFO     Evaluating the model... (41500/50000)
2025-12-12 23:46:32,283 INFO     Evaluating the model... (42000/50000)
2025-12-12 23:46:34,755 INFO     Evaluating the model... (42500/50000)
2025-12-12 23:46:37,608 INFO     Evaluating the model... (43000/50000)
2025-12-12 23:46:41,479 INFO     Evaluating the model... (43500/50000)
2025-12-12 23:46:44,286 INFO     Evaluating the model... (44000/50000)
2025-12-12 23:46:46,902 INFO     Evaluating the model... (44500/50000)
2025-12-12 23:46:49,488 INFO     Evaluating the model... (45000/50000)
2025-12-12 23:46:52,325 INFO     Evaluating the model... (45500/50000)
2025-12-12 23:46:55,322 INFO     Evaluating the model... (46000/50000)
2025-12-12 23:46:57,978 INFO     Evaluating the model... (46500/50000)
2025-12-12 23:47:00,532 INFO     Evaluating the model... (47000/50000)
2025-12-12 23:47:03,199 INFO     Evaluating the model... (47500/50000)
2025-12-12 23:47:05,732 INFO     Evaluating the model... (48000/50000)
2025-12-12 23:47:09,142 INFO     Evaluating the model... (48500/50000)
2025-12-12 23:47:11,640 INFO     Evaluating the model... (49000/50000)
2025-12-12 23:47:14,323 INFO     Evaluating the model... (49500/50000)
2025-12-12 23:47:17,165 INFO     Valid MRR at step 20000: 0.397866
2025-12-12 23:47:17,166 INFO     Valid MR at step 20000: 1442.615940
2025-12-12 23:47:17,166 INFO     Valid HITS@1 at step 20000: 0.328760
2025-12-12 23:47:17,166 INFO     Valid HITS@3 at step 20000: 0.433680
2025-12-12 23:47:17,166 INFO     Valid HITS@10 at step 20000: 0.522210
2025-12-12 23:47:17,166 INFO     Evaluating on Test Dataset...
2025-12-12 23:47:17,737 INFO     Evaluating the model... (0/59072)
2025-12-12 23:47:20,451 INFO     Evaluating the model... (500/59072)
2025-12-12 23:47:24,474 INFO     Evaluating the model... (1000/59072)
2025-12-12 23:47:27,228 INFO     Evaluating the model... (1500/59072)
2025-12-12 23:47:29,799 INFO     Evaluating the model... (2000/59072)
2025-12-12 23:47:32,389 INFO     Evaluating the model... (2500/59072)
2025-12-12 23:47:34,805 INFO     Evaluating the model... (3000/59072)
2025-12-12 23:47:38,561 INFO     Evaluating the model... (3500/59072)
2025-12-12 23:47:41,278 INFO     Evaluating the model... (4000/59072)
2025-12-12 23:47:43,997 INFO     Evaluating the model... (4500/59072)
2025-12-12 23:47:46,581 INFO     Evaluating the model... (5000/59072)
2025-12-12 23:47:49,294 INFO     Evaluating the model... (5500/59072)
2025-12-12 23:47:52,137 INFO     Evaluating the model... (6000/59072)
2025-12-12 23:47:54,708 INFO     Evaluating the model... (6500/59072)
2025-12-12 23:47:57,180 INFO     Evaluating the model... (7000/59072)
2025-12-12 23:47:59,798 INFO     Evaluating the model... (7500/59072)
2025-12-12 23:48:02,368 INFO     Evaluating the model... (8000/59072)
2025-12-12 23:48:05,574 INFO     Evaluating the model... (8500/59072)
2025-12-12 23:48:07,984 INFO     Evaluating the model... (9000/59072)
2025-12-12 23:48:10,404 INFO     Evaluating the model... (9500/59072)
2025-12-12 23:48:13,142 INFO     Evaluating the model... (10000/59072)
2025-12-12 23:48:15,532 INFO     Evaluating the model... (10500/59072)
2025-12-12 23:48:18,218 INFO     Evaluating the model... (11000/59072)
2025-12-12 23:48:20,668 INFO     Evaluating the model... (11500/59072)
2025-12-12 23:48:23,296 INFO     Evaluating the model... (12000/59072)
2025-12-12 23:48:25,839 INFO     Evaluating the model... (12500/59072)
2025-12-12 23:48:28,621 INFO     Evaluating the model... (13000/59072)
2025-12-12 23:48:31,012 INFO     Evaluating the model... (13500/59072)
2025-12-12 23:48:33,348 INFO     Evaluating the model... (14000/59072)
2025-12-12 23:48:36,190 INFO     Evaluating the model... (14500/59072)
2025-12-12 23:48:38,820 INFO     Evaluating the model... (15000/59072)
2025-12-12 23:48:42,162 INFO     Evaluating the model... (15500/59072)
2025-12-12 23:48:44,725 INFO     Evaluating the model... (16000/59072)
2025-12-12 23:48:47,385 INFO     Evaluating the model... (16500/59072)
2025-12-12 23:48:49,759 INFO     Evaluating the model... (17000/59072)
2025-12-12 23:48:52,139 INFO     Evaluating the model... (17500/59072)
2025-12-12 23:48:55,472 INFO     Evaluating the model... (18000/59072)
2025-12-12 23:48:58,075 INFO     Evaluating the model... (18500/59072)
2025-12-12 23:49:00,626 INFO     Evaluating the model... (19000/59072)
2025-12-12 23:49:03,084 INFO     Evaluating the model... (19500/59072)
2025-12-12 23:49:05,535 INFO     Evaluating the model... (20000/59072)
2025-12-12 23:49:08,967 INFO     Evaluating the model... (20500/59072)
2025-12-12 23:49:11,514 INFO     Evaluating the model... (21000/59072)
2025-12-12 23:49:13,950 INFO     Evaluating the model... (21500/59072)
2025-12-12 23:49:16,452 INFO     Evaluating the model... (22000/59072)
2025-12-12 23:49:18,910 INFO     Evaluating the model... (22500/59072)
2025-12-12 23:49:22,335 INFO     Evaluating the model... (23000/59072)
2025-12-12 23:49:24,652 INFO     Evaluating the model... (23500/59072)
2025-12-12 23:49:27,159 INFO     Evaluating the model... (24000/59072)
2025-12-12 23:49:29,621 INFO     Evaluating the model... (24500/59072)
2025-12-12 23:49:32,256 INFO     Evaluating the model... (25000/59072)
2025-12-12 23:49:36,214 INFO     Evaluating the model... (25500/59072)
2025-12-12 23:49:38,773 INFO     Evaluating the model... (26000/59072)
2025-12-12 23:49:41,438 INFO     Evaluating the model... (26500/59072)
2025-12-12 23:49:44,275 INFO     Evaluating the model... (27000/59072)
2025-12-12 23:49:46,826 INFO     Evaluating the model... (27500/59072)
2025-12-12 23:49:50,318 INFO     Evaluating the model... (28000/59072)
2025-12-12 23:49:52,737 INFO     Evaluating the model... (28500/59072)
2025-12-12 23:49:55,400 INFO     Evaluating the model... (29000/59072)
2025-12-12 23:49:57,861 INFO     Evaluating the model... (29500/59072)
2025-12-12 23:50:01,936 INFO     Evaluating the model... (30000/59072)
2025-12-12 23:50:04,337 INFO     Evaluating the model... (30500/59072)
2025-12-12 23:50:07,206 INFO     Evaluating the model... (31000/59072)
2025-12-12 23:50:09,616 INFO     Evaluating the model... (31500/59072)
2025-12-12 23:50:12,168 INFO     Evaluating the model... (32000/59072)
2025-12-12 23:50:15,329 INFO     Evaluating the model... (32500/59072)
2025-12-12 23:50:17,900 INFO     Evaluating the model... (33000/59072)
2025-12-12 23:50:20,379 INFO     Evaluating the model... (33500/59072)
2025-12-12 23:50:22,782 INFO     Evaluating the model... (34000/59072)
2025-12-12 23:50:25,302 INFO     Evaluating the model... (34500/59072)
2025-12-12 23:50:28,733 INFO     Evaluating the model... (35000/59072)
2025-12-12 23:50:31,321 INFO     Evaluating the model... (35500/59072)
2025-12-12 23:50:33,883 INFO     Evaluating the model... (36000/59072)
2025-12-12 23:50:36,664 INFO     Evaluating the model... (36500/59072)
2025-12-12 23:50:39,421 INFO     Evaluating the model... (37000/59072)
2025-12-12 23:50:42,932 INFO     Evaluating the model... (37500/59072)
2025-12-12 23:50:45,719 INFO     Evaluating the model... (38000/59072)
2025-12-12 23:50:48,204 INFO     Evaluating the model... (38500/59072)
2025-12-12 23:50:50,669 INFO     Evaluating the model... (39000/59072)
2025-12-12 23:50:53,418 INFO     Evaluating the model... (39500/59072)
2025-12-12 23:50:56,920 INFO     Evaluating the model... (40000/59072)
2025-12-12 23:50:59,385 INFO     Evaluating the model... (40500/59072)
2025-12-12 23:51:01,835 INFO     Evaluating the model... (41000/59072)
2025-12-12 23:51:04,411 INFO     Evaluating the model... (41500/59072)
2025-12-12 23:51:06,991 INFO     Evaluating the model... (42000/59072)
2025-12-12 23:51:10,658 INFO     Evaluating the model... (42500/59072)
2025-12-12 23:51:13,220 INFO     Evaluating the model... (43000/59072)
2025-12-12 23:51:15,848 INFO     Evaluating the model... (43500/59072)
2025-12-12 23:51:18,387 INFO     Evaluating the model... (44000/59072)
2025-12-12 23:51:21,574 INFO     Evaluating the model... (44500/59072)
2025-12-12 23:51:24,039 INFO     Evaluating the model... (45000/59072)
2025-12-12 23:51:26,720 INFO     Evaluating the model... (45500/59072)
2025-12-12 23:51:29,348 INFO     Evaluating the model... (46000/59072)
2025-12-12 23:51:31,888 INFO     Evaluating the model... (46500/59072)
2025-12-12 23:51:35,134 INFO     Evaluating the model... (47000/59072)
2025-12-12 23:51:37,907 INFO     Evaluating the model... (47500/59072)
2025-12-12 23:51:40,890 INFO     Evaluating the model... (48000/59072)
2025-12-12 23:51:43,643 INFO     Evaluating the model... (48500/59072)
2025-12-12 23:51:46,344 INFO     Evaluating the model... (49000/59072)
2025-12-12 23:51:49,564 INFO     Evaluating the model... (49500/59072)
2025-12-12 23:51:52,352 INFO     Evaluating the model... (50000/59072)
2025-12-12 23:51:54,875 INFO     Evaluating the model... (50500/59072)
2025-12-12 23:51:57,755 INFO     Evaluating the model... (51000/59072)
2025-12-12 23:52:00,275 INFO     Evaluating the model... (51500/59072)
2025-12-12 23:52:03,988 INFO     Evaluating the model... (52000/59072)
2025-12-12 23:52:06,464 INFO     Evaluating the model... (52500/59072)
2025-12-12 23:52:08,932 INFO     Evaluating the model... (53000/59072)
2025-12-12 23:52:11,370 INFO     Evaluating the model... (53500/59072)
2025-12-12 23:52:14,087 INFO     Evaluating the model... (54000/59072)
2025-12-12 23:52:17,543 INFO     Evaluating the model... (54500/59072)
2025-12-12 23:52:20,027 INFO     Evaluating the model... (55000/59072)
2025-12-12 23:52:22,527 INFO     Evaluating the model... (55500/59072)
2025-12-12 23:52:25,259 INFO     Evaluating the model... (56000/59072)
2025-12-12 23:52:27,674 INFO     Evaluating the model... (56500/59072)
2025-12-12 23:52:31,225 INFO     Evaluating the model... (57000/59072)
2025-12-12 23:52:33,756 INFO     Evaluating the model... (57500/59072)
2025-12-12 23:52:36,688 INFO     Evaluating the model... (58000/59072)
2025-12-12 23:52:39,458 INFO     Evaluating the model... (58500/59072)
2025-12-12 23:52:42,104 INFO     Evaluating the model... (59000/59072)
2025-12-12 23:52:42,801 INFO     Test MRR at step 20000: 0.393363
2025-12-12 23:52:42,801 INFO     Test MR at step 20000: 1461.822688
2025-12-12 23:52:42,801 INFO     Test HITS@1 at step 20000: 0.323721
2025-12-12 23:52:42,801 INFO     Test HITS@3 at step 20000: 0.430228
2025-12-12 23:52:42,801 INFO     Test HITS@10 at step 20000: 0.517614
2025-12-12 23:52:44,988 INFO     Training average regularization at step 20100: 0.364019
2025-12-12 23:52:44,988 INFO     Training average positive_sample_loss at step 20100: 0.127132
2025-12-12 23:52:44,988 INFO     Training average negative_sample_loss at step 20100: 0.141449
2025-12-12 23:52:44,988 INFO     Training average loss at step 20100: 0.498310
2025-12-12 23:52:47,175 INFO     Training average regularization at step 20200: 0.357022
2025-12-12 23:52:47,176 INFO     Training average positive_sample_loss at step 20200: 0.148038
2025-12-12 23:52:47,177 INFO     Training average negative_sample_loss at step 20200: 0.129034
2025-12-12 23:52:47,177 INFO     Training average loss at step 20200: 0.495558
2025-12-12 23:52:49,332 INFO     Training average regularization at step 20300: 0.353539
2025-12-12 23:52:49,332 INFO     Training average positive_sample_loss at step 20300: 0.147469
2025-12-12 23:52:49,332 INFO     Training average negative_sample_loss at step 20300: 0.132255
2025-12-12 23:52:49,332 INFO     Training average loss at step 20300: 0.493401
2025-12-12 23:52:51,502 INFO     Training average regularization at step 20400: 0.351384
2025-12-12 23:52:51,503 INFO     Training average positive_sample_loss at step 20400: 0.149812
2025-12-12 23:52:51,503 INFO     Training average negative_sample_loss at step 20400: 0.132569
2025-12-12 23:52:51,503 INFO     Training average loss at step 20400: 0.492575
2025-12-12 23:52:53,672 INFO     Training average regularization at step 20500: 0.349922
2025-12-12 23:52:53,673 INFO     Training average positive_sample_loss at step 20500: 0.144924
2025-12-12 23:52:53,673 INFO     Training average negative_sample_loss at step 20500: 0.132961
2025-12-12 23:52:53,673 INFO     Training average loss at step 20500: 0.488864
2025-12-12 23:52:55,802 INFO     Training average regularization at step 20600: 0.348863
2025-12-12 23:52:55,802 INFO     Training average positive_sample_loss at step 20600: 0.149761
2025-12-12 23:52:55,802 INFO     Training average negative_sample_loss at step 20600: 0.122772
2025-12-12 23:52:55,802 INFO     Training average loss at step 20600: 0.485130
2025-12-12 23:52:57,994 INFO     Training average regularization at step 20700: 0.348048
2025-12-12 23:52:57,994 INFO     Training average positive_sample_loss at step 20700: 0.142522
2025-12-12 23:52:57,994 INFO     Training average negative_sample_loss at step 20700: 0.130556
2025-12-12 23:52:57,995 INFO     Training average loss at step 20700: 0.484586
2025-12-12 23:53:00,116 INFO     Training average regularization at step 20800: 0.347358
2025-12-12 23:53:00,117 INFO     Training average positive_sample_loss at step 20800: 0.140360
2025-12-12 23:53:00,117 INFO     Training average negative_sample_loss at step 20800: 0.125555
2025-12-12 23:53:00,117 INFO     Training average loss at step 20800: 0.480316
2025-12-12 23:53:02,238 INFO     Training average regularization at step 20900: 0.346751
2025-12-12 23:53:02,239 INFO     Training average positive_sample_loss at step 20900: 0.138518
2025-12-12 23:53:02,239 INFO     Training average negative_sample_loss at step 20900: 0.131544
2025-12-12 23:53:02,239 INFO     Training average loss at step 20900: 0.481782
2025-12-12 23:53:04,367 INFO     Training average regularization at step 21000: 0.346215
2025-12-12 23:53:04,367 INFO     Training average positive_sample_loss at step 21000: 0.132262
2025-12-12 23:53:04,367 INFO     Training average negative_sample_loss at step 21000: 0.126441
2025-12-12 23:53:04,367 INFO     Training average loss at step 21000: 0.475567
2025-12-12 23:53:06,521 INFO     Training average regularization at step 21100: 0.345720
2025-12-12 23:53:06,521 INFO     Training average positive_sample_loss at step 21100: 0.128980
2025-12-12 23:53:06,521 INFO     Training average negative_sample_loss at step 21100: 0.125096
2025-12-12 23:53:06,521 INFO     Training average loss at step 21100: 0.472759
2025-12-12 23:53:08,653 INFO     Training average regularization at step 21200: 0.345258
2025-12-12 23:53:08,654 INFO     Training average positive_sample_loss at step 21200: 0.123795
2025-12-12 23:53:08,654 INFO     Training average negative_sample_loss at step 21200: 0.123574
2025-12-12 23:53:08,654 INFO     Training average loss at step 21200: 0.468943
2025-12-12 23:53:10,779 INFO     Training average regularization at step 21300: 0.344809
2025-12-12 23:53:10,779 INFO     Training average positive_sample_loss at step 21300: 0.122614
2025-12-12 23:53:10,779 INFO     Training average negative_sample_loss at step 21300: 0.123298
2025-12-12 23:53:10,779 INFO     Training average loss at step 21300: 0.467765
2025-12-12 23:53:12,881 INFO     Training average regularization at step 21400: 0.344374
2025-12-12 23:53:12,881 INFO     Training average positive_sample_loss at step 21400: 0.122342
2025-12-12 23:53:12,881 INFO     Training average negative_sample_loss at step 21400: 0.129904
2025-12-12 23:53:12,881 INFO     Training average loss at step 21400: 0.470497
2025-12-12 23:53:14,978 INFO     Training average regularization at step 21500: 0.343955
2025-12-12 23:53:14,978 INFO     Training average positive_sample_loss at step 21500: 0.119542
2025-12-12 23:53:14,978 INFO     Training average negative_sample_loss at step 21500: 0.127539
2025-12-12 23:53:14,978 INFO     Training average loss at step 21500: 0.467495
2025-12-12 23:53:17,126 INFO     Training average regularization at step 21600: 0.343563
2025-12-12 23:53:17,126 INFO     Training average positive_sample_loss at step 21600: 0.118195
2025-12-12 23:53:17,126 INFO     Training average negative_sample_loss at step 21600: 0.128494
2025-12-12 23:53:17,126 INFO     Training average loss at step 21600: 0.466908
2025-12-12 23:53:19,234 INFO     Training average regularization at step 21700: 0.343173
2025-12-12 23:53:19,234 INFO     Training average positive_sample_loss at step 21700: 0.115703
2025-12-12 23:53:19,234 INFO     Training average negative_sample_loss at step 21700: 0.131262
2025-12-12 23:53:19,234 INFO     Training average loss at step 21700: 0.466655
2025-12-12 23:53:21,402 INFO     Training average regularization at step 21800: 0.342779
2025-12-12 23:53:21,403 INFO     Training average positive_sample_loss at step 21800: 0.109531
2025-12-12 23:53:21,403 INFO     Training average negative_sample_loss at step 21800: 0.126851
2025-12-12 23:53:21,403 INFO     Training average loss at step 21800: 0.460970
2025-12-12 23:53:23,519 INFO     Training average regularization at step 21900: 0.342405
2025-12-12 23:53:23,519 INFO     Training average positive_sample_loss at step 21900: 0.112305
2025-12-12 23:53:23,519 INFO     Training average negative_sample_loss at step 21900: 0.124812
2025-12-12 23:53:23,520 INFO     Training average loss at step 21900: 0.460963
2025-12-12 23:53:25,643 INFO     Training average regularization at step 22000: 0.342050
2025-12-12 23:53:25,643 INFO     Training average positive_sample_loss at step 22000: 0.103720
2025-12-12 23:53:25,644 INFO     Training average negative_sample_loss at step 22000: 0.126379
2025-12-12 23:53:25,644 INFO     Training average loss at step 22000: 0.457100
2025-12-12 23:53:27,801 INFO     Training average regularization at step 22100: 0.341701
2025-12-12 23:53:27,801 INFO     Training average positive_sample_loss at step 22100: 0.106713
2025-12-12 23:53:27,801 INFO     Training average negative_sample_loss at step 22100: 0.123654
2025-12-12 23:53:27,801 INFO     Training average loss at step 22100: 0.456884
2025-12-12 23:53:29,907 INFO     Training average regularization at step 22200: 0.341348
2025-12-12 23:53:29,907 INFO     Training average positive_sample_loss at step 22200: 0.103870
2025-12-12 23:53:29,907 INFO     Training average negative_sample_loss at step 22200: 0.121731
2025-12-12 23:53:29,907 INFO     Training average loss at step 22200: 0.454148
2025-12-12 23:53:32,099 INFO     Training average regularization at step 22300: 0.341012
2025-12-12 23:53:32,099 INFO     Training average positive_sample_loss at step 22300: 0.100726
2025-12-12 23:53:32,099 INFO     Training average negative_sample_loss at step 22300: 0.124584
2025-12-12 23:53:32,099 INFO     Training average loss at step 22300: 0.453666
2025-12-12 23:53:34,263 INFO     Training average regularization at step 22400: 0.340672
2025-12-12 23:53:34,263 INFO     Training average positive_sample_loss at step 22400: 0.100975
2025-12-12 23:53:34,263 INFO     Training average negative_sample_loss at step 22400: 0.124561
2025-12-12 23:53:34,263 INFO     Training average loss at step 22400: 0.453440
2025-12-12 23:53:36,454 INFO     Training average regularization at step 22500: 0.340330
2025-12-12 23:53:36,454 INFO     Training average positive_sample_loss at step 22500: 0.102184
2025-12-12 23:53:36,454 INFO     Training average negative_sample_loss at step 22500: 0.124630
2025-12-12 23:53:36,454 INFO     Training average loss at step 22500: 0.453737
2025-12-12 23:53:38,685 INFO     Training average regularization at step 22600: 0.340009
2025-12-12 23:53:38,686 INFO     Training average positive_sample_loss at step 22600: 0.098336
2025-12-12 23:53:38,686 INFO     Training average negative_sample_loss at step 22600: 0.125400
2025-12-12 23:53:38,686 INFO     Training average loss at step 22600: 0.451877
2025-12-12 23:53:40,858 INFO     Training average regularization at step 22700: 0.339676
2025-12-12 23:53:40,858 INFO     Training average positive_sample_loss at step 22700: 0.093500
2025-12-12 23:53:40,858 INFO     Training average negative_sample_loss at step 22700: 0.125134
2025-12-12 23:53:40,858 INFO     Training average loss at step 22700: 0.448994
2025-12-12 23:53:43,077 INFO     Training average regularization at step 22800: 0.339346
2025-12-12 23:53:43,077 INFO     Training average positive_sample_loss at step 22800: 0.095234
2025-12-12 23:53:43,077 INFO     Training average negative_sample_loss at step 22800: 0.120236
2025-12-12 23:53:43,077 INFO     Training average loss at step 22800: 0.447081
2025-12-12 23:53:45,258 INFO     Training average regularization at step 22900: 0.339043
2025-12-12 23:53:45,258 INFO     Training average positive_sample_loss at step 22900: 0.092454
2025-12-12 23:53:45,258 INFO     Training average negative_sample_loss at step 22900: 0.123802
2025-12-12 23:53:45,258 INFO     Training average loss at step 22900: 0.447171
2025-12-12 23:53:47,445 INFO     Training average regularization at step 23000: 0.338733
2025-12-12 23:53:47,445 INFO     Training average positive_sample_loss at step 23000: 0.089488
2025-12-12 23:53:47,445 INFO     Training average negative_sample_loss at step 23000: 0.121873
2025-12-12 23:53:47,445 INFO     Training average loss at step 23000: 0.444413
2025-12-12 23:53:49,571 INFO     Training average regularization at step 23100: 0.338419
2025-12-12 23:53:49,571 INFO     Training average positive_sample_loss at step 23100: 0.092619
2025-12-12 23:53:49,571 INFO     Training average negative_sample_loss at step 23100: 0.121710
2025-12-12 23:53:49,571 INFO     Training average loss at step 23100: 0.445584
2025-12-12 23:53:51,688 INFO     Training average regularization at step 23200: 0.338111
2025-12-12 23:53:51,688 INFO     Training average positive_sample_loss at step 23200: 0.091265
2025-12-12 23:53:51,688 INFO     Training average negative_sample_loss at step 23200: 0.122895
2025-12-12 23:53:51,688 INFO     Training average loss at step 23200: 0.445191
2025-12-12 23:53:53,838 INFO     Training average regularization at step 23300: 0.337800
2025-12-12 23:53:53,838 INFO     Training average positive_sample_loss at step 23300: 0.090316
2025-12-12 23:53:53,838 INFO     Training average negative_sample_loss at step 23300: 0.121250
2025-12-12 23:53:53,838 INFO     Training average loss at step 23300: 0.443583
2025-12-12 23:53:55,986 INFO     Training average regularization at step 23400: 0.337505
2025-12-12 23:53:55,986 INFO     Training average positive_sample_loss at step 23400: 0.086721
2025-12-12 23:53:55,986 INFO     Training average negative_sample_loss at step 23400: 0.123063
2025-12-12 23:53:55,986 INFO     Training average loss at step 23400: 0.442397
2025-12-12 23:53:58,122 INFO     Training average regularization at step 23500: 0.337206
2025-12-12 23:53:58,122 INFO     Training average positive_sample_loss at step 23500: 0.087795
2025-12-12 23:53:58,123 INFO     Training average negative_sample_loss at step 23500: 0.119031
2025-12-12 23:53:58,123 INFO     Training average loss at step 23500: 0.440619
2025-12-12 23:54:00,293 INFO     Training average regularization at step 23600: 0.336909
2025-12-12 23:54:00,293 INFO     Training average positive_sample_loss at step 23600: 0.087825
2025-12-12 23:54:00,293 INFO     Training average negative_sample_loss at step 23600: 0.123797
2025-12-12 23:54:00,293 INFO     Training average loss at step 23600: 0.442721
2025-12-12 23:54:02,405 INFO     Training average regularization at step 23700: 0.336605
2025-12-12 23:54:02,406 INFO     Training average positive_sample_loss at step 23700: 0.083419
2025-12-12 23:54:02,406 INFO     Training average negative_sample_loss at step 23700: 0.122844
2025-12-12 23:54:02,406 INFO     Training average loss at step 23700: 0.439736
2025-12-12 23:54:04,554 INFO     Training average regularization at step 23800: 0.336316
2025-12-12 23:54:04,554 INFO     Training average positive_sample_loss at step 23800: 0.086964
2025-12-12 23:54:04,554 INFO     Training average negative_sample_loss at step 23800: 0.120388
2025-12-12 23:54:04,554 INFO     Training average loss at step 23800: 0.439992
2025-12-12 23:54:06,697 INFO     Training average regularization at step 23900: 0.336022
2025-12-12 23:54:06,697 INFO     Training average positive_sample_loss at step 23900: 0.085433
2025-12-12 23:54:06,697 INFO     Training average negative_sample_loss at step 23900: 0.123293
2025-12-12 23:54:06,697 INFO     Training average loss at step 23900: 0.440385
2025-12-12 23:54:08,876 INFO     Training average regularization at step 24000: 0.335728
2025-12-12 23:54:08,877 INFO     Training average positive_sample_loss at step 24000: 0.084926
2025-12-12 23:54:08,877 INFO     Training average negative_sample_loss at step 24000: 0.121960
2025-12-12 23:54:08,877 INFO     Training average loss at step 24000: 0.439171
2025-12-12 23:54:11,001 INFO     Training average regularization at step 24100: 0.335430
2025-12-12 23:54:11,001 INFO     Training average positive_sample_loss at step 24100: 0.082272
2025-12-12 23:54:11,002 INFO     Training average negative_sample_loss at step 24100: 0.121138
2025-12-12 23:54:11,002 INFO     Training average loss at step 24100: 0.437135
2025-12-12 23:54:14,122 INFO     Training average regularization at step 24200: 0.335116
2025-12-12 23:54:14,122 INFO     Training average positive_sample_loss at step 24200: 0.074094
2025-12-12 23:54:14,122 INFO     Training average negative_sample_loss at step 24200: 0.118779
2025-12-12 23:54:14,122 INFO     Training average loss at step 24200: 0.431553
2025-12-12 23:54:16,308 INFO     Training average regularization at step 24300: 0.334764
2025-12-12 23:54:16,309 INFO     Training average positive_sample_loss at step 24300: 0.063567
2025-12-12 23:54:16,309 INFO     Training average negative_sample_loss at step 24300: 0.115081
2025-12-12 23:54:16,309 INFO     Training average loss at step 24300: 0.424088
2025-12-12 23:54:18,417 INFO     Training average regularization at step 24400: 0.334411
2025-12-12 23:54:18,418 INFO     Training average positive_sample_loss at step 24400: 0.062763
2025-12-12 23:54:18,418 INFO     Training average negative_sample_loss at step 24400: 0.114242
2025-12-12 23:54:18,418 INFO     Training average loss at step 24400: 0.422913
2025-12-12 23:54:20,521 INFO     Training average regularization at step 24500: 0.334073
2025-12-12 23:54:20,521 INFO     Training average positive_sample_loss at step 24500: 0.066346
2025-12-12 23:54:20,521 INFO     Training average negative_sample_loss at step 24500: 0.113601
2025-12-12 23:54:20,522 INFO     Training average loss at step 24500: 0.424047
2025-12-12 23:54:22,614 INFO     Training average regularization at step 24600: 0.333748
2025-12-12 23:54:22,614 INFO     Training average positive_sample_loss at step 24600: 0.065742
2025-12-12 23:54:22,614 INFO     Training average negative_sample_loss at step 24600: 0.113341
2025-12-12 23:54:22,614 INFO     Training average loss at step 24600: 0.423290
2025-12-12 23:54:24,730 INFO     Training average regularization at step 24700: 0.333426
2025-12-12 23:54:24,730 INFO     Training average positive_sample_loss at step 24700: 0.066238
2025-12-12 23:54:24,730 INFO     Training average negative_sample_loss at step 24700: 0.111126
2025-12-12 23:54:24,730 INFO     Training average loss at step 24700: 0.422108
2025-12-12 23:54:26,903 INFO     Training average regularization at step 24800: 0.333115
2025-12-12 23:54:26,903 INFO     Training average positive_sample_loss at step 24800: 0.066447
2025-12-12 23:54:26,903 INFO     Training average negative_sample_loss at step 24800: 0.113723
2025-12-12 23:54:26,903 INFO     Training average loss at step 24800: 0.423200
2025-12-12 23:54:29,080 INFO     Training average regularization at step 24900: 0.332815
2025-12-12 23:54:29,080 INFO     Training average positive_sample_loss at step 24900: 0.070388
2025-12-12 23:54:29,080 INFO     Training average negative_sample_loss at step 24900: 0.112848
2025-12-12 23:54:29,080 INFO     Training average loss at step 24900: 0.424433
2025-12-12 23:54:31,202 INFO     Training average regularization at step 25000: 0.332521
2025-12-12 23:54:31,203 INFO     Training average positive_sample_loss at step 25000: 0.067806
2025-12-12 23:54:31,203 INFO     Training average negative_sample_loss at step 25000: 0.111301
2025-12-12 23:54:31,203 INFO     Training average loss at step 25000: 0.422074
2025-12-12 23:54:33,347 INFO     Training average regularization at step 25100: 0.332235
2025-12-12 23:54:33,347 INFO     Training average positive_sample_loss at step 25100: 0.068829
2025-12-12 23:54:33,347 INFO     Training average negative_sample_loss at step 25100: 0.111347
2025-12-12 23:54:33,347 INFO     Training average loss at step 25100: 0.422323
2025-12-12 23:54:35,524 INFO     Training average regularization at step 25200: 0.331947
2025-12-12 23:54:35,525 INFO     Training average positive_sample_loss at step 25200: 0.068639
2025-12-12 23:54:35,525 INFO     Training average negative_sample_loss at step 25200: 0.105352
2025-12-12 23:54:35,525 INFO     Training average loss at step 25200: 0.418943
2025-12-12 23:54:37,794 INFO     Training average regularization at step 25300: 0.331674
2025-12-12 23:54:37,797 INFO     Training average positive_sample_loss at step 25300: 0.068543
2025-12-12 23:54:37,797 INFO     Training average negative_sample_loss at step 25300: 0.107639
2025-12-12 23:54:37,797 INFO     Training average loss at step 25300: 0.419765
2025-12-12 23:54:40,000 INFO     Training average regularization at step 25400: 0.331386
2025-12-12 23:54:40,000 INFO     Training average positive_sample_loss at step 25400: 0.070564
2025-12-12 23:54:40,000 INFO     Training average negative_sample_loss at step 25400: 0.110829
2025-12-12 23:54:40,000 INFO     Training average loss at step 25400: 0.422082
2025-12-12 23:54:42,205 INFO     Training average regularization at step 25500: 0.331102
2025-12-12 23:54:42,205 INFO     Training average positive_sample_loss at step 25500: 0.070618
2025-12-12 23:54:42,205 INFO     Training average negative_sample_loss at step 25500: 0.109045
2025-12-12 23:54:42,205 INFO     Training average loss at step 25500: 0.420933
2025-12-12 23:54:44,371 INFO     Training average regularization at step 25600: 0.330844
2025-12-12 23:54:44,371 INFO     Training average positive_sample_loss at step 25600: 0.070849
2025-12-12 23:54:44,371 INFO     Training average negative_sample_loss at step 25600: 0.109176
2025-12-12 23:54:44,371 INFO     Training average loss at step 25600: 0.420856
2025-12-12 23:54:46,543 INFO     Training average regularization at step 25700: 0.330578
2025-12-12 23:54:46,544 INFO     Training average positive_sample_loss at step 25700: 0.070090
2025-12-12 23:54:46,544 INFO     Training average negative_sample_loss at step 25700: 0.111048
2025-12-12 23:54:46,544 INFO     Training average loss at step 25700: 0.421146
2025-12-12 23:54:48,735 INFO     Training average regularization at step 25800: 0.330316
2025-12-12 23:54:48,735 INFO     Training average positive_sample_loss at step 25800: 0.070757
2025-12-12 23:54:48,735 INFO     Training average negative_sample_loss at step 25800: 0.109878
2025-12-12 23:54:48,735 INFO     Training average loss at step 25800: 0.420633
2025-12-12 23:54:50,903 INFO     Training average regularization at step 25900: 0.330059
2025-12-12 23:54:50,904 INFO     Training average positive_sample_loss at step 25900: 0.070093
2025-12-12 23:54:50,904 INFO     Training average negative_sample_loss at step 25900: 0.108141
2025-12-12 23:54:50,904 INFO     Training average loss at step 25900: 0.419176
2025-12-12 23:54:53,067 INFO     Training average regularization at step 26000: 0.329800
2025-12-12 23:54:53,068 INFO     Training average positive_sample_loss at step 26000: 0.071760
2025-12-12 23:54:53,068 INFO     Training average negative_sample_loss at step 26000: 0.109224
2025-12-12 23:54:53,068 INFO     Training average loss at step 26000: 0.420292
2025-12-12 23:54:55,231 INFO     Training average regularization at step 26100: 0.329550
2025-12-12 23:54:55,231 INFO     Training average positive_sample_loss at step 26100: 0.070836
2025-12-12 23:54:55,231 INFO     Training average negative_sample_loss at step 26100: 0.110040
2025-12-12 23:54:55,231 INFO     Training average loss at step 26100: 0.419988
2025-12-12 23:54:57,383 INFO     Training average regularization at step 26200: 0.329288
2025-12-12 23:54:57,383 INFO     Training average positive_sample_loss at step 26200: 0.071265
2025-12-12 23:54:57,383 INFO     Training average negative_sample_loss at step 26200: 0.110623
2025-12-12 23:54:57,383 INFO     Training average loss at step 26200: 0.420232
2025-12-12 23:54:59,588 INFO     Training average regularization at step 26300: 0.329030
2025-12-12 23:54:59,588 INFO     Training average positive_sample_loss at step 26300: 0.071845
2025-12-12 23:54:59,589 INFO     Training average negative_sample_loss at step 26300: 0.107877
2025-12-12 23:54:59,589 INFO     Training average loss at step 26300: 0.418891
2025-12-12 23:55:01,777 INFO     Training average regularization at step 26400: 0.328784
2025-12-12 23:55:01,778 INFO     Training average positive_sample_loss at step 26400: 0.070664
2025-12-12 23:55:01,778 INFO     Training average negative_sample_loss at step 26400: 0.109385
2025-12-12 23:55:01,778 INFO     Training average loss at step 26400: 0.418808
2025-12-12 23:55:03,943 INFO     Training average regularization at step 26500: 0.328547
2025-12-12 23:55:03,943 INFO     Training average positive_sample_loss at step 26500: 0.071516
2025-12-12 23:55:03,943 INFO     Training average negative_sample_loss at step 26500: 0.113758
2025-12-12 23:55:03,943 INFO     Training average loss at step 26500: 0.421184
2025-12-12 23:55:06,141 INFO     Training average regularization at step 26600: 0.328292
2025-12-12 23:55:06,141 INFO     Training average positive_sample_loss at step 26600: 0.070046
2025-12-12 23:55:06,141 INFO     Training average negative_sample_loss at step 26600: 0.110289
2025-12-12 23:55:06,141 INFO     Training average loss at step 26600: 0.418459
2025-12-12 23:55:08,277 INFO     Training average regularization at step 26700: 0.328049
2025-12-12 23:55:08,277 INFO     Training average positive_sample_loss at step 26700: 0.071796
2025-12-12 23:55:08,278 INFO     Training average negative_sample_loss at step 26700: 0.109845
2025-12-12 23:55:08,278 INFO     Training average loss at step 26700: 0.418869
2025-12-12 23:55:10,464 INFO     Training average regularization at step 26800: 0.327814
2025-12-12 23:55:10,464 INFO     Training average positive_sample_loss at step 26800: 0.070387
2025-12-12 23:55:10,464 INFO     Training average negative_sample_loss at step 26800: 0.107943
2025-12-12 23:55:10,465 INFO     Training average loss at step 26800: 0.416980
2025-12-12 23:55:12,625 INFO     Training average regularization at step 26900: 0.327578
2025-12-12 23:55:12,625 INFO     Training average positive_sample_loss at step 26900: 0.069868
2025-12-12 23:55:12,625 INFO     Training average negative_sample_loss at step 26900: 0.110352
2025-12-12 23:55:12,625 INFO     Training average loss at step 26900: 0.417688
2025-12-12 23:55:14,790 INFO     Training average regularization at step 27000: 0.327325
2025-12-12 23:55:14,790 INFO     Training average positive_sample_loss at step 27000: 0.069930
2025-12-12 23:55:14,790 INFO     Training average negative_sample_loss at step 27000: 0.110585
2025-12-12 23:55:14,790 INFO     Training average loss at step 27000: 0.417583
2025-12-12 23:55:16,939 INFO     Training average regularization at step 27100: 0.327087
2025-12-12 23:55:16,940 INFO     Training average positive_sample_loss at step 27100: 0.070142
2025-12-12 23:55:16,940 INFO     Training average negative_sample_loss at step 27100: 0.110556
2025-12-12 23:55:16,940 INFO     Training average loss at step 27100: 0.417436
2025-12-12 23:55:19,101 INFO     Training average regularization at step 27200: 0.326850
2025-12-12 23:55:19,101 INFO     Training average positive_sample_loss at step 27200: 0.069954
2025-12-12 23:55:19,101 INFO     Training average negative_sample_loss at step 27200: 0.107797
2025-12-12 23:55:19,101 INFO     Training average loss at step 27200: 0.415726
2025-12-12 23:55:21,291 INFO     Training average regularization at step 27300: 0.326615
2025-12-12 23:55:21,292 INFO     Training average positive_sample_loss at step 27300: 0.070502
2025-12-12 23:55:21,292 INFO     Training average negative_sample_loss at step 27300: 0.107350
2025-12-12 23:55:21,292 INFO     Training average loss at step 27300: 0.415541
2025-12-12 23:55:23,453 INFO     Training average regularization at step 27400: 0.326386
2025-12-12 23:55:23,454 INFO     Training average positive_sample_loss at step 27400: 0.069223
2025-12-12 23:55:23,454 INFO     Training average negative_sample_loss at step 27400: 0.110857
2025-12-12 23:55:23,454 INFO     Training average loss at step 27400: 0.416426
2025-12-12 23:55:25,615 INFO     Training average regularization at step 27500: 0.326160
2025-12-12 23:55:25,615 INFO     Training average positive_sample_loss at step 27500: 0.071734
2025-12-12 23:55:25,615 INFO     Training average negative_sample_loss at step 27500: 0.107696
2025-12-12 23:55:25,615 INFO     Training average loss at step 27500: 0.415876
2025-12-12 23:55:27,779 INFO     Training average regularization at step 27600: 0.325935
2025-12-12 23:55:27,780 INFO     Training average positive_sample_loss at step 27600: 0.069270
2025-12-12 23:55:27,780 INFO     Training average negative_sample_loss at step 27600: 0.110805
2025-12-12 23:55:27,780 INFO     Training average loss at step 27600: 0.415973
2025-12-12 23:55:29,939 INFO     Training average regularization at step 27700: 0.325700
2025-12-12 23:55:29,939 INFO     Training average positive_sample_loss at step 27700: 0.069843
2025-12-12 23:55:29,939 INFO     Training average negative_sample_loss at step 27700: 0.107921
2025-12-12 23:55:29,939 INFO     Training average loss at step 27700: 0.414582
2025-12-12 23:55:32,110 INFO     Training average regularization at step 27800: 0.325481
2025-12-12 23:55:32,111 INFO     Training average positive_sample_loss at step 27800: 0.070343
2025-12-12 23:55:32,111 INFO     Training average negative_sample_loss at step 27800: 0.109728
2025-12-12 23:55:32,111 INFO     Training average loss at step 27800: 0.415516
2025-12-12 23:55:34,287 INFO     Training average regularization at step 27900: 0.325259
2025-12-12 23:55:34,287 INFO     Training average positive_sample_loss at step 27900: 0.070061
2025-12-12 23:55:34,287 INFO     Training average negative_sample_loss at step 27900: 0.111613
2025-12-12 23:55:34,287 INFO     Training average loss at step 27900: 0.416096
2025-12-12 23:55:36,473 INFO     Training average regularization at step 28000: 0.325041
2025-12-12 23:55:36,473 INFO     Training average positive_sample_loss at step 28000: 0.070575
2025-12-12 23:55:36,473 INFO     Training average negative_sample_loss at step 28000: 0.109866
2025-12-12 23:55:36,473 INFO     Training average loss at step 28000: 0.415262
2025-12-12 23:55:38,663 INFO     Training average regularization at step 28100: 0.324832
2025-12-12 23:55:38,664 INFO     Training average positive_sample_loss at step 28100: 0.070058
2025-12-12 23:55:38,664 INFO     Training average negative_sample_loss at step 28100: 0.113421
2025-12-12 23:55:38,664 INFO     Training average loss at step 28100: 0.416572
2025-12-12 23:55:40,844 INFO     Training average regularization at step 28200: 0.324613
2025-12-12 23:55:40,844 INFO     Training average positive_sample_loss at step 28200: 0.071545
2025-12-12 23:55:40,844 INFO     Training average negative_sample_loss at step 28200: 0.108550
2025-12-12 23:55:40,844 INFO     Training average loss at step 28200: 0.414661
2025-12-12 23:55:43,049 INFO     Training average regularization at step 28300: 0.324401
2025-12-12 23:55:43,050 INFO     Training average positive_sample_loss at step 28300: 0.070258
2025-12-12 23:55:43,050 INFO     Training average negative_sample_loss at step 28300: 0.109733
2025-12-12 23:55:43,050 INFO     Training average loss at step 28300: 0.414397
2025-12-12 23:55:45,292 INFO     Training average regularization at step 28400: 0.324195
2025-12-12 23:55:45,292 INFO     Training average positive_sample_loss at step 28400: 0.070599
2025-12-12 23:55:45,292 INFO     Training average negative_sample_loss at step 28400: 0.109333
2025-12-12 23:55:45,292 INFO     Training average loss at step 28400: 0.414161
2025-12-12 23:55:47,454 INFO     Training average regularization at step 28500: 0.323992
2025-12-12 23:55:47,454 INFO     Training average positive_sample_loss at step 28500: 0.070422
2025-12-12 23:55:47,454 INFO     Training average negative_sample_loss at step 28500: 0.111550
2025-12-12 23:55:47,454 INFO     Training average loss at step 28500: 0.414978
2025-12-12 23:55:49,612 INFO     Training average regularization at step 28600: 0.323777
2025-12-12 23:55:49,612 INFO     Training average positive_sample_loss at step 28600: 0.070326
2025-12-12 23:55:49,612 INFO     Training average negative_sample_loss at step 28600: 0.111494
2025-12-12 23:55:49,612 INFO     Training average loss at step 28600: 0.414686
2025-12-12 23:55:51,757 INFO     Training average regularization at step 28700: 0.323567
2025-12-12 23:55:51,757 INFO     Training average positive_sample_loss at step 28700: 0.069501
2025-12-12 23:55:51,757 INFO     Training average negative_sample_loss at step 28700: 0.106860
2025-12-12 23:55:51,757 INFO     Training average loss at step 28700: 0.411747
2025-12-12 23:55:53,908 INFO     Training average regularization at step 28800: 0.323360
2025-12-12 23:55:53,908 INFO     Training average positive_sample_loss at step 28800: 0.070809
2025-12-12 23:55:53,908 INFO     Training average negative_sample_loss at step 28800: 0.108188
2025-12-12 23:55:53,908 INFO     Training average loss at step 28800: 0.412859
2025-12-12 23:55:56,087 INFO     Training average regularization at step 28900: 0.323162
2025-12-12 23:55:56,088 INFO     Training average positive_sample_loss at step 28900: 0.070992
2025-12-12 23:55:56,088 INFO     Training average negative_sample_loss at step 28900: 0.109620
2025-12-12 23:55:56,088 INFO     Training average loss at step 28900: 0.413468
2025-12-12 23:55:59,238 INFO     Training average regularization at step 29000: 0.322972
2025-12-12 23:55:59,239 INFO     Training average positive_sample_loss at step 29000: 0.069415
2025-12-12 23:55:59,239 INFO     Training average negative_sample_loss at step 29000: 0.109021
2025-12-12 23:55:59,239 INFO     Training average loss at step 29000: 0.412190
2025-12-12 23:56:01,396 INFO     Training average regularization at step 29100: 0.322742
2025-12-12 23:56:01,396 INFO     Training average positive_sample_loss at step 29100: 0.057962
2025-12-12 23:56:01,396 INFO     Training average negative_sample_loss at step 29100: 0.109450
2025-12-12 23:56:01,396 INFO     Training average loss at step 29100: 0.406448
2025-12-12 23:56:03,534 INFO     Training average regularization at step 29200: 0.322443
2025-12-12 23:56:03,534 INFO     Training average positive_sample_loss at step 29200: 0.058426
2025-12-12 23:56:03,534 INFO     Training average negative_sample_loss at step 29200: 0.106907
2025-12-12 23:56:03,534 INFO     Training average loss at step 29200: 0.405109
2025-12-12 23:56:05,706 INFO     Training average regularization at step 29300: 0.322183
2025-12-12 23:56:05,706 INFO     Training average positive_sample_loss at step 29300: 0.061317
2025-12-12 23:56:05,706 INFO     Training average negative_sample_loss at step 29300: 0.105641
2025-12-12 23:56:05,706 INFO     Training average loss at step 29300: 0.405662
2025-12-12 23:56:07,858 INFO     Training average regularization at step 29400: 0.321927
2025-12-12 23:56:07,859 INFO     Training average positive_sample_loss at step 29400: 0.061159
2025-12-12 23:56:07,859 INFO     Training average negative_sample_loss at step 29400: 0.106977
2025-12-12 23:56:07,859 INFO     Training average loss at step 29400: 0.405995
2025-12-12 23:56:10,010 INFO     Training average regularization at step 29500: 0.321684
2025-12-12 23:56:10,010 INFO     Training average positive_sample_loss at step 29500: 0.062769
2025-12-12 23:56:10,010 INFO     Training average negative_sample_loss at step 29500: 0.106230
2025-12-12 23:56:10,010 INFO     Training average loss at step 29500: 0.406184
2025-12-12 23:56:12,155 INFO     Training average regularization at step 29600: 0.321460
2025-12-12 23:56:12,155 INFO     Training average positive_sample_loss at step 29600: 0.063824
2025-12-12 23:56:12,155 INFO     Training average negative_sample_loss at step 29600: 0.106513
2025-12-12 23:56:12,155 INFO     Training average loss at step 29600: 0.406629
2025-12-12 23:56:14,308 INFO     Training average regularization at step 29700: 0.321251
2025-12-12 23:56:14,308 INFO     Training average positive_sample_loss at step 29700: 0.065801
2025-12-12 23:56:14,308 INFO     Training average negative_sample_loss at step 29700: 0.104858
2025-12-12 23:56:14,308 INFO     Training average loss at step 29700: 0.406581
2025-12-12 23:56:16,516 INFO     Training average regularization at step 29800: 0.321060
2025-12-12 23:56:16,516 INFO     Training average positive_sample_loss at step 29800: 0.064700
2025-12-12 23:56:16,517 INFO     Training average negative_sample_loss at step 29800: 0.104758
2025-12-12 23:56:16,517 INFO     Training average loss at step 29800: 0.405789
2025-12-12 23:56:18,687 INFO     Training average regularization at step 29900: 0.320847
2025-12-12 23:56:18,687 INFO     Training average positive_sample_loss at step 29900: 0.065031
2025-12-12 23:56:18,687 INFO     Training average negative_sample_loss at step 29900: 0.105666
2025-12-12 23:56:18,687 INFO     Training average loss at step 29900: 0.406196
2025-12-12 23:56:20,837 INFO     Training average regularization at step 30000: 0.320646
2025-12-12 23:56:20,838 INFO     Training average positive_sample_loss at step 30000: 0.065958
2025-12-12 23:56:20,838 INFO     Training average negative_sample_loss at step 30000: 0.105432
2025-12-12 23:56:20,838 INFO     Training average loss at step 30000: 0.406341
2025-12-12 23:56:20,838 INFO     Evaluating on Valid Dataset...
2025-12-12 23:56:21,503 INFO     Evaluating the model... (0/50000)
2025-12-12 23:56:24,052 INFO     Evaluating the model... (500/50000)
2025-12-12 23:56:26,743 INFO     Evaluating the model... (1000/50000)
2025-12-12 23:56:29,460 INFO     Evaluating the model... (1500/50000)
2025-12-12 23:56:31,873 INFO     Evaluating the model... (2000/50000)
2025-12-12 23:56:35,249 INFO     Evaluating the model... (2500/50000)
2025-12-12 23:56:38,017 INFO     Evaluating the model... (3000/50000)
2025-12-12 23:56:40,930 INFO     Evaluating the model... (3500/50000)
2025-12-12 23:56:43,647 INFO     Evaluating the model... (4000/50000)
2025-12-12 23:56:46,184 INFO     Evaluating the model... (4500/50000)
2025-12-12 23:56:49,222 INFO     Evaluating the model... (5000/50000)
2025-12-12 23:56:51,924 INFO     Evaluating the model... (5500/50000)
2025-12-12 23:56:54,541 INFO     Evaluating the model... (6000/50000)
2025-12-12 23:56:57,056 INFO     Evaluating the model... (6500/50000)
2025-12-12 23:56:59,490 INFO     Evaluating the model... (7000/50000)
2025-12-12 23:57:02,724 INFO     Evaluating the model... (7500/50000)
2025-12-12 23:57:05,295 INFO     Evaluating the model... (8000/50000)
2025-12-12 23:57:07,715 INFO     Evaluating the model... (8500/50000)
2025-12-12 23:57:10,293 INFO     Evaluating the model... (9000/50000)
2025-12-12 23:57:12,707 INFO     Evaluating the model... (9500/50000)
2025-12-12 23:57:15,874 INFO     Evaluating the model... (10000/50000)
2025-12-12 23:57:18,268 INFO     Evaluating the model... (10500/50000)
2025-12-12 23:57:20,734 INFO     Evaluating the model... (11000/50000)
2025-12-12 23:57:23,108 INFO     Evaluating the model... (11500/50000)
2025-12-12 23:57:26,468 INFO     Evaluating the model... (12000/50000)
2025-12-12 23:57:28,849 INFO     Evaluating the model... (12500/50000)
2025-12-12 23:57:31,309 INFO     Evaluating the model... (13000/50000)
2025-12-12 23:57:33,828 INFO     Evaluating the model... (13500/50000)
2025-12-12 23:57:36,500 INFO     Evaluating the model... (14000/50000)
2025-12-12 23:57:40,016 INFO     Evaluating the model... (14500/50000)
2025-12-12 23:57:42,482 INFO     Evaluating the model... (15000/50000)
2025-12-12 23:57:45,231 INFO     Evaluating the model... (15500/50000)
2025-12-12 23:57:47,800 INFO     Evaluating the model... (16000/50000)
2025-12-12 23:57:50,462 INFO     Evaluating the model... (16500/50000)
2025-12-12 23:57:53,865 INFO     Evaluating the model... (17000/50000)
2025-12-12 23:57:56,358 INFO     Evaluating the model... (17500/50000)
2025-12-12 23:57:58,782 INFO     Evaluating the model... (18000/50000)
2025-12-12 23:58:01,455 INFO     Evaluating the model... (18500/50000)
2025-12-12 23:58:04,002 INFO     Evaluating the model... (19000/50000)
2025-12-12 23:58:07,821 INFO     Evaluating the model... (19500/50000)
2025-12-12 23:58:10,256 INFO     Evaluating the model... (20000/50000)
2025-12-12 23:58:12,871 INFO     Evaluating the model... (20500/50000)
2025-12-12 23:58:15,274 INFO     Evaluating the model... (21000/50000)
2025-12-12 23:58:17,728 INFO     Evaluating the model... (21500/50000)
2025-12-12 23:58:21,493 INFO     Evaluating the model... (22000/50000)
2025-12-12 23:58:24,120 INFO     Evaluating the model... (22500/50000)
2025-12-12 23:58:26,566 INFO     Evaluating the model... (23000/50000)
2025-12-12 23:58:28,984 INFO     Evaluating the model... (23500/50000)
2025-12-12 23:58:31,436 INFO     Evaluating the model... (24000/50000)
2025-12-12 23:58:35,394 INFO     Evaluating the model... (24500/50000)
2025-12-12 23:58:38,361 INFO     Evaluating the model... (25000/50000)
2025-12-12 23:58:41,059 INFO     Evaluating the model... (25500/50000)
2025-12-12 23:58:43,868 INFO     Evaluating the model... (26000/50000)
2025-12-12 23:58:46,850 INFO     Evaluating the model... (26500/50000)
2025-12-12 23:58:50,347 INFO     Evaluating the model... (27000/50000)
2025-12-12 23:58:52,770 INFO     Evaluating the model... (27500/50000)
2025-12-12 23:58:55,239 INFO     Evaluating the model... (28000/50000)
2025-12-12 23:58:57,998 INFO     Evaluating the model... (28500/50000)
2025-12-12 23:59:00,599 INFO     Evaluating the model... (29000/50000)
2025-12-12 23:59:04,250 INFO     Evaluating the model... (29500/50000)
2025-12-12 23:59:06,812 INFO     Evaluating the model... (30000/50000)
2025-12-12 23:59:09,484 INFO     Evaluating the model... (30500/50000)
2025-12-12 23:59:11,984 INFO     Evaluating the model... (31000/50000)
2025-12-12 23:59:14,448 INFO     Evaluating the model... (31500/50000)
2025-12-12 23:59:17,832 INFO     Evaluating the model... (32000/50000)
2025-12-12 23:59:20,585 INFO     Evaluating the model... (32500/50000)
2025-12-12 23:59:23,097 INFO     Evaluating the model... (33000/50000)
2025-12-12 23:59:25,700 INFO     Evaluating the model... (33500/50000)
2025-12-12 23:59:28,179 INFO     Evaluating the model... (34000/50000)
2025-12-12 23:59:31,328 INFO     Evaluating the model... (34500/50000)
2025-12-12 23:59:33,938 INFO     Evaluating the model... (35000/50000)
2025-12-12 23:59:36,552 INFO     Evaluating the model... (35500/50000)
2025-12-12 23:59:39,281 INFO     Evaluating the model... (36000/50000)
2025-12-12 23:59:42,156 INFO     Evaluating the model... (36500/50000)
2025-12-12 23:59:45,448 INFO     Evaluating the model... (37000/50000)
2025-12-12 23:59:47,931 INFO     Evaluating the model... (37500/50000)
2025-12-12 23:59:50,527 INFO     Evaluating the model... (38000/50000)
2025-12-12 23:59:53,067 INFO     Evaluating the model... (38500/50000)
2025-12-12 23:59:56,555 INFO     Evaluating the model... (39000/50000)
2025-12-12 23:59:59,047 INFO     Evaluating the model... (39500/50000)
2025-12-13 00:00:01,637 INFO     Evaluating the model... (40000/50000)
2025-12-13 00:00:04,216 INFO     Evaluating the model... (40500/50000)
2025-12-13 00:00:06,997 INFO     Evaluating the model... (41000/50000)
2025-12-13 00:00:10,428 INFO     Evaluating the model... (41500/50000)
2025-12-13 00:00:13,027 INFO     Evaluating the model... (42000/50000)
2025-12-13 00:00:15,618 INFO     Evaluating the model... (42500/50000)
2025-12-13 00:00:18,472 INFO     Evaluating the model... (43000/50000)
2025-12-13 00:00:21,015 INFO     Evaluating the model... (43500/50000)
2025-12-13 00:00:24,413 INFO     Evaluating the model... (44000/50000)
2025-12-13 00:00:26,902 INFO     Evaluating the model... (44500/50000)
2025-12-13 00:00:29,784 INFO     Evaluating the model... (45000/50000)
2025-12-13 00:00:32,213 INFO     Evaluating the model... (45500/50000)
2025-12-13 00:00:34,796 INFO     Evaluating the model... (46000/50000)
2025-12-13 00:00:38,436 INFO     Evaluating the model... (46500/50000)
2025-12-13 00:00:41,488 INFO     Evaluating the model... (47000/50000)
2025-12-13 00:00:44,124 INFO     Evaluating the model... (47500/50000)
2025-12-13 00:00:46,722 INFO     Evaluating the model... (48000/50000)
2025-12-13 00:00:49,185 INFO     Evaluating the model... (48500/50000)
2025-12-13 00:00:53,008 INFO     Evaluating the model... (49000/50000)
2025-12-13 00:00:55,574 INFO     Evaluating the model... (49500/50000)
2025-12-13 00:00:58,276 INFO     Valid MRR at step 30000: 0.541430
2025-12-13 00:00:58,277 INFO     Valid MR at step 30000: 408.221420
2025-12-13 00:00:58,277 INFO     Valid HITS@1 at step 30000: 0.447890
2025-12-13 00:00:58,277 INFO     Valid HITS@3 at step 30000: 0.595010
2025-12-13 00:00:58,277 INFO     Valid HITS@10 at step 30000: 0.713510
2025-12-13 00:00:59,474 INFO     Evaluating on Test Dataset...
2025-12-13 00:01:00,042 INFO     Evaluating the model... (0/59072)
2025-12-13 00:01:02,575 INFO     Evaluating the model... (500/59072)
2025-12-13 00:01:05,507 INFO     Evaluating the model... (1000/59072)
2025-12-13 00:01:08,988 INFO     Evaluating the model... (1500/59072)
2025-12-13 00:01:11,442 INFO     Evaluating the model... (2000/59072)
2025-12-13 00:01:14,054 INFO     Evaluating the model... (2500/59072)
2025-12-13 00:01:16,743 INFO     Evaluating the model... (3000/59072)
2025-12-13 00:01:19,194 INFO     Evaluating the model... (3500/59072)
2025-12-13 00:01:22,594 INFO     Evaluating the model... (4000/59072)
2025-12-13 00:01:25,015 INFO     Evaluating the model... (4500/59072)
2025-12-13 00:01:27,754 INFO     Evaluating the model... (5000/59072)
2025-12-13 00:01:30,220 INFO     Evaluating the model... (5500/59072)
2025-12-13 00:01:32,582 INFO     Evaluating the model... (6000/59072)
2025-12-13 00:01:36,021 INFO     Evaluating the model... (6500/59072)
2025-12-13 00:01:39,059 INFO     Evaluating the model... (7000/59072)
2025-12-13 00:01:41,855 INFO     Evaluating the model... (7500/59072)
2025-12-13 00:01:44,493 INFO     Evaluating the model... (8000/59072)
2025-12-13 00:01:47,020 INFO     Evaluating the model... (8500/59072)
2025-12-13 00:01:50,233 INFO     Evaluating the model... (9000/59072)
2025-12-13 00:01:52,650 INFO     Evaluating the model... (9500/59072)
2025-12-13 00:01:55,260 INFO     Evaluating the model... (10000/59072)
2025-12-13 00:01:57,818 INFO     Evaluating the model... (10500/59072)
2025-12-13 00:02:00,370 INFO     Evaluating the model... (11000/59072)
2025-12-13 00:02:03,373 INFO     Evaluating the model... (11500/59072)
2025-12-13 00:02:05,756 INFO     Evaluating the model... (12000/59072)
2025-12-13 00:02:08,286 INFO     Evaluating the model... (12500/59072)
2025-12-13 00:02:10,773 INFO     Evaluating the model... (13000/59072)
2025-12-13 00:02:13,414 INFO     Evaluating the model... (13500/59072)
2025-12-13 00:02:16,679 INFO     Evaluating the model... (14000/59072)
2025-12-13 00:02:19,026 INFO     Evaluating the model... (14500/59072)
2025-12-13 00:02:21,533 INFO     Evaluating the model... (15000/59072)
2025-12-13 00:02:23,977 INFO     Evaluating the model... (15500/59072)
2025-12-13 00:02:27,685 INFO     Evaluating the model... (16000/59072)
2025-12-13 00:02:30,078 INFO     Evaluating the model... (16500/59072)
2025-12-13 00:02:32,527 INFO     Evaluating the model... (17000/59072)
2025-12-13 00:02:35,054 INFO     Evaluating the model... (17500/59072)
2025-12-13 00:02:37,967 INFO     Evaluating the model... (18000/59072)
2025-12-13 00:02:41,400 INFO     Evaluating the model... (18500/59072)
2025-12-13 00:02:44,016 INFO     Evaluating the model... (19000/59072)
2025-12-13 00:02:46,555 INFO     Evaluating the model... (19500/59072)
2025-12-13 00:02:49,193 INFO     Evaluating the model... (20000/59072)
2025-12-13 00:02:51,686 INFO     Evaluating the model... (20500/59072)
2025-12-13 00:02:55,133 INFO     Evaluating the model... (21000/59072)
2025-12-13 00:02:57,488 INFO     Evaluating the model... (21500/59072)
2025-12-13 00:03:00,198 INFO     Evaluating the model... (22000/59072)
2025-12-13 00:03:02,628 INFO     Evaluating the model... (22500/59072)
2025-12-13 00:03:05,072 INFO     Evaluating the model... (23000/59072)
2025-12-13 00:03:08,293 INFO     Evaluating the model... (23500/59072)
2025-12-13 00:03:10,822 INFO     Evaluating the model... (24000/59072)
2025-12-13 00:03:13,177 INFO     Evaluating the model... (24500/59072)
2025-12-13 00:03:15,566 INFO     Evaluating the model... (25000/59072)
2025-12-13 00:03:18,024 INFO     Evaluating the model... (25500/59072)
2025-12-13 00:03:21,562 INFO     Evaluating the model... (26000/59072)
2025-12-13 00:03:24,107 INFO     Evaluating the model... (26500/59072)
2025-12-13 00:03:26,642 INFO     Evaluating the model... (27000/59072)
2025-12-13 00:03:29,055 INFO     Evaluating the model... (27500/59072)
2025-12-13 00:03:31,434 INFO     Evaluating the model... (28000/59072)
2025-12-13 00:03:35,204 INFO     Evaluating the model... (28500/59072)
2025-12-13 00:03:37,791 INFO     Evaluating the model... (29000/59072)
2025-12-13 00:03:40,510 INFO     Evaluating the model... (29500/59072)
2025-12-13 00:03:43,618 INFO     Evaluating the model... (30000/59072)
2025-12-13 00:03:47,337 INFO     Evaluating the model... (30500/59072)
2025-12-13 00:03:49,871 INFO     Evaluating the model... (31000/59072)
2025-12-13 00:03:52,357 INFO     Evaluating the model... (31500/59072)
2025-12-13 00:03:54,966 INFO     Evaluating the model... (32000/59072)
2025-12-13 00:03:57,763 INFO     Evaluating the model... (32500/59072)
2025-12-13 00:04:01,203 INFO     Evaluating the model... (33000/59072)
2025-12-13 00:04:03,677 INFO     Evaluating the model... (33500/59072)
2025-12-13 00:04:06,128 INFO     Evaluating the model... (34000/59072)
2025-12-13 00:04:08,733 INFO     Evaluating the model... (34500/59072)
2025-12-13 00:04:11,155 INFO     Evaluating the model... (35000/59072)
2025-12-13 00:04:14,450 INFO     Evaluating the model... (35500/59072)
2025-12-13 00:04:16,854 INFO     Evaluating the model... (36000/59072)
2025-12-13 00:04:19,407 INFO     Evaluating the model... (36500/59072)
2025-12-13 00:04:21,913 INFO     Evaluating the model... (37000/59072)
2025-12-13 00:04:24,391 INFO     Evaluating the model... (37500/59072)
2025-12-13 00:04:27,390 INFO     Evaluating the model... (38000/59072)
2025-12-13 00:04:29,944 INFO     Evaluating the model... (38500/59072)
2025-12-13 00:04:32,588 INFO     Evaluating the model... (39000/59072)
2025-12-13 00:04:34,997 INFO     Evaluating the model... (39500/59072)
2025-12-13 00:04:37,850 INFO     Evaluating the model... (40000/59072)
2025-12-13 00:04:41,677 INFO     Evaluating the model... (40500/59072)
2025-12-13 00:04:44,585 INFO     Evaluating the model... (41000/59072)
2025-12-13 00:04:47,171 INFO     Evaluating the model... (41500/59072)
2025-12-13 00:04:49,702 INFO     Evaluating the model... (42000/59072)
2025-12-13 00:04:52,171 INFO     Evaluating the model... (42500/59072)
2025-12-13 00:04:55,665 INFO     Evaluating the model... (43000/59072)
2025-12-13 00:04:58,161 INFO     Evaluating the model... (43500/59072)
2025-12-13 00:05:00,630 INFO     Evaluating the model... (44000/59072)
2025-12-13 00:05:03,039 INFO     Evaluating the model... (44500/59072)
2025-12-13 00:05:05,695 INFO     Evaluating the model... (45000/59072)
2025-12-13 00:05:08,979 INFO     Evaluating the model... (45500/59072)
2025-12-13 00:05:11,452 INFO     Evaluating the model... (46000/59072)
2025-12-13 00:05:13,966 INFO     Evaluating the model... (46500/59072)
2025-12-13 00:05:16,699 INFO     Evaluating the model... (47000/59072)
2025-12-13 00:05:20,211 INFO     Evaluating the model... (47500/59072)
2025-12-13 00:05:22,659 INFO     Evaluating the model... (48000/59072)
2025-12-13 00:05:25,205 INFO     Evaluating the model... (48500/59072)
2025-12-13 00:05:27,807 INFO     Evaluating the model... (49000/59072)
2025-12-13 00:05:30,476 INFO     Evaluating the model... (49500/59072)
2025-12-13 00:05:34,140 INFO     Evaluating the model... (50000/59072)
2025-12-13 00:05:36,776 INFO     Evaluating the model... (50500/59072)
2025-12-13 00:05:39,493 INFO     Evaluating the model... (51000/59072)
2025-12-13 00:05:42,418 INFO     Evaluating the model... (51500/59072)
2025-12-13 00:05:45,134 INFO     Evaluating the model... (52000/59072)
2025-12-13 00:05:49,068 INFO     Evaluating the model... (52500/59072)
2025-12-13 00:05:51,669 INFO     Evaluating the model... (53000/59072)
2025-12-13 00:05:54,240 INFO     Evaluating the model... (53500/59072)
2025-12-13 00:05:56,798 INFO     Evaluating the model... (54000/59072)
2025-12-13 00:05:59,317 INFO     Evaluating the model... (54500/59072)
2025-12-13 00:06:03,330 INFO     Evaluating the model... (55000/59072)
2025-12-13 00:06:05,791 INFO     Evaluating the model... (55500/59072)
2025-12-13 00:06:08,334 INFO     Evaluating the model... (56000/59072)
2025-12-13 00:06:10,823 INFO     Evaluating the model... (56500/59072)
2025-12-13 00:06:13,227 INFO     Evaluating the model... (57000/59072)
2025-12-13 00:06:17,293 INFO     Evaluating the model... (57500/59072)
2025-12-13 00:06:19,832 INFO     Evaluating the model... (58000/59072)
2025-12-13 00:06:22,370 INFO     Evaluating the model... (58500/59072)
2025-12-13 00:06:24,990 INFO     Evaluating the model... (59000/59072)
2025-12-13 00:06:25,645 INFO     Test MRR at step 30000: 0.536562
2025-12-13 00:06:25,645 INFO     Test MR at step 30000: 417.343570
2025-12-13 00:06:25,645 INFO     Test HITS@1 at step 30000: 0.441689
2025-12-13 00:06:25,645 INFO     Test HITS@3 at step 30000: 0.590857
2025-12-13 00:06:25,645 INFO     Test HITS@10 at step 30000: 0.709781
2025-12-13 00:06:27,805 INFO     Training average regularization at step 30100: 0.320459
2025-12-13 00:06:27,805 INFO     Training average positive_sample_loss at step 30100: 0.065989
2025-12-13 00:06:27,805 INFO     Training average negative_sample_loss at step 30100: 0.105280
2025-12-13 00:06:27,806 INFO     Training average loss at step 30100: 0.406094
2025-12-13 00:06:29,996 INFO     Training average regularization at step 30200: 0.320271
2025-12-13 00:06:29,996 INFO     Training average positive_sample_loss at step 30200: 0.065559
2025-12-13 00:06:29,996 INFO     Training average negative_sample_loss at step 30200: 0.104785
2025-12-13 00:06:29,996 INFO     Training average loss at step 30200: 0.405443
2025-12-13 00:06:32,175 INFO     Training average regularization at step 30300: 0.320086
2025-12-13 00:06:32,176 INFO     Training average positive_sample_loss at step 30300: 0.067665
2025-12-13 00:06:32,176 INFO     Training average negative_sample_loss at step 30300: 0.112257
2025-12-13 00:06:32,176 INFO     Training average loss at step 30300: 0.410047
2025-12-13 00:06:34,366 INFO     Training average regularization at step 30400: 0.319917
2025-12-13 00:06:34,366 INFO     Training average positive_sample_loss at step 30400: 0.068123
2025-12-13 00:06:34,366 INFO     Training average negative_sample_loss at step 30400: 0.106964
2025-12-13 00:06:34,366 INFO     Training average loss at step 30400: 0.407460
2025-12-13 00:06:36,571 INFO     Training average regularization at step 30500: 0.319741
2025-12-13 00:06:36,572 INFO     Training average positive_sample_loss at step 30500: 0.064697
2025-12-13 00:06:36,572 INFO     Training average negative_sample_loss at step 30500: 0.103637
2025-12-13 00:06:36,572 INFO     Training average loss at step 30500: 0.403908
2025-12-13 00:06:38,808 INFO     Training average regularization at step 30600: 0.319545
2025-12-13 00:06:38,808 INFO     Training average positive_sample_loss at step 30600: 0.065984
2025-12-13 00:06:38,808 INFO     Training average negative_sample_loss at step 30600: 0.106554
2025-12-13 00:06:38,808 INFO     Training average loss at step 30600: 0.405815
2025-12-13 00:06:41,040 INFO     Training average regularization at step 30700: 0.319368
2025-12-13 00:06:41,041 INFO     Training average positive_sample_loss at step 30700: 0.068375
2025-12-13 00:06:41,041 INFO     Training average negative_sample_loss at step 30700: 0.107859
2025-12-13 00:06:41,041 INFO     Training average loss at step 30700: 0.407485
2025-12-13 00:06:43,253 INFO     Training average regularization at step 30800: 0.319206
2025-12-13 00:06:43,253 INFO     Training average positive_sample_loss at step 30800: 0.066470
2025-12-13 00:06:43,253 INFO     Training average negative_sample_loss at step 30800: 0.105932
2025-12-13 00:06:43,253 INFO     Training average loss at step 30800: 0.405406
2025-12-13 00:06:45,451 INFO     Training average regularization at step 30900: 0.319020
2025-12-13 00:06:45,451 INFO     Training average positive_sample_loss at step 30900: 0.068322
2025-12-13 00:06:45,451 INFO     Training average negative_sample_loss at step 30900: 0.109772
2025-12-13 00:06:45,451 INFO     Training average loss at step 30900: 0.408067
2025-12-13 00:06:47,622 INFO     Training average regularization at step 31000: 0.318843
2025-12-13 00:06:47,622 INFO     Training average positive_sample_loss at step 31000: 0.067604
2025-12-13 00:06:47,623 INFO     Training average negative_sample_loss at step 31000: 0.109329
2025-12-13 00:06:47,623 INFO     Training average loss at step 31000: 0.407310
2025-12-13 00:06:49,792 INFO     Training average regularization at step 31100: 0.318672
2025-12-13 00:06:49,792 INFO     Training average positive_sample_loss at step 31100: 0.068568
2025-12-13 00:06:49,792 INFO     Training average negative_sample_loss at step 31100: 0.111548
2025-12-13 00:06:49,792 INFO     Training average loss at step 31100: 0.408731
2025-12-13 00:06:51,971 INFO     Training average regularization at step 31200: 0.318510
2025-12-13 00:06:51,972 INFO     Training average positive_sample_loss at step 31200: 0.069747
2025-12-13 00:06:51,972 INFO     Training average negative_sample_loss at step 31200: 0.108627
2025-12-13 00:06:51,972 INFO     Training average loss at step 31200: 0.407698
2025-12-13 00:06:54,140 INFO     Training average regularization at step 31300: 0.318342
2025-12-13 00:06:54,141 INFO     Training average positive_sample_loss at step 31300: 0.067696
2025-12-13 00:06:54,141 INFO     Training average negative_sample_loss at step 31300: 0.107781
2025-12-13 00:06:54,141 INFO     Training average loss at step 31300: 0.406081
2025-12-13 00:06:56,317 INFO     Training average regularization at step 31400: 0.318179
2025-12-13 00:06:56,317 INFO     Training average positive_sample_loss at step 31400: 0.069082
2025-12-13 00:06:56,317 INFO     Training average negative_sample_loss at step 31400: 0.108224
2025-12-13 00:06:56,317 INFO     Training average loss at step 31400: 0.406833
2025-12-13 00:06:58,507 INFO     Training average regularization at step 31500: 0.318032
2025-12-13 00:06:58,507 INFO     Training average positive_sample_loss at step 31500: 0.068377
2025-12-13 00:06:58,507 INFO     Training average negative_sample_loss at step 31500: 0.107395
2025-12-13 00:06:58,507 INFO     Training average loss at step 31500: 0.405918
2025-12-13 00:07:00,700 INFO     Training average regularization at step 31600: 0.317881
2025-12-13 00:07:00,700 INFO     Training average positive_sample_loss at step 31600: 0.068879
2025-12-13 00:07:00,700 INFO     Training average negative_sample_loss at step 31600: 0.109689
2025-12-13 00:07:00,700 INFO     Training average loss at step 31600: 0.407165
2025-12-13 00:07:02,861 INFO     Training average regularization at step 31700: 0.317721
2025-12-13 00:07:02,862 INFO     Training average positive_sample_loss at step 31700: 0.069500
2025-12-13 00:07:02,862 INFO     Training average negative_sample_loss at step 31700: 0.106320
2025-12-13 00:07:02,862 INFO     Training average loss at step 31700: 0.405630
2025-12-13 00:07:05,027 INFO     Training average regularization at step 31800: 0.317579
2025-12-13 00:07:05,027 INFO     Training average positive_sample_loss at step 31800: 0.071058
2025-12-13 00:07:05,027 INFO     Training average negative_sample_loss at step 31800: 0.111143
2025-12-13 00:07:05,027 INFO     Training average loss at step 31800: 0.408680
2025-12-13 00:07:07,201 INFO     Training average regularization at step 31900: 0.317446
2025-12-13 00:07:07,201 INFO     Training average positive_sample_loss at step 31900: 0.069499
2025-12-13 00:07:07,201 INFO     Training average negative_sample_loss at step 31900: 0.108259
2025-12-13 00:07:07,201 INFO     Training average loss at step 31900: 0.406325
2025-12-13 00:07:09,374 INFO     Training average regularization at step 32000: 0.317294
2025-12-13 00:07:09,375 INFO     Training average positive_sample_loss at step 32000: 0.070275
2025-12-13 00:07:09,375 INFO     Training average negative_sample_loss at step 32000: 0.110323
2025-12-13 00:07:09,375 INFO     Training average loss at step 32000: 0.407593
2025-12-13 00:07:11,533 INFO     Training average regularization at step 32100: 0.317134
2025-12-13 00:07:11,533 INFO     Training average positive_sample_loss at step 32100: 0.069762
2025-12-13 00:07:11,533 INFO     Training average negative_sample_loss at step 32100: 0.108500
2025-12-13 00:07:11,533 INFO     Training average loss at step 32100: 0.406264
2025-12-13 00:07:13,704 INFO     Training average regularization at step 32200: 0.316971
2025-12-13 00:07:13,704 INFO     Training average positive_sample_loss at step 32200: 0.069684
2025-12-13 00:07:13,704 INFO     Training average negative_sample_loss at step 32200: 0.107841
2025-12-13 00:07:13,704 INFO     Training average loss at step 32200: 0.405733
2025-12-13 00:07:15,893 INFO     Training average regularization at step 32300: 0.316827
2025-12-13 00:07:15,893 INFO     Training average positive_sample_loss at step 32300: 0.070434
2025-12-13 00:07:15,893 INFO     Training average negative_sample_loss at step 32300: 0.112975
2025-12-13 00:07:15,893 INFO     Training average loss at step 32300: 0.408532
2025-12-13 00:07:18,061 INFO     Training average regularization at step 32400: 0.316682
2025-12-13 00:07:18,061 INFO     Training average positive_sample_loss at step 32400: 0.069865
2025-12-13 00:07:18,061 INFO     Training average negative_sample_loss at step 32400: 0.108555
2025-12-13 00:07:18,061 INFO     Training average loss at step 32400: 0.405892
2025-12-13 00:07:20,230 INFO     Training average regularization at step 32500: 0.316539
2025-12-13 00:07:20,230 INFO     Training average positive_sample_loss at step 32500: 0.069880
2025-12-13 00:07:20,230 INFO     Training average negative_sample_loss at step 32500: 0.109137
2025-12-13 00:07:20,230 INFO     Training average loss at step 32500: 0.406048
2025-12-13 00:07:22,427 INFO     Training average regularization at step 32600: 0.316403
2025-12-13 00:07:22,428 INFO     Training average positive_sample_loss at step 32600: 0.070347
2025-12-13 00:07:22,428 INFO     Training average negative_sample_loss at step 32600: 0.109277
2025-12-13 00:07:22,428 INFO     Training average loss at step 32600: 0.406215
2025-12-13 00:07:24,584 INFO     Training average regularization at step 32700: 0.316269
2025-12-13 00:07:24,584 INFO     Training average positive_sample_loss at step 32700: 0.070701
2025-12-13 00:07:24,584 INFO     Training average negative_sample_loss at step 32700: 0.108343
2025-12-13 00:07:24,584 INFO     Training average loss at step 32700: 0.405791
2025-12-13 00:07:26,739 INFO     Training average regularization at step 32800: 0.316119
2025-12-13 00:07:26,739 INFO     Training average positive_sample_loss at step 32800: 0.067946
2025-12-13 00:07:26,739 INFO     Training average negative_sample_loss at step 32800: 0.108281
2025-12-13 00:07:26,739 INFO     Training average loss at step 32800: 0.404232
2025-12-13 00:07:28,889 INFO     Training average regularization at step 32900: 0.315984
2025-12-13 00:07:28,889 INFO     Training average positive_sample_loss at step 32900: 0.070212
2025-12-13 00:07:28,889 INFO     Training average negative_sample_loss at step 32900: 0.110146
2025-12-13 00:07:28,889 INFO     Training average loss at step 32900: 0.406163
2025-12-13 00:07:31,028 INFO     Training average regularization at step 33000: 0.315858
2025-12-13 00:07:31,029 INFO     Training average positive_sample_loss at step 33000: 0.071167
2025-12-13 00:07:31,029 INFO     Training average negative_sample_loss at step 33000: 0.116681
2025-12-13 00:07:31,029 INFO     Training average loss at step 33000: 0.409782
2025-12-13 00:07:33,228 INFO     Training average regularization at step 33100: 0.315726
2025-12-13 00:07:33,228 INFO     Training average positive_sample_loss at step 33100: 0.069961
2025-12-13 00:07:33,228 INFO     Training average negative_sample_loss at step 33100: 0.110230
2025-12-13 00:07:33,229 INFO     Training average loss at step 33100: 0.405821
2025-12-13 00:07:35,411 INFO     Training average regularization at step 33200: 0.315584
2025-12-13 00:07:35,411 INFO     Training average positive_sample_loss at step 33200: 0.071016
2025-12-13 00:07:35,412 INFO     Training average negative_sample_loss at step 33200: 0.110196
2025-12-13 00:07:35,412 INFO     Training average loss at step 33200: 0.406190
2025-12-13 00:07:37,571 INFO     Training average regularization at step 33300: 0.315448
2025-12-13 00:07:37,572 INFO     Training average positive_sample_loss at step 33300: 0.068932
2025-12-13 00:07:37,572 INFO     Training average negative_sample_loss at step 33300: 0.107577
2025-12-13 00:07:37,572 INFO     Training average loss at step 33300: 0.403703
2025-12-13 00:07:39,780 INFO     Training average regularization at step 33400: 0.315323
2025-12-13 00:07:39,780 INFO     Training average positive_sample_loss at step 33400: 0.068846
2025-12-13 00:07:39,781 INFO     Training average negative_sample_loss at step 33400: 0.108701
2025-12-13 00:07:39,781 INFO     Training average loss at step 33400: 0.404096
2025-12-13 00:07:41,961 INFO     Training average regularization at step 33500: 0.315172
2025-12-13 00:07:41,961 INFO     Training average positive_sample_loss at step 33500: 0.069726
2025-12-13 00:07:41,961 INFO     Training average negative_sample_loss at step 33500: 0.111956
2025-12-13 00:07:41,961 INFO     Training average loss at step 33500: 0.406012
2025-12-13 00:07:44,155 INFO     Training average regularization at step 33600: 0.315029
2025-12-13 00:07:44,156 INFO     Training average positive_sample_loss at step 33600: 0.070613
2025-12-13 00:07:44,156 INFO     Training average negative_sample_loss at step 33600: 0.113231
2025-12-13 00:07:44,156 INFO     Training average loss at step 33600: 0.406951
2025-12-13 00:07:46,336 INFO     Training average regularization at step 33700: 0.314893
2025-12-13 00:07:46,336 INFO     Training average positive_sample_loss at step 33700: 0.070947
2025-12-13 00:07:46,336 INFO     Training average negative_sample_loss at step 33700: 0.113751
2025-12-13 00:07:46,336 INFO     Training average loss at step 33700: 0.407242
2025-12-13 00:07:48,510 INFO     Training average regularization at step 33800: 0.314773
2025-12-13 00:07:48,510 INFO     Training average positive_sample_loss at step 33800: 0.072199
2025-12-13 00:07:48,510 INFO     Training average negative_sample_loss at step 33800: 0.111792
2025-12-13 00:07:48,510 INFO     Training average loss at step 33800: 0.406768
2025-12-13 00:07:51,654 INFO     Training average regularization at step 33900: 0.314635
2025-12-13 00:07:51,654 INFO     Training average positive_sample_loss at step 33900: 0.060812
2025-12-13 00:07:51,654 INFO     Training average negative_sample_loss at step 33900: 0.106236
2025-12-13 00:07:51,654 INFO     Training average loss at step 33900: 0.398159
2025-12-13 00:07:53,833 INFO     Training average regularization at step 34000: 0.314426
2025-12-13 00:07:53,835 INFO     Training average positive_sample_loss at step 34000: 0.061128
2025-12-13 00:07:53,835 INFO     Training average negative_sample_loss at step 34000: 0.109969
2025-12-13 00:07:53,835 INFO     Training average loss at step 34000: 0.399975
2025-12-13 00:07:56,000 INFO     Training average regularization at step 34100: 0.314227
2025-12-13 00:07:56,000 INFO     Training average positive_sample_loss at step 34100: 0.061548
2025-12-13 00:07:56,000 INFO     Training average negative_sample_loss at step 34100: 0.109053
2025-12-13 00:07:56,000 INFO     Training average loss at step 34100: 0.399527
2025-12-13 00:07:58,158 INFO     Training average regularization at step 34200: 0.314059
2025-12-13 00:07:58,158 INFO     Training average positive_sample_loss at step 34200: 0.062759
2025-12-13 00:07:58,158 INFO     Training average negative_sample_loss at step 34200: 0.106276
2025-12-13 00:07:58,158 INFO     Training average loss at step 34200: 0.398577
2025-12-13 00:08:00,307 INFO     Training average regularization at step 34300: 0.313898
2025-12-13 00:08:00,307 INFO     Training average positive_sample_loss at step 34300: 0.063584
2025-12-13 00:08:00,307 INFO     Training average negative_sample_loss at step 34300: 0.107000
2025-12-13 00:08:00,307 INFO     Training average loss at step 34300: 0.399189
2025-12-13 00:08:02,464 INFO     Training average regularization at step 34400: 0.313750
2025-12-13 00:08:02,465 INFO     Training average positive_sample_loss at step 34400: 0.065191
2025-12-13 00:08:02,465 INFO     Training average negative_sample_loss at step 34400: 0.105799
2025-12-13 00:08:02,465 INFO     Training average loss at step 34400: 0.399245
2025-12-13 00:08:04,640 INFO     Training average regularization at step 34500: 0.313622
2025-12-13 00:08:04,640 INFO     Training average positive_sample_loss at step 34500: 0.066317
2025-12-13 00:08:04,640 INFO     Training average negative_sample_loss at step 34500: 0.105360
2025-12-13 00:08:04,640 INFO     Training average loss at step 34500: 0.399460
2025-12-13 00:08:06,801 INFO     Training average regularization at step 34600: 0.313495
2025-12-13 00:08:06,801 INFO     Training average positive_sample_loss at step 34600: 0.065324
2025-12-13 00:08:06,801 INFO     Training average negative_sample_loss at step 34600: 0.107166
2025-12-13 00:08:06,801 INFO     Training average loss at step 34600: 0.399740
2025-12-13 00:08:08,958 INFO     Training average regularization at step 34700: 0.313360
2025-12-13 00:08:08,959 INFO     Training average positive_sample_loss at step 34700: 0.065094
2025-12-13 00:08:08,959 INFO     Training average negative_sample_loss at step 34700: 0.107401
2025-12-13 00:08:08,959 INFO     Training average loss at step 34700: 0.399608
2025-12-13 00:08:11,115 INFO     Training average regularization at step 34800: 0.313236
2025-12-13 00:08:11,115 INFO     Training average positive_sample_loss at step 34800: 0.066235
2025-12-13 00:08:11,115 INFO     Training average negative_sample_loss at step 34800: 0.108217
2025-12-13 00:08:11,115 INFO     Training average loss at step 34800: 0.400462
2025-12-13 00:08:13,252 INFO     Training average regularization at step 34900: 0.313109
2025-12-13 00:08:13,253 INFO     Training average positive_sample_loss at step 34900: 0.065754
2025-12-13 00:08:13,253 INFO     Training average negative_sample_loss at step 34900: 0.106636
2025-12-13 00:08:13,253 INFO     Training average loss at step 34900: 0.399304
2025-12-13 00:08:15,427 INFO     Training average regularization at step 35000: 0.312978
2025-12-13 00:08:15,427 INFO     Training average positive_sample_loss at step 35000: 0.067305
2025-12-13 00:08:15,427 INFO     Training average negative_sample_loss at step 35000: 0.106713
2025-12-13 00:08:15,427 INFO     Training average loss at step 35000: 0.399988
2025-12-13 00:08:17,587 INFO     Training average regularization at step 35100: 0.312851
2025-12-13 00:08:17,587 INFO     Training average positive_sample_loss at step 35100: 0.066515
2025-12-13 00:08:17,587 INFO     Training average negative_sample_loss at step 35100: 0.108534
2025-12-13 00:08:17,587 INFO     Training average loss at step 35100: 0.400375
2025-12-13 00:08:19,739 INFO     Training average regularization at step 35200: 0.312734
2025-12-13 00:08:19,739 INFO     Training average positive_sample_loss at step 35200: 0.067978
2025-12-13 00:08:19,739 INFO     Training average negative_sample_loss at step 35200: 0.109285
2025-12-13 00:08:19,740 INFO     Training average loss at step 35200: 0.401365
2025-12-13 00:08:21,905 INFO     Training average regularization at step 35300: 0.312619
2025-12-13 00:08:21,906 INFO     Training average positive_sample_loss at step 35300: 0.068951
2025-12-13 00:08:21,906 INFO     Training average negative_sample_loss at step 35300: 0.107756
2025-12-13 00:08:21,906 INFO     Training average loss at step 35300: 0.400972
2025-12-13 00:08:24,062 INFO     Training average regularization at step 35400: 0.312512
2025-12-13 00:08:24,062 INFO     Training average positive_sample_loss at step 35400: 0.069060
2025-12-13 00:08:24,062 INFO     Training average negative_sample_loss at step 35400: 0.108937
2025-12-13 00:08:24,062 INFO     Training average loss at step 35400: 0.401510
2025-12-13 00:08:26,219 INFO     Training average regularization at step 35500: 0.312402
2025-12-13 00:08:26,219 INFO     Training average positive_sample_loss at step 35500: 0.068643
2025-12-13 00:08:26,219 INFO     Training average negative_sample_loss at step 35500: 0.107851
2025-12-13 00:08:26,219 INFO     Training average loss at step 35500: 0.400648
2025-12-13 00:08:28,445 INFO     Training average regularization at step 35600: 0.312287
2025-12-13 00:08:28,446 INFO     Training average positive_sample_loss at step 35600: 0.068235
2025-12-13 00:08:28,446 INFO     Training average negative_sample_loss at step 35600: 0.110503
2025-12-13 00:08:28,446 INFO     Training average loss at step 35600: 0.401656
2025-12-13 00:08:30,593 INFO     Training average regularization at step 35700: 0.312174
2025-12-13 00:08:30,594 INFO     Training average positive_sample_loss at step 35700: 0.068665
2025-12-13 00:08:30,594 INFO     Training average negative_sample_loss at step 35700: 0.109274
2025-12-13 00:08:30,594 INFO     Training average loss at step 35700: 0.401144
2025-12-13 00:08:32,754 INFO     Training average regularization at step 35800: 0.312088
2025-12-13 00:08:32,756 INFO     Training average positive_sample_loss at step 35800: 0.070168
2025-12-13 00:08:32,756 INFO     Training average negative_sample_loss at step 35800: 0.108522
2025-12-13 00:08:32,756 INFO     Training average loss at step 35800: 0.401433
2025-12-13 00:08:34,907 INFO     Training average regularization at step 35900: 0.311992
2025-12-13 00:08:34,907 INFO     Training average positive_sample_loss at step 35900: 0.069030
2025-12-13 00:08:34,907 INFO     Training average negative_sample_loss at step 35900: 0.109412
2025-12-13 00:08:34,907 INFO     Training average loss at step 35900: 0.401213
2025-12-13 00:08:37,065 INFO     Training average regularization at step 36000: 0.311888
2025-12-13 00:08:37,065 INFO     Training average positive_sample_loss at step 36000: 0.068145
2025-12-13 00:08:37,065 INFO     Training average negative_sample_loss at step 36000: 0.109828
2025-12-13 00:08:37,065 INFO     Training average loss at step 36000: 0.400874
2025-12-13 00:08:39,273 INFO     Training average regularization at step 36100: 0.311775
2025-12-13 00:08:39,274 INFO     Training average positive_sample_loss at step 36100: 0.070867
2025-12-13 00:08:39,274 INFO     Training average negative_sample_loss at step 36100: 0.110379
2025-12-13 00:08:39,274 INFO     Training average loss at step 36100: 0.402398
2025-12-13 00:08:41,469 INFO     Training average regularization at step 36200: 0.311684
2025-12-13 00:08:41,469 INFO     Training average positive_sample_loss at step 36200: 0.069429
2025-12-13 00:08:41,469 INFO     Training average negative_sample_loss at step 36200: 0.109730
2025-12-13 00:08:41,469 INFO     Training average loss at step 36200: 0.401264
2025-12-13 00:08:43,675 INFO     Training average regularization at step 36300: 0.311581
2025-12-13 00:08:43,675 INFO     Training average positive_sample_loss at step 36300: 0.069972
2025-12-13 00:08:43,675 INFO     Training average negative_sample_loss at step 36300: 0.110173
2025-12-13 00:08:43,675 INFO     Training average loss at step 36300: 0.401654
2025-12-13 00:08:45,911 INFO     Training average regularization at step 36400: 0.311491
2025-12-13 00:08:45,911 INFO     Training average positive_sample_loss at step 36400: 0.071441
2025-12-13 00:08:45,911 INFO     Training average negative_sample_loss at step 36400: 0.110866
2025-12-13 00:08:45,911 INFO     Training average loss at step 36400: 0.402645
2025-12-13 00:08:48,089 INFO     Training average regularization at step 36500: 0.311400
2025-12-13 00:08:48,089 INFO     Training average positive_sample_loss at step 36500: 0.070163
2025-12-13 00:08:48,089 INFO     Training average negative_sample_loss at step 36500: 0.108644
2025-12-13 00:08:48,089 INFO     Training average loss at step 36500: 0.400803
2025-12-13 00:08:50,268 INFO     Training average regularization at step 36600: 0.311307
2025-12-13 00:08:50,268 INFO     Training average positive_sample_loss at step 36600: 0.070380
2025-12-13 00:08:50,268 INFO     Training average negative_sample_loss at step 36600: 0.109471
2025-12-13 00:08:50,268 INFO     Training average loss at step 36600: 0.401232
2025-12-13 00:08:52,411 INFO     Training average regularization at step 36700: 0.311219
2025-12-13 00:08:52,412 INFO     Training average positive_sample_loss at step 36700: 0.070838
2025-12-13 00:08:52,412 INFO     Training average negative_sample_loss at step 36700: 0.112636
2025-12-13 00:08:52,412 INFO     Training average loss at step 36700: 0.402955
2025-12-13 00:08:54,581 INFO     Training average regularization at step 36800: 0.311131
2025-12-13 00:08:54,582 INFO     Training average positive_sample_loss at step 36800: 0.069792
2025-12-13 00:08:54,582 INFO     Training average negative_sample_loss at step 36800: 0.110006
2025-12-13 00:08:54,582 INFO     Training average loss at step 36800: 0.401030
2025-12-13 00:08:56,723 INFO     Training average regularization at step 36900: 0.311032
2025-12-13 00:08:56,723 INFO     Training average positive_sample_loss at step 36900: 0.069441
2025-12-13 00:08:56,723 INFO     Training average negative_sample_loss at step 36900: 0.110135
2025-12-13 00:08:56,723 INFO     Training average loss at step 36900: 0.400820
2025-12-13 00:08:58,869 INFO     Training average regularization at step 37000: 0.310930
2025-12-13 00:08:58,869 INFO     Training average positive_sample_loss at step 37000: 0.070022
2025-12-13 00:08:58,869 INFO     Training average negative_sample_loss at step 37000: 0.112182
2025-12-13 00:08:58,869 INFO     Training average loss at step 37000: 0.402032
2025-12-13 00:09:01,031 INFO     Training average regularization at step 37100: 0.310836
2025-12-13 00:09:01,031 INFO     Training average positive_sample_loss at step 37100: 0.069264
2025-12-13 00:09:01,032 INFO     Training average negative_sample_loss at step 37100: 0.108291
2025-12-13 00:09:01,032 INFO     Training average loss at step 37100: 0.399613
2025-12-13 00:09:03,172 INFO     Training average regularization at step 37200: 0.310750
2025-12-13 00:09:03,173 INFO     Training average positive_sample_loss at step 37200: 0.071056
2025-12-13 00:09:03,173 INFO     Training average negative_sample_loss at step 37200: 0.112821
2025-12-13 00:09:03,173 INFO     Training average loss at step 37200: 0.402689
2025-12-13 00:09:05,312 INFO     Training average regularization at step 37300: 0.310670
2025-12-13 00:09:05,313 INFO     Training average positive_sample_loss at step 37300: 0.069753
2025-12-13 00:09:05,313 INFO     Training average negative_sample_loss at step 37300: 0.111940
2025-12-13 00:09:05,313 INFO     Training average loss at step 37300: 0.401516
2025-12-13 00:09:07,479 INFO     Training average regularization at step 37400: 0.310579
2025-12-13 00:09:07,479 INFO     Training average positive_sample_loss at step 37400: 0.070394
2025-12-13 00:09:07,479 INFO     Training average negative_sample_loss at step 37400: 0.110889
2025-12-13 00:09:07,479 INFO     Training average loss at step 37400: 0.401220
2025-12-13 00:09:09,618 INFO     Training average regularization at step 37500: 0.310480
2025-12-13 00:09:09,619 INFO     Training average positive_sample_loss at step 37500: 0.070807
2025-12-13 00:09:09,619 INFO     Training average negative_sample_loss at step 37500: 0.111685
2025-12-13 00:09:09,619 INFO     Training average loss at step 37500: 0.401726
2025-12-13 00:09:11,787 INFO     Training average regularization at step 37600: 0.310387
2025-12-13 00:09:11,787 INFO     Training average positive_sample_loss at step 37600: 0.071512
2025-12-13 00:09:11,787 INFO     Training average negative_sample_loss at step 37600: 0.111798
2025-12-13 00:09:11,787 INFO     Training average loss at step 37600: 0.402042
2025-12-13 00:09:13,929 INFO     Training average regularization at step 37700: 0.310304
2025-12-13 00:09:13,929 INFO     Training average positive_sample_loss at step 37700: 0.070959
2025-12-13 00:09:13,929 INFO     Training average negative_sample_loss at step 37700: 0.111262
2025-12-13 00:09:13,929 INFO     Training average loss at step 37700: 0.401415
2025-12-13 00:09:16,095 INFO     Training average regularization at step 37800: 0.310217
2025-12-13 00:09:16,095 INFO     Training average positive_sample_loss at step 37800: 0.072435
2025-12-13 00:09:16,095 INFO     Training average negative_sample_loss at step 37800: 0.112035
2025-12-13 00:09:16,095 INFO     Training average loss at step 37800: 0.402452
2025-12-13 00:09:18,241 INFO     Training average regularization at step 37900: 0.310137
2025-12-13 00:09:18,241 INFO     Training average positive_sample_loss at step 37900: 0.072327
2025-12-13 00:09:18,241 INFO     Training average negative_sample_loss at step 37900: 0.114663
2025-12-13 00:09:18,241 INFO     Training average loss at step 37900: 0.403632
2025-12-13 00:09:20,404 INFO     Training average regularization at step 38000: 0.310050
2025-12-13 00:09:20,404 INFO     Training average positive_sample_loss at step 38000: 0.071356
2025-12-13 00:09:20,404 INFO     Training average negative_sample_loss at step 38000: 0.110744
2025-12-13 00:09:20,404 INFO     Training average loss at step 38000: 0.401101
2025-12-13 00:09:22,591 INFO     Training average regularization at step 38100: 0.309965
2025-12-13 00:09:22,592 INFO     Training average positive_sample_loss at step 38100: 0.071340
2025-12-13 00:09:22,592 INFO     Training average negative_sample_loss at step 38100: 0.112562
2025-12-13 00:09:22,592 INFO     Training average loss at step 38100: 0.401917
2025-12-13 00:09:24,727 INFO     Training average regularization at step 38200: 0.309884
2025-12-13 00:09:24,727 INFO     Training average positive_sample_loss at step 38200: 0.070950
2025-12-13 00:09:24,727 INFO     Training average negative_sample_loss at step 38200: 0.114592
2025-12-13 00:09:24,727 INFO     Training average loss at step 38200: 0.402655
2025-12-13 00:09:26,887 INFO     Training average regularization at step 38300: 0.309793
2025-12-13 00:09:26,887 INFO     Training average positive_sample_loss at step 38300: 0.070757
2025-12-13 00:09:26,887 INFO     Training average negative_sample_loss at step 38300: 0.112761
2025-12-13 00:09:26,887 INFO     Training average loss at step 38300: 0.401552
2025-12-13 00:09:29,015 INFO     Training average regularization at step 38400: 0.309708
2025-12-13 00:09:29,015 INFO     Training average positive_sample_loss at step 38400: 0.071605
2025-12-13 00:09:29,015 INFO     Training average negative_sample_loss at step 38400: 0.114683
2025-12-13 00:09:29,015 INFO     Training average loss at step 38400: 0.402852
2025-12-13 00:09:31,149 INFO     Training average regularization at step 38500: 0.309635
2025-12-13 00:09:31,149 INFO     Training average positive_sample_loss at step 38500: 0.070690
2025-12-13 00:09:31,149 INFO     Training average negative_sample_loss at step 38500: 0.111212
2025-12-13 00:09:31,149 INFO     Training average loss at step 38500: 0.400586
2025-12-13 00:09:33,318 INFO     Training average regularization at step 38600: 0.309552
2025-12-13 00:09:33,319 INFO     Training average positive_sample_loss at step 38600: 0.071190
2025-12-13 00:09:33,319 INFO     Training average negative_sample_loss at step 38600: 0.113217
2025-12-13 00:09:33,319 INFO     Training average loss at step 38600: 0.401756
2025-12-13 00:09:36,592 INFO     Training average regularization at step 38700: 0.309466
2025-12-13 00:09:36,592 INFO     Training average positive_sample_loss at step 38700: 0.066040
2025-12-13 00:09:36,592 INFO     Training average negative_sample_loss at step 38700: 0.113740
2025-12-13 00:09:36,592 INFO     Training average loss at step 38700: 0.399357
2025-12-13 00:09:38,742 INFO     Training average regularization at step 38800: 0.309302
2025-12-13 00:09:38,743 INFO     Training average positive_sample_loss at step 38800: 0.061649
2025-12-13 00:09:38,743 INFO     Training average negative_sample_loss at step 38800: 0.110769
2025-12-13 00:09:38,743 INFO     Training average loss at step 38800: 0.395511
2025-12-13 00:09:40,899 INFO     Training average regularization at step 38900: 0.309151
2025-12-13 00:09:40,899 INFO     Training average positive_sample_loss at step 38900: 0.062740
2025-12-13 00:09:40,899 INFO     Training average negative_sample_loss at step 38900: 0.109455
2025-12-13 00:09:40,899 INFO     Training average loss at step 38900: 0.395249
2025-12-13 00:09:43,050 INFO     Training average regularization at step 39000: 0.309033
2025-12-13 00:09:43,050 INFO     Training average positive_sample_loss at step 39000: 0.064374
2025-12-13 00:09:43,050 INFO     Training average negative_sample_loss at step 39000: 0.109628
2025-12-13 00:09:43,050 INFO     Training average loss at step 39000: 0.396034
2025-12-13 00:09:45,270 INFO     Training average regularization at step 39100: 0.308914
2025-12-13 00:09:45,270 INFO     Training average positive_sample_loss at step 39100: 0.063972
2025-12-13 00:09:45,270 INFO     Training average negative_sample_loss at step 39100: 0.109739
2025-12-13 00:09:45,270 INFO     Training average loss at step 39100: 0.395770
2025-12-13 00:09:47,400 INFO     Training average regularization at step 39200: 0.308796
2025-12-13 00:09:47,400 INFO     Training average positive_sample_loss at step 39200: 0.064858
2025-12-13 00:09:47,400 INFO     Training average negative_sample_loss at step 39200: 0.110151
2025-12-13 00:09:47,400 INFO     Training average loss at step 39200: 0.396300
2025-12-13 00:09:49,547 INFO     Training average regularization at step 39300: 0.308706
2025-12-13 00:09:49,548 INFO     Training average positive_sample_loss at step 39300: 0.066189
2025-12-13 00:09:49,548 INFO     Training average negative_sample_loss at step 39300: 0.111664
2025-12-13 00:09:49,548 INFO     Training average loss at step 39300: 0.397632
2025-12-13 00:09:51,700 INFO     Training average regularization at step 39400: 0.308622
2025-12-13 00:09:51,700 INFO     Training average positive_sample_loss at step 39400: 0.065867
2025-12-13 00:09:51,700 INFO     Training average negative_sample_loss at step 39400: 0.107255
2025-12-13 00:09:51,700 INFO     Training average loss at step 39400: 0.395183
2025-12-13 00:09:53,845 INFO     Training average regularization at step 39500: 0.308541
2025-12-13 00:09:53,845 INFO     Training average positive_sample_loss at step 39500: 0.066448
2025-12-13 00:09:53,845 INFO     Training average negative_sample_loss at step 39500: 0.110819
2025-12-13 00:09:53,845 INFO     Training average loss at step 39500: 0.397175
2025-12-13 00:09:55,995 INFO     Training average regularization at step 39600: 0.308449
2025-12-13 00:09:55,995 INFO     Training average positive_sample_loss at step 39600: 0.066218
2025-12-13 00:09:55,995 INFO     Training average negative_sample_loss at step 39600: 0.110571
2025-12-13 00:09:55,995 INFO     Training average loss at step 39600: 0.396844
2025-12-13 00:09:58,132 INFO     Training average regularization at step 39700: 0.308373
2025-12-13 00:09:58,133 INFO     Training average positive_sample_loss at step 39700: 0.068270
2025-12-13 00:09:58,133 INFO     Training average negative_sample_loss at step 39700: 0.108793
2025-12-13 00:09:58,133 INFO     Training average loss at step 39700: 0.396905
2025-12-13 00:10:00,279 INFO     Training average regularization at step 39800: 0.308306
2025-12-13 00:10:00,279 INFO     Training average positive_sample_loss at step 39800: 0.068725
2025-12-13 00:10:00,279 INFO     Training average negative_sample_loss at step 39800: 0.109976
2025-12-13 00:10:00,279 INFO     Training average loss at step 39800: 0.397657
2025-12-13 00:10:02,424 INFO     Training average regularization at step 39900: 0.308245
2025-12-13 00:10:02,427 INFO     Training average positive_sample_loss at step 39900: 0.067749
2025-12-13 00:10:02,427 INFO     Training average negative_sample_loss at step 39900: 0.107102
2025-12-13 00:10:02,427 INFO     Training average loss at step 39900: 0.395670
2025-12-13 00:10:04,566 INFO     Change learning_rate to 0.000026 at step 40000
2025-12-13 00:10:05,353 INFO     Training average regularization at step 40000: 0.308170
2025-12-13 00:10:05,353 INFO     Training average positive_sample_loss at step 40000: 0.067955
2025-12-13 00:10:05,354 INFO     Training average negative_sample_loss at step 40000: 0.112498
2025-12-13 00:10:05,354 INFO     Training average loss at step 40000: 0.398396
2025-12-13 00:10:05,354 INFO     Evaluating on Valid Dataset...
2025-12-13 00:10:05,974 INFO     Evaluating the model... (0/50000)
2025-12-13 00:10:09,790 INFO     Evaluating the model... (500/50000)
2025-12-13 00:10:12,291 INFO     Evaluating the model... (1000/50000)
2025-12-13 00:10:14,721 INFO     Evaluating the model... (1500/50000)
2025-12-13 00:10:17,319 INFO     Evaluating the model... (2000/50000)
2025-12-13 00:10:19,963 INFO     Evaluating the model... (2500/50000)
2025-12-13 00:10:23,387 INFO     Evaluating the model... (3000/50000)
2025-12-13 00:10:25,902 INFO     Evaluating the model... (3500/50000)
2025-12-13 00:10:28,295 INFO     Evaluating the model... (4000/50000)
2025-12-13 00:10:30,933 INFO     Evaluating the model... (4500/50000)
2025-12-13 00:10:33,443 INFO     Evaluating the model... (5000/50000)
2025-12-13 00:10:36,730 INFO     Evaluating the model... (5500/50000)
2025-12-13 00:10:39,269 INFO     Evaluating the model... (6000/50000)
2025-12-13 00:10:42,253 INFO     Evaluating the model... (6500/50000)
2025-12-13 00:10:44,867 INFO     Evaluating the model... (7000/50000)
2025-12-13 00:10:47,357 INFO     Evaluating the model... (7500/50000)
2025-12-13 00:10:50,418 INFO     Evaluating the model... (8000/50000)
2025-12-13 00:10:52,976 INFO     Evaluating the model... (8500/50000)
2025-12-13 00:10:55,440 INFO     Evaluating the model... (9000/50000)
2025-12-13 00:10:57,937 INFO     Evaluating the model... (9500/50000)
2025-12-13 00:11:00,293 INFO     Evaluating the model... (10000/50000)
2025-12-13 00:11:03,225 INFO     Evaluating the model... (10500/50000)
2025-12-13 00:11:05,960 INFO     Evaluating the model... (11000/50000)
2025-12-13 00:11:08,442 INFO     Evaluating the model... (11500/50000)
2025-12-13 00:11:10,798 INFO     Evaluating the model... (12000/50000)
2025-12-13 00:11:13,896 INFO     Evaluating the model... (12500/50000)
2025-12-13 00:11:16,552 INFO     Evaluating the model... (13000/50000)
2025-12-13 00:11:19,013 INFO     Evaluating the model... (13500/50000)
2025-12-13 00:11:21,489 INFO     Evaluating the model... (14000/50000)
2025-12-13 00:11:23,943 INFO     Evaluating the model... (14500/50000)
2025-12-13 00:11:27,073 INFO     Evaluating the model... (15000/50000)
2025-12-13 00:11:29,539 INFO     Evaluating the model... (15500/50000)
2025-12-13 00:11:32,004 INFO     Evaluating the model... (16000/50000)
2025-12-13 00:11:34,399 INFO     Evaluating the model... (16500/50000)
2025-12-13 00:11:37,042 INFO     Evaluating the model... (17000/50000)
2025-12-13 00:11:40,750 INFO     Evaluating the model... (17500/50000)
2025-12-13 00:11:43,614 INFO     Evaluating the model... (18000/50000)
2025-12-13 00:11:46,157 INFO     Evaluating the model... (18500/50000)
2025-12-13 00:11:48,516 INFO     Evaluating the model... (19000/50000)
2025-12-13 00:11:51,138 INFO     Evaluating the model... (19500/50000)
2025-12-13 00:11:54,849 INFO     Evaluating the model... (20000/50000)
2025-12-13 00:11:57,293 INFO     Evaluating the model... (20500/50000)
2025-12-13 00:11:59,716 INFO     Evaluating the model... (21000/50000)
2025-12-13 00:12:02,307 INFO     Evaluating the model... (21500/50000)
2025-12-13 00:12:04,734 INFO     Evaluating the model... (22000/50000)
2025-12-13 00:12:08,304 INFO     Evaluating the model... (22500/50000)
2025-12-13 00:12:10,662 INFO     Evaluating the model... (23000/50000)
2025-12-13 00:12:13,200 INFO     Evaluating the model... (23500/50000)
2025-12-13 00:12:15,678 INFO     Evaluating the model... (24000/50000)
2025-12-13 00:12:18,049 INFO     Evaluating the model... (24500/50000)
2025-12-13 00:12:21,794 INFO     Evaluating the model... (25000/50000)
2025-12-13 00:12:24,564 INFO     Evaluating the model... (25500/50000)
2025-12-13 00:12:27,365 INFO     Evaluating the model... (26000/50000)
2025-12-13 00:12:29,941 INFO     Evaluating the model... (26500/50000)
2025-12-13 00:12:32,595 INFO     Evaluating the model... (27000/50000)
2025-12-13 00:12:36,614 INFO     Evaluating the model... (27500/50000)
2025-12-13 00:12:39,397 INFO     Evaluating the model... (28000/50000)
2025-12-13 00:12:41,993 INFO     Evaluating the model... (28500/50000)
2025-12-13 00:12:44,704 INFO     Evaluating the model... (29000/50000)
2025-12-13 00:12:47,222 INFO     Evaluating the model... (29500/50000)
2025-12-13 00:12:50,762 INFO     Evaluating the model... (30000/50000)
2025-12-13 00:12:53,330 INFO     Evaluating the model... (30500/50000)
2025-12-13 00:12:55,877 INFO     Evaluating the model... (31000/50000)
2025-12-13 00:12:58,422 INFO     Evaluating the model... (31500/50000)
2025-12-13 00:13:00,985 INFO     Evaluating the model... (32000/50000)
2025-12-13 00:13:04,442 INFO     Evaluating the model... (32500/50000)
2025-12-13 00:13:06,935 INFO     Evaluating the model... (33000/50000)
2025-12-13 00:13:09,436 INFO     Evaluating the model... (33500/50000)
2025-12-13 00:13:12,098 INFO     Evaluating the model... (34000/50000)
2025-12-13 00:13:14,638 INFO     Evaluating the model... (34500/50000)
2025-12-13 00:13:18,218 INFO     Evaluating the model... (35000/50000)
2025-12-13 00:13:20,741 INFO     Evaluating the model... (35500/50000)
2025-12-13 00:13:23,461 INFO     Evaluating the model... (36000/50000)
2025-12-13 00:13:26,012 INFO     Evaluating the model... (36500/50000)
2025-12-13 00:13:28,637 INFO     Evaluating the model... (37000/50000)
2025-12-13 00:13:32,067 INFO     Evaluating the model... (37500/50000)
2025-12-13 00:13:34,713 INFO     Evaluating the model... (38000/50000)
2025-12-13 00:13:37,462 INFO     Evaluating the model... (38500/50000)
2025-12-13 00:13:40,282 INFO     Evaluating the model... (39000/50000)
2025-12-13 00:13:43,870 INFO     Evaluating the model... (39500/50000)
2025-12-13 00:13:46,711 INFO     Evaluating the model... (40000/50000)
2025-12-13 00:13:49,353 INFO     Evaluating the model... (40500/50000)
2025-12-13 00:13:51,918 INFO     Evaluating the model... (41000/50000)
2025-12-13 00:13:54,442 INFO     Evaluating the model... (41500/50000)
2025-12-13 00:13:57,866 INFO     Evaluating the model... (42000/50000)
2025-12-13 00:14:00,490 INFO     Evaluating the model... (42500/50000)
2025-12-13 00:14:03,073 INFO     Evaluating the model... (43000/50000)
2025-12-13 00:14:05,651 INFO     Evaluating the model... (43500/50000)
2025-12-13 00:14:08,442 INFO     Evaluating the model... (44000/50000)
2025-12-13 00:14:12,076 INFO     Evaluating the model... (44500/50000)
2025-12-13 00:14:14,565 INFO     Evaluating the model... (45000/50000)
2025-12-13 00:14:17,127 INFO     Evaluating the model... (45500/50000)
2025-12-13 00:14:19,784 INFO     Evaluating the model... (46000/50000)
2025-12-13 00:14:22,284 INFO     Evaluating the model... (46500/50000)
2025-12-13 00:14:25,811 INFO     Evaluating the model... (47000/50000)
2025-12-13 00:14:28,294 INFO     Evaluating the model... (47500/50000)
2025-12-13 00:14:30,857 INFO     Evaluating the model... (48000/50000)
2025-12-13 00:14:33,424 INFO     Evaluating the model... (48500/50000)
2025-12-13 00:14:36,042 INFO     Evaluating the model... (49000/50000)
2025-12-13 00:14:40,046 INFO     Evaluating the model... (49500/50000)
2025-12-13 00:14:43,279 INFO     Valid MRR at step 40000: 0.572573
2025-12-13 00:14:43,279 INFO     Valid MR at step 40000: 293.857680
2025-12-13 00:14:43,279 INFO     Valid HITS@1 at step 40000: 0.478620
2025-12-13 00:14:43,279 INFO     Valid HITS@3 at step 40000: 0.626500
2025-12-13 00:14:43,279 INFO     Valid HITS@10 at step 40000: 0.744240
2025-12-13 00:14:44,604 INFO     Evaluating on Test Dataset...
2025-12-13 00:14:45,216 INFO     Evaluating the model... (0/59072)
2025-12-13 00:14:47,807 INFO     Evaluating the model... (500/59072)
2025-12-13 00:14:50,353 INFO     Evaluating the model... (1000/59072)
2025-12-13 00:14:52,938 INFO     Evaluating the model... (1500/59072)
2025-12-13 00:14:56,590 INFO     Evaluating the model... (2000/59072)
2025-12-13 00:14:59,108 INFO     Evaluating the model... (2500/59072)
2025-12-13 00:15:01,600 INFO     Evaluating the model... (3000/59072)
2025-12-13 00:15:04,065 INFO     Evaluating the model... (3500/59072)
2025-12-13 00:15:06,884 INFO     Evaluating the model... (4000/59072)
2025-12-13 00:15:10,090 INFO     Evaluating the model... (4500/59072)
2025-12-13 00:15:12,477 INFO     Evaluating the model... (5000/59072)
2025-12-13 00:15:14,919 INFO     Evaluating the model... (5500/59072)
2025-12-13 00:15:17,661 INFO     Evaluating the model... (6000/59072)
2025-12-13 00:15:20,126 INFO     Evaluating the model... (6500/59072)
2025-12-13 00:15:23,081 INFO     Evaluating the model... (7000/59072)
2025-12-13 00:15:25,447 INFO     Evaluating the model... (7500/59072)
2025-12-13 00:15:27,903 INFO     Evaluating the model... (8000/59072)
2025-12-13 00:15:30,572 INFO     Evaluating the model... (8500/59072)
2025-12-13 00:15:33,050 INFO     Evaluating the model... (9000/59072)
2025-12-13 00:15:36,133 INFO     Evaluating the model... (9500/59072)
2025-12-13 00:15:38,649 INFO     Evaluating the model... (10000/59072)
2025-12-13 00:15:41,449 INFO     Evaluating the model... (10500/59072)
2025-12-13 00:15:44,072 INFO     Evaluating the model... (11000/59072)
2025-12-13 00:15:46,660 INFO     Evaluating the model... (11500/59072)
2025-12-13 00:15:49,653 INFO     Evaluating the model... (12000/59072)
2025-12-13 00:15:52,314 INFO     Evaluating the model... (12500/59072)
2025-12-13 00:15:54,709 INFO     Evaluating the model... (13000/59072)
2025-12-13 00:15:57,369 INFO     Evaluating the model... (13500/59072)
2025-12-13 00:15:59,713 INFO     Evaluating the model... (14000/59072)
2025-12-13 00:16:03,106 INFO     Evaluating the model... (14500/59072)
2025-12-13 00:16:05,639 INFO     Evaluating the model... (15000/59072)
2025-12-13 00:16:07,997 INFO     Evaluating the model... (15500/59072)
2025-12-13 00:16:10,392 INFO     Evaluating the model... (16000/59072)
2025-12-13 00:16:13,139 INFO     Evaluating the model... (16500/59072)
2025-12-13 00:16:16,527 INFO     Evaluating the model... (17000/59072)
2025-12-13 00:16:19,004 INFO     Evaluating the model... (17500/59072)
2025-12-13 00:16:21,433 INFO     Evaluating the model... (18000/59072)
2025-12-13 00:16:24,017 INFO     Evaluating the model... (18500/59072)
2025-12-13 00:16:27,594 INFO     Evaluating the model... (19000/59072)
2025-12-13 00:16:30,024 INFO     Evaluating the model... (19500/59072)
2025-12-13 00:16:32,418 INFO     Evaluating the model... (20000/59072)
2025-12-13 00:16:34,988 INFO     Evaluating the model... (20500/59072)
2025-12-13 00:16:37,822 INFO     Evaluating the model... (21000/59072)
2025-12-13 00:16:41,464 INFO     Evaluating the model... (21500/59072)
2025-12-13 00:16:43,994 INFO     Evaluating the model... (22000/59072)
2025-12-13 00:16:46,546 INFO     Evaluating the model... (22500/59072)
2025-12-13 00:16:49,237 INFO     Evaluating the model... (23000/59072)
2025-12-13 00:16:51,684 INFO     Evaluating the model... (23500/59072)
2025-12-13 00:16:55,274 INFO     Evaluating the model... (24000/59072)
2025-12-13 00:16:57,780 INFO     Evaluating the model... (24500/59072)
2025-12-13 00:17:00,368 INFO     Evaluating the model... (25000/59072)
2025-12-13 00:17:02,872 INFO     Evaluating the model... (25500/59072)
2025-12-13 00:17:05,347 INFO     Evaluating the model... (26000/59072)
2025-12-13 00:17:08,950 INFO     Evaluating the model... (26500/59072)
2025-12-13 00:17:11,504 INFO     Evaluating the model... (27000/59072)
2025-12-13 00:17:13,922 INFO     Evaluating the model... (27500/59072)
2025-12-13 00:17:16,380 INFO     Evaluating the model... (28000/59072)
2025-12-13 00:17:18,702 INFO     Evaluating the model... (28500/59072)
2025-12-13 00:17:21,938 INFO     Evaluating the model... (29000/59072)
2025-12-13 00:17:24,517 INFO     Evaluating the model... (29500/59072)
2025-12-13 00:17:27,328 INFO     Evaluating the model... (30000/59072)
2025-12-13 00:17:29,830 INFO     Evaluating the model... (30500/59072)
2025-12-13 00:17:33,257 INFO     Evaluating the model... (31000/59072)
2025-12-13 00:17:36,202 INFO     Evaluating the model... (31500/59072)
2025-12-13 00:17:38,946 INFO     Evaluating the model... (32000/59072)
2025-12-13 00:17:41,538 INFO     Evaluating the model... (32500/59072)
2025-12-13 00:17:44,238 INFO     Evaluating the model... (33000/59072)
2025-12-13 00:17:47,730 INFO     Evaluating the model... (33500/59072)
2025-12-13 00:17:50,163 INFO     Evaluating the model... (34000/59072)
2025-12-13 00:17:52,647 INFO     Evaluating the model... (34500/59072)
2025-12-13 00:17:55,160 INFO     Evaluating the model... (35000/59072)
2025-12-13 00:17:57,875 INFO     Evaluating the model... (35500/59072)
2025-12-13 00:18:00,958 INFO     Evaluating the model... (36000/59072)
2025-12-13 00:18:03,459 INFO     Evaluating the model... (36500/59072)
2025-12-13 00:18:06,153 INFO     Evaluating the model... (37000/59072)
2025-12-13 00:18:08,782 INFO     Evaluating the model... (37500/59072)
2025-12-13 00:18:11,245 INFO     Evaluating the model... (38000/59072)
2025-12-13 00:18:14,370 INFO     Evaluating the model... (38500/59072)
2025-12-13 00:18:16,975 INFO     Evaluating the model... (39000/59072)
2025-12-13 00:18:19,393 INFO     Evaluating the model... (39500/59072)
2025-12-13 00:18:22,092 INFO     Evaluating the model... (40000/59072)
2025-12-13 00:18:24,560 INFO     Evaluating the model... (40500/59072)
2025-12-13 00:18:27,733 INFO     Evaluating the model... (41000/59072)
2025-12-13 00:18:30,235 INFO     Evaluating the model... (41500/59072)
2025-12-13 00:18:32,891 INFO     Evaluating the model... (42000/59072)
2025-12-13 00:18:35,374 INFO     Evaluating the model... (42500/59072)
2025-12-13 00:18:38,126 INFO     Evaluating the model... (43000/59072)
2025-12-13 00:18:41,791 INFO     Evaluating the model... (43500/59072)
2025-12-13 00:18:44,768 INFO     Evaluating the model... (44000/59072)
2025-12-13 00:18:47,385 INFO     Evaluating the model... (44500/59072)
2025-12-13 00:18:49,989 INFO     Evaluating the model... (45000/59072)
2025-12-13 00:18:52,467 INFO     Evaluating the model... (45500/59072)
2025-12-13 00:18:55,846 INFO     Evaluating the model... (46000/59072)
2025-12-13 00:18:58,312 INFO     Evaluating the model... (46500/59072)
2025-12-13 00:19:00,804 INFO     Evaluating the model... (47000/59072)
2025-12-13 00:19:03,312 INFO     Evaluating the model... (47500/59072)
2025-12-13 00:19:06,004 INFO     Evaluating the model... (48000/59072)
2025-12-13 00:19:09,079 INFO     Evaluating the model... (48500/59072)
2025-12-13 00:19:11,564 INFO     Evaluating the model... (49000/59072)
2025-12-13 00:19:13,942 INFO     Evaluating the model... (49500/59072)
2025-12-13 00:19:16,438 INFO     Evaluating the model... (50000/59072)
2025-12-13 00:19:19,734 INFO     Evaluating the model... (50500/59072)
2025-12-13 00:19:22,183 INFO     Evaluating the model... (51000/59072)
2025-12-13 00:19:24,612 INFO     Evaluating the model... (51500/59072)
2025-12-13 00:19:27,170 INFO     Evaluating the model... (52000/59072)
2025-12-13 00:19:29,839 INFO     Evaluating the model... (52500/59072)
2025-12-13 00:19:33,455 INFO     Evaluating the model... (53000/59072)
2025-12-13 00:19:35,909 INFO     Evaluating the model... (53500/59072)
2025-12-13 00:19:38,599 INFO     Evaluating the model... (54000/59072)
2025-12-13 00:19:41,625 INFO     Evaluating the model... (54500/59072)
2025-12-13 00:19:44,255 INFO     Evaluating the model... (55000/59072)
2025-12-13 00:19:47,781 INFO     Evaluating the model... (55500/59072)
2025-12-13 00:19:50,285 INFO     Evaluating the model... (56000/59072)
2025-12-13 00:19:52,991 INFO     Evaluating the model... (56500/59072)
2025-12-13 00:19:55,529 INFO     Evaluating the model... (57000/59072)
2025-12-13 00:19:58,022 INFO     Evaluating the model... (57500/59072)
2025-12-13 00:20:01,734 INFO     Evaluating the model... (58000/59072)
2025-12-13 00:20:04,227 INFO     Evaluating the model... (58500/59072)
2025-12-13 00:20:06,803 INFO     Evaluating the model... (59000/59072)
2025-12-13 00:20:07,443 INFO     Test MRR at step 40000: 0.569224
2025-12-13 00:20:07,443 INFO     Test MR at step 40000: 292.955553
2025-12-13 00:20:07,443 INFO     Test HITS@1 at step 40000: 0.473591
2025-12-13 00:20:07,443 INFO     Test HITS@3 at step 40000: 0.625070
2025-12-13 00:20:07,443 INFO     Test HITS@10 at step 40000: 0.743284
2025-12-13 00:20:09,593 INFO     Training average regularization at step 40100: 0.307479
2025-12-13 00:20:09,593 INFO     Training average positive_sample_loss at step 40100: 0.070240
2025-12-13 00:20:09,593 INFO     Training average negative_sample_loss at step 40100: 0.107486
2025-12-13 00:20:09,593 INFO     Training average loss at step 40100: 0.396342
2025-12-13 00:20:11,757 INFO     Training average regularization at step 40200: 0.306927
2025-12-13 00:20:11,758 INFO     Training average positive_sample_loss at step 40200: 0.073823
2025-12-13 00:20:11,758 INFO     Training average negative_sample_loss at step 40200: 0.109318
2025-12-13 00:20:11,758 INFO     Training average loss at step 40200: 0.398497
2025-12-13 00:20:13,930 INFO     Training average regularization at step 40300: 0.306671
2025-12-13 00:20:13,930 INFO     Training average positive_sample_loss at step 40300: 0.075259
2025-12-13 00:20:13,930 INFO     Training average negative_sample_loss at step 40300: 0.111558
2025-12-13 00:20:13,930 INFO     Training average loss at step 40300: 0.400079
2025-12-13 00:20:16,109 INFO     Training average regularization at step 40400: 0.306514
2025-12-13 00:20:16,110 INFO     Training average positive_sample_loss at step 40400: 0.073127
2025-12-13 00:20:16,110 INFO     Training average negative_sample_loss at step 40400: 0.109827
2025-12-13 00:20:16,110 INFO     Training average loss at step 40400: 0.397991
2025-12-13 00:20:18,255 INFO     Training average regularization at step 40500: 0.306404
2025-12-13 00:20:18,256 INFO     Training average positive_sample_loss at step 40500: 0.075533
2025-12-13 00:20:18,256 INFO     Training average negative_sample_loss at step 40500: 0.107468
2025-12-13 00:20:18,256 INFO     Training average loss at step 40500: 0.397904
2025-12-13 00:20:20,415 INFO     Training average regularization at step 40600: 0.306321
2025-12-13 00:20:20,415 INFO     Training average positive_sample_loss at step 40600: 0.073628
2025-12-13 00:20:20,415 INFO     Training average negative_sample_loss at step 40600: 0.108445
2025-12-13 00:20:20,415 INFO     Training average loss at step 40600: 0.397358
2025-12-13 00:20:22,566 INFO     Training average regularization at step 40700: 0.306257
2025-12-13 00:20:22,567 INFO     Training average positive_sample_loss at step 40700: 0.074333
2025-12-13 00:20:22,567 INFO     Training average negative_sample_loss at step 40700: 0.109378
2025-12-13 00:20:22,567 INFO     Training average loss at step 40700: 0.398113
2025-12-13 00:20:24,740 INFO     Training average regularization at step 40800: 0.306206
2025-12-13 00:20:24,740 INFO     Training average positive_sample_loss at step 40800: 0.074815
2025-12-13 00:20:24,740 INFO     Training average negative_sample_loss at step 40800: 0.109793
2025-12-13 00:20:24,740 INFO     Training average loss at step 40800: 0.398510
2025-12-13 00:20:26,905 INFO     Training average regularization at step 40900: 0.306164
2025-12-13 00:20:26,905 INFO     Training average positive_sample_loss at step 40900: 0.074859
2025-12-13 00:20:26,905 INFO     Training average negative_sample_loss at step 40900: 0.107944
2025-12-13 00:20:26,905 INFO     Training average loss at step 40900: 0.397565
2025-12-13 00:20:29,064 INFO     Training average regularization at step 41000: 0.306131
2025-12-13 00:20:29,064 INFO     Training average positive_sample_loss at step 41000: 0.074828
2025-12-13 00:20:29,064 INFO     Training average negative_sample_loss at step 41000: 0.107573
2025-12-13 00:20:29,064 INFO     Training average loss at step 41000: 0.397331
2025-12-13 00:20:31,243 INFO     Training average regularization at step 41100: 0.306100
2025-12-13 00:20:31,243 INFO     Training average positive_sample_loss at step 41100: 0.074356
2025-12-13 00:20:31,243 INFO     Training average negative_sample_loss at step 41100: 0.107313
2025-12-13 00:20:31,243 INFO     Training average loss at step 41100: 0.396935
2025-12-13 00:20:33,406 INFO     Training average regularization at step 41200: 0.306073
2025-12-13 00:20:33,407 INFO     Training average positive_sample_loss at step 41200: 0.074715
2025-12-13 00:20:33,407 INFO     Training average negative_sample_loss at step 41200: 0.108220
2025-12-13 00:20:33,407 INFO     Training average loss at step 41200: 0.397541
2025-12-13 00:20:35,604 INFO     Training average regularization at step 41300: 0.306049
2025-12-13 00:20:35,605 INFO     Training average positive_sample_loss at step 41300: 0.074779
2025-12-13 00:20:35,605 INFO     Training average negative_sample_loss at step 41300: 0.110060
2025-12-13 00:20:35,605 INFO     Training average loss at step 41300: 0.398469
2025-12-13 00:20:37,844 INFO     Training average regularization at step 41400: 0.306027
2025-12-13 00:20:37,844 INFO     Training average positive_sample_loss at step 41400: 0.074990
2025-12-13 00:20:37,844 INFO     Training average negative_sample_loss at step 41400: 0.109162
2025-12-13 00:20:37,844 INFO     Training average loss at step 41400: 0.398103
2025-12-13 00:20:39,998 INFO     Training average regularization at step 41500: 0.306007
2025-12-13 00:20:39,998 INFO     Training average positive_sample_loss at step 41500: 0.075241
2025-12-13 00:20:39,998 INFO     Training average negative_sample_loss at step 41500: 0.109069
2025-12-13 00:20:39,998 INFO     Training average loss at step 41500: 0.398162
2025-12-13 00:20:42,199 INFO     Training average regularization at step 41600: 0.305990
2025-12-13 00:20:42,199 INFO     Training average positive_sample_loss at step 41600: 0.075057
2025-12-13 00:20:42,199 INFO     Training average negative_sample_loss at step 41600: 0.111008
2025-12-13 00:20:42,199 INFO     Training average loss at step 41600: 0.399023
2025-12-13 00:20:44,389 INFO     Training average regularization at step 41700: 0.305973
2025-12-13 00:20:44,389 INFO     Training average positive_sample_loss at step 41700: 0.075120
2025-12-13 00:20:44,389 INFO     Training average negative_sample_loss at step 41700: 0.109552
2025-12-13 00:20:44,389 INFO     Training average loss at step 41700: 0.398309
2025-12-13 00:20:46,511 INFO     Training average regularization at step 41800: 0.305959
2025-12-13 00:20:46,511 INFO     Training average positive_sample_loss at step 41800: 0.075291
2025-12-13 00:20:46,511 INFO     Training average negative_sample_loss at step 41800: 0.108808
2025-12-13 00:20:46,511 INFO     Training average loss at step 41800: 0.398009
2025-12-13 00:20:48,668 INFO     Training average regularization at step 41900: 0.305947
2025-12-13 00:20:48,668 INFO     Training average positive_sample_loss at step 41900: 0.074999
2025-12-13 00:20:48,668 INFO     Training average negative_sample_loss at step 41900: 0.108480
2025-12-13 00:20:48,669 INFO     Training average loss at step 41900: 0.397686
2025-12-13 00:20:50,814 INFO     Training average regularization at step 42000: 0.305934
2025-12-13 00:20:50,814 INFO     Training average positive_sample_loss at step 42000: 0.076442
2025-12-13 00:20:50,814 INFO     Training average negative_sample_loss at step 42000: 0.110764
2025-12-13 00:20:50,814 INFO     Training average loss at step 42000: 0.399537
2025-12-13 00:20:52,951 INFO     Training average regularization at step 42100: 0.305924
2025-12-13 00:20:52,951 INFO     Training average positive_sample_loss at step 42100: 0.075286
2025-12-13 00:20:52,951 INFO     Training average negative_sample_loss at step 42100: 0.108202
2025-12-13 00:20:52,951 INFO     Training average loss at step 42100: 0.397668
2025-12-13 00:20:55,088 INFO     Training average regularization at step 42200: 0.305913
2025-12-13 00:20:55,088 INFO     Training average positive_sample_loss at step 42200: 0.074371
2025-12-13 00:20:55,088 INFO     Training average negative_sample_loss at step 42200: 0.108641
2025-12-13 00:20:55,088 INFO     Training average loss at step 42200: 0.397418
2025-12-13 00:20:57,242 INFO     Training average regularization at step 42300: 0.305902
2025-12-13 00:20:57,242 INFO     Training average positive_sample_loss at step 42300: 0.076697
2025-12-13 00:20:57,242 INFO     Training average negative_sample_loss at step 42300: 0.108981
2025-12-13 00:20:57,242 INFO     Training average loss at step 42300: 0.398741
2025-12-13 00:20:59,427 INFO     Training average regularization at step 42400: 0.305893
2025-12-13 00:20:59,427 INFO     Training average positive_sample_loss at step 42400: 0.075582
2025-12-13 00:20:59,427 INFO     Training average negative_sample_loss at step 42400: 0.109378
2025-12-13 00:20:59,427 INFO     Training average loss at step 42400: 0.398373
2025-12-13 00:21:01,560 INFO     Training average regularization at step 42500: 0.305884
2025-12-13 00:21:01,560 INFO     Training average positive_sample_loss at step 42500: 0.075046
2025-12-13 00:21:01,560 INFO     Training average negative_sample_loss at step 42500: 0.108140
2025-12-13 00:21:01,560 INFO     Training average loss at step 42500: 0.397477
2025-12-13 00:21:03,708 INFO     Training average regularization at step 42600: 0.305874
2025-12-13 00:21:03,709 INFO     Training average positive_sample_loss at step 42600: 0.074686
2025-12-13 00:21:03,709 INFO     Training average negative_sample_loss at step 42600: 0.106124
2025-12-13 00:21:03,709 INFO     Training average loss at step 42600: 0.396280
2025-12-13 00:21:05,855 INFO     Training average regularization at step 42700: 0.305866
2025-12-13 00:21:05,855 INFO     Training average positive_sample_loss at step 42700: 0.074518
2025-12-13 00:21:05,855 INFO     Training average negative_sample_loss at step 42700: 0.106558
2025-12-13 00:21:05,855 INFO     Training average loss at step 42700: 0.396404
2025-12-13 00:21:08,006 INFO     Training average regularization at step 42800: 0.305858
2025-12-13 00:21:08,006 INFO     Training average positive_sample_loss at step 42800: 0.075150
2025-12-13 00:21:08,006 INFO     Training average negative_sample_loss at step 42800: 0.106821
2025-12-13 00:21:08,006 INFO     Training average loss at step 42800: 0.396844
2025-12-13 00:21:10,189 INFO     Training average regularization at step 42900: 0.305850
2025-12-13 00:21:10,189 INFO     Training average positive_sample_loss at step 42900: 0.073962
2025-12-13 00:21:10,189 INFO     Training average negative_sample_loss at step 42900: 0.107811
2025-12-13 00:21:10,189 INFO     Training average loss at step 42900: 0.396736
2025-12-13 00:21:12,319 INFO     Training average regularization at step 43000: 0.305840
2025-12-13 00:21:12,319 INFO     Training average positive_sample_loss at step 43000: 0.073725
2025-12-13 00:21:12,319 INFO     Training average negative_sample_loss at step 43000: 0.109715
2025-12-13 00:21:12,319 INFO     Training average loss at step 43000: 0.397560
2025-12-13 00:21:14,472 INFO     Training average regularization at step 43100: 0.305830
2025-12-13 00:21:14,472 INFO     Training average positive_sample_loss at step 43100: 0.074250
2025-12-13 00:21:14,472 INFO     Training average negative_sample_loss at step 43100: 0.112066
2025-12-13 00:21:14,472 INFO     Training average loss at step 43100: 0.398988
2025-12-13 00:21:16,623 INFO     Training average regularization at step 43200: 0.305821
2025-12-13 00:21:16,623 INFO     Training average positive_sample_loss at step 43200: 0.074942
2025-12-13 00:21:16,623 INFO     Training average negative_sample_loss at step 43200: 0.108863
2025-12-13 00:21:16,624 INFO     Training average loss at step 43200: 0.397724
2025-12-13 00:21:18,766 INFO     Training average regularization at step 43300: 0.305813
2025-12-13 00:21:18,766 INFO     Training average positive_sample_loss at step 43300: 0.073120
2025-12-13 00:21:18,766 INFO     Training average negative_sample_loss at step 43300: 0.108803
2025-12-13 00:21:18,766 INFO     Training average loss at step 43300: 0.396774
2025-12-13 00:21:20,961 INFO     Training average regularization at step 43400: 0.305804
2025-12-13 00:21:20,961 INFO     Training average positive_sample_loss at step 43400: 0.073613
2025-12-13 00:21:20,961 INFO     Training average negative_sample_loss at step 43400: 0.110410
2025-12-13 00:21:20,961 INFO     Training average loss at step 43400: 0.397816
2025-12-13 00:21:24,151 INFO     Training average regularization at step 43500: 0.305795
2025-12-13 00:21:24,151 INFO     Training average positive_sample_loss at step 43500: 0.075004
2025-12-13 00:21:24,152 INFO     Training average negative_sample_loss at step 43500: 0.106960
2025-12-13 00:21:24,152 INFO     Training average loss at step 43500: 0.396778
2025-12-13 00:21:26,302 INFO     Training average regularization at step 43600: 0.305783
2025-12-13 00:21:26,303 INFO     Training average positive_sample_loss at step 43600: 0.067774
2025-12-13 00:21:26,303 INFO     Training average negative_sample_loss at step 43600: 0.108855
2025-12-13 00:21:26,303 INFO     Training average loss at step 43600: 0.394097
2025-12-13 00:21:28,461 INFO     Training average regularization at step 43700: 0.305768
2025-12-13 00:21:28,461 INFO     Training average positive_sample_loss at step 43700: 0.066497
2025-12-13 00:21:28,461 INFO     Training average negative_sample_loss at step 43700: 0.111938
2025-12-13 00:21:28,461 INFO     Training average loss at step 43700: 0.394986
2025-12-13 00:21:30,610 INFO     Training average regularization at step 43800: 0.305752
2025-12-13 00:21:30,610 INFO     Training average positive_sample_loss at step 43800: 0.067902
2025-12-13 00:21:30,610 INFO     Training average negative_sample_loss at step 43800: 0.109162
2025-12-13 00:21:30,610 INFO     Training average loss at step 43800: 0.394285
2025-12-13 00:21:32,772 INFO     Training average regularization at step 43900: 0.305740
2025-12-13 00:21:32,773 INFO     Training average positive_sample_loss at step 43900: 0.067557
2025-12-13 00:21:32,773 INFO     Training average negative_sample_loss at step 43900: 0.111357
2025-12-13 00:21:32,773 INFO     Training average loss at step 43900: 0.395197
2025-12-13 00:21:34,923 INFO     Training average regularization at step 44000: 0.305727
2025-12-13 00:21:34,927 INFO     Training average positive_sample_loss at step 44000: 0.065769
2025-12-13 00:21:34,927 INFO     Training average negative_sample_loss at step 44000: 0.108662
2025-12-13 00:21:34,927 INFO     Training average loss at step 44000: 0.392942
2025-12-13 00:21:37,147 INFO     Training average regularization at step 44100: 0.305713
2025-12-13 00:21:37,147 INFO     Training average positive_sample_loss at step 44100: 0.068736
2025-12-13 00:21:37,148 INFO     Training average negative_sample_loss at step 44100: 0.109250
2025-12-13 00:21:37,148 INFO     Training average loss at step 44100: 0.394707
2025-12-13 00:21:39,350 INFO     Training average regularization at step 44200: 0.305702
2025-12-13 00:21:39,351 INFO     Training average positive_sample_loss at step 44200: 0.069563
2025-12-13 00:21:39,351 INFO     Training average negative_sample_loss at step 44200: 0.110315
2025-12-13 00:21:39,351 INFO     Training average loss at step 44200: 0.395641
2025-12-13 00:21:41,537 INFO     Training average regularization at step 44300: 0.305689
2025-12-13 00:21:41,538 INFO     Training average positive_sample_loss at step 44300: 0.068203
2025-12-13 00:21:41,538 INFO     Training average negative_sample_loss at step 44300: 0.109865
2025-12-13 00:21:41,538 INFO     Training average loss at step 44300: 0.394723
2025-12-13 00:21:43,774 INFO     Training average regularization at step 44400: 0.305677
2025-12-13 00:21:43,774 INFO     Training average positive_sample_loss at step 44400: 0.066728
2025-12-13 00:21:43,774 INFO     Training average negative_sample_loss at step 44400: 0.107583
2025-12-13 00:21:43,774 INFO     Training average loss at step 44400: 0.392833
2025-12-13 00:21:45,938 INFO     Training average regularization at step 44500: 0.305664
2025-12-13 00:21:45,938 INFO     Training average positive_sample_loss at step 44500: 0.068065
2025-12-13 00:21:45,938 INFO     Training average negative_sample_loss at step 44500: 0.105704
2025-12-13 00:21:45,938 INFO     Training average loss at step 44500: 0.392549
2025-12-13 00:21:48,080 INFO     Training average regularization at step 44600: 0.305653
2025-12-13 00:21:48,080 INFO     Training average positive_sample_loss at step 44600: 0.067486
2025-12-13 00:21:48,081 INFO     Training average negative_sample_loss at step 44600: 0.107962
2025-12-13 00:21:48,081 INFO     Training average loss at step 44600: 0.393377
2025-12-13 00:21:50,228 INFO     Training average regularization at step 44700: 0.305640
2025-12-13 00:21:50,228 INFO     Training average positive_sample_loss at step 44700: 0.068614
2025-12-13 00:21:50,228 INFO     Training average negative_sample_loss at step 44700: 0.111258
2025-12-13 00:21:50,228 INFO     Training average loss at step 44700: 0.395576
2025-12-13 00:21:52,370 INFO     Training average regularization at step 44800: 0.305626
2025-12-13 00:21:52,370 INFO     Training average positive_sample_loss at step 44800: 0.065198
2025-12-13 00:21:52,370 INFO     Training average negative_sample_loss at step 44800: 0.110905
2025-12-13 00:21:52,370 INFO     Training average loss at step 44800: 0.393678
2025-12-13 00:21:54,507 INFO     Training average regularization at step 44900: 0.305613
2025-12-13 00:21:54,508 INFO     Training average positive_sample_loss at step 44900: 0.069248
2025-12-13 00:21:54,508 INFO     Training average negative_sample_loss at step 44900: 0.109972
2025-12-13 00:21:54,508 INFO     Training average loss at step 44900: 0.395223
2025-12-13 00:21:56,650 INFO     Training average regularization at step 45000: 0.305603
2025-12-13 00:21:56,650 INFO     Training average positive_sample_loss at step 45000: 0.067991
2025-12-13 00:21:56,650 INFO     Training average negative_sample_loss at step 45000: 0.113329
2025-12-13 00:21:56,651 INFO     Training average loss at step 45000: 0.396263
2025-12-13 00:21:58,799 INFO     Training average regularization at step 45100: 0.305591
2025-12-13 00:21:58,799 INFO     Training average positive_sample_loss at step 45100: 0.067813
2025-12-13 00:21:58,799 INFO     Training average negative_sample_loss at step 45100: 0.111011
2025-12-13 00:21:58,799 INFO     Training average loss at step 45100: 0.395002
2025-12-13 00:22:00,947 INFO     Training average regularization at step 45200: 0.305578
2025-12-13 00:22:00,947 INFO     Training average positive_sample_loss at step 45200: 0.067808
2025-12-13 00:22:00,947 INFO     Training average negative_sample_loss at step 45200: 0.109303
2025-12-13 00:22:00,947 INFO     Training average loss at step 45200: 0.394134
2025-12-13 00:22:03,090 INFO     Training average regularization at step 45300: 0.305567
2025-12-13 00:22:03,090 INFO     Training average positive_sample_loss at step 45300: 0.068439
2025-12-13 00:22:03,090 INFO     Training average negative_sample_loss at step 45300: 0.107964
2025-12-13 00:22:03,090 INFO     Training average loss at step 45300: 0.393768
2025-12-13 00:22:05,269 INFO     Training average regularization at step 45400: 0.305555
2025-12-13 00:22:05,269 INFO     Training average positive_sample_loss at step 45400: 0.068902
2025-12-13 00:22:05,269 INFO     Training average negative_sample_loss at step 45400: 0.109390
2025-12-13 00:22:05,269 INFO     Training average loss at step 45400: 0.394702
2025-12-13 00:22:07,410 INFO     Training average regularization at step 45500: 0.305545
2025-12-13 00:22:07,410 INFO     Training average positive_sample_loss at step 45500: 0.068736
2025-12-13 00:22:07,410 INFO     Training average negative_sample_loss at step 45500: 0.109625
2025-12-13 00:22:07,410 INFO     Training average loss at step 45500: 0.394725
2025-12-13 00:22:09,547 INFO     Training average regularization at step 45600: 0.305534
2025-12-13 00:22:09,547 INFO     Training average positive_sample_loss at step 45600: 0.070533
2025-12-13 00:22:09,547 INFO     Training average negative_sample_loss at step 45600: 0.109668
2025-12-13 00:22:09,547 INFO     Training average loss at step 45600: 0.395634
2025-12-13 00:22:11,691 INFO     Training average regularization at step 45700: 0.305524
2025-12-13 00:22:11,692 INFO     Training average positive_sample_loss at step 45700: 0.067799
2025-12-13 00:22:11,692 INFO     Training average negative_sample_loss at step 45700: 0.104505
2025-12-13 00:22:11,692 INFO     Training average loss at step 45700: 0.391676
2025-12-13 00:22:13,850 INFO     Training average regularization at step 45800: 0.305515
2025-12-13 00:22:13,850 INFO     Training average positive_sample_loss at step 45800: 0.069304
2025-12-13 00:22:13,850 INFO     Training average negative_sample_loss at step 45800: 0.108107
2025-12-13 00:22:13,850 INFO     Training average loss at step 45800: 0.394220
2025-12-13 00:22:16,045 INFO     Training average regularization at step 45900: 0.305506
2025-12-13 00:22:16,045 INFO     Training average positive_sample_loss at step 45900: 0.070380
2025-12-13 00:22:16,045 INFO     Training average negative_sample_loss at step 45900: 0.110841
2025-12-13 00:22:16,045 INFO     Training average loss at step 45900: 0.396117
2025-12-13 00:22:18,205 INFO     Training average regularization at step 46000: 0.305496
2025-12-13 00:22:18,205 INFO     Training average positive_sample_loss at step 46000: 0.067364
2025-12-13 00:22:18,206 INFO     Training average negative_sample_loss at step 46000: 0.108359
2025-12-13 00:22:18,206 INFO     Training average loss at step 46000: 0.393358
2025-12-13 00:22:20,353 INFO     Training average regularization at step 46100: 0.305487
2025-12-13 00:22:20,353 INFO     Training average positive_sample_loss at step 46100: 0.068868
2025-12-13 00:22:20,353 INFO     Training average negative_sample_loss at step 46100: 0.105690
2025-12-13 00:22:20,353 INFO     Training average loss at step 46100: 0.392766
2025-12-13 00:22:22,511 INFO     Training average regularization at step 46200: 0.305479
2025-12-13 00:22:22,511 INFO     Training average positive_sample_loss at step 46200: 0.069015
2025-12-13 00:22:22,511 INFO     Training average negative_sample_loss at step 46200: 0.108401
2025-12-13 00:22:22,511 INFO     Training average loss at step 46200: 0.394186
2025-12-13 00:22:24,685 INFO     Training average regularization at step 46300: 0.305470
2025-12-13 00:22:24,686 INFO     Training average positive_sample_loss at step 46300: 0.068361
2025-12-13 00:22:24,686 INFO     Training average negative_sample_loss at step 46300: 0.109110
2025-12-13 00:22:24,686 INFO     Training average loss at step 46300: 0.394205
2025-12-13 00:22:26,850 INFO     Training average regularization at step 46400: 0.305460
2025-12-13 00:22:26,850 INFO     Training average positive_sample_loss at step 46400: 0.069611
2025-12-13 00:22:26,850 INFO     Training average negative_sample_loss at step 46400: 0.109292
2025-12-13 00:22:26,850 INFO     Training average loss at step 46400: 0.394912
2025-12-13 00:22:29,014 INFO     Training average regularization at step 46500: 0.305452
2025-12-13 00:22:29,014 INFO     Training average positive_sample_loss at step 46500: 0.067961
2025-12-13 00:22:29,014 INFO     Training average negative_sample_loss at step 46500: 0.108803
2025-12-13 00:22:29,014 INFO     Training average loss at step 46500: 0.393834
2025-12-13 00:22:31,176 INFO     Training average regularization at step 46600: 0.305442
2025-12-13 00:22:31,177 INFO     Training average positive_sample_loss at step 46600: 0.069538
2025-12-13 00:22:31,177 INFO     Training average negative_sample_loss at step 46600: 0.107635
2025-12-13 00:22:31,177 INFO     Training average loss at step 46600: 0.394029
2025-12-13 00:22:33,340 INFO     Training average regularization at step 46700: 0.305435
2025-12-13 00:22:33,340 INFO     Training average positive_sample_loss at step 46700: 0.069166
2025-12-13 00:22:33,340 INFO     Training average negative_sample_loss at step 46700: 0.110017
2025-12-13 00:22:33,340 INFO     Training average loss at step 46700: 0.395026
2025-12-13 00:22:35,516 INFO     Training average regularization at step 46800: 0.305425
2025-12-13 00:22:35,516 INFO     Training average positive_sample_loss at step 46800: 0.069703
2025-12-13 00:22:35,516 INFO     Training average negative_sample_loss at step 46800: 0.107667
2025-12-13 00:22:35,516 INFO     Training average loss at step 46800: 0.394110
2025-12-13 00:22:37,687 INFO     Training average regularization at step 46900: 0.305417
2025-12-13 00:22:37,687 INFO     Training average positive_sample_loss at step 46900: 0.069943
2025-12-13 00:22:37,687 INFO     Training average negative_sample_loss at step 46900: 0.108035
2025-12-13 00:22:37,687 INFO     Training average loss at step 46900: 0.394406
2025-12-13 00:22:39,862 INFO     Training average regularization at step 47000: 0.305408
2025-12-13 00:22:39,862 INFO     Training average positive_sample_loss at step 47000: 0.069405
2025-12-13 00:22:39,862 INFO     Training average negative_sample_loss at step 47000: 0.109346
2025-12-13 00:22:39,862 INFO     Training average loss at step 47000: 0.394784
2025-12-13 00:22:42,067 INFO     Training average regularization at step 47100: 0.305400
2025-12-13 00:22:42,068 INFO     Training average positive_sample_loss at step 47100: 0.070298
2025-12-13 00:22:42,068 INFO     Training average negative_sample_loss at step 47100: 0.108463
2025-12-13 00:22:42,068 INFO     Training average loss at step 47100: 0.394780
2025-12-13 00:22:44,224 INFO     Training average regularization at step 47200: 0.305392
2025-12-13 00:22:44,224 INFO     Training average positive_sample_loss at step 47200: 0.070041
2025-12-13 00:22:44,224 INFO     Training average negative_sample_loss at step 47200: 0.109347
2025-12-13 00:22:44,224 INFO     Training average loss at step 47200: 0.395086
2025-12-13 00:22:46,370 INFO     Training average regularization at step 47300: 0.305383
2025-12-13 00:22:46,371 INFO     Training average positive_sample_loss at step 47300: 0.068384
2025-12-13 00:22:46,371 INFO     Training average negative_sample_loss at step 47300: 0.109325
2025-12-13 00:22:46,371 INFO     Training average loss at step 47300: 0.394237
2025-12-13 00:22:48,536 INFO     Training average regularization at step 47400: 0.305373
2025-12-13 00:22:48,536 INFO     Training average positive_sample_loss at step 47400: 0.069205
2025-12-13 00:22:48,536 INFO     Training average negative_sample_loss at step 47400: 0.107990
2025-12-13 00:22:48,536 INFO     Training average loss at step 47400: 0.393970
2025-12-13 00:22:50,724 INFO     Training average regularization at step 47500: 0.305365
2025-12-13 00:22:50,724 INFO     Training average positive_sample_loss at step 47500: 0.069055
2025-12-13 00:22:50,724 INFO     Training average negative_sample_loss at step 47500: 0.108487
2025-12-13 00:22:50,724 INFO     Training average loss at step 47500: 0.394136
2025-12-13 00:22:52,906 INFO     Training average regularization at step 47600: 0.305356
2025-12-13 00:22:52,906 INFO     Training average positive_sample_loss at step 47600: 0.069352
2025-12-13 00:22:52,906 INFO     Training average negative_sample_loss at step 47600: 0.107140
2025-12-13 00:22:52,906 INFO     Training average loss at step 47600: 0.393603
2025-12-13 00:22:55,077 INFO     Training average regularization at step 47700: 0.305347
2025-12-13 00:22:55,078 INFO     Training average positive_sample_loss at step 47700: 0.066953
2025-12-13 00:22:55,078 INFO     Training average negative_sample_loss at step 47700: 0.109627
2025-12-13 00:22:55,078 INFO     Training average loss at step 47700: 0.393637
2025-12-13 00:22:57,208 INFO     Training average regularization at step 47800: 0.305337
2025-12-13 00:22:57,208 INFO     Training average positive_sample_loss at step 47800: 0.069297
2025-12-13 00:22:57,208 INFO     Training average negative_sample_loss at step 47800: 0.111025
2025-12-13 00:22:57,208 INFO     Training average loss at step 47800: 0.395498
2025-12-13 00:22:59,369 INFO     Training average regularization at step 47900: 0.305327
2025-12-13 00:22:59,369 INFO     Training average positive_sample_loss at step 47900: 0.067815
2025-12-13 00:22:59,369 INFO     Training average negative_sample_loss at step 47900: 0.110402
2025-12-13 00:22:59,369 INFO     Training average loss at step 47900: 0.394435
2025-12-13 00:23:01,534 INFO     Training average regularization at step 48000: 0.305317
2025-12-13 00:23:01,534 INFO     Training average positive_sample_loss at step 48000: 0.067952
2025-12-13 00:23:01,534 INFO     Training average negative_sample_loss at step 48000: 0.109684
2025-12-13 00:23:01,534 INFO     Training average loss at step 48000: 0.394135
2025-12-13 00:23:03,679 INFO     Training average regularization at step 48100: 0.305307
2025-12-13 00:23:03,680 INFO     Training average positive_sample_loss at step 48100: 0.069146
2025-12-13 00:23:03,680 INFO     Training average negative_sample_loss at step 48100: 0.110399
2025-12-13 00:23:03,680 INFO     Training average loss at step 48100: 0.395080
2025-12-13 00:23:05,835 INFO     Training average regularization at step 48200: 0.305298
2025-12-13 00:23:05,835 INFO     Training average positive_sample_loss at step 48200: 0.068716
2025-12-13 00:23:05,835 INFO     Training average negative_sample_loss at step 48200: 0.108791
2025-12-13 00:23:05,835 INFO     Training average loss at step 48200: 0.394052
2025-12-13 00:23:08,150 INFO     Training average regularization at step 48300: 0.305289
2025-12-13 00:23:08,150 INFO     Training average positive_sample_loss at step 48300: 0.068095
2025-12-13 00:23:08,150 INFO     Training average negative_sample_loss at step 48300: 0.111319
2025-12-13 00:23:08,150 INFO     Training average loss at step 48300: 0.394996
2025-12-13 00:23:11,189 INFO     Training average regularization at step 48400: 0.305279
2025-12-13 00:23:11,190 INFO     Training average positive_sample_loss at step 48400: 0.068256
2025-12-13 00:23:11,190 INFO     Training average negative_sample_loss at step 48400: 0.106957
2025-12-13 00:23:11,190 INFO     Training average loss at step 48400: 0.392886
2025-12-13 00:23:13,354 INFO     Training average regularization at step 48500: 0.305269
2025-12-13 00:23:13,354 INFO     Training average positive_sample_loss at step 48500: 0.066122
2025-12-13 00:23:13,354 INFO     Training average negative_sample_loss at step 48500: 0.107636
2025-12-13 00:23:13,354 INFO     Training average loss at step 48500: 0.392148
2025-12-13 00:23:15,500 INFO     Training average regularization at step 48600: 0.305256
2025-12-13 00:23:15,500 INFO     Training average positive_sample_loss at step 48600: 0.067475
2025-12-13 00:23:15,500 INFO     Training average negative_sample_loss at step 48600: 0.107347
2025-12-13 00:23:15,500 INFO     Training average loss at step 48600: 0.392667
2025-12-13 00:23:17,679 INFO     Training average regularization at step 48700: 0.305244
2025-12-13 00:23:17,679 INFO     Training average positive_sample_loss at step 48700: 0.066573
2025-12-13 00:23:17,679 INFO     Training average negative_sample_loss at step 48700: 0.109209
2025-12-13 00:23:17,679 INFO     Training average loss at step 48700: 0.393135
2025-12-13 00:23:19,847 INFO     Training average regularization at step 48800: 0.305233
2025-12-13 00:23:19,847 INFO     Training average positive_sample_loss at step 48800: 0.067871
2025-12-13 00:23:19,847 INFO     Training average negative_sample_loss at step 48800: 0.109184
2025-12-13 00:23:19,847 INFO     Training average loss at step 48800: 0.393760
2025-12-13 00:23:22,039 INFO     Training average regularization at step 48900: 0.305222
2025-12-13 00:23:22,039 INFO     Training average positive_sample_loss at step 48900: 0.066558
2025-12-13 00:23:22,039 INFO     Training average negative_sample_loss at step 48900: 0.108777
2025-12-13 00:23:22,040 INFO     Training average loss at step 48900: 0.392890
2025-12-13 00:23:24,191 INFO     Training average regularization at step 49000: 0.305210
2025-12-13 00:23:24,191 INFO     Training average positive_sample_loss at step 49000: 0.067741
2025-12-13 00:23:24,191 INFO     Training average negative_sample_loss at step 49000: 0.110112
2025-12-13 00:23:24,191 INFO     Training average loss at step 49000: 0.394137
2025-12-13 00:23:26,351 INFO     Training average regularization at step 49100: 0.305200
2025-12-13 00:23:26,351 INFO     Training average positive_sample_loss at step 49100: 0.066649
2025-12-13 00:23:26,351 INFO     Training average negative_sample_loss at step 49100: 0.106201
2025-12-13 00:23:26,351 INFO     Training average loss at step 49100: 0.391625
2025-12-13 00:23:28,518 INFO     Training average regularization at step 49200: 0.305192
2025-12-13 00:23:28,518 INFO     Training average positive_sample_loss at step 49200: 0.068954
2025-12-13 00:23:28,518 INFO     Training average negative_sample_loss at step 49200: 0.109147
2025-12-13 00:23:28,518 INFO     Training average loss at step 49200: 0.394242
2025-12-13 00:23:30,669 INFO     Training average regularization at step 49300: 0.305182
2025-12-13 00:23:30,669 INFO     Training average positive_sample_loss at step 49300: 0.066276
2025-12-13 00:23:30,669 INFO     Training average negative_sample_loss at step 49300: 0.107700
2025-12-13 00:23:30,669 INFO     Training average loss at step 49300: 0.392170
2025-12-13 00:23:32,837 INFO     Training average regularization at step 49400: 0.305169
2025-12-13 00:23:32,837 INFO     Training average positive_sample_loss at step 49400: 0.067474
2025-12-13 00:23:32,837 INFO     Training average negative_sample_loss at step 49400: 0.108998
2025-12-13 00:23:32,837 INFO     Training average loss at step 49400: 0.393405
2025-12-13 00:23:34,981 INFO     Training average regularization at step 49500: 0.305158
2025-12-13 00:23:34,981 INFO     Training average positive_sample_loss at step 49500: 0.066271
2025-12-13 00:23:34,981 INFO     Training average negative_sample_loss at step 49500: 0.105852
2025-12-13 00:23:34,981 INFO     Training average loss at step 49500: 0.391219
2025-12-13 00:23:37,148 INFO     Training average regularization at step 49600: 0.305146
2025-12-13 00:23:37,148 INFO     Training average positive_sample_loss at step 49600: 0.066655
2025-12-13 00:23:37,148 INFO     Training average negative_sample_loss at step 49600: 0.109814
2025-12-13 00:23:37,148 INFO     Training average loss at step 49600: 0.393380
2025-12-13 00:23:39,358 INFO     Training average regularization at step 49700: 0.305137
2025-12-13 00:23:39,359 INFO     Training average positive_sample_loss at step 49700: 0.068085
2025-12-13 00:23:39,359 INFO     Training average negative_sample_loss at step 49700: 0.106535
2025-12-13 00:23:39,359 INFO     Training average loss at step 49700: 0.392447
2025-12-13 00:23:41,563 INFO     Training average regularization at step 49800: 0.305126
2025-12-13 00:23:41,563 INFO     Training average positive_sample_loss at step 49800: 0.067487
2025-12-13 00:23:41,563 INFO     Training average negative_sample_loss at step 49800: 0.110847
2025-12-13 00:23:41,563 INFO     Training average loss at step 49800: 0.394293
2025-12-13 00:23:43,743 INFO     Training average regularization at step 49900: 0.305115
2025-12-13 00:23:43,743 INFO     Training average positive_sample_loss at step 49900: 0.067517
2025-12-13 00:23:43,743 INFO     Training average negative_sample_loss at step 49900: 0.106225
2025-12-13 00:23:43,743 INFO     Training average loss at step 49900: 0.391987
2025-12-13 00:23:45,927 INFO     Training average regularization at step 50000: 0.305106
2025-12-13 00:23:45,928 INFO     Training average positive_sample_loss at step 50000: 0.065970
2025-12-13 00:23:45,928 INFO     Training average negative_sample_loss at step 50000: 0.107993
2025-12-13 00:23:45,928 INFO     Training average loss at step 50000: 0.392087
2025-12-13 00:23:45,928 INFO     Evaluating on Valid Dataset...
2025-12-13 00:23:46,561 INFO     Evaluating the model... (0/50000)
2025-12-13 00:23:49,138 INFO     Evaluating the model... (500/50000)
2025-12-13 00:23:52,511 INFO     Evaluating the model... (1000/50000)
2025-12-13 00:23:55,198 INFO     Evaluating the model... (1500/50000)
2025-12-13 00:23:57,662 INFO     Evaluating the model... (2000/50000)
2025-12-13 00:24:00,073 INFO     Evaluating the model... (2500/50000)
2025-12-13 00:24:02,397 INFO     Evaluating the model... (3000/50000)
2025-12-13 00:24:05,541 INFO     Evaluating the model... (3500/50000)
2025-12-13 00:24:08,207 INFO     Evaluating the model... (4000/50000)
2025-12-13 00:24:10,623 INFO     Evaluating the model... (4500/50000)
2025-12-13 00:24:13,036 INFO     Evaluating the model... (5000/50000)
2025-12-13 00:24:15,531 INFO     Evaluating the model... (5500/50000)
2025-12-13 00:24:18,812 INFO     Evaluating the model... (6000/50000)
2025-12-13 00:24:21,223 INFO     Evaluating the model... (6500/50000)
2025-12-13 00:24:23,596 INFO     Evaluating the model... (7000/50000)
2025-12-13 00:24:26,055 INFO     Evaluating the model... (7500/50000)
2025-12-13 00:24:28,563 INFO     Evaluating the model... (8000/50000)
2025-12-13 00:24:31,731 INFO     Evaluating the model... (8500/50000)
2025-12-13 00:24:34,128 INFO     Evaluating the model... (9000/50000)
2025-12-13 00:24:36,739 INFO     Evaluating the model... (9500/50000)
2025-12-13 00:24:39,411 INFO     Evaluating the model... (10000/50000)
2025-12-13 00:24:42,268 INFO     Evaluating the model... (10500/50000)
2025-12-13 00:24:45,445 INFO     Evaluating the model... (11000/50000)
2025-12-13 00:24:47,911 INFO     Evaluating the model... (11500/50000)
2025-12-13 00:24:50,254 INFO     Evaluating the model... (12000/50000)
2025-12-13 00:24:52,755 INFO     Evaluating the model... (12500/50000)
2025-12-13 00:24:55,296 INFO     Evaluating the model... (13000/50000)
2025-12-13 00:24:58,393 INFO     Evaluating the model... (13500/50000)
2025-12-13 00:25:00,958 INFO     Evaluating the model... (14000/50000)
2025-12-13 00:25:03,299 INFO     Evaluating the model... (14500/50000)
2025-12-13 00:25:05,916 INFO     Evaluating the model... (15000/50000)
2025-12-13 00:25:09,499 INFO     Evaluating the model... (15500/50000)
2025-12-13 00:25:11,979 INFO     Evaluating the model... (16000/50000)
2025-12-13 00:25:14,380 INFO     Evaluating the model... (16500/50000)
2025-12-13 00:25:17,058 INFO     Evaluating the model... (17000/50000)
2025-12-13 00:25:19,487 INFO     Evaluating the model... (17500/50000)
2025-12-13 00:25:23,029 INFO     Evaluating the model... (18000/50000)
2025-12-13 00:25:25,358 INFO     Evaluating the model... (18500/50000)
2025-12-13 00:25:28,007 INFO     Evaluating the model... (19000/50000)
2025-12-13 00:25:30,342 INFO     Evaluating the model... (19500/50000)
2025-12-13 00:25:32,828 INFO     Evaluating the model... (20000/50000)
2025-12-13 00:25:36,472 INFO     Evaluating the model... (20500/50000)
2025-12-13 00:25:39,225 INFO     Evaluating the model... (21000/50000)
2025-12-13 00:25:41,855 INFO     Evaluating the model... (21500/50000)
2025-12-13 00:25:44,509 INFO     Evaluating the model... (22000/50000)
2025-12-13 00:25:47,055 INFO     Evaluating the model... (22500/50000)
2025-12-13 00:25:50,993 INFO     Evaluating the model... (23000/50000)
2025-12-13 00:25:53,400 INFO     Evaluating the model... (23500/50000)
2025-12-13 00:25:55,795 INFO     Evaluating the model... (24000/50000)
2025-12-13 00:25:58,347 INFO     Evaluating the model... (24500/50000)
2025-12-13 00:26:01,117 INFO     Evaluating the model... (25000/50000)
2025-12-13 00:26:04,814 INFO     Evaluating the model... (25500/50000)
2025-12-13 00:26:07,471 INFO     Evaluating the model... (26000/50000)
2025-12-13 00:26:10,046 INFO     Evaluating the model... (26500/50000)
2025-12-13 00:26:12,740 INFO     Evaluating the model... (27000/50000)
2025-12-13 00:26:15,550 INFO     Evaluating the model... (27500/50000)
2025-12-13 00:26:18,896 INFO     Evaluating the model... (28000/50000)
2025-12-13 00:26:21,290 INFO     Evaluating the model... (28500/50000)
2025-12-13 00:26:23,827 INFO     Evaluating the model... (29000/50000)
2025-12-13 00:26:26,536 INFO     Evaluating the model... (29500/50000)
2025-12-13 00:26:29,002 INFO     Evaluating the model... (30000/50000)
2025-12-13 00:26:31,984 INFO     Evaluating the model... (30500/50000)
2025-12-13 00:26:34,440 INFO     Evaluating the model... (31000/50000)
2025-12-13 00:26:37,322 INFO     Evaluating the model... (31500/50000)
2025-12-13 00:26:39,950 INFO     Evaluating the model... (32000/50000)
2025-12-13 00:26:42,748 INFO     Evaluating the model... (32500/50000)
2025-12-13 00:26:45,903 INFO     Evaluating the model... (33000/50000)
2025-12-13 00:26:48,644 INFO     Evaluating the model... (33500/50000)
2025-12-13 00:26:51,144 INFO     Evaluating the model... (34000/50000)
2025-12-13 00:26:53,610 INFO     Evaluating the model... (34500/50000)
2025-12-13 00:26:56,157 INFO     Evaluating the model... (35000/50000)
2025-12-13 00:26:59,731 INFO     Evaluating the model... (35500/50000)
2025-12-13 00:27:02,291 INFO     Evaluating the model... (36000/50000)
2025-12-13 00:27:04,782 INFO     Evaluating the model... (36500/50000)
2025-12-13 00:27:07,313 INFO     Evaluating the model... (37000/50000)
2025-12-13 00:27:09,807 INFO     Evaluating the model... (37500/50000)
2025-12-13 00:27:13,236 INFO     Evaluating the model... (38000/50000)
2025-12-13 00:27:15,870 INFO     Evaluating the model... (38500/50000)
2025-12-13 00:27:18,389 INFO     Evaluating the model... (39000/50000)
2025-12-13 00:27:20,783 INFO     Evaluating the model... (39500/50000)
2025-12-13 00:27:24,067 INFO     Evaluating the model... (40000/50000)
2025-12-13 00:27:27,032 INFO     Evaluating the model... (40500/50000)
2025-12-13 00:27:29,645 INFO     Evaluating the model... (41000/50000)
2025-12-13 00:27:32,153 INFO     Evaluating the model... (41500/50000)
2025-12-13 00:27:34,760 INFO     Evaluating the model... (42000/50000)
2025-12-13 00:27:38,496 INFO     Evaluating the model... (42500/50000)
2025-12-13 00:27:41,259 INFO     Evaluating the model... (43000/50000)
2025-12-13 00:27:44,043 INFO     Evaluating the model... (43500/50000)
2025-12-13 00:27:46,962 INFO     Evaluating the model... (44000/50000)
2025-12-13 00:27:49,410 INFO     Evaluating the model... (44500/50000)
2025-12-13 00:27:53,262 INFO     Evaluating the model... (45000/50000)
2025-12-13 00:27:55,671 INFO     Evaluating the model... (45500/50000)
2025-12-13 00:27:58,444 INFO     Evaluating the model... (46000/50000)
2025-12-13 00:28:00,906 INFO     Evaluating the model... (46500/50000)
2025-12-13 00:28:03,326 INFO     Evaluating the model... (47000/50000)
2025-12-13 00:28:06,938 INFO     Evaluating the model... (47500/50000)
2025-12-13 00:28:09,634 INFO     Evaluating the model... (48000/50000)
2025-12-13 00:28:12,097 INFO     Evaluating the model... (48500/50000)
2025-12-13 00:28:14,571 INFO     Evaluating the model... (49000/50000)
2025-12-13 00:28:17,090 INFO     Evaluating the model... (49500/50000)
2025-12-13 00:28:21,139 INFO     Valid MRR at step 50000: 0.605164
2025-12-13 00:28:21,139 INFO     Valid MR at step 50000: 273.446800
2025-12-13 00:28:21,139 INFO     Valid HITS@1 at step 50000: 0.512660
2025-12-13 00:28:21,139 INFO     Valid HITS@3 at step 50000: 0.661490
2025-12-13 00:28:21,139 INFO     Valid HITS@10 at step 50000: 0.771280
2025-12-13 00:28:22,338 INFO     Evaluating on Test Dataset...
2025-12-13 00:28:23,399 INFO     Evaluating the model... (0/59072)
2025-12-13 00:28:25,940 INFO     Evaluating the model... (500/59072)
2025-12-13 00:28:28,482 INFO     Evaluating the model... (1000/59072)
2025-12-13 00:28:31,327 INFO     Evaluating the model... (1500/59072)
2025-12-13 00:28:33,833 INFO     Evaluating the model... (2000/59072)
2025-12-13 00:28:37,321 INFO     Evaluating the model... (2500/59072)
2025-12-13 00:28:39,941 INFO     Evaluating the model... (3000/59072)
2025-12-13 00:28:42,678 INFO     Evaluating the model... (3500/59072)
2025-12-13 00:28:45,345 INFO     Evaluating the model... (4000/59072)
2025-12-13 00:28:47,882 INFO     Evaluating the model... (4500/59072)
2025-12-13 00:28:51,295 INFO     Evaluating the model... (5000/59072)
2025-12-13 00:28:53,703 INFO     Evaluating the model... (5500/59072)
2025-12-13 00:28:56,311 INFO     Evaluating the model... (6000/59072)
2025-12-13 00:28:58,745 INFO     Evaluating the model... (6500/59072)
2025-12-13 00:29:01,106 INFO     Evaluating the model... (7000/59072)
2025-12-13 00:29:04,449 INFO     Evaluating the model... (7500/59072)
2025-12-13 00:29:07,129 INFO     Evaluating the model... (8000/59072)
2025-12-13 00:29:09,474 INFO     Evaluating the model... (8500/59072)
2025-12-13 00:29:11,953 INFO     Evaluating the model... (9000/59072)
2025-12-13 00:29:14,477 INFO     Evaluating the model... (9500/59072)
2025-12-13 00:29:18,539 INFO     Evaluating the model... (10000/59072)
2025-12-13 00:29:20,969 INFO     Evaluating the model... (10500/59072)
2025-12-13 00:29:23,420 INFO     Evaluating the model... (11000/59072)
2025-12-13 00:29:26,030 INFO     Evaluating the model... (11500/59072)
2025-12-13 00:29:28,576 INFO     Evaluating the model... (12000/59072)
2025-12-13 00:29:32,537 INFO     Evaluating the model... (12500/59072)
2025-12-13 00:29:34,981 INFO     Evaluating the model... (13000/59072)
2025-12-13 00:29:37,731 INFO     Evaluating the model... (13500/59072)
2025-12-13 00:29:40,411 INFO     Evaluating the model... (14000/59072)
2025-12-13 00:29:43,225 INFO     Evaluating the model... (14500/59072)
2025-12-13 00:29:47,020 INFO     Evaluating the model... (15000/59072)
2025-12-13 00:29:49,577 INFO     Evaluating the model... (15500/59072)
2025-12-13 00:29:52,170 INFO     Evaluating the model... (16000/59072)
2025-12-13 00:29:54,760 INFO     Evaluating the model... (16500/59072)
2025-12-13 00:29:57,174 INFO     Evaluating the model... (17000/59072)
2025-12-13 00:30:00,680 INFO     Evaluating the model... (17500/59072)
2025-12-13 00:30:03,317 INFO     Evaluating the model... (18000/59072)
2025-12-13 00:30:05,881 INFO     Evaluating the model... (18500/59072)
2025-12-13 00:30:08,331 INFO     Evaluating the model... (19000/59072)
2025-12-13 00:30:11,567 INFO     Evaluating the model... (19500/59072)
2025-12-13 00:30:14,220 INFO     Evaluating the model... (20000/59072)
2025-12-13 00:30:16,912 INFO     Evaluating the model... (20500/59072)
2025-12-13 00:30:19,337 INFO     Evaluating the model... (21000/59072)
2025-12-13 00:30:21,909 INFO     Evaluating the model... (21500/59072)
2025-12-13 00:30:25,831 INFO     Evaluating the model... (22000/59072)
2025-12-13 00:30:28,447 INFO     Evaluating the model... (22500/59072)
2025-12-13 00:30:30,831 INFO     Evaluating the model... (23000/59072)
2025-12-13 00:30:33,255 INFO     Evaluating the model... (23500/59072)
2025-12-13 00:30:35,787 INFO     Evaluating the model... (24000/59072)
2025-12-13 00:30:40,021 INFO     Evaluating the model... (24500/59072)
2025-12-13 00:30:42,705 INFO     Evaluating the model... (25000/59072)
2025-12-13 00:30:45,389 INFO     Evaluating the model... (25500/59072)
2025-12-13 00:30:47,914 INFO     Evaluating the model... (26000/59072)
2025-12-13 00:30:50,564 INFO     Evaluating the model... (26500/59072)
2025-12-13 00:30:54,224 INFO     Evaluating the model... (27000/59072)
2025-12-13 00:30:56,698 INFO     Evaluating the model... (27500/59072)
2025-12-13 00:30:59,170 INFO     Evaluating the model... (28000/59072)
2025-12-13 00:31:01,857 INFO     Evaluating the model... (28500/59072)
2025-12-13 00:31:04,289 INFO     Evaluating the model... (29000/59072)
2025-12-13 00:31:08,006 INFO     Evaluating the model... (29500/59072)
2025-12-13 00:31:10,801 INFO     Evaluating the model... (30000/59072)
2025-12-13 00:31:13,529 INFO     Evaluating the model... (30500/59072)
2025-12-13 00:31:16,153 INFO     Evaluating the model... (31000/59072)
2025-12-13 00:31:18,666 INFO     Evaluating the model... (31500/59072)
2025-12-13 00:31:22,114 INFO     Evaluating the model... (32000/59072)
2025-12-13 00:31:24,821 INFO     Evaluating the model... (32500/59072)
2025-12-13 00:31:27,301 INFO     Evaluating the model... (33000/59072)
2025-12-13 00:31:29,724 INFO     Evaluating the model... (33500/59072)
2025-12-13 00:31:33,108 INFO     Evaluating the model... (34000/59072)
2025-12-13 00:31:35,854 INFO     Evaluating the model... (34500/59072)
2025-12-13 00:31:38,696 INFO     Evaluating the model... (35000/59072)
2025-12-13 00:31:41,376 INFO     Evaluating the model... (35500/59072)
2025-12-13 00:31:44,053 INFO     Evaluating the model... (36000/59072)
2025-12-13 00:31:47,270 INFO     Evaluating the model... (36500/59072)
2025-12-13 00:31:49,780 INFO     Evaluating the model... (37000/59072)
2025-12-13 00:31:52,243 INFO     Evaluating the model... (37500/59072)
2025-12-13 00:31:54,704 INFO     Evaluating the model... (38000/59072)
2025-12-13 00:31:57,175 INFO     Evaluating the model... (38500/59072)
2025-12-13 00:32:00,734 INFO     Evaluating the model... (39000/59072)
2025-12-13 00:32:03,194 INFO     Evaluating the model... (39500/59072)
2025-12-13 00:32:05,803 INFO     Evaluating the model... (40000/59072)
2025-12-13 00:32:08,342 INFO     Evaluating the model... (40500/59072)
2025-12-13 00:32:11,042 INFO     Evaluating the model... (41000/59072)
2025-12-13 00:32:14,097 INFO     Evaluating the model... (41500/59072)
2025-12-13 00:32:16,623 INFO     Evaluating the model... (42000/59072)
2025-12-13 00:32:19,103 INFO     Evaluating the model... (42500/59072)
2025-12-13 00:32:21,864 INFO     Evaluating the model... (43000/59072)
2025-12-13 00:32:24,301 INFO     Evaluating the model... (43500/59072)
2025-12-13 00:32:27,825 INFO     Evaluating the model... (44000/59072)
2025-12-13 00:32:30,366 INFO     Evaluating the model... (44500/59072)
2025-12-13 00:32:33,130 INFO     Evaluating the model... (45000/59072)
2025-12-13 00:32:35,760 INFO     Evaluating the model... (45500/59072)
2025-12-13 00:32:38,483 INFO     Evaluating the model... (46000/59072)
2025-12-13 00:32:42,106 INFO     Evaluating the model... (46500/59072)
2025-12-13 00:32:45,053 INFO     Evaluating the model... (47000/59072)
2025-12-13 00:32:47,504 INFO     Evaluating the model... (47500/59072)
2025-12-13 00:32:49,976 INFO     Evaluating the model... (48000/59072)
2025-12-13 00:32:52,387 INFO     Evaluating the model... (48500/59072)
2025-12-13 00:32:55,664 INFO     Evaluating the model... (49000/59072)
2025-12-13 00:32:58,244 INFO     Evaluating the model... (49500/59072)
2025-12-13 00:33:00,723 INFO     Evaluating the model... (50000/59072)
2025-12-13 00:33:03,317 INFO     Evaluating the model... (50500/59072)
2025-12-13 00:33:05,766 INFO     Evaluating the model... (51000/59072)
2025-12-13 00:33:09,089 INFO     Evaluating the model... (51500/59072)
2025-12-13 00:33:11,549 INFO     Evaluating the model... (52000/59072)
2025-12-13 00:33:14,140 INFO     Evaluating the model... (52500/59072)
2025-12-13 00:33:16,682 INFO     Evaluating the model... (53000/59072)
2025-12-13 00:33:20,496 INFO     Evaluating the model... (53500/59072)
2025-12-13 00:33:23,108 INFO     Evaluating the model... (54000/59072)
2025-12-13 00:33:25,701 INFO     Evaluating the model... (54500/59072)
2025-12-13 00:33:28,178 INFO     Evaluating the model... (55000/59072)
2025-12-13 00:33:30,811 INFO     Evaluating the model... (55500/59072)
2025-12-13 00:33:34,530 INFO     Evaluating the model... (56000/59072)
2025-12-13 00:33:37,256 INFO     Evaluating the model... (56500/59072)
2025-12-13 00:33:39,910 INFO     Evaluating the model... (57000/59072)
2025-12-13 00:33:42,763 INFO     Evaluating the model... (57500/59072)
2025-12-13 00:33:45,425 INFO     Evaluating the model... (58000/59072)
2025-12-13 00:33:48,854 INFO     Evaluating the model... (58500/59072)
2025-12-13 00:33:51,248 INFO     Evaluating the model... (59000/59072)
2025-12-13 00:33:51,854 INFO     Test MRR at step 50000: 0.601265
2025-12-13 00:33:51,854 INFO     Test MR at step 50000: 273.717983
2025-12-13 00:33:51,854 INFO     Test HITS@1 at step 50000: 0.506932
2025-12-13 00:33:51,854 INFO     Test HITS@3 at step 50000: 0.659571
2025-12-13 00:33:51,854 INFO     Test HITS@10 at step 50000: 0.770014
2025-12-13 00:33:54,058 INFO     Training average regularization at step 50100: 0.305095
2025-12-13 00:33:54,058 INFO     Training average positive_sample_loss at step 50100: 0.068955
2025-12-13 00:33:54,058 INFO     Training average negative_sample_loss at step 50100: 0.113295
2025-12-13 00:33:54,058 INFO     Training average loss at step 50100: 0.396220
2025-12-13 00:33:56,224 INFO     Training average regularization at step 50200: 0.305085
2025-12-13 00:33:56,225 INFO     Training average positive_sample_loss at step 50200: 0.068207
2025-12-13 00:33:56,225 INFO     Training average negative_sample_loss at step 50200: 0.109233
2025-12-13 00:33:56,225 INFO     Training average loss at step 50200: 0.393805
2025-12-13 00:33:58,385 INFO     Training average regularization at step 50300: 0.305076
2025-12-13 00:33:58,385 INFO     Training average positive_sample_loss at step 50300: 0.068074
2025-12-13 00:33:58,385 INFO     Training average negative_sample_loss at step 50300: 0.107228
2025-12-13 00:33:58,385 INFO     Training average loss at step 50300: 0.392728
2025-12-13 00:34:00,540 INFO     Training average regularization at step 50400: 0.305067
2025-12-13 00:34:00,540 INFO     Training average positive_sample_loss at step 50400: 0.067419
2025-12-13 00:34:00,540 INFO     Training average negative_sample_loss at step 50400: 0.108102
2025-12-13 00:34:00,540 INFO     Training average loss at step 50400: 0.392828
2025-12-13 00:34:02,709 INFO     Training average regularization at step 50500: 0.305057
2025-12-13 00:34:02,709 INFO     Training average positive_sample_loss at step 50500: 0.068686
2025-12-13 00:34:02,710 INFO     Training average negative_sample_loss at step 50500: 0.109205
2025-12-13 00:34:02,710 INFO     Training average loss at step 50500: 0.394002
2025-12-13 00:34:04,912 INFO     Training average regularization at step 50600: 0.305047
2025-12-13 00:34:04,912 INFO     Training average positive_sample_loss at step 50600: 0.067519
2025-12-13 00:34:04,912 INFO     Training average negative_sample_loss at step 50600: 0.111870
2025-12-13 00:34:04,912 INFO     Training average loss at step 50600: 0.394742
2025-12-13 00:34:07,109 INFO     Training average regularization at step 50700: 0.305038
2025-12-13 00:34:07,109 INFO     Training average positive_sample_loss at step 50700: 0.068343
2025-12-13 00:34:07,109 INFO     Training average negative_sample_loss at step 50700: 0.109473
2025-12-13 00:34:07,109 INFO     Training average loss at step 50700: 0.393946
2025-12-13 00:34:09,257 INFO     Training average regularization at step 50800: 0.305028
2025-12-13 00:34:09,258 INFO     Training average positive_sample_loss at step 50800: 0.067151
2025-12-13 00:34:09,258 INFO     Training average negative_sample_loss at step 50800: 0.108858
2025-12-13 00:34:09,258 INFO     Training average loss at step 50800: 0.393033
2025-12-13 00:34:11,419 INFO     Training average regularization at step 50900: 0.305018
2025-12-13 00:34:11,420 INFO     Training average positive_sample_loss at step 50900: 0.067678
2025-12-13 00:34:11,420 INFO     Training average negative_sample_loss at step 50900: 0.104945
2025-12-13 00:34:11,420 INFO     Training average loss at step 50900: 0.391330
2025-12-13 00:34:13,577 INFO     Training average regularization at step 51000: 0.305012
2025-12-13 00:34:13,578 INFO     Training average positive_sample_loss at step 51000: 0.069597
2025-12-13 00:34:13,578 INFO     Training average negative_sample_loss at step 51000: 0.109380
2025-12-13 00:34:13,578 INFO     Training average loss at step 51000: 0.394500
2025-12-13 00:34:15,741 INFO     Training average regularization at step 51100: 0.305004
2025-12-13 00:34:15,741 INFO     Training average positive_sample_loss at step 51100: 0.068171
2025-12-13 00:34:15,741 INFO     Training average negative_sample_loss at step 51100: 0.108595
2025-12-13 00:34:15,741 INFO     Training average loss at step 51100: 0.393387
2025-12-13 00:34:17,866 INFO     Training average regularization at step 51200: 0.304995
2025-12-13 00:34:17,866 INFO     Training average positive_sample_loss at step 51200: 0.067761
2025-12-13 00:34:17,866 INFO     Training average negative_sample_loss at step 51200: 0.107206
2025-12-13 00:34:17,866 INFO     Training average loss at step 51200: 0.392479
2025-12-13 00:34:20,024 INFO     Training average regularization at step 51300: 0.304986
2025-12-13 00:34:20,024 INFO     Training average positive_sample_loss at step 51300: 0.067773
2025-12-13 00:34:20,024 INFO     Training average negative_sample_loss at step 51300: 0.107213
2025-12-13 00:34:20,024 INFO     Training average loss at step 51300: 0.392479
2025-12-13 00:34:22,145 INFO     Training average regularization at step 51400: 0.304977
2025-12-13 00:34:22,145 INFO     Training average positive_sample_loss at step 51400: 0.068435
2025-12-13 00:34:22,145 INFO     Training average negative_sample_loss at step 51400: 0.107366
2025-12-13 00:34:22,145 INFO     Training average loss at step 51400: 0.392877
2025-12-13 00:34:24,288 INFO     Training average regularization at step 51500: 0.304969
2025-12-13 00:34:24,288 INFO     Training average positive_sample_loss at step 51500: 0.068160
2025-12-13 00:34:24,288 INFO     Training average negative_sample_loss at step 51500: 0.109134
2025-12-13 00:34:24,288 INFO     Training average loss at step 51500: 0.393616
2025-12-13 00:34:26,478 INFO     Training average regularization at step 51600: 0.304960
2025-12-13 00:34:26,478 INFO     Training average positive_sample_loss at step 51600: 0.068630
2025-12-13 00:34:26,478 INFO     Training average negative_sample_loss at step 51600: 0.106326
2025-12-13 00:34:26,478 INFO     Training average loss at step 51600: 0.392438
2025-12-13 00:34:28,625 INFO     Training average regularization at step 51700: 0.304952
2025-12-13 00:34:28,625 INFO     Training average positive_sample_loss at step 51700: 0.068097
2025-12-13 00:34:28,625 INFO     Training average negative_sample_loss at step 51700: 0.109917
2025-12-13 00:34:28,625 INFO     Training average loss at step 51700: 0.393959
2025-12-13 00:34:30,777 INFO     Training average regularization at step 51800: 0.304942
2025-12-13 00:34:30,777 INFO     Training average positive_sample_loss at step 51800: 0.068067
2025-12-13 00:34:30,777 INFO     Training average negative_sample_loss at step 51800: 0.108322
2025-12-13 00:34:30,777 INFO     Training average loss at step 51800: 0.393137
2025-12-13 00:34:32,917 INFO     Training average regularization at step 51900: 0.304934
2025-12-13 00:34:32,917 INFO     Training average positive_sample_loss at step 51900: 0.068062
2025-12-13 00:34:32,917 INFO     Training average negative_sample_loss at step 51900: 0.108215
2025-12-13 00:34:32,917 INFO     Training average loss at step 51900: 0.393073
2025-12-13 00:34:35,068 INFO     Training average regularization at step 52000: 0.304925
2025-12-13 00:34:35,068 INFO     Training average positive_sample_loss at step 52000: 0.068396
2025-12-13 00:34:35,068 INFO     Training average negative_sample_loss at step 52000: 0.107275
2025-12-13 00:34:35,068 INFO     Training average loss at step 52000: 0.392761
2025-12-13 00:34:37,303 INFO     Training average regularization at step 52100: 0.304917
2025-12-13 00:34:37,303 INFO     Training average positive_sample_loss at step 52100: 0.068787
2025-12-13 00:34:37,303 INFO     Training average negative_sample_loss at step 52100: 0.108227
2025-12-13 00:34:37,303 INFO     Training average loss at step 52100: 0.393424
2025-12-13 00:34:39,490 INFO     Training average regularization at step 52200: 0.304909
2025-12-13 00:34:39,490 INFO     Training average positive_sample_loss at step 52200: 0.068171
2025-12-13 00:34:39,490 INFO     Training average negative_sample_loss at step 52200: 0.108166
2025-12-13 00:34:39,490 INFO     Training average loss at step 52200: 0.393078
2025-12-13 00:34:41,706 INFO     Training average regularization at step 52300: 0.304902
2025-12-13 00:34:41,706 INFO     Training average positive_sample_loss at step 52300: 0.069406
2025-12-13 00:34:41,706 INFO     Training average negative_sample_loss at step 52300: 0.108663
2025-12-13 00:34:41,706 INFO     Training average loss at step 52300: 0.393936
2025-12-13 00:34:43,886 INFO     Training average regularization at step 52400: 0.304893
2025-12-13 00:34:43,886 INFO     Training average positive_sample_loss at step 52400: 0.068514
2025-12-13 00:34:43,886 INFO     Training average negative_sample_loss at step 52400: 0.108304
2025-12-13 00:34:43,886 INFO     Training average loss at step 52400: 0.393302
2025-12-13 00:34:46,052 INFO     Training average regularization at step 52500: 0.304885
2025-12-13 00:34:46,052 INFO     Training average positive_sample_loss at step 52500: 0.069249
2025-12-13 00:34:46,052 INFO     Training average negative_sample_loss at step 52500: 0.110364
2025-12-13 00:34:46,052 INFO     Training average loss at step 52500: 0.394692
2025-12-13 00:34:48,234 INFO     Training average regularization at step 52600: 0.304878
2025-12-13 00:34:48,235 INFO     Training average positive_sample_loss at step 52600: 0.068912
2025-12-13 00:34:48,235 INFO     Training average negative_sample_loss at step 52600: 0.109662
2025-12-13 00:34:48,235 INFO     Training average loss at step 52600: 0.394165
2025-12-13 00:34:50,372 INFO     Training average regularization at step 52700: 0.304870
2025-12-13 00:34:50,372 INFO     Training average positive_sample_loss at step 52700: 0.068589
2025-12-13 00:34:50,372 INFO     Training average negative_sample_loss at step 52700: 0.108301
2025-12-13 00:34:50,372 INFO     Training average loss at step 52700: 0.393315
2025-12-13 00:34:52,484 INFO     Training average regularization at step 52800: 0.304862
2025-12-13 00:34:52,484 INFO     Training average positive_sample_loss at step 52800: 0.067935
2025-12-13 00:34:52,484 INFO     Training average negative_sample_loss at step 52800: 0.107634
2025-12-13 00:34:52,484 INFO     Training average loss at step 52800: 0.392646
2025-12-13 00:34:54,623 INFO     Training average regularization at step 52900: 0.304854
2025-12-13 00:34:54,624 INFO     Training average positive_sample_loss at step 52900: 0.068485
2025-12-13 00:34:54,624 INFO     Training average negative_sample_loss at step 52900: 0.110234
2025-12-13 00:34:54,624 INFO     Training average loss at step 52900: 0.394214
2025-12-13 00:34:56,773 INFO     Training average regularization at step 53000: 0.304847
2025-12-13 00:34:56,773 INFO     Training average positive_sample_loss at step 53000: 0.069556
2025-12-13 00:34:56,773 INFO     Training average negative_sample_loss at step 53000: 0.108130
2025-12-13 00:34:56,773 INFO     Training average loss at step 53000: 0.393690
2025-12-13 00:34:58,944 INFO     Training average regularization at step 53100: 0.304839
2025-12-13 00:34:58,944 INFO     Training average positive_sample_loss at step 53100: 0.067904
2025-12-13 00:34:58,944 INFO     Training average negative_sample_loss at step 53100: 0.109218
2025-12-13 00:34:58,944 INFO     Training average loss at step 53100: 0.393400
2025-12-13 00:35:02,057 INFO     Training average regularization at step 53200: 0.304829
2025-12-13 00:35:02,057 INFO     Training average positive_sample_loss at step 53200: 0.067663
2025-12-13 00:35:02,057 INFO     Training average negative_sample_loss at step 53200: 0.107850
2025-12-13 00:35:02,057 INFO     Training average loss at step 53200: 0.392585
2025-12-13 00:35:04,186 INFO     Training average regularization at step 53300: 0.304818
2025-12-13 00:35:04,187 INFO     Training average positive_sample_loss at step 53300: 0.067036
2025-12-13 00:35:04,187 INFO     Training average negative_sample_loss at step 53300: 0.107959
2025-12-13 00:35:04,187 INFO     Training average loss at step 53300: 0.392316
2025-12-13 00:35:06,320 INFO     Training average regularization at step 53400: 0.304808
2025-12-13 00:35:06,320 INFO     Training average positive_sample_loss at step 53400: 0.066519
2025-12-13 00:35:06,320 INFO     Training average negative_sample_loss at step 53400: 0.110932
2025-12-13 00:35:06,320 INFO     Training average loss at step 53400: 0.393533
2025-12-13 00:35:08,456 INFO     Training average regularization at step 53500: 0.304798
2025-12-13 00:35:08,456 INFO     Training average positive_sample_loss at step 53500: 0.066704
2025-12-13 00:35:08,456 INFO     Training average negative_sample_loss at step 53500: 0.107601
2025-12-13 00:35:08,456 INFO     Training average loss at step 53500: 0.391950
2025-12-13 00:35:10,633 INFO     Training average regularization at step 53600: 0.304787
2025-12-13 00:35:10,644 INFO     Training average positive_sample_loss at step 53600: 0.066160
2025-12-13 00:35:10,644 INFO     Training average negative_sample_loss at step 53600: 0.108135
2025-12-13 00:35:10,644 INFO     Training average loss at step 53600: 0.391935
2025-12-13 00:35:12,734 INFO     Training average regularization at step 53700: 0.304776
2025-12-13 00:35:12,734 INFO     Training average positive_sample_loss at step 53700: 0.066751
2025-12-13 00:35:12,734 INFO     Training average negative_sample_loss at step 53700: 0.107132
2025-12-13 00:35:12,734 INFO     Training average loss at step 53700: 0.391718
2025-12-13 00:35:14,854 INFO     Training average regularization at step 53800: 0.304765
2025-12-13 00:35:14,855 INFO     Training average positive_sample_loss at step 53800: 0.067398
2025-12-13 00:35:14,855 INFO     Training average negative_sample_loss at step 53800: 0.108371
2025-12-13 00:35:14,855 INFO     Training average loss at step 53800: 0.392650
2025-12-13 00:35:16,966 INFO     Training average regularization at step 53900: 0.304756
2025-12-13 00:35:16,966 INFO     Training average positive_sample_loss at step 53900: 0.068277
2025-12-13 00:35:16,966 INFO     Training average negative_sample_loss at step 53900: 0.109176
2025-12-13 00:35:16,966 INFO     Training average loss at step 53900: 0.393482
2025-12-13 00:35:19,069 INFO     Training average regularization at step 54000: 0.304746
2025-12-13 00:35:19,069 INFO     Training average positive_sample_loss at step 54000: 0.065972
2025-12-13 00:35:19,069 INFO     Training average negative_sample_loss at step 54000: 0.107283
2025-12-13 00:35:19,069 INFO     Training average loss at step 54000: 0.391373
2025-12-13 00:35:21,212 INFO     Training average regularization at step 54100: 0.304735
2025-12-13 00:35:21,213 INFO     Training average positive_sample_loss at step 54100: 0.067416
2025-12-13 00:35:21,213 INFO     Training average negative_sample_loss at step 54100: 0.109117
2025-12-13 00:35:21,213 INFO     Training average loss at step 54100: 0.393002
2025-12-13 00:35:23,328 INFO     Training average regularization at step 54200: 0.304725
2025-12-13 00:35:23,329 INFO     Training average positive_sample_loss at step 54200: 0.066898
2025-12-13 00:35:23,329 INFO     Training average negative_sample_loss at step 54200: 0.107129
2025-12-13 00:35:23,329 INFO     Training average loss at step 54200: 0.391739
2025-12-13 00:35:25,469 INFO     Training average regularization at step 54300: 0.304717
2025-12-13 00:35:25,469 INFO     Training average positive_sample_loss at step 54300: 0.067129
2025-12-13 00:35:25,469 INFO     Training average negative_sample_loss at step 54300: 0.108076
2025-12-13 00:35:25,470 INFO     Training average loss at step 54300: 0.392319
2025-12-13 00:35:27,615 INFO     Training average regularization at step 54400: 0.304707
2025-12-13 00:35:27,616 INFO     Training average positive_sample_loss at step 54400: 0.066984
2025-12-13 00:35:27,616 INFO     Training average negative_sample_loss at step 54400: 0.110814
2025-12-13 00:35:27,616 INFO     Training average loss at step 54400: 0.393606
2025-12-13 00:35:29,718 INFO     Training average regularization at step 54500: 0.304697
2025-12-13 00:35:29,718 INFO     Training average positive_sample_loss at step 54500: 0.067543
2025-12-13 00:35:29,718 INFO     Training average negative_sample_loss at step 54500: 0.107385
2025-12-13 00:35:29,718 INFO     Training average loss at step 54500: 0.392161
2025-12-13 00:35:31,833 INFO     Training average regularization at step 54600: 0.304688
2025-12-13 00:35:31,833 INFO     Training average positive_sample_loss at step 54600: 0.067373
2025-12-13 00:35:31,833 INFO     Training average negative_sample_loss at step 54600: 0.109950
2025-12-13 00:35:31,833 INFO     Training average loss at step 54600: 0.393350
2025-12-13 00:35:33,937 INFO     Training average regularization at step 54700: 0.304679
2025-12-13 00:35:33,937 INFO     Training average positive_sample_loss at step 54700: 0.068405
2025-12-13 00:35:33,937 INFO     Training average negative_sample_loss at step 54700: 0.110366
2025-12-13 00:35:33,937 INFO     Training average loss at step 54700: 0.394065
2025-12-13 00:35:36,099 INFO     Training average regularization at step 54800: 0.304671
2025-12-13 00:35:36,100 INFO     Training average positive_sample_loss at step 54800: 0.067343
2025-12-13 00:35:36,100 INFO     Training average negative_sample_loss at step 54800: 0.111075
2025-12-13 00:35:36,100 INFO     Training average loss at step 54800: 0.393880
2025-12-13 00:35:38,296 INFO     Training average regularization at step 54900: 0.304661
2025-12-13 00:35:38,297 INFO     Training average positive_sample_loss at step 54900: 0.067335
2025-12-13 00:35:38,297 INFO     Training average negative_sample_loss at step 54900: 0.109355
2025-12-13 00:35:38,297 INFO     Training average loss at step 54900: 0.393006
2025-12-13 00:35:40,458 INFO     Training average regularization at step 55000: 0.304652
2025-12-13 00:35:40,459 INFO     Training average positive_sample_loss at step 55000: 0.067303
2025-12-13 00:35:40,459 INFO     Training average negative_sample_loss at step 55000: 0.107189
2025-12-13 00:35:40,459 INFO     Training average loss at step 55000: 0.391898
2025-12-13 00:35:42,634 INFO     Training average regularization at step 55100: 0.304644
2025-12-13 00:35:42,634 INFO     Training average positive_sample_loss at step 55100: 0.067741
2025-12-13 00:35:42,634 INFO     Training average negative_sample_loss at step 55100: 0.108048
2025-12-13 00:35:42,634 INFO     Training average loss at step 55100: 0.392538
2025-12-13 00:35:44,792 INFO     Training average regularization at step 55200: 0.304636
2025-12-13 00:35:44,792 INFO     Training average positive_sample_loss at step 55200: 0.067344
2025-12-13 00:35:44,792 INFO     Training average negative_sample_loss at step 55200: 0.109628
2025-12-13 00:35:44,792 INFO     Training average loss at step 55200: 0.393122
2025-12-13 00:35:46,957 INFO     Training average regularization at step 55300: 0.304628
2025-12-13 00:35:46,958 INFO     Training average positive_sample_loss at step 55300: 0.067104
2025-12-13 00:35:46,958 INFO     Training average negative_sample_loss at step 55300: 0.108651
2025-12-13 00:35:46,958 INFO     Training average loss at step 55300: 0.392505
2025-12-13 00:35:49,076 INFO     Training average regularization at step 55400: 0.304620
2025-12-13 00:35:49,076 INFO     Training average positive_sample_loss at step 55400: 0.067021
2025-12-13 00:35:49,076 INFO     Training average negative_sample_loss at step 55400: 0.110443
2025-12-13 00:35:49,076 INFO     Training average loss at step 55400: 0.393352
2025-12-13 00:35:51,173 INFO     Training average regularization at step 55500: 0.304610
2025-12-13 00:35:51,173 INFO     Training average positive_sample_loss at step 55500: 0.067262
2025-12-13 00:35:51,173 INFO     Training average negative_sample_loss at step 55500: 0.109335
2025-12-13 00:35:51,173 INFO     Training average loss at step 55500: 0.392909
2025-12-13 00:35:53,254 INFO     Training average regularization at step 55600: 0.304601
2025-12-13 00:35:53,254 INFO     Training average positive_sample_loss at step 55600: 0.066696
2025-12-13 00:35:53,254 INFO     Training average negative_sample_loss at step 55600: 0.108132
2025-12-13 00:35:53,254 INFO     Training average loss at step 55600: 0.392015
2025-12-13 00:35:55,398 INFO     Training average regularization at step 55700: 0.304593
2025-12-13 00:35:55,398 INFO     Training average positive_sample_loss at step 55700: 0.068149
2025-12-13 00:35:55,398 INFO     Training average negative_sample_loss at step 55700: 0.108398
2025-12-13 00:35:55,398 INFO     Training average loss at step 55700: 0.392866
2025-12-13 00:35:57,485 INFO     Training average regularization at step 55800: 0.304585
2025-12-13 00:35:57,485 INFO     Training average positive_sample_loss at step 55800: 0.067410
2025-12-13 00:35:57,485 INFO     Training average negative_sample_loss at step 55800: 0.108961
2025-12-13 00:35:57,485 INFO     Training average loss at step 55800: 0.392771
2025-12-13 00:35:59,595 INFO     Training average regularization at step 55900: 0.304578
2025-12-13 00:35:59,596 INFO     Training average positive_sample_loss at step 55900: 0.068889
2025-12-13 00:35:59,596 INFO     Training average negative_sample_loss at step 55900: 0.108176
2025-12-13 00:35:59,596 INFO     Training average loss at step 55900: 0.393111
2025-12-13 00:36:01,715 INFO     Training average regularization at step 56000: 0.304570
2025-12-13 00:36:01,715 INFO     Training average positive_sample_loss at step 56000: 0.067361
2025-12-13 00:36:01,715 INFO     Training average negative_sample_loss at step 56000: 0.109253
2025-12-13 00:36:01,715 INFO     Training average loss at step 56000: 0.392877
2025-12-13 00:36:03,842 INFO     Training average regularization at step 56100: 0.304562
2025-12-13 00:36:03,842 INFO     Training average positive_sample_loss at step 56100: 0.067159
2025-12-13 00:36:03,842 INFO     Training average negative_sample_loss at step 56100: 0.108115
2025-12-13 00:36:03,842 INFO     Training average loss at step 56100: 0.392198
2025-12-13 00:36:05,979 INFO     Training average regularization at step 56200: 0.304553
2025-12-13 00:36:05,980 INFO     Training average positive_sample_loss at step 56200: 0.066594
2025-12-13 00:36:05,980 INFO     Training average negative_sample_loss at step 56200: 0.109514
2025-12-13 00:36:05,980 INFO     Training average loss at step 56200: 0.392607
2025-12-13 00:36:08,124 INFO     Training average regularization at step 56300: 0.304544
2025-12-13 00:36:08,124 INFO     Training average positive_sample_loss at step 56300: 0.068238
2025-12-13 00:36:08,124 INFO     Training average negative_sample_loss at step 56300: 0.108259
2025-12-13 00:36:08,125 INFO     Training average loss at step 56300: 0.392793
2025-12-13 00:36:10,248 INFO     Training average regularization at step 56400: 0.304537
2025-12-13 00:36:10,249 INFO     Training average positive_sample_loss at step 56400: 0.068233
2025-12-13 00:36:10,249 INFO     Training average negative_sample_loss at step 56400: 0.108632
2025-12-13 00:36:10,249 INFO     Training average loss at step 56400: 0.392970
2025-12-13 00:36:12,373 INFO     Training average regularization at step 56500: 0.304531
2025-12-13 00:36:12,373 INFO     Training average positive_sample_loss at step 56500: 0.068263
2025-12-13 00:36:12,373 INFO     Training average negative_sample_loss at step 56500: 0.109263
2025-12-13 00:36:12,373 INFO     Training average loss at step 56500: 0.393294
2025-12-13 00:36:14,484 INFO     Training average regularization at step 56600: 0.304524
2025-12-13 00:36:14,484 INFO     Training average positive_sample_loss at step 56600: 0.067401
2025-12-13 00:36:14,485 INFO     Training average negative_sample_loss at step 56600: 0.108329
2025-12-13 00:36:14,485 INFO     Training average loss at step 56600: 0.392389
2025-12-13 00:36:16,642 INFO     Training average regularization at step 56700: 0.304516
2025-12-13 00:36:16,645 INFO     Training average positive_sample_loss at step 56700: 0.067255
2025-12-13 00:36:16,645 INFO     Training average negative_sample_loss at step 56700: 0.107623
2025-12-13 00:36:16,645 INFO     Training average loss at step 56700: 0.391955
2025-12-13 00:36:18,754 INFO     Training average regularization at step 56800: 0.304508
2025-12-13 00:36:18,755 INFO     Training average positive_sample_loss at step 56800: 0.067771
2025-12-13 00:36:18,755 INFO     Training average negative_sample_loss at step 56800: 0.107085
2025-12-13 00:36:18,755 INFO     Training average loss at step 56800: 0.391936
2025-12-13 00:36:20,887 INFO     Training average regularization at step 56900: 0.304501
2025-12-13 00:36:20,887 INFO     Training average positive_sample_loss at step 56900: 0.068707
2025-12-13 00:36:20,887 INFO     Training average negative_sample_loss at step 56900: 0.108044
2025-12-13 00:36:20,887 INFO     Training average loss at step 56900: 0.392877
2025-12-13 00:36:22,994 INFO     Training average regularization at step 57000: 0.304494
2025-12-13 00:36:22,994 INFO     Training average positive_sample_loss at step 57000: 0.067337
2025-12-13 00:36:22,994 INFO     Training average negative_sample_loss at step 57000: 0.108994
2025-12-13 00:36:22,994 INFO     Training average loss at step 57000: 0.392659
2025-12-13 00:36:25,093 INFO     Training average regularization at step 57100: 0.304485
2025-12-13 00:36:25,093 INFO     Training average positive_sample_loss at step 57100: 0.067579
2025-12-13 00:36:25,093 INFO     Training average negative_sample_loss at step 57100: 0.107131
2025-12-13 00:36:25,093 INFO     Training average loss at step 57100: 0.391840
2025-12-13 00:36:27,251 INFO     Training average regularization at step 57200: 0.304476
2025-12-13 00:36:27,251 INFO     Training average positive_sample_loss at step 57200: 0.069297
2025-12-13 00:36:27,251 INFO     Training average negative_sample_loss at step 57200: 0.110742
2025-12-13 00:36:27,252 INFO     Training average loss at step 57200: 0.394495
2025-12-13 00:36:29,363 INFO     Training average regularization at step 57300: 0.304469
2025-12-13 00:36:29,364 INFO     Training average positive_sample_loss at step 57300: 0.067763
2025-12-13 00:36:29,364 INFO     Training average negative_sample_loss at step 57300: 0.106629
2025-12-13 00:36:29,364 INFO     Training average loss at step 57300: 0.391665
2025-12-13 00:36:31,466 INFO     Training average regularization at step 57400: 0.304461
2025-12-13 00:36:31,466 INFO     Training average positive_sample_loss at step 57400: 0.067683
2025-12-13 00:36:31,466 INFO     Training average negative_sample_loss at step 57400: 0.106925
2025-12-13 00:36:31,466 INFO     Training average loss at step 57400: 0.391765
2025-12-13 00:36:33,572 INFO     Training average regularization at step 57500: 0.304454
2025-12-13 00:36:33,572 INFO     Training average positive_sample_loss at step 57500: 0.069515
2025-12-13 00:36:33,572 INFO     Training average negative_sample_loss at step 57500: 0.107674
2025-12-13 00:36:33,572 INFO     Training average loss at step 57500: 0.393049
2025-12-13 00:36:35,699 INFO     Training average regularization at step 57600: 0.304447
2025-12-13 00:36:35,699 INFO     Training average positive_sample_loss at step 57600: 0.067690
2025-12-13 00:36:35,699 INFO     Training average negative_sample_loss at step 57600: 0.107763
2025-12-13 00:36:35,699 INFO     Training average loss at step 57600: 0.392174
2025-12-13 00:36:37,912 INFO     Training average regularization at step 57700: 0.304439
2025-12-13 00:36:37,912 INFO     Training average positive_sample_loss at step 57700: 0.067827
2025-12-13 00:36:37,912 INFO     Training average negative_sample_loss at step 57700: 0.109201
2025-12-13 00:36:37,912 INFO     Training average loss at step 57700: 0.392953
2025-12-13 00:36:40,043 INFO     Training average regularization at step 57800: 0.304429
2025-12-13 00:36:40,043 INFO     Training average positive_sample_loss at step 57800: 0.066871
2025-12-13 00:36:40,043 INFO     Training average negative_sample_loss at step 57800: 0.109224
2025-12-13 00:36:40,043 INFO     Training average loss at step 57800: 0.392477
2025-12-13 00:36:42,198 INFO     Training average regularization at step 57900: 0.304420
2025-12-13 00:36:42,199 INFO     Training average positive_sample_loss at step 57900: 0.068134
2025-12-13 00:36:42,199 INFO     Training average negative_sample_loss at step 57900: 0.110276
2025-12-13 00:36:42,199 INFO     Training average loss at step 57900: 0.393625
2025-12-13 00:36:45,566 INFO     Training average regularization at step 58000: 0.304413
2025-12-13 00:36:45,566 INFO     Training average positive_sample_loss at step 58000: 0.068977
2025-12-13 00:36:45,567 INFO     Training average negative_sample_loss at step 58000: 0.109540
2025-12-13 00:36:45,567 INFO     Training average loss at step 58000: 0.393671
2025-12-13 00:36:47,744 INFO     Training average regularization at step 58100: 0.304405
2025-12-13 00:36:47,745 INFO     Training average positive_sample_loss at step 58100: 0.066592
2025-12-13 00:36:47,745 INFO     Training average negative_sample_loss at step 58100: 0.108916
2025-12-13 00:36:47,745 INFO     Training average loss at step 58100: 0.392159
2025-12-13 00:36:49,951 INFO     Training average regularization at step 58200: 0.304395
2025-12-13 00:36:49,951 INFO     Training average positive_sample_loss at step 58200: 0.066613
2025-12-13 00:36:49,951 INFO     Training average negative_sample_loss at step 58200: 0.105751
2025-12-13 00:36:49,951 INFO     Training average loss at step 58200: 0.390577
2025-12-13 00:36:52,110 INFO     Training average regularization at step 58300: 0.304388
2025-12-13 00:36:52,110 INFO     Training average positive_sample_loss at step 58300: 0.067413
2025-12-13 00:36:52,110 INFO     Training average negative_sample_loss at step 58300: 0.106632
2025-12-13 00:36:52,110 INFO     Training average loss at step 58300: 0.391411
2025-12-13 00:36:54,229 INFO     Training average regularization at step 58400: 0.304380
2025-12-13 00:36:54,230 INFO     Training average positive_sample_loss at step 58400: 0.067168
2025-12-13 00:36:54,230 INFO     Training average negative_sample_loss at step 58400: 0.107559
2025-12-13 00:36:54,230 INFO     Training average loss at step 58400: 0.391743
2025-12-13 00:36:56,329 INFO     Training average regularization at step 58500: 0.304372
2025-12-13 00:36:56,330 INFO     Training average positive_sample_loss at step 58500: 0.067548
2025-12-13 00:36:56,330 INFO     Training average negative_sample_loss at step 58500: 0.108993
2025-12-13 00:36:56,330 INFO     Training average loss at step 58500: 0.392643
2025-12-13 00:36:58,453 INFO     Training average regularization at step 58600: 0.304365
2025-12-13 00:36:58,453 INFO     Training average positive_sample_loss at step 58600: 0.066221
2025-12-13 00:36:58,453 INFO     Training average negative_sample_loss at step 58600: 0.109019
2025-12-13 00:36:58,453 INFO     Training average loss at step 58600: 0.391985
2025-12-13 00:37:00,589 INFO     Training average regularization at step 58700: 0.304355
2025-12-13 00:37:00,589 INFO     Training average positive_sample_loss at step 58700: 0.066600
2025-12-13 00:37:00,589 INFO     Training average negative_sample_loss at step 58700: 0.110022
2025-12-13 00:37:00,589 INFO     Training average loss at step 58700: 0.392666
2025-12-13 00:37:02,678 INFO     Training average regularization at step 58800: 0.304346
2025-12-13 00:37:02,678 INFO     Training average positive_sample_loss at step 58800: 0.066324
2025-12-13 00:37:02,678 INFO     Training average negative_sample_loss at step 58800: 0.108632
2025-12-13 00:37:02,678 INFO     Training average loss at step 58800: 0.391824
2025-12-13 00:37:04,765 INFO     Training average regularization at step 58900: 0.304336
2025-12-13 00:37:04,765 INFO     Training average positive_sample_loss at step 58900: 0.066778
2025-12-13 00:37:04,765 INFO     Training average negative_sample_loss at step 58900: 0.106254
2025-12-13 00:37:04,765 INFO     Training average loss at step 58900: 0.390851
2025-12-13 00:37:06,908 INFO     Training average regularization at step 59000: 0.304327
2025-12-13 00:37:06,929 INFO     Training average positive_sample_loss at step 59000: 0.067468
2025-12-13 00:37:06,929 INFO     Training average negative_sample_loss at step 59000: 0.110197
2025-12-13 00:37:06,929 INFO     Training average loss at step 59000: 0.393160
2025-12-13 00:37:09,017 INFO     Training average regularization at step 59100: 0.304319
2025-12-13 00:37:09,017 INFO     Training average positive_sample_loss at step 59100: 0.066087
2025-12-13 00:37:09,017 INFO     Training average negative_sample_loss at step 59100: 0.108382
2025-12-13 00:37:09,017 INFO     Training average loss at step 59100: 0.391554
2025-12-13 00:37:11,172 INFO     Training average regularization at step 59200: 0.304310
2025-12-13 00:37:11,181 INFO     Training average positive_sample_loss at step 59200: 0.065960
2025-12-13 00:37:11,181 INFO     Training average negative_sample_loss at step 59200: 0.108145
2025-12-13 00:37:11,181 INFO     Training average loss at step 59200: 0.391362
2025-12-13 00:37:13,290 INFO     Training average regularization at step 59300: 0.304300
2025-12-13 00:37:13,290 INFO     Training average positive_sample_loss at step 59300: 0.066424
2025-12-13 00:37:13,290 INFO     Training average negative_sample_loss at step 59300: 0.108630
2025-12-13 00:37:13,290 INFO     Training average loss at step 59300: 0.391827
2025-12-13 00:37:15,406 INFO     Training average regularization at step 59400: 0.304291
2025-12-13 00:37:15,406 INFO     Training average positive_sample_loss at step 59400: 0.067436
2025-12-13 00:37:15,406 INFO     Training average negative_sample_loss at step 59400: 0.108121
2025-12-13 00:37:15,406 INFO     Training average loss at step 59400: 0.392069
2025-12-13 00:37:17,559 INFO     Training average regularization at step 59500: 0.304283
2025-12-13 00:37:17,560 INFO     Training average positive_sample_loss at step 59500: 0.068704
2025-12-13 00:37:17,560 INFO     Training average negative_sample_loss at step 59500: 0.109961
2025-12-13 00:37:17,560 INFO     Training average loss at step 59500: 0.393615
2025-12-13 00:37:19,660 INFO     Training average regularization at step 59600: 0.304276
2025-12-13 00:37:19,661 INFO     Training average positive_sample_loss at step 59600: 0.066767
2025-12-13 00:37:19,661 INFO     Training average negative_sample_loss at step 59600: 0.107650
2025-12-13 00:37:19,661 INFO     Training average loss at step 59600: 0.391484
2025-12-13 00:37:21,777 INFO     Training average regularization at step 59700: 0.304267
2025-12-13 00:37:21,778 INFO     Training average positive_sample_loss at step 59700: 0.066270
2025-12-13 00:37:21,778 INFO     Training average negative_sample_loss at step 59700: 0.109260
2025-12-13 00:37:21,778 INFO     Training average loss at step 59700: 0.392032
2025-12-13 00:37:23,861 INFO     Training average regularization at step 59800: 0.304258
2025-12-13 00:37:23,861 INFO     Training average positive_sample_loss at step 59800: 0.065479
2025-12-13 00:37:23,861 INFO     Training average negative_sample_loss at step 59800: 0.108151
2025-12-13 00:37:23,861 INFO     Training average loss at step 59800: 0.391073
2025-12-13 00:37:25,970 INFO     Training average regularization at step 59900: 0.304249
2025-12-13 00:37:25,970 INFO     Training average positive_sample_loss at step 59900: 0.066831
2025-12-13 00:37:25,970 INFO     Training average negative_sample_loss at step 59900: 0.107450
2025-12-13 00:37:25,970 INFO     Training average loss at step 59900: 0.391389
2025-12-13 00:37:29,255 INFO     Training average regularization at step 60000: 0.304241
2025-12-13 00:37:29,255 INFO     Training average positive_sample_loss at step 60000: 0.067550
2025-12-13 00:37:29,255 INFO     Training average negative_sample_loss at step 60000: 0.107081
2025-12-13 00:37:29,255 INFO     Training average loss at step 60000: 0.391557
2025-12-13 00:37:29,256 INFO     Evaluating on Valid Dataset...
2025-12-13 00:37:29,900 INFO     Evaluating the model... (0/50000)
2025-12-13 00:37:32,430 INFO     Evaluating the model... (500/50000)
2025-12-13 00:37:35,176 INFO     Evaluating the model... (1000/50000)
2025-12-13 00:37:38,624 INFO     Evaluating the model... (1500/50000)
2025-12-13 00:37:41,360 INFO     Evaluating the model... (2000/50000)
2025-12-13 00:37:43,979 INFO     Evaluating the model... (2500/50000)
2025-12-13 00:37:46,687 INFO     Evaluating the model... (3000/50000)
2025-12-13 00:37:49,246 INFO     Evaluating the model... (3500/50000)
2025-12-13 00:37:52,363 INFO     Evaluating the model... (4000/50000)
2025-12-13 00:37:54,720 INFO     Evaluating the model... (4500/50000)
2025-12-13 00:37:57,365 INFO     Evaluating the model... (5000/50000)
2025-12-13 00:37:59,856 INFO     Evaluating the model... (5500/50000)
2025-12-13 00:38:02,333 INFO     Evaluating the model... (6000/50000)
2025-12-13 00:38:05,520 INFO     Evaluating the model... (6500/50000)
2025-12-13 00:38:08,053 INFO     Evaluating the model... (7000/50000)
2025-12-13 00:38:10,587 INFO     Evaluating the model... (7500/50000)
2025-12-13 00:38:13,044 INFO     Evaluating the model... (8000/50000)
2025-12-13 00:38:15,518 INFO     Evaluating the model... (8500/50000)
2025-12-13 00:38:18,644 INFO     Evaluating the model... (9000/50000)
2025-12-13 00:38:21,265 INFO     Evaluating the model... (9500/50000)
2025-12-13 00:38:23,740 INFO     Evaluating the model... (10000/50000)
2025-12-13 00:38:26,234 INFO     Evaluating the model... (10500/50000)
2025-12-13 00:38:28,601 INFO     Evaluating the model... (11000/50000)
2025-12-13 00:38:32,099 INFO     Evaluating the model... (11500/50000)
2025-12-13 00:38:34,551 INFO     Evaluating the model... (12000/50000)
2025-12-13 00:38:37,256 INFO     Evaluating the model... (12500/50000)
2025-12-13 00:38:39,823 INFO     Evaluating the model... (13000/50000)
2025-12-13 00:38:42,744 INFO     Evaluating the model... (13500/50000)
2025-12-13 00:38:46,098 INFO     Evaluating the model... (14000/50000)
2025-12-13 00:38:48,631 INFO     Evaluating the model... (14500/50000)
2025-12-13 00:38:51,017 INFO     Evaluating the model... (15000/50000)
2025-12-13 00:38:53,534 INFO     Evaluating the model... (15500/50000)
2025-12-13 00:38:56,207 INFO     Evaluating the model... (16000/50000)
2025-12-13 00:38:59,446 INFO     Evaluating the model... (16500/50000)
2025-12-13 00:39:01,936 INFO     Evaluating the model... (17000/50000)
2025-12-13 00:39:04,368 INFO     Evaluating the model... (17500/50000)
2025-12-13 00:39:07,116 INFO     Evaluating the model... (18000/50000)
2025-12-13 00:39:10,731 INFO     Evaluating the model... (18500/50000)
2025-12-13 00:39:13,120 INFO     Evaluating the model... (19000/50000)
2025-12-13 00:39:15,559 INFO     Evaluating the model... (19500/50000)
2025-12-13 00:39:18,135 INFO     Evaluating the model... (20000/50000)
2025-12-13 00:39:20,616 INFO     Evaluating the model... (20500/50000)
2025-12-13 00:39:24,132 INFO     Evaluating the model... (21000/50000)
2025-12-13 00:39:26,620 INFO     Evaluating the model... (21500/50000)
2025-12-13 00:39:29,250 INFO     Evaluating the model... (22000/50000)
2025-12-13 00:39:31,656 INFO     Evaluating the model... (22500/50000)
2025-12-13 00:39:34,021 INFO     Evaluating the model... (23000/50000)
2025-12-13 00:39:37,906 INFO     Evaluating the model... (23500/50000)
2025-12-13 00:39:40,792 INFO     Evaluating the model... (24000/50000)
2025-12-13 00:39:43,387 INFO     Evaluating the model... (24500/50000)
2025-12-13 00:39:46,459 INFO     Evaluating the model... (25000/50000)
2025-12-13 00:39:48,984 INFO     Evaluating the model... (25500/50000)
2025-12-13 00:39:52,795 INFO     Evaluating the model... (26000/50000)
2025-12-13 00:39:55,389 INFO     Evaluating the model... (26500/50000)
2025-12-13 00:39:57,996 INFO     Evaluating the model... (27000/50000)
2025-12-13 00:40:00,460 INFO     Evaluating the model... (27500/50000)
2025-12-13 00:40:03,030 INFO     Evaluating the model... (28000/50000)
2025-12-13 00:40:06,257 INFO     Evaluating the model... (28500/50000)
2025-12-13 00:40:08,688 INFO     Evaluating the model... (29000/50000)
2025-12-13 00:40:11,165 INFO     Evaluating the model... (29500/50000)
2025-12-13 00:40:13,747 INFO     Evaluating the model... (30000/50000)
2025-12-13 00:40:16,419 INFO     Evaluating the model... (30500/50000)
2025-12-13 00:40:19,586 INFO     Evaluating the model... (31000/50000)
2025-12-13 00:40:22,123 INFO     Evaluating the model... (31500/50000)
2025-12-13 00:40:24,643 INFO     Evaluating the model... (32000/50000)
2025-12-13 00:40:27,520 INFO     Evaluating the model... (32500/50000)
2025-12-13 00:40:30,061 INFO     Evaluating the model... (33000/50000)
2025-12-13 00:40:33,176 INFO     Evaluating the model... (33500/50000)
2025-12-13 00:40:35,744 INFO     Evaluating the model... (34000/50000)
2025-12-13 00:40:38,701 INFO     Evaluating the model... (34500/50000)
2025-12-13 00:40:41,396 INFO     Evaluating the model... (35000/50000)
2025-12-13 00:40:43,995 INFO     Evaluating the model... (35500/50000)
2025-12-13 00:40:47,202 INFO     Evaluating the model... (36000/50000)
2025-12-13 00:40:49,870 INFO     Evaluating the model... (36500/50000)
2025-12-13 00:40:52,405 INFO     Evaluating the model... (37000/50000)
2025-12-13 00:40:54,970 INFO     Evaluating the model... (37500/50000)
2025-12-13 00:40:57,659 INFO     Evaluating the model... (38000/50000)
2025-12-13 00:41:01,352 INFO     Evaluating the model... (38500/50000)
2025-12-13 00:41:03,810 INFO     Evaluating the model... (39000/50000)
2025-12-13 00:41:06,318 INFO     Evaluating the model... (39500/50000)
2025-12-13 00:41:08,736 INFO     Evaluating the model... (40000/50000)
2025-12-13 00:41:11,284 INFO     Evaluating the model... (40500/50000)
2025-12-13 00:41:14,491 INFO     Evaluating the model... (41000/50000)
2025-12-13 00:41:17,021 INFO     Evaluating the model... (41500/50000)
2025-12-13 00:41:19,519 INFO     Evaluating the model... (42000/50000)
2025-12-13 00:41:21,948 INFO     Evaluating the model... (42500/50000)
2025-12-13 00:41:24,730 INFO     Evaluating the model... (43000/50000)
2025-12-13 00:41:28,175 INFO     Evaluating the model... (43500/50000)
2025-12-13 00:41:30,731 INFO     Evaluating the model... (44000/50000)
2025-12-13 00:41:33,314 INFO     Evaluating the model... (44500/50000)
2025-12-13 00:41:36,247 INFO     Evaluating the model... (45000/50000)
2025-12-13 00:41:40,091 INFO     Evaluating the model... (45500/50000)
2025-12-13 00:41:42,891 INFO     Evaluating the model... (46000/50000)
2025-12-13 00:41:45,764 INFO     Evaluating the model... (46500/50000)
2025-12-13 00:41:48,419 INFO     Evaluating the model... (47000/50000)
2025-12-13 00:41:50,938 INFO     Evaluating the model... (47500/50000)
2025-12-13 00:41:54,865 INFO     Evaluating the model... (48000/50000)
2025-12-13 00:41:57,478 INFO     Evaluating the model... (48500/50000)
2025-12-13 00:42:00,240 INFO     Evaluating the model... (49000/50000)
2025-12-13 00:42:02,713 INFO     Evaluating the model... (49500/50000)
2025-12-13 00:42:05,591 INFO     Valid MRR at step 60000: 0.615771
2025-12-13 00:42:05,591 INFO     Valid MR at step 60000: 268.168890
2025-12-13 00:42:05,591 INFO     Valid HITS@1 at step 60000: 0.525170
2025-12-13 00:42:05,591 INFO     Valid HITS@3 at step 60000: 0.671470
2025-12-13 00:42:05,591 INFO     Valid HITS@10 at step 60000: 0.777010
2025-12-13 00:42:06,864 INFO     Evaluating on Test Dataset...
2025-12-13 00:42:07,411 INFO     Evaluating the model... (0/59072)
2025-12-13 00:42:10,265 INFO     Evaluating the model... (500/59072)
2025-12-13 00:42:13,784 INFO     Evaluating the model... (1000/59072)
2025-12-13 00:42:16,312 INFO     Evaluating the model... (1500/59072)
2025-12-13 00:42:18,907 INFO     Evaluating the model... (2000/59072)
2025-12-13 00:42:21,506 INFO     Evaluating the model... (2500/59072)
2025-12-13 00:42:24,620 INFO     Evaluating the model... (3000/59072)
2025-12-13 00:42:27,158 INFO     Evaluating the model... (3500/59072)
2025-12-13 00:42:29,540 INFO     Evaluating the model... (4000/59072)
2025-12-13 00:42:32,047 INFO     Evaluating the model... (4500/59072)
2025-12-13 00:42:34,748 INFO     Evaluating the model... (5000/59072)
2025-12-13 00:42:37,998 INFO     Evaluating the model... (5500/59072)
2025-12-13 00:42:40,775 INFO     Evaluating the model... (6000/59072)
2025-12-13 00:42:43,690 INFO     Evaluating the model... (6500/59072)
2025-12-13 00:42:46,433 INFO     Evaluating the model... (7000/59072)
2025-12-13 00:42:48,873 INFO     Evaluating the model... (7500/59072)
2025-12-13 00:42:51,834 INFO     Evaluating the model... (8000/59072)
2025-12-13 00:42:54,225 INFO     Evaluating the model... (8500/59072)
2025-12-13 00:42:56,894 INFO     Evaluating the model... (9000/59072)
2025-12-13 00:42:59,254 INFO     Evaluating the model... (9500/59072)
2025-12-13 00:43:01,592 INFO     Evaluating the model... (10000/59072)
2025-12-13 00:43:04,874 INFO     Evaluating the model... (10500/59072)
2025-12-13 00:43:07,436 INFO     Evaluating the model... (11000/59072)
2025-12-13 00:43:09,881 INFO     Evaluating the model... (11500/59072)
2025-12-13 00:43:12,339 INFO     Evaluating the model... (12000/59072)
2025-12-13 00:43:14,833 INFO     Evaluating the model... (12500/59072)
2025-12-13 00:43:18,176 INFO     Evaluating the model... (13000/59072)
2025-12-13 00:43:20,838 INFO     Evaluating the model... (13500/59072)
2025-12-13 00:43:23,220 INFO     Evaluating the model... (14000/59072)
2025-12-13 00:43:25,686 INFO     Evaluating the model... (14500/59072)
2025-12-13 00:43:28,248 INFO     Evaluating the model... (15000/59072)
2025-12-13 00:43:31,410 INFO     Evaluating the model... (15500/59072)
2025-12-13 00:43:33,833 INFO     Evaluating the model... (16000/59072)
2025-12-13 00:43:36,423 INFO     Evaluating the model... (16500/59072)
2025-12-13 00:43:38,981 INFO     Evaluating the model... (17000/59072)
2025-12-13 00:43:41,675 INFO     Evaluating the model... (17500/59072)
2025-12-13 00:43:44,974 INFO     Evaluating the model... (18000/59072)
2025-12-13 00:43:47,464 INFO     Evaluating the model... (18500/59072)
2025-12-13 00:43:50,034 INFO     Evaluating the model... (19000/59072)
2025-12-13 00:43:52,484 INFO     Evaluating the model... (19500/59072)
2025-12-13 00:43:55,184 INFO     Evaluating the model... (20000/59072)
2025-12-13 00:43:58,553 INFO     Evaluating the model... (20500/59072)
2025-12-13 00:44:00,987 INFO     Evaluating the model... (21000/59072)
2025-12-13 00:44:03,330 INFO     Evaluating the model... (21500/59072)
2025-12-13 00:44:06,042 INFO     Evaluating the model... (22000/59072)
2025-12-13 00:44:09,341 INFO     Evaluating the model... (22500/59072)
2025-12-13 00:44:11,657 INFO     Evaluating the model... (23000/59072)
2025-12-13 00:44:14,058 INFO     Evaluating the model... (23500/59072)
2025-12-13 00:44:16,722 INFO     Evaluating the model... (24000/59072)
2025-12-13 00:44:19,261 INFO     Evaluating the model... (24500/59072)
2025-12-13 00:44:22,846 INFO     Evaluating the model... (25000/59072)
2025-12-13 00:44:25,348 INFO     Evaluating the model... (25500/59072)
2025-12-13 00:44:27,954 INFO     Evaluating the model... (26000/59072)
2025-12-13 00:44:30,533 INFO     Evaluating the model... (26500/59072)
2025-12-13 00:44:32,830 INFO     Evaluating the model... (27000/59072)
2025-12-13 00:44:36,504 INFO     Evaluating the model... (27500/59072)
2025-12-13 00:44:39,280 INFO     Evaluating the model... (28000/59072)
2025-12-13 00:44:42,120 INFO     Evaluating the model... (28500/59072)
2025-12-13 00:44:44,746 INFO     Evaluating the model... (29000/59072)
2025-12-13 00:44:47,251 INFO     Evaluating the model... (29500/59072)
2025-12-13 00:44:51,116 INFO     Evaluating the model... (30000/59072)
2025-12-13 00:44:53,840 INFO     Evaluating the model... (30500/59072)
2025-12-13 00:44:56,434 INFO     Evaluating the model... (31000/59072)
2025-12-13 00:44:58,884 INFO     Evaluating the model... (31500/59072)
2025-12-13 00:45:01,429 INFO     Evaluating the model... (32000/59072)
2025-12-13 00:45:04,992 INFO     Evaluating the model... (32500/59072)
2025-12-13 00:45:07,741 INFO     Evaluating the model... (33000/59072)
2025-12-13 00:45:10,243 INFO     Evaluating the model... (33500/59072)
2025-12-13 00:45:12,764 INFO     Evaluating the model... (34000/59072)
2025-12-13 00:45:16,397 INFO     Evaluating the model... (34500/59072)
2025-12-13 00:45:18,947 INFO     Evaluating the model... (35000/59072)
2025-12-13 00:45:21,511 INFO     Evaluating the model... (35500/59072)
2025-12-13 00:45:24,081 INFO     Evaluating the model... (36000/59072)
2025-12-13 00:45:26,904 INFO     Evaluating the model... (36500/59072)
2025-12-13 00:45:30,334 INFO     Evaluating the model... (37000/59072)
2025-12-13 00:45:32,805 INFO     Evaluating the model... (37500/59072)
2025-12-13 00:45:35,381 INFO     Evaluating the model... (38000/59072)
2025-12-13 00:45:38,317 INFO     Evaluating the model... (38500/59072)
2025-12-13 00:45:41,154 INFO     Evaluating the model... (39000/59072)
2025-12-13 00:45:45,000 INFO     Evaluating the model... (39500/59072)
2025-12-13 00:45:47,584 INFO     Evaluating the model... (40000/59072)
2025-12-13 00:45:50,179 INFO     Evaluating the model... (40500/59072)
2025-12-13 00:45:52,579 INFO     Evaluating the model... (41000/59072)
2025-12-13 00:45:55,017 INFO     Evaluating the model... (41500/59072)
2025-12-13 00:45:58,611 INFO     Evaluating the model... (42000/59072)
2025-12-13 00:46:01,336 INFO     Evaluating the model... (42500/59072)
2025-12-13 00:46:03,819 INFO     Evaluating the model... (43000/59072)
2025-12-13 00:46:06,474 INFO     Evaluating the model... (43500/59072)
2025-12-13 00:46:09,095 INFO     Evaluating the model... (44000/59072)
2025-12-13 00:46:12,913 INFO     Evaluating the model... (44500/59072)
2025-12-13 00:46:15,535 INFO     Evaluating the model... (45000/59072)
2025-12-13 00:46:17,878 INFO     Evaluating the model... (45500/59072)
2025-12-13 00:46:20,324 INFO     Evaluating the model... (46000/59072)
2025-12-13 00:46:22,828 INFO     Evaluating the model... (46500/59072)
2025-12-13 00:46:26,640 INFO     Evaluating the model... (47000/59072)
2025-12-13 00:46:29,201 INFO     Evaluating the model... (47500/59072)
2025-12-13 00:46:31,653 INFO     Evaluating the model... (48000/59072)
2025-12-13 00:46:34,339 INFO     Evaluating the model... (48500/59072)
2025-12-13 00:46:37,378 INFO     Evaluating the model... (49000/59072)
2025-12-13 00:46:41,322 INFO     Evaluating the model... (49500/59072)
2025-12-13 00:46:43,997 INFO     Evaluating the model... (50000/59072)
2025-12-13 00:46:46,778 INFO     Evaluating the model... (50500/59072)
2025-12-13 00:46:49,325 INFO     Evaluating the model... (51000/59072)
2025-12-13 00:46:51,882 INFO     Evaluating the model... (51500/59072)
2025-12-13 00:46:55,705 INFO     Evaluating the model... (52000/59072)
2025-12-13 00:46:58,418 INFO     Evaluating the model... (52500/59072)
2025-12-13 00:47:00,940 INFO     Evaluating the model... (53000/59072)
2025-12-13 00:47:03,451 INFO     Evaluating the model... (53500/59072)
2025-12-13 00:47:07,248 INFO     Evaluating the model... (54000/59072)
2025-12-13 00:47:09,960 INFO     Evaluating the model... (54500/59072)
2025-12-13 00:47:12,453 INFO     Evaluating the model... (55000/59072)
2025-12-13 00:47:14,889 INFO     Evaluating the model... (55500/59072)
2025-12-13 00:47:17,453 INFO     Evaluating the model... (56000/59072)
2025-12-13 00:47:21,088 INFO     Evaluating the model... (56500/59072)
2025-12-13 00:47:23,713 INFO     Evaluating the model... (57000/59072)
2025-12-13 00:47:26,280 INFO     Evaluating the model... (57500/59072)
2025-12-13 00:47:28,853 INFO     Evaluating the model... (58000/59072)
2025-12-13 00:47:31,238 INFO     Evaluating the model... (58500/59072)
2025-12-13 00:47:35,316 INFO     Evaluating the model... (59000/59072)
2025-12-13 00:47:35,978 INFO     Test MRR at step 60000: 0.612404
2025-12-13 00:47:35,980 INFO     Test MR at step 60000: 268.853067
2025-12-13 00:47:35,980 INFO     Test HITS@1 at step 60000: 0.520450
2025-12-13 00:47:35,980 INFO     Test HITS@3 at step 60000: 0.669703
2025-12-13 00:47:35,980 INFO     Test HITS@10 at step 60000: 0.776024
2025-12-13 00:47:38,179 INFO     Training average regularization at step 60100: 0.304234
2025-12-13 00:47:38,179 INFO     Training average positive_sample_loss at step 60100: 0.066789
2025-12-13 00:47:38,179 INFO     Training average negative_sample_loss at step 60100: 0.109335
2025-12-13 00:47:38,179 INFO     Training average loss at step 60100: 0.392296
2025-12-13 00:47:40,319 INFO     Training average regularization at step 60200: 0.304225
2025-12-13 00:47:40,320 INFO     Training average positive_sample_loss at step 60200: 0.066495
2025-12-13 00:47:40,320 INFO     Training average negative_sample_loss at step 60200: 0.108465
2025-12-13 00:47:40,320 INFO     Training average loss at step 60200: 0.391705
2025-12-13 00:47:42,513 INFO     Training average regularization at step 60300: 0.304217
2025-12-13 00:47:42,513 INFO     Training average positive_sample_loss at step 60300: 0.067018
2025-12-13 00:47:42,513 INFO     Training average negative_sample_loss at step 60300: 0.109558
2025-12-13 00:47:42,513 INFO     Training average loss at step 60300: 0.392505
2025-12-13 00:47:44,730 INFO     Training average regularization at step 60400: 0.304208
2025-12-13 00:47:44,730 INFO     Training average positive_sample_loss at step 60400: 0.066692
2025-12-13 00:47:44,730 INFO     Training average negative_sample_loss at step 60400: 0.110745
2025-12-13 00:47:44,730 INFO     Training average loss at step 60400: 0.392926
2025-12-13 00:47:46,911 INFO     Training average regularization at step 60500: 0.304199
2025-12-13 00:47:46,912 INFO     Training average positive_sample_loss at step 60500: 0.066692
2025-12-13 00:47:46,912 INFO     Training average negative_sample_loss at step 60500: 0.106501
2025-12-13 00:47:46,912 INFO     Training average loss at step 60500: 0.390796
2025-12-13 00:47:49,095 INFO     Training average regularization at step 60600: 0.304191
2025-12-13 00:47:49,096 INFO     Training average positive_sample_loss at step 60600: 0.067106
2025-12-13 00:47:49,096 INFO     Training average negative_sample_loss at step 60600: 0.109730
2025-12-13 00:47:49,096 INFO     Training average loss at step 60600: 0.392609
2025-12-13 00:47:51,264 INFO     Training average regularization at step 60700: 0.304182
2025-12-13 00:47:51,264 INFO     Training average positive_sample_loss at step 60700: 0.066622
2025-12-13 00:47:51,264 INFO     Training average negative_sample_loss at step 60700: 0.108662
2025-12-13 00:47:51,264 INFO     Training average loss at step 60700: 0.391825
2025-12-13 00:47:53,439 INFO     Training average regularization at step 60800: 0.304174
2025-12-13 00:47:53,441 INFO     Training average positive_sample_loss at step 60800: 0.066509
2025-12-13 00:47:53,441 INFO     Training average negative_sample_loss at step 60800: 0.108239
2025-12-13 00:47:53,441 INFO     Training average loss at step 60800: 0.391548
2025-12-13 00:47:55,634 INFO     Training average regularization at step 60900: 0.304166
2025-12-13 00:47:55,634 INFO     Training average positive_sample_loss at step 60900: 0.067557
2025-12-13 00:47:55,634 INFO     Training average negative_sample_loss at step 60900: 0.108941
2025-12-13 00:47:55,634 INFO     Training average loss at step 60900: 0.392415
2025-12-13 00:47:57,786 INFO     Training average regularization at step 61000: 0.304158
2025-12-13 00:47:57,787 INFO     Training average positive_sample_loss at step 61000: 0.067070
2025-12-13 00:47:57,787 INFO     Training average negative_sample_loss at step 61000: 0.106266
2025-12-13 00:47:57,787 INFO     Training average loss at step 61000: 0.390826
2025-12-13 00:47:59,935 INFO     Training average regularization at step 61100: 0.304150
2025-12-13 00:47:59,936 INFO     Training average positive_sample_loss at step 61100: 0.067440
2025-12-13 00:47:59,936 INFO     Training average negative_sample_loss at step 61100: 0.109454
2025-12-13 00:47:59,936 INFO     Training average loss at step 61100: 0.392597
2025-12-13 00:48:02,043 INFO     Training average regularization at step 61200: 0.304142
2025-12-13 00:48:02,043 INFO     Training average positive_sample_loss at step 61200: 0.068645
2025-12-13 00:48:02,043 INFO     Training average negative_sample_loss at step 61200: 0.108352
2025-12-13 00:48:02,043 INFO     Training average loss at step 61200: 0.392641
2025-12-13 00:48:04,198 INFO     Training average regularization at step 61300: 0.304134
2025-12-13 00:48:04,198 INFO     Training average positive_sample_loss at step 61300: 0.066841
2025-12-13 00:48:04,198 INFO     Training average negative_sample_loss at step 61300: 0.109132
2025-12-13 00:48:04,198 INFO     Training average loss at step 61300: 0.392121
2025-12-13 00:48:06,405 INFO     Training average regularization at step 61400: 0.304125
2025-12-13 00:48:06,406 INFO     Training average positive_sample_loss at step 61400: 0.067455
2025-12-13 00:48:06,406 INFO     Training average negative_sample_loss at step 61400: 0.109213
2025-12-13 00:48:06,406 INFO     Training average loss at step 61400: 0.392459
2025-12-13 00:48:08,574 INFO     Training average regularization at step 61500: 0.304117
2025-12-13 00:48:08,574 INFO     Training average positive_sample_loss at step 61500: 0.067466
2025-12-13 00:48:08,574 INFO     Training average negative_sample_loss at step 61500: 0.108265
2025-12-13 00:48:08,574 INFO     Training average loss at step 61500: 0.391983
2025-12-13 00:48:10,736 INFO     Training average regularization at step 61600: 0.304110
2025-12-13 00:48:10,737 INFO     Training average positive_sample_loss at step 61600: 0.067015
2025-12-13 00:48:10,737 INFO     Training average negative_sample_loss at step 61600: 0.110443
2025-12-13 00:48:10,737 INFO     Training average loss at step 61600: 0.392839
2025-12-13 00:48:12,855 INFO     Training average regularization at step 61700: 0.304104
2025-12-13 00:48:12,905 INFO     Training average positive_sample_loss at step 61700: 0.068943
2025-12-13 00:48:12,905 INFO     Training average negative_sample_loss at step 61700: 0.108425
2025-12-13 00:48:12,905 INFO     Training average loss at step 61700: 0.392788
2025-12-13 00:48:15,058 INFO     Training average regularization at step 61800: 0.304097
2025-12-13 00:48:15,058 INFO     Training average positive_sample_loss at step 61800: 0.067569
2025-12-13 00:48:15,058 INFO     Training average negative_sample_loss at step 61800: 0.108956
2025-12-13 00:48:15,058 INFO     Training average loss at step 61800: 0.392360
2025-12-13 00:48:17,232 INFO     Training average regularization at step 61900: 0.304090
2025-12-13 00:48:17,238 INFO     Training average positive_sample_loss at step 61900: 0.068651
2025-12-13 00:48:17,238 INFO     Training average negative_sample_loss at step 61900: 0.111679
2025-12-13 00:48:17,238 INFO     Training average loss at step 61900: 0.394256
2025-12-13 00:48:19,396 INFO     Training average regularization at step 62000: 0.304083
2025-12-13 00:48:19,397 INFO     Training average positive_sample_loss at step 62000: 0.068625
2025-12-13 00:48:19,397 INFO     Training average negative_sample_loss at step 62000: 0.108674
2025-12-13 00:48:19,397 INFO     Training average loss at step 62000: 0.392732
2025-12-13 00:48:21,565 INFO     Training average regularization at step 62100: 0.304074
2025-12-13 00:48:21,565 INFO     Training average positive_sample_loss at step 62100: 0.068078
2025-12-13 00:48:21,565 INFO     Training average negative_sample_loss at step 62100: 0.107564
2025-12-13 00:48:21,565 INFO     Training average loss at step 62100: 0.391895
2025-12-13 00:48:23,715 INFO     Training average regularization at step 62200: 0.304068
2025-12-13 00:48:23,716 INFO     Training average positive_sample_loss at step 62200: 0.068879
2025-12-13 00:48:23,716 INFO     Training average negative_sample_loss at step 62200: 0.107196
2025-12-13 00:48:23,716 INFO     Training average loss at step 62200: 0.392105
2025-12-13 00:48:25,870 INFO     Training average regularization at step 62300: 0.304059
2025-12-13 00:48:25,870 INFO     Training average positive_sample_loss at step 62300: 0.067615
2025-12-13 00:48:25,870 INFO     Training average negative_sample_loss at step 62300: 0.110630
2025-12-13 00:48:25,870 INFO     Training average loss at step 62300: 0.393181
2025-12-13 00:48:28,072 INFO     Training average regularization at step 62400: 0.304052
2025-12-13 00:48:28,073 INFO     Training average positive_sample_loss at step 62400: 0.068467
2025-12-13 00:48:28,073 INFO     Training average negative_sample_loss at step 62400: 0.109382
2025-12-13 00:48:28,073 INFO     Training average loss at step 62400: 0.392976
2025-12-13 00:48:30,228 INFO     Training average regularization at step 62500: 0.304045
2025-12-13 00:48:30,228 INFO     Training average positive_sample_loss at step 62500: 0.067275
2025-12-13 00:48:30,228 INFO     Training average negative_sample_loss at step 62500: 0.106743
2025-12-13 00:48:30,228 INFO     Training average loss at step 62500: 0.391054
2025-12-13 00:48:32,382 INFO     Training average regularization at step 62600: 0.304039
2025-12-13 00:48:32,382 INFO     Training average positive_sample_loss at step 62600: 0.069017
2025-12-13 00:48:32,382 INFO     Training average negative_sample_loss at step 62600: 0.106710
2025-12-13 00:48:32,382 INFO     Training average loss at step 62600: 0.391903
2025-12-13 00:48:34,536 INFO     Training average regularization at step 62700: 0.304033
2025-12-13 00:48:34,537 INFO     Training average positive_sample_loss at step 62700: 0.068057
2025-12-13 00:48:34,537 INFO     Training average negative_sample_loss at step 62700: 0.109443
2025-12-13 00:48:34,537 INFO     Training average loss at step 62700: 0.392783
2025-12-13 00:48:36,931 INFO     Training average regularization at step 62800: 0.304028
2025-12-13 00:48:36,931 INFO     Training average positive_sample_loss at step 62800: 0.068223
2025-12-13 00:48:36,931 INFO     Training average negative_sample_loss at step 62800: 0.107981
2025-12-13 00:48:36,931 INFO     Training average loss at step 62800: 0.392130
2025-12-13 00:48:40,111 INFO     Training average regularization at step 62900: 0.304020
2025-12-13 00:48:40,111 INFO     Training average positive_sample_loss at step 62900: 0.065523
2025-12-13 00:48:40,111 INFO     Training average negative_sample_loss at step 62900: 0.110939
2025-12-13 00:48:40,112 INFO     Training average loss at step 62900: 0.392251
2025-12-13 00:48:42,288 INFO     Training average regularization at step 63000: 0.304008
2025-12-13 00:48:42,289 INFO     Training average positive_sample_loss at step 63000: 0.066016
2025-12-13 00:48:42,289 INFO     Training average negative_sample_loss at step 63000: 0.109134
2025-12-13 00:48:42,289 INFO     Training average loss at step 63000: 0.391583
2025-12-13 00:48:44,484 INFO     Training average regularization at step 63100: 0.303999
2025-12-13 00:48:44,484 INFO     Training average positive_sample_loss at step 63100: 0.065271
2025-12-13 00:48:44,484 INFO     Training average negative_sample_loss at step 63100: 0.108455
2025-12-13 00:48:44,484 INFO     Training average loss at step 63100: 0.390862
2025-12-13 00:48:46,667 INFO     Training average regularization at step 63200: 0.303987
2025-12-13 00:48:46,667 INFO     Training average positive_sample_loss at step 63200: 0.065848
2025-12-13 00:48:46,667 INFO     Training average negative_sample_loss at step 63200: 0.109195
2025-12-13 00:48:46,667 INFO     Training average loss at step 63200: 0.391508
2025-12-13 00:48:48,821 INFO     Training average regularization at step 63300: 0.303976
2025-12-13 00:48:48,821 INFO     Training average positive_sample_loss at step 63300: 0.066280
2025-12-13 00:48:48,821 INFO     Training average negative_sample_loss at step 63300: 0.109418
2025-12-13 00:48:48,821 INFO     Training average loss at step 63300: 0.391825
2025-12-13 00:48:50,998 INFO     Training average regularization at step 63400: 0.303968
2025-12-13 00:48:50,999 INFO     Training average positive_sample_loss at step 63400: 0.066766
2025-12-13 00:48:50,999 INFO     Training average negative_sample_loss at step 63400: 0.108861
2025-12-13 00:48:50,999 INFO     Training average loss at step 63400: 0.391781
2025-12-13 00:48:53,138 INFO     Training average regularization at step 63500: 0.303959
2025-12-13 00:48:53,139 INFO     Training average positive_sample_loss at step 63500: 0.065470
2025-12-13 00:48:53,139 INFO     Training average negative_sample_loss at step 63500: 0.108755
2025-12-13 00:48:53,139 INFO     Training average loss at step 63500: 0.391071
2025-12-13 00:48:55,295 INFO     Training average regularization at step 63600: 0.303950
2025-12-13 00:48:55,295 INFO     Training average positive_sample_loss at step 63600: 0.064853
2025-12-13 00:48:55,295 INFO     Training average negative_sample_loss at step 63600: 0.108576
2025-12-13 00:48:55,295 INFO     Training average loss at step 63600: 0.390664
2025-12-13 00:48:57,441 INFO     Training average regularization at step 63700: 0.303941
2025-12-13 00:48:57,442 INFO     Training average positive_sample_loss at step 63700: 0.066918
2025-12-13 00:48:57,442 INFO     Training average negative_sample_loss at step 63700: 0.109870
2025-12-13 00:48:57,442 INFO     Training average loss at step 63700: 0.392335
2025-12-13 00:48:59,586 INFO     Training average regularization at step 63800: 0.303932
2025-12-13 00:48:59,587 INFO     Training average positive_sample_loss at step 63800: 0.066075
2025-12-13 00:48:59,587 INFO     Training average negative_sample_loss at step 63800: 0.109597
2025-12-13 00:48:59,587 INFO     Training average loss at step 63800: 0.391768
2025-12-13 00:49:01,751 INFO     Training average regularization at step 63900: 0.303923
2025-12-13 00:49:01,751 INFO     Training average positive_sample_loss at step 63900: 0.067091
2025-12-13 00:49:01,751 INFO     Training average negative_sample_loss at step 63900: 0.107843
2025-12-13 00:49:01,751 INFO     Training average loss at step 63900: 0.391391
2025-12-13 00:49:03,896 INFO     Training average regularization at step 64000: 0.303916
2025-12-13 00:49:03,896 INFO     Training average positive_sample_loss at step 64000: 0.067478
2025-12-13 00:49:03,896 INFO     Training average negative_sample_loss at step 64000: 0.109413
2025-12-13 00:49:03,896 INFO     Training average loss at step 64000: 0.392362
2025-12-13 00:49:06,036 INFO     Training average regularization at step 64100: 0.303909
2025-12-13 00:49:06,036 INFO     Training average positive_sample_loss at step 64100: 0.067154
2025-12-13 00:49:06,036 INFO     Training average negative_sample_loss at step 64100: 0.110124
2025-12-13 00:49:06,036 INFO     Training average loss at step 64100: 0.392548
2025-12-13 00:49:08,183 INFO     Training average regularization at step 64200: 0.303902
2025-12-13 00:49:08,184 INFO     Training average positive_sample_loss at step 64200: 0.066079
2025-12-13 00:49:08,184 INFO     Training average negative_sample_loss at step 64200: 0.106589
2025-12-13 00:49:08,184 INFO     Training average loss at step 64200: 0.390236
2025-12-13 00:49:10,327 INFO     Training average regularization at step 64300: 0.303892
2025-12-13 00:49:10,328 INFO     Training average positive_sample_loss at step 64300: 0.067005
2025-12-13 00:49:10,328 INFO     Training average negative_sample_loss at step 64300: 0.107306
2025-12-13 00:49:10,328 INFO     Training average loss at step 64300: 0.391048
2025-12-13 00:49:12,488 INFO     Training average regularization at step 64400: 0.303883
2025-12-13 00:49:12,488 INFO     Training average positive_sample_loss at step 64400: 0.066193
2025-12-13 00:49:12,488 INFO     Training average negative_sample_loss at step 64400: 0.109261
2025-12-13 00:49:12,488 INFO     Training average loss at step 64400: 0.391610
2025-12-13 00:49:14,639 INFO     Training average regularization at step 64500: 0.303875
2025-12-13 00:49:14,639 INFO     Training average positive_sample_loss at step 64500: 0.066532
2025-12-13 00:49:14,639 INFO     Training average negative_sample_loss at step 64500: 0.107960
2025-12-13 00:49:14,639 INFO     Training average loss at step 64500: 0.391121
2025-12-13 00:49:16,794 INFO     Training average regularization at step 64600: 0.303867
2025-12-13 00:49:16,794 INFO     Training average positive_sample_loss at step 64600: 0.067890
2025-12-13 00:49:16,794 INFO     Training average negative_sample_loss at step 64600: 0.110014
2025-12-13 00:49:16,794 INFO     Training average loss at step 64600: 0.392819
2025-12-13 00:49:18,939 INFO     Training average regularization at step 64700: 0.303858
2025-12-13 00:49:18,939 INFO     Training average positive_sample_loss at step 64700: 0.068112
2025-12-13 00:49:18,939 INFO     Training average negative_sample_loss at step 64700: 0.110665
2025-12-13 00:49:18,939 INFO     Training average loss at step 64700: 0.393247
2025-12-13 00:49:21,082 INFO     Training average regularization at step 64800: 0.303850
2025-12-13 00:49:21,082 INFO     Training average positive_sample_loss at step 64800: 0.066468
2025-12-13 00:49:21,082 INFO     Training average negative_sample_loss at step 64800: 0.109523
2025-12-13 00:49:21,083 INFO     Training average loss at step 64800: 0.391846
2025-12-13 00:49:23,264 INFO     Training average regularization at step 64900: 0.303842
2025-12-13 00:49:23,264 INFO     Training average positive_sample_loss at step 64900: 0.067144
2025-12-13 00:49:23,264 INFO     Training average negative_sample_loss at step 64900: 0.111226
2025-12-13 00:49:23,264 INFO     Training average loss at step 64900: 0.393027
2025-12-13 00:49:25,413 INFO     Training average regularization at step 65000: 0.303834
2025-12-13 00:49:25,413 INFO     Training average positive_sample_loss at step 65000: 0.066606
2025-12-13 00:49:25,413 INFO     Training average negative_sample_loss at step 65000: 0.108618
2025-12-13 00:49:25,413 INFO     Training average loss at step 65000: 0.391446
2025-12-13 00:49:27,558 INFO     Training average regularization at step 65100: 0.303825
2025-12-13 00:49:27,559 INFO     Training average positive_sample_loss at step 65100: 0.067250
2025-12-13 00:49:27,559 INFO     Training average negative_sample_loss at step 65100: 0.109519
2025-12-13 00:49:27,559 INFO     Training average loss at step 65100: 0.392209
2025-12-13 00:49:29,720 INFO     Training average regularization at step 65200: 0.303819
2025-12-13 00:49:29,720 INFO     Training average positive_sample_loss at step 65200: 0.067156
2025-12-13 00:49:29,721 INFO     Training average negative_sample_loss at step 65200: 0.108269
2025-12-13 00:49:29,721 INFO     Training average loss at step 65200: 0.391531
2025-12-13 00:49:31,873 INFO     Training average regularization at step 65300: 0.303813
2025-12-13 00:49:31,873 INFO     Training average positive_sample_loss at step 65300: 0.067673
2025-12-13 00:49:31,873 INFO     Training average negative_sample_loss at step 65300: 0.110037
2025-12-13 00:49:31,873 INFO     Training average loss at step 65300: 0.392668
2025-12-13 00:49:34,052 INFO     Training average regularization at step 65400: 0.303805
2025-12-13 00:49:34,052 INFO     Training average positive_sample_loss at step 65400: 0.066354
2025-12-13 00:49:34,053 INFO     Training average negative_sample_loss at step 65400: 0.109761
2025-12-13 00:49:34,053 INFO     Training average loss at step 65400: 0.391863
2025-12-13 00:49:36,213 INFO     Training average regularization at step 65500: 0.303798
2025-12-13 00:49:36,213 INFO     Training average positive_sample_loss at step 65500: 0.067549
2025-12-13 00:49:36,213 INFO     Training average negative_sample_loss at step 65500: 0.110170
2025-12-13 00:49:36,213 INFO     Training average loss at step 65500: 0.392657
2025-12-13 00:49:38,388 INFO     Training average regularization at step 65600: 0.303791
2025-12-13 00:49:38,389 INFO     Training average positive_sample_loss at step 65600: 0.067103
2025-12-13 00:49:38,389 INFO     Training average negative_sample_loss at step 65600: 0.108908
2025-12-13 00:49:38,389 INFO     Training average loss at step 65600: 0.391797
2025-12-13 00:49:40,563 INFO     Training average regularization at step 65700: 0.303785
2025-12-13 00:49:40,563 INFO     Training average positive_sample_loss at step 65700: 0.068769
2025-12-13 00:49:40,563 INFO     Training average negative_sample_loss at step 65700: 0.110531
2025-12-13 00:49:40,564 INFO     Training average loss at step 65700: 0.393435
2025-12-13 00:49:42,729 INFO     Training average regularization at step 65800: 0.303777
2025-12-13 00:49:42,729 INFO     Training average positive_sample_loss at step 65800: 0.066561
2025-12-13 00:49:42,729 INFO     Training average negative_sample_loss at step 65800: 0.108532
2025-12-13 00:49:42,729 INFO     Training average loss at step 65800: 0.391324
2025-12-13 00:49:44,904 INFO     Training average regularization at step 65900: 0.303771
2025-12-13 00:49:44,904 INFO     Training average positive_sample_loss at step 65900: 0.067992
2025-12-13 00:49:44,904 INFO     Training average negative_sample_loss at step 65900: 0.108244
2025-12-13 00:49:44,904 INFO     Training average loss at step 65900: 0.391889
2025-12-13 00:49:47,067 INFO     Training average regularization at step 66000: 0.303764
2025-12-13 00:49:47,067 INFO     Training average positive_sample_loss at step 66000: 0.067743
2025-12-13 00:49:47,067 INFO     Training average negative_sample_loss at step 66000: 0.111213
2025-12-13 00:49:47,067 INFO     Training average loss at step 66000: 0.393242
2025-12-13 00:49:49,241 INFO     Training average regularization at step 66100: 0.303758
2025-12-13 00:49:49,241 INFO     Training average positive_sample_loss at step 66100: 0.068266
2025-12-13 00:49:49,241 INFO     Training average negative_sample_loss at step 66100: 0.107694
2025-12-13 00:49:49,241 INFO     Training average loss at step 66100: 0.391738
2025-12-13 00:49:51,393 INFO     Training average regularization at step 66200: 0.303752
2025-12-13 00:49:51,393 INFO     Training average positive_sample_loss at step 66200: 0.068770
2025-12-13 00:49:51,393 INFO     Training average negative_sample_loss at step 66200: 0.108190
2025-12-13 00:49:51,394 INFO     Training average loss at step 66200: 0.392232
2025-12-13 00:49:53,546 INFO     Training average regularization at step 66300: 0.303747
2025-12-13 00:49:53,546 INFO     Training average positive_sample_loss at step 66300: 0.066732
2025-12-13 00:49:53,546 INFO     Training average negative_sample_loss at step 66300: 0.110732
2025-12-13 00:49:53,546 INFO     Training average loss at step 66300: 0.392480
2025-12-13 00:49:55,696 INFO     Training average regularization at step 66400: 0.303739
2025-12-13 00:49:55,696 INFO     Training average positive_sample_loss at step 66400: 0.066633
2025-12-13 00:49:55,696 INFO     Training average negative_sample_loss at step 66400: 0.107810
2025-12-13 00:49:55,697 INFO     Training average loss at step 66400: 0.390961
2025-12-13 00:49:57,833 INFO     Training average regularization at step 66500: 0.303732
2025-12-13 00:49:57,836 INFO     Training average positive_sample_loss at step 66500: 0.068562
2025-12-13 00:49:57,836 INFO     Training average negative_sample_loss at step 66500: 0.107791
2025-12-13 00:49:57,836 INFO     Training average loss at step 66500: 0.391908
2025-12-13 00:49:59,981 INFO     Training average regularization at step 66600: 0.303726
2025-12-13 00:49:59,981 INFO     Training average positive_sample_loss at step 66600: 0.068017
2025-12-13 00:49:59,981 INFO     Training average negative_sample_loss at step 66600: 0.111463
2025-12-13 00:49:59,981 INFO     Training average loss at step 66600: 0.393466
2025-12-13 00:50:02,137 INFO     Training average regularization at step 66700: 0.303719
2025-12-13 00:50:02,137 INFO     Training average positive_sample_loss at step 66700: 0.068320
2025-12-13 00:50:02,137 INFO     Training average negative_sample_loss at step 66700: 0.111174
2025-12-13 00:50:02,137 INFO     Training average loss at step 66700: 0.393466
2025-12-13 00:50:04,277 INFO     Training average regularization at step 66800: 0.303714
2025-12-13 00:50:04,277 INFO     Training average positive_sample_loss at step 66800: 0.067896
2025-12-13 00:50:04,277 INFO     Training average negative_sample_loss at step 66800: 0.110329
2025-12-13 00:50:04,277 INFO     Training average loss at step 66800: 0.392827
2025-12-13 00:50:06,432 INFO     Training average regularization at step 66900: 0.303706
2025-12-13 00:50:06,432 INFO     Training average positive_sample_loss at step 66900: 0.068653
2025-12-13 00:50:06,432 INFO     Training average negative_sample_loss at step 66900: 0.110438
2025-12-13 00:50:06,432 INFO     Training average loss at step 66900: 0.393252
2025-12-13 00:50:08,614 INFO     Training average regularization at step 67000: 0.303700
2025-12-13 00:50:08,614 INFO     Training average positive_sample_loss at step 67000: 0.067795
2025-12-13 00:50:08,614 INFO     Training average negative_sample_loss at step 67000: 0.109870
2025-12-13 00:50:08,614 INFO     Training average loss at step 67000: 0.392533
2025-12-13 00:50:10,765 INFO     Training average regularization at step 67100: 0.303694
2025-12-13 00:50:10,766 INFO     Training average positive_sample_loss at step 67100: 0.068508
2025-12-13 00:50:10,766 INFO     Training average negative_sample_loss at step 67100: 0.109277
2025-12-13 00:50:10,766 INFO     Training average loss at step 67100: 0.392586
2025-12-13 00:50:12,916 INFO     Training average regularization at step 67200: 0.303687
2025-12-13 00:50:12,916 INFO     Training average positive_sample_loss at step 67200: 0.068453
2025-12-13 00:50:12,916 INFO     Training average negative_sample_loss at step 67200: 0.110677
2025-12-13 00:50:12,916 INFO     Training average loss at step 67200: 0.393252
2025-12-13 00:50:15,056 INFO     Training average regularization at step 67300: 0.303682
2025-12-13 00:50:15,056 INFO     Training average positive_sample_loss at step 67300: 0.068578
2025-12-13 00:50:15,056 INFO     Training average negative_sample_loss at step 67300: 0.107354
2025-12-13 00:50:15,056 INFO     Training average loss at step 67300: 0.391648
2025-12-13 00:50:17,211 INFO     Training average regularization at step 67400: 0.303676
2025-12-13 00:50:17,211 INFO     Training average positive_sample_loss at step 67400: 0.068109
2025-12-13 00:50:17,211 INFO     Training average negative_sample_loss at step 67400: 0.107305
2025-12-13 00:50:17,211 INFO     Training average loss at step 67400: 0.391383
2025-12-13 00:50:19,384 INFO     Training average regularization at step 67500: 0.303671
2025-12-13 00:50:19,384 INFO     Training average positive_sample_loss at step 67500: 0.068200
2025-12-13 00:50:19,384 INFO     Training average negative_sample_loss at step 67500: 0.111545
2025-12-13 00:50:19,384 INFO     Training average loss at step 67500: 0.393543
2025-12-13 00:50:21,537 INFO     Training average regularization at step 67600: 0.303665
2025-12-13 00:50:21,537 INFO     Training average positive_sample_loss at step 67600: 0.068505
2025-12-13 00:50:21,537 INFO     Training average negative_sample_loss at step 67600: 0.109328
2025-12-13 00:50:21,537 INFO     Training average loss at step 67600: 0.392581
2025-12-13 00:50:24,720 INFO     Training average regularization at step 67700: 0.303659
2025-12-13 00:50:24,721 INFO     Training average positive_sample_loss at step 67700: 0.066421
2025-12-13 00:50:24,721 INFO     Training average negative_sample_loss at step 67700: 0.110661
2025-12-13 00:50:24,721 INFO     Training average loss at step 67700: 0.392200
2025-12-13 00:50:26,877 INFO     Training average regularization at step 67800: 0.303649
2025-12-13 00:50:26,878 INFO     Training average positive_sample_loss at step 67800: 0.065342
2025-12-13 00:50:26,878 INFO     Training average negative_sample_loss at step 67800: 0.110636
2025-12-13 00:50:26,878 INFO     Training average loss at step 67800: 0.391638
2025-12-13 00:50:29,055 INFO     Training average regularization at step 67900: 0.303639
2025-12-13 00:50:29,056 INFO     Training average positive_sample_loss at step 67900: 0.065183
2025-12-13 00:50:29,056 INFO     Training average negative_sample_loss at step 67900: 0.107437
2025-12-13 00:50:29,056 INFO     Training average loss at step 67900: 0.389949
2025-12-13 00:50:31,209 INFO     Training average regularization at step 68000: 0.303630
2025-12-13 00:50:31,209 INFO     Training average positive_sample_loss at step 68000: 0.067061
2025-12-13 00:50:31,210 INFO     Training average negative_sample_loss at step 68000: 0.106707
2025-12-13 00:50:31,210 INFO     Training average loss at step 68000: 0.390514
2025-12-13 00:50:33,370 INFO     Training average regularization at step 68100: 0.303623
2025-12-13 00:50:33,371 INFO     Training average positive_sample_loss at step 68100: 0.066363
2025-12-13 00:50:33,371 INFO     Training average negative_sample_loss at step 68100: 0.109757
2025-12-13 00:50:33,371 INFO     Training average loss at step 68100: 0.391683
2025-12-13 00:50:35,528 INFO     Training average regularization at step 68200: 0.303613
2025-12-13 00:50:35,528 INFO     Training average positive_sample_loss at step 68200: 0.065135
2025-12-13 00:50:35,528 INFO     Training average negative_sample_loss at step 68200: 0.111020
2025-12-13 00:50:35,528 INFO     Training average loss at step 68200: 0.391690
2025-12-13 00:50:37,699 INFO     Training average regularization at step 68300: 0.303602
2025-12-13 00:50:37,699 INFO     Training average positive_sample_loss at step 68300: 0.064541
2025-12-13 00:50:37,699 INFO     Training average negative_sample_loss at step 68300: 0.107399
2025-12-13 00:50:37,699 INFO     Training average loss at step 68300: 0.389572
2025-12-13 00:50:39,933 INFO     Training average regularization at step 68400: 0.303594
2025-12-13 00:50:39,933 INFO     Training average positive_sample_loss at step 68400: 0.066949
2025-12-13 00:50:39,933 INFO     Training average negative_sample_loss at step 68400: 0.108271
2025-12-13 00:50:39,933 INFO     Training average loss at step 68400: 0.391204
2025-12-13 00:50:42,162 INFO     Training average regularization at step 68500: 0.303587
2025-12-13 00:50:42,163 INFO     Training average positive_sample_loss at step 68500: 0.065915
2025-12-13 00:50:42,163 INFO     Training average negative_sample_loss at step 68500: 0.107688
2025-12-13 00:50:42,163 INFO     Training average loss at step 68500: 0.390388
2025-12-13 00:50:44,341 INFO     Training average regularization at step 68600: 0.303579
2025-12-13 00:50:44,341 INFO     Training average positive_sample_loss at step 68600: 0.067264
2025-12-13 00:50:44,341 INFO     Training average negative_sample_loss at step 68600: 0.108471
2025-12-13 00:50:44,341 INFO     Training average loss at step 68600: 0.391446
2025-12-13 00:50:46,525 INFO     Training average regularization at step 68700: 0.303572
2025-12-13 00:50:46,529 INFO     Training average positive_sample_loss at step 68700: 0.066518
2025-12-13 00:50:46,529 INFO     Training average negative_sample_loss at step 68700: 0.107481
2025-12-13 00:50:46,529 INFO     Training average loss at step 68700: 0.390571
2025-12-13 00:50:48,696 INFO     Training average regularization at step 68800: 0.303564
2025-12-13 00:50:48,696 INFO     Training average positive_sample_loss at step 68800: 0.065621
2025-12-13 00:50:48,696 INFO     Training average negative_sample_loss at step 68800: 0.107713
2025-12-13 00:50:48,696 INFO     Training average loss at step 68800: 0.390232
2025-12-13 00:50:50,859 INFO     Training average regularization at step 68900: 0.303556
2025-12-13 00:50:50,859 INFO     Training average positive_sample_loss at step 68900: 0.067057
2025-12-13 00:50:50,859 INFO     Training average negative_sample_loss at step 68900: 0.109225
2025-12-13 00:50:50,859 INFO     Training average loss at step 68900: 0.391697
2025-12-13 00:50:53,030 INFO     Training average regularization at step 69000: 0.303550
2025-12-13 00:50:53,033 INFO     Training average positive_sample_loss at step 69000: 0.066632
2025-12-13 00:50:53,033 INFO     Training average negative_sample_loss at step 69000: 0.107087
2025-12-13 00:50:53,033 INFO     Training average loss at step 69000: 0.390410
2025-12-13 00:50:55,189 INFO     Training average regularization at step 69100: 0.303544
2025-12-13 00:50:55,189 INFO     Training average positive_sample_loss at step 69100: 0.067449
2025-12-13 00:50:55,189 INFO     Training average negative_sample_loss at step 69100: 0.110152
2025-12-13 00:50:55,189 INFO     Training average loss at step 69100: 0.392344
2025-12-13 00:50:57,350 INFO     Training average regularization at step 69200: 0.303537
2025-12-13 00:50:57,350 INFO     Training average positive_sample_loss at step 69200: 0.066255
2025-12-13 00:50:57,350 INFO     Training average negative_sample_loss at step 69200: 0.106684
2025-12-13 00:50:57,350 INFO     Training average loss at step 69200: 0.390006
2025-12-13 00:50:59,502 INFO     Training average regularization at step 69300: 0.303529
2025-12-13 00:50:59,503 INFO     Training average positive_sample_loss at step 69300: 0.067256
2025-12-13 00:50:59,503 INFO     Training average negative_sample_loss at step 69300: 0.109234
2025-12-13 00:50:59,503 INFO     Training average loss at step 69300: 0.391774
2025-12-13 00:51:01,649 INFO     Training average regularization at step 69400: 0.303521
2025-12-13 00:51:01,650 INFO     Training average positive_sample_loss at step 69400: 0.065531
2025-12-13 00:51:01,650 INFO     Training average negative_sample_loss at step 69400: 0.109718
2025-12-13 00:51:01,650 INFO     Training average loss at step 69400: 0.391145
2025-12-13 00:51:03,817 INFO     Training average regularization at step 69500: 0.303514
2025-12-13 00:51:03,817 INFO     Training average positive_sample_loss at step 69500: 0.068106
2025-12-13 00:51:03,817 INFO     Training average negative_sample_loss at step 69500: 0.106952
2025-12-13 00:51:03,817 INFO     Training average loss at step 69500: 0.391043
2025-12-13 00:51:05,954 INFO     Training average regularization at step 69600: 0.303508
2025-12-13 00:51:05,954 INFO     Training average positive_sample_loss at step 69600: 0.066197
2025-12-13 00:51:05,954 INFO     Training average negative_sample_loss at step 69600: 0.109612
2025-12-13 00:51:05,954 INFO     Training average loss at step 69600: 0.391413
2025-12-13 00:51:08,110 INFO     Training average regularization at step 69700: 0.303501
2025-12-13 00:51:08,110 INFO     Training average positive_sample_loss at step 69700: 0.066531
2025-12-13 00:51:08,110 INFO     Training average negative_sample_loss at step 69700: 0.110044
2025-12-13 00:51:08,110 INFO     Training average loss at step 69700: 0.391789
2025-12-13 00:51:10,264 INFO     Training average regularization at step 69800: 0.303494
2025-12-13 00:51:10,264 INFO     Training average positive_sample_loss at step 69800: 0.067752
2025-12-13 00:51:10,264 INFO     Training average negative_sample_loss at step 69800: 0.109809
2025-12-13 00:51:10,264 INFO     Training average loss at step 69800: 0.392274
2025-12-13 00:51:12,422 INFO     Training average regularization at step 69900: 0.303487
2025-12-13 00:51:12,427 INFO     Training average positive_sample_loss at step 69900: 0.067825
2025-12-13 00:51:12,427 INFO     Training average negative_sample_loss at step 69900: 0.107933
2025-12-13 00:51:12,427 INFO     Training average loss at step 69900: 0.391366
2025-12-13 00:51:14,601 INFO     Training average regularization at step 70000: 0.303482
2025-12-13 00:51:14,602 INFO     Training average positive_sample_loss at step 70000: 0.066769
2025-12-13 00:51:14,602 INFO     Training average negative_sample_loss at step 70000: 0.110275
2025-12-13 00:51:14,602 INFO     Training average loss at step 70000: 0.392004
2025-12-13 00:51:14,602 INFO     Evaluating on Valid Dataset...
2025-12-13 00:51:15,237 INFO     Evaluating the model... (0/50000)
2025-12-13 00:51:17,793 INFO     Evaluating the model... (500/50000)
2025-12-13 00:51:20,177 INFO     Evaluating the model... (1000/50000)
2025-12-13 00:51:22,609 INFO     Evaluating the model... (1500/50000)
2025-12-13 00:51:26,173 INFO     Evaluating the model... (2000/50000)
2025-12-13 00:51:28,648 INFO     Evaluating the model... (2500/50000)
2025-12-13 00:51:31,019 INFO     Evaluating the model... (3000/50000)
2025-12-13 00:51:33,372 INFO     Evaluating the model... (3500/50000)
2025-12-13 00:51:36,046 INFO     Evaluating the model... (4000/50000)
2025-12-13 00:51:39,559 INFO     Evaluating the model... (4500/50000)
2025-12-13 00:51:42,199 INFO     Evaluating the model... (5000/50000)
2025-12-13 00:51:44,737 INFO     Evaluating the model... (5500/50000)
2025-12-13 00:51:47,202 INFO     Evaluating the model... (6000/50000)
2025-12-13 00:51:49,734 INFO     Evaluating the model... (6500/50000)
2025-12-13 00:51:52,881 INFO     Evaluating the model... (7000/50000)
2025-12-13 00:51:55,257 INFO     Evaluating the model... (7500/50000)
2025-12-13 00:51:57,783 INFO     Evaluating the model... (8000/50000)
2025-12-13 00:52:00,425 INFO     Evaluating the model... (8500/50000)
2025-12-13 00:52:02,797 INFO     Evaluating the model... (9000/50000)
2025-12-13 00:52:05,901 INFO     Evaluating the model... (9500/50000)
2025-12-13 00:52:08,322 INFO     Evaluating the model... (10000/50000)
2025-12-13 00:52:10,891 INFO     Evaluating the model... (10500/50000)
2025-12-13 00:52:13,253 INFO     Evaluating the model... (11000/50000)
2025-12-13 00:52:15,773 INFO     Evaluating the model... (11500/50000)
2025-12-13 00:52:18,805 INFO     Evaluating the model... (12000/50000)
2025-12-13 00:52:21,179 INFO     Evaluating the model... (12500/50000)
2025-12-13 00:52:23,681 INFO     Evaluating the model... (13000/50000)
2025-12-13 00:52:26,107 INFO     Evaluating the model... (13500/50000)
2025-12-13 00:52:28,576 INFO     Evaluating the model... (14000/50000)
2025-12-13 00:52:32,032 INFO     Evaluating the model... (14500/50000)
2025-12-13 00:52:34,660 INFO     Evaluating the model... (15000/50000)
2025-12-13 00:52:37,360 INFO     Evaluating the model... (15500/50000)
2025-12-13 00:52:40,040 INFO     Evaluating the model... (16000/50000)
2025-12-13 00:52:43,583 INFO     Evaluating the model... (16500/50000)
2025-12-13 00:52:46,372 INFO     Evaluating the model... (17000/50000)
2025-12-13 00:52:48,736 INFO     Evaluating the model... (17500/50000)
2025-12-13 00:52:51,076 INFO     Evaluating the model... (18000/50000)
2025-12-13 00:52:53,415 INFO     Evaluating the model... (18500/50000)
2025-12-13 00:52:56,814 INFO     Evaluating the model... (19000/50000)
2025-12-13 00:52:59,230 INFO     Evaluating the model... (19500/50000)
2025-12-13 00:53:01,580 INFO     Evaluating the model... (20000/50000)
2025-12-13 00:53:04,056 INFO     Evaluating the model... (20500/50000)
2025-12-13 00:53:06,579 INFO     Evaluating the model... (21000/50000)
2025-12-13 00:53:10,001 INFO     Evaluating the model... (21500/50000)
2025-12-13 00:53:12,380 INFO     Evaluating the model... (22000/50000)
2025-12-13 00:53:14,742 INFO     Evaluating the model... (22500/50000)
2025-12-13 00:53:17,292 INFO     Evaluating the model... (23000/50000)
2025-12-13 00:53:19,794 INFO     Evaluating the model... (23500/50000)
2025-12-13 00:53:23,502 INFO     Evaluating the model... (24000/50000)
2025-12-13 00:53:26,028 INFO     Evaluating the model... (24500/50000)
2025-12-13 00:53:28,806 INFO     Evaluating the model... (25000/50000)
2025-12-13 00:53:31,677 INFO     Evaluating the model... (25500/50000)
2025-12-13 00:53:34,227 INFO     Evaluating the model... (26000/50000)
2025-12-13 00:53:38,010 INFO     Evaluating the model... (26500/50000)
2025-12-13 00:53:40,722 INFO     Evaluating the model... (27000/50000)
2025-12-13 00:53:43,797 INFO     Evaluating the model... (27500/50000)
2025-12-13 00:53:46,417 INFO     Evaluating the model... (28000/50000)
2025-12-13 00:53:48,945 INFO     Evaluating the model... (28500/50000)
2025-12-13 00:53:52,042 INFO     Evaluating the model... (29000/50000)
2025-12-13 00:53:54,758 INFO     Evaluating the model... (29500/50000)
2025-12-13 00:53:57,364 INFO     Evaluating the model... (30000/50000)
2025-12-13 00:53:59,923 INFO     Evaluating the model... (30500/50000)
2025-12-13 00:54:02,336 INFO     Evaluating the model... (31000/50000)
2025-12-13 00:54:05,579 INFO     Evaluating the model... (31500/50000)
2025-12-13 00:54:08,097 INFO     Evaluating the model... (32000/50000)
2025-12-13 00:54:10,601 INFO     Evaluating the model... (32500/50000)
2025-12-13 00:54:13,049 INFO     Evaluating the model... (33000/50000)
2025-12-13 00:54:15,515 INFO     Evaluating the model... (33500/50000)
2025-12-13 00:54:19,021 INFO     Evaluating the model... (34000/50000)
2025-12-13 00:54:21,438 INFO     Evaluating the model... (34500/50000)
2025-12-13 00:54:23,850 INFO     Evaluating the model... (35000/50000)
2025-12-13 00:54:26,361 INFO     Evaluating the model... (35500/50000)
2025-12-13 00:54:29,131 INFO     Evaluating the model... (36000/50000)
2025-12-13 00:54:32,505 INFO     Evaluating the model... (36500/50000)
2025-12-13 00:54:35,085 INFO     Evaluating the model... (37000/50000)
2025-12-13 00:54:37,701 INFO     Evaluating the model... (37500/50000)
2025-12-13 00:54:40,660 INFO     Evaluating the model... (38000/50000)
2025-12-13 00:54:43,343 INFO     Evaluating the model... (38500/50000)
2025-12-13 00:54:46,965 INFO     Evaluating the model... (39000/50000)
2025-12-13 00:54:49,489 INFO     Evaluating the model... (39500/50000)
2025-12-13 00:54:52,178 INFO     Evaluating the model... (40000/50000)
2025-12-13 00:54:54,728 INFO     Evaluating the model... (40500/50000)
2025-12-13 00:54:57,252 INFO     Evaluating the model... (41000/50000)
2025-12-13 00:55:00,641 INFO     Evaluating the model... (41500/50000)
2025-12-13 00:55:03,292 INFO     Evaluating the model... (42000/50000)
2025-12-13 00:55:05,834 INFO     Evaluating the model... (42500/50000)
2025-12-13 00:55:08,281 INFO     Evaluating the model... (43000/50000)
2025-12-13 00:55:11,925 INFO     Evaluating the model... (43500/50000)
2025-12-13 00:55:14,456 INFO     Evaluating the model... (44000/50000)
2025-12-13 00:55:17,060 INFO     Evaluating the model... (44500/50000)
2025-12-13 00:55:19,558 INFO     Evaluating the model... (45000/50000)
2025-12-13 00:55:21,962 INFO     Evaluating the model... (45500/50000)
2025-12-13 00:55:25,844 INFO     Evaluating the model... (46000/50000)
2025-12-13 00:55:28,283 INFO     Evaluating the model... (46500/50000)
2025-12-13 00:55:30,735 INFO     Evaluating the model... (47000/50000)
2025-12-13 00:55:33,109 INFO     Evaluating the model... (47500/50000)
2025-12-13 00:55:35,815 INFO     Evaluating the model... (48000/50000)
2025-12-13 00:55:40,217 INFO     Evaluating the model... (48500/50000)
2025-12-13 00:55:42,771 INFO     Evaluating the model... (49000/50000)
2025-12-13 00:55:45,469 INFO     Evaluating the model... (49500/50000)
2025-12-13 00:55:48,244 INFO     Valid MRR at step 70000: 0.623226
2025-12-13 00:55:48,244 INFO     Valid MR at step 70000: 266.626200
2025-12-13 00:55:48,244 INFO     Valid HITS@1 at step 70000: 0.534730
2025-12-13 00:55:48,244 INFO     Valid HITS@3 at step 70000: 0.677290
2025-12-13 00:55:48,244 INFO     Valid HITS@10 at step 70000: 0.780260
2025-12-13 00:55:49,320 INFO     Evaluating on Test Dataset...
2025-12-13 00:55:49,861 INFO     Evaluating the model... (0/59072)
2025-12-13 00:55:52,410 INFO     Evaluating the model... (500/59072)
2025-12-13 00:55:56,015 INFO     Evaluating the model... (1000/59072)
2025-12-13 00:55:58,447 INFO     Evaluating the model... (1500/59072)
2025-12-13 00:56:01,122 INFO     Evaluating the model... (2000/59072)
2025-12-13 00:56:03,657 INFO     Evaluating the model... (2500/59072)
2025-12-13 00:56:06,136 INFO     Evaluating the model... (3000/59072)
2025-12-13 00:56:09,472 INFO     Evaluating the model... (3500/59072)
2025-12-13 00:56:12,142 INFO     Evaluating the model... (4000/59072)
2025-12-13 00:56:14,506 INFO     Evaluating the model... (4500/59072)
2025-12-13 00:56:16,982 INFO     Evaluating the model... (5000/59072)
2025-12-13 00:56:19,495 INFO     Evaluating the model... (5500/59072)
2025-12-13 00:56:22,966 INFO     Evaluating the model... (6000/59072)
2025-12-13 00:56:25,441 INFO     Evaluating the model... (6500/59072)
2025-12-13 00:56:27,821 INFO     Evaluating the model... (7000/59072)
2025-12-13 00:56:30,269 INFO     Evaluating the model... (7500/59072)
2025-12-13 00:56:32,621 INFO     Evaluating the model... (8000/59072)
2025-12-13 00:56:35,901 INFO     Evaluating the model... (8500/59072)
2025-12-13 00:56:38,672 INFO     Evaluating the model... (9000/59072)
2025-12-13 00:56:41,346 INFO     Evaluating the model... (9500/59072)
2025-12-13 00:56:44,029 INFO     Evaluating the model... (10000/59072)
2025-12-13 00:56:46,878 INFO     Evaluating the model... (10500/59072)
2025-12-13 00:56:49,880 INFO     Evaluating the model... (11000/59072)
2025-12-13 00:56:52,244 INFO     Evaluating the model... (11500/59072)
2025-12-13 00:56:54,605 INFO     Evaluating the model... (12000/59072)
2025-12-13 00:56:57,079 INFO     Evaluating the model... (12500/59072)
2025-12-13 00:56:59,663 INFO     Evaluating the model... (13000/59072)
2025-12-13 00:57:02,408 INFO     Evaluating the model... (13500/59072)
2025-12-13 00:57:04,870 INFO     Evaluating the model... (14000/59072)
2025-12-13 00:57:07,400 INFO     Evaluating the model... (14500/59072)
2025-12-13 00:57:10,069 INFO     Evaluating the model... (15000/59072)
2025-12-13 00:57:12,416 INFO     Evaluating the model... (15500/59072)
2025-12-13 00:57:15,517 INFO     Evaluating the model... (16000/59072)
2025-12-13 00:57:17,910 INFO     Evaluating the model... (16500/59072)
2025-12-13 00:57:20,447 INFO     Evaluating the model... (17000/59072)
2025-12-13 00:57:23,003 INFO     Evaluating the model... (17500/59072)
2025-12-13 00:57:25,369 INFO     Evaluating the model... (18000/59072)
2025-12-13 00:57:28,484 INFO     Evaluating the model... (18500/59072)
2025-12-13 00:57:30,947 INFO     Evaluating the model... (19000/59072)
2025-12-13 00:57:33,635 INFO     Evaluating the model... (19500/59072)
2025-12-13 00:57:36,194 INFO     Evaluating the model... (20000/59072)
2025-12-13 00:57:39,392 INFO     Evaluating the model... (20500/59072)
2025-12-13 00:57:41,901 INFO     Evaluating the model... (21000/59072)
2025-12-13 00:57:44,613 INFO     Evaluating the model... (21500/59072)
2025-12-13 00:57:47,145 INFO     Evaluating the model... (22000/59072)
2025-12-13 00:57:49,625 INFO     Evaluating the model... (22500/59072)
2025-12-13 00:57:52,908 INFO     Evaluating the model... (23000/59072)
2025-12-13 00:57:55,617 INFO     Evaluating the model... (23500/59072)
2025-12-13 00:57:58,032 INFO     Evaluating the model... (24000/59072)
2025-12-13 00:58:00,582 INFO     Evaluating the model... (24500/59072)
2025-12-13 00:58:03,035 INFO     Evaluating the model... (25000/59072)
2025-12-13 00:58:06,495 INFO     Evaluating the model... (25500/59072)
2025-12-13 00:58:08,996 INFO     Evaluating the model... (26000/59072)
2025-12-13 00:58:11,479 INFO     Evaluating the model... (26500/59072)
2025-12-13 00:58:14,006 INFO     Evaluating the model... (27000/59072)
2025-12-13 00:58:16,533 INFO     Evaluating the model... (27500/59072)
2025-12-13 00:58:20,214 INFO     Evaluating the model... (28000/59072)
2025-12-13 00:58:22,746 INFO     Evaluating the model... (28500/59072)
2025-12-13 00:58:25,332 INFO     Evaluating the model... (29000/59072)
2025-12-13 00:58:27,910 INFO     Evaluating the model... (29500/59072)
2025-12-13 00:58:30,943 INFO     Evaluating the model... (30000/59072)
2025-12-13 00:58:34,717 INFO     Evaluating the model... (30500/59072)
2025-12-13 00:58:37,580 INFO     Evaluating the model... (31000/59072)
2025-12-13 00:58:40,464 INFO     Evaluating the model... (31500/59072)
2025-12-13 00:58:43,469 INFO     Evaluating the model... (32000/59072)
2025-12-13 00:58:46,942 INFO     Evaluating the model... (32500/59072)
2025-12-13 00:58:49,402 INFO     Evaluating the model... (33000/59072)
2025-12-13 00:58:52,073 INFO     Evaluating the model... (33500/59072)
2025-12-13 00:58:54,759 INFO     Evaluating the model... (34000/59072)
2025-12-13 00:58:57,365 INFO     Evaluating the model... (34500/59072)
2025-12-13 00:59:00,429 INFO     Evaluating the model... (35000/59072)
2025-12-13 00:59:02,858 INFO     Evaluating the model... (35500/59072)
2025-12-13 00:59:05,643 INFO     Evaluating the model... (36000/59072)
2025-12-13 00:59:08,170 INFO     Evaluating the model... (36500/59072)
2025-12-13 00:59:10,630 INFO     Evaluating the model... (37000/59072)
2025-12-13 00:59:13,675 INFO     Evaluating the model... (37500/59072)
2025-12-13 00:59:16,441 INFO     Evaluating the model... (38000/59072)
2025-12-13 00:59:18,853 INFO     Evaluating the model... (38500/59072)
2025-12-13 00:59:21,372 INFO     Evaluating the model... (39000/59072)
2025-12-13 00:59:23,843 INFO     Evaluating the model... (39500/59072)
2025-12-13 00:59:27,150 INFO     Evaluating the model... (40000/59072)
2025-12-13 00:59:29,645 INFO     Evaluating the model... (40500/59072)
2025-12-13 00:59:32,398 INFO     Evaluating the model... (41000/59072)
2025-12-13 00:59:34,905 INFO     Evaluating the model... (41500/59072)
2025-12-13 00:59:37,604 INFO     Evaluating the model... (42000/59072)
2025-12-13 00:59:41,174 INFO     Evaluating the model... (42500/59072)
2025-12-13 00:59:43,922 INFO     Evaluating the model... (43000/59072)
2025-12-13 00:59:46,478 INFO     Evaluating the model... (43500/59072)
2025-12-13 00:59:48,953 INFO     Evaluating the model... (44000/59072)
2025-12-13 00:59:51,670 INFO     Evaluating the model... (44500/59072)
2025-12-13 00:59:55,097 INFO     Evaluating the model... (45000/59072)
2025-12-13 00:59:57,684 INFO     Evaluating the model... (45500/59072)
2025-12-13 01:00:00,104 INFO     Evaluating the model... (46000/59072)
2025-12-13 01:00:02,730 INFO     Evaluating the model... (46500/59072)
2025-12-13 01:00:05,184 INFO     Evaluating the model... (47000/59072)
2025-12-13 01:00:08,763 INFO     Evaluating the model... (47500/59072)
2025-12-13 01:00:11,205 INFO     Evaluating the model... (48000/59072)
2025-12-13 01:00:13,833 INFO     Evaluating the model... (48500/59072)
2025-12-13 01:00:16,344 INFO     Evaluating the model... (49000/59072)
2025-12-13 01:00:18,697 INFO     Evaluating the model... (49500/59072)
2025-12-13 01:00:22,040 INFO     Evaluating the model... (50000/59072)
2025-12-13 01:00:24,606 INFO     Evaluating the model... (50500/59072)
2025-12-13 01:00:27,172 INFO     Evaluating the model... (51000/59072)
2025-12-13 01:00:29,554 INFO     Evaluating the model... (51500/59072)
2025-12-13 01:00:32,769 INFO     Evaluating the model... (52000/59072)
2025-12-13 01:00:35,810 INFO     Evaluating the model... (52500/59072)
2025-12-13 01:00:38,705 INFO     Evaluating the model... (53000/59072)
2025-12-13 01:00:41,535 INFO     Evaluating the model... (53500/59072)
2025-12-13 01:00:44,146 INFO     Evaluating the model... (54000/59072)
2025-12-13 01:00:48,244 INFO     Evaluating the model... (54500/59072)
2025-12-13 01:00:50,660 INFO     Evaluating the model... (55000/59072)
2025-12-13 01:00:53,151 INFO     Evaluating the model... (55500/59072)
2025-12-13 01:00:55,690 INFO     Evaluating the model... (56000/59072)
2025-12-13 01:00:58,190 INFO     Evaluating the model... (56500/59072)
2025-12-13 01:01:02,226 INFO     Evaluating the model... (57000/59072)
2025-12-13 01:01:04,681 INFO     Evaluating the model... (57500/59072)
2025-12-13 01:01:07,284 INFO     Evaluating the model... (58000/59072)
2025-12-13 01:01:09,659 INFO     Evaluating the model... (58500/59072)
2025-12-13 01:01:12,387 INFO     Evaluating the model... (59000/59072)
2025-12-13 01:01:12,992 INFO     Test MRR at step 70000: 0.620331
2025-12-13 01:01:12,992 INFO     Test MR at step 70000: 268.042830
2025-12-13 01:01:12,992 INFO     Test HITS@1 at step 70000: 0.530438
2025-12-13 01:01:12,992 INFO     Test HITS@3 at step 70000: 0.676059
2025-12-13 01:01:12,992 INFO     Test HITS@10 at step 70000: 0.778081
2025-12-13 01:01:15,163 INFO     Training average regularization at step 70100: 0.303475
2025-12-13 01:01:15,163 INFO     Training average positive_sample_loss at step 70100: 0.066920
2025-12-13 01:01:15,163 INFO     Training average negative_sample_loss at step 70100: 0.107533
2025-12-13 01:01:15,163 INFO     Training average loss at step 70100: 0.390702
2025-12-13 01:01:17,325 INFO     Training average regularization at step 70200: 0.303468
2025-12-13 01:01:17,333 INFO     Training average positive_sample_loss at step 70200: 0.067086
2025-12-13 01:01:17,333 INFO     Training average negative_sample_loss at step 70200: 0.110022
2025-12-13 01:01:17,333 INFO     Training average loss at step 70200: 0.392022
2025-12-13 01:01:19,500 INFO     Training average regularization at step 70300: 0.303461
2025-12-13 01:01:19,501 INFO     Training average positive_sample_loss at step 70300: 0.067361
2025-12-13 01:01:19,501 INFO     Training average negative_sample_loss at step 70300: 0.108187
2025-12-13 01:01:19,501 INFO     Training average loss at step 70300: 0.391235
2025-12-13 01:01:21,702 INFO     Training average regularization at step 70400: 0.303453
2025-12-13 01:01:21,702 INFO     Training average positive_sample_loss at step 70400: 0.066844
2025-12-13 01:01:21,702 INFO     Training average negative_sample_loss at step 70400: 0.108244
2025-12-13 01:01:21,702 INFO     Training average loss at step 70400: 0.390997
2025-12-13 01:01:23,894 INFO     Training average regularization at step 70500: 0.303446
2025-12-13 01:01:23,894 INFO     Training average positive_sample_loss at step 70500: 0.067786
2025-12-13 01:01:23,895 INFO     Training average negative_sample_loss at step 70500: 0.110364
2025-12-13 01:01:23,895 INFO     Training average loss at step 70500: 0.392521
2025-12-13 01:01:26,113 INFO     Training average regularization at step 70600: 0.303439
2025-12-13 01:01:26,113 INFO     Training average positive_sample_loss at step 70600: 0.068119
2025-12-13 01:01:26,113 INFO     Training average negative_sample_loss at step 70600: 0.112014
2025-12-13 01:01:26,113 INFO     Training average loss at step 70600: 0.393506
2025-12-13 01:01:28,300 INFO     Training average regularization at step 70700: 0.303433
2025-12-13 01:01:28,300 INFO     Training average positive_sample_loss at step 70700: 0.068003
2025-12-13 01:01:28,300 INFO     Training average negative_sample_loss at step 70700: 0.108671
2025-12-13 01:01:28,301 INFO     Training average loss at step 70700: 0.391769
2025-12-13 01:01:30,483 INFO     Training average regularization at step 70800: 0.303427
2025-12-13 01:01:30,509 INFO     Training average positive_sample_loss at step 70800: 0.068067
2025-12-13 01:01:30,509 INFO     Training average negative_sample_loss at step 70800: 0.108428
2025-12-13 01:01:30,509 INFO     Training average loss at step 70800: 0.391674
2025-12-13 01:01:32,701 INFO     Training average regularization at step 70900: 0.303421
2025-12-13 01:01:32,701 INFO     Training average positive_sample_loss at step 70900: 0.067610
2025-12-13 01:01:32,701 INFO     Training average negative_sample_loss at step 70900: 0.109022
2025-12-13 01:01:32,701 INFO     Training average loss at step 70900: 0.391738
2025-12-13 01:01:34,860 INFO     Training average regularization at step 71000: 0.303415
2025-12-13 01:01:34,860 INFO     Training average positive_sample_loss at step 71000: 0.067041
2025-12-13 01:01:34,860 INFO     Training average negative_sample_loss at step 71000: 0.107604
2025-12-13 01:01:34,860 INFO     Training average loss at step 71000: 0.390738
2025-12-13 01:01:37,050 INFO     Training average regularization at step 71100: 0.303409
2025-12-13 01:01:37,050 INFO     Training average positive_sample_loss at step 71100: 0.068668
2025-12-13 01:01:37,050 INFO     Training average negative_sample_loss at step 71100: 0.108092
2025-12-13 01:01:37,050 INFO     Training average loss at step 71100: 0.391789
2025-12-13 01:01:39,260 INFO     Training average regularization at step 71200: 0.303405
2025-12-13 01:01:39,260 INFO     Training average positive_sample_loss at step 71200: 0.067360
2025-12-13 01:01:39,260 INFO     Training average negative_sample_loss at step 71200: 0.111896
2025-12-13 01:01:39,260 INFO     Training average loss at step 71200: 0.393033
2025-12-13 01:01:41,434 INFO     Training average regularization at step 71300: 0.303398
2025-12-13 01:01:41,434 INFO     Training average positive_sample_loss at step 71300: 0.068035
2025-12-13 01:01:41,434 INFO     Training average negative_sample_loss at step 71300: 0.110289
2025-12-13 01:01:41,434 INFO     Training average loss at step 71300: 0.392560
2025-12-13 01:01:43,606 INFO     Training average regularization at step 71400: 0.303391
2025-12-13 01:01:43,606 INFO     Training average positive_sample_loss at step 71400: 0.067902
2025-12-13 01:01:43,606 INFO     Training average negative_sample_loss at step 71400: 0.107481
2025-12-13 01:01:43,606 INFO     Training average loss at step 71400: 0.391083
2025-12-13 01:01:45,828 INFO     Training average regularization at step 71500: 0.303386
2025-12-13 01:01:45,828 INFO     Training average positive_sample_loss at step 71500: 0.069179
2025-12-13 01:01:45,828 INFO     Training average negative_sample_loss at step 71500: 0.110340
2025-12-13 01:01:45,828 INFO     Training average loss at step 71500: 0.393145
2025-12-13 01:01:47,983 INFO     Training average regularization at step 71600: 0.303381
2025-12-13 01:01:47,983 INFO     Training average positive_sample_loss at step 71600: 0.068387
2025-12-13 01:01:47,983 INFO     Training average negative_sample_loss at step 71600: 0.107968
2025-12-13 01:01:47,983 INFO     Training average loss at step 71600: 0.391559
2025-12-13 01:01:50,133 INFO     Training average regularization at step 71700: 0.303376
2025-12-13 01:01:50,133 INFO     Training average positive_sample_loss at step 71700: 0.066512
2025-12-13 01:01:50,133 INFO     Training average negative_sample_loss at step 71700: 0.108698
2025-12-13 01:01:50,133 INFO     Training average loss at step 71700: 0.390981
2025-12-13 01:01:52,285 INFO     Training average regularization at step 71800: 0.303370
2025-12-13 01:01:52,285 INFO     Training average positive_sample_loss at step 71800: 0.068280
2025-12-13 01:01:52,285 INFO     Training average negative_sample_loss at step 71800: 0.110072
2025-12-13 01:01:52,285 INFO     Training average loss at step 71800: 0.392546
2025-12-13 01:01:54,438 INFO     Training average regularization at step 71900: 0.303363
2025-12-13 01:01:54,438 INFO     Training average positive_sample_loss at step 71900: 0.066866
2025-12-13 01:01:54,439 INFO     Training average negative_sample_loss at step 71900: 0.110631
2025-12-13 01:01:54,439 INFO     Training average loss at step 71900: 0.392111
2025-12-13 01:01:56,577 INFO     Training average regularization at step 72000: 0.303357
2025-12-13 01:01:56,578 INFO     Training average positive_sample_loss at step 72000: 0.068678
2025-12-13 01:01:56,578 INFO     Training average negative_sample_loss at step 72000: 0.108230
2025-12-13 01:01:56,578 INFO     Training average loss at step 72000: 0.391811
2025-12-13 01:01:58,735 INFO     Training average regularization at step 72100: 0.303351
2025-12-13 01:01:58,736 INFO     Training average positive_sample_loss at step 72100: 0.068607
2025-12-13 01:01:58,736 INFO     Training average negative_sample_loss at step 72100: 0.107551
2025-12-13 01:01:58,736 INFO     Training average loss at step 72100: 0.391430
2025-12-13 01:02:00,888 INFO     Training average regularization at step 72200: 0.303345
2025-12-13 01:02:00,888 INFO     Training average positive_sample_loss at step 72200: 0.067999
2025-12-13 01:02:00,888 INFO     Training average negative_sample_loss at step 72200: 0.108044
2025-12-13 01:02:00,888 INFO     Training average loss at step 72200: 0.391367
2025-12-13 01:02:03,030 INFO     Training average regularization at step 72300: 0.303339
2025-12-13 01:02:03,030 INFO     Training average positive_sample_loss at step 72300: 0.067414
2025-12-13 01:02:03,030 INFO     Training average negative_sample_loss at step 72300: 0.110083
2025-12-13 01:02:03,030 INFO     Training average loss at step 72300: 0.392088
2025-12-13 01:02:05,188 INFO     Training average regularization at step 72400: 0.303333
2025-12-13 01:02:05,189 INFO     Training average positive_sample_loss at step 72400: 0.068211
2025-12-13 01:02:05,189 INFO     Training average negative_sample_loss at step 72400: 0.109229
2025-12-13 01:02:05,189 INFO     Training average loss at step 72400: 0.392053
2025-12-13 01:02:08,400 INFO     Training average regularization at step 72500: 0.303326
2025-12-13 01:02:08,401 INFO     Training average positive_sample_loss at step 72500: 0.066107
2025-12-13 01:02:08,401 INFO     Training average negative_sample_loss at step 72500: 0.109052
2025-12-13 01:02:08,401 INFO     Training average loss at step 72500: 0.390905
2025-12-13 01:02:10,548 INFO     Training average regularization at step 72600: 0.303316
2025-12-13 01:02:10,550 INFO     Training average positive_sample_loss at step 72600: 0.066374
2025-12-13 01:02:10,550 INFO     Training average negative_sample_loss at step 72600: 0.109403
2025-12-13 01:02:10,550 INFO     Training average loss at step 72600: 0.391204
2025-12-13 01:02:12,804 INFO     Training average regularization at step 72700: 0.303308
2025-12-13 01:02:12,804 INFO     Training average positive_sample_loss at step 72700: 0.066290
2025-12-13 01:02:12,804 INFO     Training average negative_sample_loss at step 72700: 0.109670
2025-12-13 01:02:12,804 INFO     Training average loss at step 72700: 0.391288
2025-12-13 01:02:15,170 INFO     Training average regularization at step 72800: 0.303300
2025-12-13 01:02:15,171 INFO     Training average positive_sample_loss at step 72800: 0.065230
2025-12-13 01:02:15,171 INFO     Training average negative_sample_loss at step 72800: 0.108341
2025-12-13 01:02:15,171 INFO     Training average loss at step 72800: 0.390086
2025-12-13 01:02:17,370 INFO     Training average regularization at step 72900: 0.303291
2025-12-13 01:02:17,371 INFO     Training average positive_sample_loss at step 72900: 0.066210
2025-12-13 01:02:17,371 INFO     Training average negative_sample_loss at step 72900: 0.108770
2025-12-13 01:02:17,371 INFO     Training average loss at step 72900: 0.390781
2025-12-13 01:02:19,531 INFO     Training average regularization at step 73000: 0.303281
2025-12-13 01:02:19,531 INFO     Training average positive_sample_loss at step 73000: 0.065602
2025-12-13 01:02:19,531 INFO     Training average negative_sample_loss at step 73000: 0.108482
2025-12-13 01:02:19,531 INFO     Training average loss at step 73000: 0.390324
2025-12-13 01:02:21,688 INFO     Training average regularization at step 73100: 0.303273
2025-12-13 01:02:21,689 INFO     Training average positive_sample_loss at step 73100: 0.065927
2025-12-13 01:02:21,689 INFO     Training average negative_sample_loss at step 73100: 0.107649
2025-12-13 01:02:21,689 INFO     Training average loss at step 73100: 0.390061
2025-12-13 01:02:23,842 INFO     Training average regularization at step 73200: 0.303264
2025-12-13 01:02:23,843 INFO     Training average positive_sample_loss at step 73200: 0.066589
2025-12-13 01:02:23,843 INFO     Training average negative_sample_loss at step 73200: 0.108091
2025-12-13 01:02:23,843 INFO     Training average loss at step 73200: 0.390604
2025-12-13 01:02:26,005 INFO     Training average regularization at step 73300: 0.303255
2025-12-13 01:02:26,005 INFO     Training average positive_sample_loss at step 73300: 0.066628
2025-12-13 01:02:26,005 INFO     Training average negative_sample_loss at step 73300: 0.107655
2025-12-13 01:02:26,006 INFO     Training average loss at step 73300: 0.390397
2025-12-13 01:02:28,200 INFO     Training average regularization at step 73400: 0.303247
2025-12-13 01:02:28,200 INFO     Training average positive_sample_loss at step 73400: 0.066973
2025-12-13 01:02:28,200 INFO     Training average negative_sample_loss at step 73400: 0.108549
2025-12-13 01:02:28,200 INFO     Training average loss at step 73400: 0.391009
2025-12-13 01:02:30,360 INFO     Training average regularization at step 73500: 0.303240
2025-12-13 01:02:30,376 INFO     Training average positive_sample_loss at step 73500: 0.066725
2025-12-13 01:02:30,376 INFO     Training average negative_sample_loss at step 73500: 0.109273
2025-12-13 01:02:30,376 INFO     Training average loss at step 73500: 0.391238
2025-12-13 01:02:32,543 INFO     Training average regularization at step 73600: 0.303233
2025-12-13 01:02:32,544 INFO     Training average positive_sample_loss at step 73600: 0.066412
2025-12-13 01:02:32,544 INFO     Training average negative_sample_loss at step 73600: 0.108633
2025-12-13 01:02:32,544 INFO     Training average loss at step 73600: 0.390756
2025-12-13 01:02:34,697 INFO     Training average regularization at step 73700: 0.303227
2025-12-13 01:02:34,697 INFO     Training average positive_sample_loss at step 73700: 0.067335
2025-12-13 01:02:34,697 INFO     Training average negative_sample_loss at step 73700: 0.108259
2025-12-13 01:02:34,697 INFO     Training average loss at step 73700: 0.391024
2025-12-13 01:02:36,893 INFO     Training average regularization at step 73800: 0.303220
2025-12-13 01:02:36,893 INFO     Training average positive_sample_loss at step 73800: 0.067323
2025-12-13 01:02:36,893 INFO     Training average negative_sample_loss at step 73800: 0.110181
2025-12-13 01:02:36,893 INFO     Training average loss at step 73800: 0.391972
2025-12-13 01:02:39,104 INFO     Training average regularization at step 73900: 0.303214
2025-12-13 01:02:39,105 INFO     Training average positive_sample_loss at step 73900: 0.066313
2025-12-13 01:02:39,105 INFO     Training average negative_sample_loss at step 73900: 0.108074
2025-12-13 01:02:39,105 INFO     Training average loss at step 73900: 0.390408
2025-12-13 01:02:41,325 INFO     Training average regularization at step 74000: 0.303207
2025-12-13 01:02:41,325 INFO     Training average positive_sample_loss at step 74000: 0.066058
2025-12-13 01:02:41,325 INFO     Training average negative_sample_loss at step 74000: 0.108421
2025-12-13 01:02:41,326 INFO     Training average loss at step 74000: 0.390446
2025-12-13 01:02:43,527 INFO     Training average regularization at step 74100: 0.303198
2025-12-13 01:02:43,530 INFO     Training average positive_sample_loss at step 74100: 0.066416
2025-12-13 01:02:43,530 INFO     Training average negative_sample_loss at step 74100: 0.109970
2025-12-13 01:02:43,530 INFO     Training average loss at step 74100: 0.391391
2025-12-13 01:02:45,701 INFO     Training average regularization at step 74200: 0.303191
2025-12-13 01:02:45,701 INFO     Training average positive_sample_loss at step 74200: 0.065935
2025-12-13 01:02:45,701 INFO     Training average negative_sample_loss at step 74200: 0.111279
2025-12-13 01:02:45,701 INFO     Training average loss at step 74200: 0.391798
2025-12-13 01:02:47,846 INFO     Training average regularization at step 74300: 0.303183
2025-12-13 01:02:47,846 INFO     Training average positive_sample_loss at step 74300: 0.067120
2025-12-13 01:02:47,846 INFO     Training average negative_sample_loss at step 74300: 0.109138
2025-12-13 01:02:47,846 INFO     Training average loss at step 74300: 0.391312
2025-12-13 01:02:50,019 INFO     Training average regularization at step 74400: 0.303176
2025-12-13 01:02:50,019 INFO     Training average positive_sample_loss at step 74400: 0.066719
2025-12-13 01:02:50,019 INFO     Training average negative_sample_loss at step 74400: 0.109566
2025-12-13 01:02:50,019 INFO     Training average loss at step 74400: 0.391318
2025-12-13 01:02:52,173 INFO     Training average regularization at step 74500: 0.303169
2025-12-13 01:02:52,173 INFO     Training average positive_sample_loss at step 74500: 0.066907
2025-12-13 01:02:52,173 INFO     Training average negative_sample_loss at step 74500: 0.108335
2025-12-13 01:02:52,173 INFO     Training average loss at step 74500: 0.390790
2025-12-13 01:02:54,332 INFO     Training average regularization at step 74600: 0.303161
2025-12-13 01:02:54,332 INFO     Training average positive_sample_loss at step 74600: 0.066091
2025-12-13 01:02:54,332 INFO     Training average negative_sample_loss at step 74600: 0.108339
2025-12-13 01:02:54,332 INFO     Training average loss at step 74600: 0.390376
2025-12-13 01:02:56,501 INFO     Training average regularization at step 74700: 0.303154
2025-12-13 01:02:56,501 INFO     Training average positive_sample_loss at step 74700: 0.067118
2025-12-13 01:02:56,501 INFO     Training average negative_sample_loss at step 74700: 0.107220
2025-12-13 01:02:56,502 INFO     Training average loss at step 74700: 0.390324
2025-12-13 01:02:58,677 INFO     Training average regularization at step 74800: 0.303150
2025-12-13 01:02:58,678 INFO     Training average positive_sample_loss at step 74800: 0.068088
2025-12-13 01:02:58,678 INFO     Training average negative_sample_loss at step 74800: 0.105999
2025-12-13 01:02:58,678 INFO     Training average loss at step 74800: 0.390193
2025-12-13 01:03:00,845 INFO     Training average regularization at step 74900: 0.303145
2025-12-13 01:03:00,846 INFO     Training average positive_sample_loss at step 74900: 0.067785
2025-12-13 01:03:00,846 INFO     Training average negative_sample_loss at step 74900: 0.107786
2025-12-13 01:03:00,846 INFO     Training average loss at step 74900: 0.390931
2025-12-13 01:03:03,004 INFO     Training average regularization at step 75000: 0.303139
2025-12-13 01:03:03,004 INFO     Training average positive_sample_loss at step 75000: 0.066296
2025-12-13 01:03:03,004 INFO     Training average negative_sample_loss at step 75000: 0.109958
2025-12-13 01:03:03,004 INFO     Training average loss at step 75000: 0.391266
2025-12-13 01:03:05,149 INFO     Training average regularization at step 75100: 0.303131
2025-12-13 01:03:05,150 INFO     Training average positive_sample_loss at step 75100: 0.067085
2025-12-13 01:03:05,150 INFO     Training average negative_sample_loss at step 75100: 0.110412
2025-12-13 01:03:05,150 INFO     Training average loss at step 75100: 0.391880
2025-12-13 01:03:07,304 INFO     Training average regularization at step 75200: 0.303123
2025-12-13 01:03:07,304 INFO     Training average positive_sample_loss at step 75200: 0.067311
2025-12-13 01:03:07,304 INFO     Training average negative_sample_loss at step 75200: 0.109542
2025-12-13 01:03:07,304 INFO     Training average loss at step 75200: 0.391550
2025-12-13 01:03:09,460 INFO     Training average regularization at step 75300: 0.303118
2025-12-13 01:03:09,460 INFO     Training average positive_sample_loss at step 75300: 0.069141
2025-12-13 01:03:09,460 INFO     Training average negative_sample_loss at step 75300: 0.107308
2025-12-13 01:03:09,460 INFO     Training average loss at step 75300: 0.391342
2025-12-13 01:03:11,629 INFO     Training average regularization at step 75400: 0.303113
2025-12-13 01:03:11,629 INFO     Training average positive_sample_loss at step 75400: 0.066828
2025-12-13 01:03:11,629 INFO     Training average negative_sample_loss at step 75400: 0.109716
2025-12-13 01:03:11,629 INFO     Training average loss at step 75400: 0.391385
2025-12-13 01:03:13,787 INFO     Training average regularization at step 75500: 0.303106
2025-12-13 01:03:13,787 INFO     Training average positive_sample_loss at step 75500: 0.066575
2025-12-13 01:03:13,787 INFO     Training average negative_sample_loss at step 75500: 0.109035
2025-12-13 01:03:13,787 INFO     Training average loss at step 75500: 0.390911
2025-12-13 01:03:15,937 INFO     Training average regularization at step 75600: 0.303101
2025-12-13 01:03:15,937 INFO     Training average positive_sample_loss at step 75600: 0.067857
2025-12-13 01:03:15,937 INFO     Training average negative_sample_loss at step 75600: 0.110234
2025-12-13 01:03:15,937 INFO     Training average loss at step 75600: 0.392147
2025-12-13 01:03:18,079 INFO     Training average regularization at step 75700: 0.303096
2025-12-13 01:03:18,080 INFO     Training average positive_sample_loss at step 75700: 0.068788
2025-12-13 01:03:18,080 INFO     Training average negative_sample_loss at step 75700: 0.110461
2025-12-13 01:03:18,080 INFO     Training average loss at step 75700: 0.392721
2025-12-13 01:03:20,232 INFO     Training average regularization at step 75800: 0.303090
2025-12-13 01:03:20,232 INFO     Training average positive_sample_loss at step 75800: 0.068233
2025-12-13 01:03:20,232 INFO     Training average negative_sample_loss at step 75800: 0.110839
2025-12-13 01:03:20,232 INFO     Training average loss at step 75800: 0.392626
2025-12-13 01:03:22,392 INFO     Training average regularization at step 75900: 0.303083
2025-12-13 01:03:22,392 INFO     Training average positive_sample_loss at step 75900: 0.066418
2025-12-13 01:03:22,392 INFO     Training average negative_sample_loss at step 75900: 0.110113
2025-12-13 01:03:22,392 INFO     Training average loss at step 75900: 0.391349
2025-12-13 01:03:24,561 INFO     Training average regularization at step 76000: 0.303076
2025-12-13 01:03:24,561 INFO     Training average positive_sample_loss at step 76000: 0.066784
2025-12-13 01:03:24,561 INFO     Training average negative_sample_loss at step 76000: 0.108804
2025-12-13 01:03:24,561 INFO     Training average loss at step 76000: 0.390870
2025-12-13 01:03:26,720 INFO     Training average regularization at step 76100: 0.303070
2025-12-13 01:03:26,720 INFO     Training average positive_sample_loss at step 76100: 0.066528
2025-12-13 01:03:26,720 INFO     Training average negative_sample_loss at step 76100: 0.107199
2025-12-13 01:03:26,720 INFO     Training average loss at step 76100: 0.389934
2025-12-13 01:03:28,874 INFO     Training average regularization at step 76200: 0.303065
2025-12-13 01:03:28,875 INFO     Training average positive_sample_loss at step 76200: 0.067103
2025-12-13 01:03:28,875 INFO     Training average negative_sample_loss at step 76200: 0.109986
2025-12-13 01:03:28,875 INFO     Training average loss at step 76200: 0.391610
2025-12-13 01:03:31,026 INFO     Training average regularization at step 76300: 0.303058
2025-12-13 01:03:31,026 INFO     Training average positive_sample_loss at step 76300: 0.067861
2025-12-13 01:03:31,026 INFO     Training average negative_sample_loss at step 76300: 0.109274
2025-12-13 01:03:31,026 INFO     Training average loss at step 76300: 0.391625
2025-12-13 01:03:33,194 INFO     Training average regularization at step 76400: 0.303052
2025-12-13 01:03:33,194 INFO     Training average positive_sample_loss at step 76400: 0.069443
2025-12-13 01:03:33,194 INFO     Training average negative_sample_loss at step 76400: 0.110288
2025-12-13 01:03:33,194 INFO     Training average loss at step 76400: 0.392917
2025-12-13 01:03:35,343 INFO     Training average regularization at step 76500: 0.303047
2025-12-13 01:03:35,343 INFO     Training average positive_sample_loss at step 76500: 0.068628
2025-12-13 01:03:35,343 INFO     Training average negative_sample_loss at step 76500: 0.110494
2025-12-13 01:03:35,343 INFO     Training average loss at step 76500: 0.392608
2025-12-13 01:03:37,536 INFO     Training average regularization at step 76600: 0.303043
2025-12-13 01:03:37,536 INFO     Training average positive_sample_loss at step 76600: 0.067951
2025-12-13 01:03:37,536 INFO     Training average negative_sample_loss at step 76600: 0.111369
2025-12-13 01:03:37,536 INFO     Training average loss at step 76600: 0.392703
2025-12-13 01:03:39,733 INFO     Training average regularization at step 76700: 0.303036
2025-12-13 01:03:39,733 INFO     Training average positive_sample_loss at step 76700: 0.067761
2025-12-13 01:03:39,733 INFO     Training average negative_sample_loss at step 76700: 0.109553
2025-12-13 01:03:39,733 INFO     Training average loss at step 76700: 0.391693
2025-12-13 01:03:41,913 INFO     Training average regularization at step 76800: 0.303030
2025-12-13 01:03:41,913 INFO     Training average positive_sample_loss at step 76800: 0.068704
2025-12-13 01:03:41,913 INFO     Training average negative_sample_loss at step 76800: 0.108392
2025-12-13 01:03:41,913 INFO     Training average loss at step 76800: 0.391578
2025-12-13 01:03:44,123 INFO     Training average regularization at step 76900: 0.303025
2025-12-13 01:03:44,123 INFO     Training average positive_sample_loss at step 76900: 0.067657
2025-12-13 01:03:44,123 INFO     Training average negative_sample_loss at step 76900: 0.110017
2025-12-13 01:03:44,123 INFO     Training average loss at step 76900: 0.391862
2025-12-13 01:03:46,353 INFO     Training average regularization at step 77000: 0.303019
2025-12-13 01:03:46,353 INFO     Training average positive_sample_loss at step 77000: 0.068296
2025-12-13 01:03:46,353 INFO     Training average negative_sample_loss at step 77000: 0.110073
2025-12-13 01:03:46,353 INFO     Training average loss at step 77000: 0.392204
2025-12-13 01:03:48,498 INFO     Training average regularization at step 77100: 0.303014
2025-12-13 01:03:48,499 INFO     Training average positive_sample_loss at step 77100: 0.067094
2025-12-13 01:03:48,499 INFO     Training average negative_sample_loss at step 77100: 0.108459
2025-12-13 01:03:48,499 INFO     Training average loss at step 77100: 0.390790
2025-12-13 01:03:50,648 INFO     Training average regularization at step 77200: 0.303008
2025-12-13 01:03:50,648 INFO     Training average positive_sample_loss at step 77200: 0.067288
2025-12-13 01:03:50,648 INFO     Training average negative_sample_loss at step 77200: 0.108496
2025-12-13 01:03:50,648 INFO     Training average loss at step 77200: 0.390900
2025-12-13 01:03:52,924 INFO     Training average regularization at step 77300: 0.303002
2025-12-13 01:03:52,924 INFO     Training average positive_sample_loss at step 77300: 0.067920
2025-12-13 01:03:52,924 INFO     Training average negative_sample_loss at step 77300: 0.108537
2025-12-13 01:03:52,924 INFO     Training average loss at step 77300: 0.391230
2025-12-13 01:03:55,952 INFO     Training average regularization at step 77400: 0.302994
2025-12-13 01:03:55,952 INFO     Training average positive_sample_loss at step 77400: 0.066204
2025-12-13 01:03:55,952 INFO     Training average negative_sample_loss at step 77400: 0.106290
2025-12-13 01:03:55,952 INFO     Training average loss at step 77400: 0.389242
2025-12-13 01:03:58,118 INFO     Training average regularization at step 77500: 0.302987
2025-12-13 01:03:58,119 INFO     Training average positive_sample_loss at step 77500: 0.065148
2025-12-13 01:03:58,119 INFO     Training average negative_sample_loss at step 77500: 0.107161
2025-12-13 01:03:58,119 INFO     Training average loss at step 77500: 0.389141
2025-12-13 01:04:00,339 INFO     Training average regularization at step 77600: 0.302977
2025-12-13 01:04:00,339 INFO     Training average positive_sample_loss at step 77600: 0.065253
2025-12-13 01:04:00,339 INFO     Training average negative_sample_loss at step 77600: 0.107876
2025-12-13 01:04:00,339 INFO     Training average loss at step 77600: 0.389542
2025-12-13 01:04:02,511 INFO     Training average regularization at step 77700: 0.302969
2025-12-13 01:04:02,511 INFO     Training average positive_sample_loss at step 77700: 0.066679
2025-12-13 01:04:02,511 INFO     Training average negative_sample_loss at step 77700: 0.108458
2025-12-13 01:04:02,511 INFO     Training average loss at step 77700: 0.390537
2025-12-13 01:04:04,656 INFO     Training average regularization at step 77800: 0.302959
2025-12-13 01:04:04,656 INFO     Training average positive_sample_loss at step 77800: 0.065436
2025-12-13 01:04:04,656 INFO     Training average negative_sample_loss at step 77800: 0.108510
2025-12-13 01:04:04,656 INFO     Training average loss at step 77800: 0.389932
2025-12-13 01:04:06,795 INFO     Training average regularization at step 77900: 0.302950
2025-12-13 01:04:06,795 INFO     Training average positive_sample_loss at step 77900: 0.065269
2025-12-13 01:04:06,795 INFO     Training average negative_sample_loss at step 77900: 0.112030
2025-12-13 01:04:06,795 INFO     Training average loss at step 77900: 0.391599
2025-12-13 01:04:08,968 INFO     Training average regularization at step 78000: 0.302941
2025-12-13 01:04:08,968 INFO     Training average positive_sample_loss at step 78000: 0.066184
2025-12-13 01:04:08,968 INFO     Training average negative_sample_loss at step 78000: 0.107417
2025-12-13 01:04:08,968 INFO     Training average loss at step 78000: 0.389741
2025-12-13 01:04:11,118 INFO     Training average regularization at step 78100: 0.302932
2025-12-13 01:04:11,118 INFO     Training average positive_sample_loss at step 78100: 0.066665
2025-12-13 01:04:11,118 INFO     Training average negative_sample_loss at step 78100: 0.113165
2025-12-13 01:04:11,118 INFO     Training average loss at step 78100: 0.392848
2025-12-13 01:04:13,266 INFO     Training average regularization at step 78200: 0.302924
2025-12-13 01:04:13,266 INFO     Training average positive_sample_loss at step 78200: 0.066016
2025-12-13 01:04:13,266 INFO     Training average negative_sample_loss at step 78200: 0.110132
2025-12-13 01:04:13,266 INFO     Training average loss at step 78200: 0.390998
2025-12-13 01:04:15,412 INFO     Training average regularization at step 78300: 0.302917
2025-12-13 01:04:15,412 INFO     Training average positive_sample_loss at step 78300: 0.067457
2025-12-13 01:04:15,412 INFO     Training average negative_sample_loss at step 78300: 0.110210
2025-12-13 01:04:15,412 INFO     Training average loss at step 78300: 0.391751
2025-12-13 01:04:17,561 INFO     Training average regularization at step 78400: 0.302911
2025-12-13 01:04:17,562 INFO     Training average positive_sample_loss at step 78400: 0.067671
2025-12-13 01:04:17,562 INFO     Training average negative_sample_loss at step 78400: 0.108254
2025-12-13 01:04:17,562 INFO     Training average loss at step 78400: 0.390874
2025-12-13 01:04:19,745 INFO     Training average regularization at step 78500: 0.302904
2025-12-13 01:04:19,746 INFO     Training average positive_sample_loss at step 78500: 0.068262
2025-12-13 01:04:19,746 INFO     Training average negative_sample_loss at step 78500: 0.111025
2025-12-13 01:04:19,746 INFO     Training average loss at step 78500: 0.392548
2025-12-13 01:04:21,900 INFO     Training average regularization at step 78600: 0.302897
2025-12-13 01:04:21,900 INFO     Training average positive_sample_loss at step 78600: 0.066020
2025-12-13 01:04:21,900 INFO     Training average negative_sample_loss at step 78600: 0.109608
2025-12-13 01:04:21,901 INFO     Training average loss at step 78600: 0.390711
2025-12-13 01:04:24,043 INFO     Training average regularization at step 78700: 0.302890
2025-12-13 01:04:24,043 INFO     Training average positive_sample_loss at step 78700: 0.067828
2025-12-13 01:04:24,043 INFO     Training average negative_sample_loss at step 78700: 0.109668
2025-12-13 01:04:24,043 INFO     Training average loss at step 78700: 0.391638
2025-12-13 01:04:26,199 INFO     Training average regularization at step 78800: 0.302883
2025-12-13 01:04:26,199 INFO     Training average positive_sample_loss at step 78800: 0.066032
2025-12-13 01:04:26,199 INFO     Training average negative_sample_loss at step 78800: 0.109959
2025-12-13 01:04:26,199 INFO     Training average loss at step 78800: 0.390879
2025-12-13 01:04:28,360 INFO     Training average regularization at step 78900: 0.302876
2025-12-13 01:04:28,360 INFO     Training average positive_sample_loss at step 78900: 0.067715
2025-12-13 01:04:28,360 INFO     Training average negative_sample_loss at step 78900: 0.107567
2025-12-13 01:04:28,360 INFO     Training average loss at step 78900: 0.390518
2025-12-13 01:04:30,566 INFO     Training average regularization at step 79000: 0.302873
2025-12-13 01:04:30,566 INFO     Training average positive_sample_loss at step 79000: 0.067672
2025-12-13 01:04:30,566 INFO     Training average negative_sample_loss at step 79000: 0.109955
2025-12-13 01:04:30,566 INFO     Training average loss at step 79000: 0.391686
2025-12-13 01:04:32,712 INFO     Training average regularization at step 79100: 0.302868
2025-12-13 01:04:32,712 INFO     Training average positive_sample_loss at step 79100: 0.066359
2025-12-13 01:04:32,712 INFO     Training average negative_sample_loss at step 79100: 0.109733
2025-12-13 01:04:32,712 INFO     Training average loss at step 79100: 0.390914
2025-12-13 01:04:34,855 INFO     Training average regularization at step 79200: 0.302861
2025-12-13 01:04:34,855 INFO     Training average positive_sample_loss at step 79200: 0.067023
2025-12-13 01:04:34,855 INFO     Training average negative_sample_loss at step 79200: 0.109448
2025-12-13 01:04:34,855 INFO     Training average loss at step 79200: 0.391097
2025-12-13 01:04:37,036 INFO     Training average regularization at step 79300: 0.302855
2025-12-13 01:04:37,037 INFO     Training average positive_sample_loss at step 79300: 0.066573
2025-12-13 01:04:37,037 INFO     Training average negative_sample_loss at step 79300: 0.109795
2025-12-13 01:04:37,037 INFO     Training average loss at step 79300: 0.391039
2025-12-13 01:04:39,204 INFO     Training average regularization at step 79400: 0.302848
2025-12-13 01:04:39,204 INFO     Training average positive_sample_loss at step 79400: 0.066146
2025-12-13 01:04:39,204 INFO     Training average negative_sample_loss at step 79400: 0.109104
2025-12-13 01:04:39,204 INFO     Training average loss at step 79400: 0.390474
2025-12-13 01:04:41,424 INFO     Training average regularization at step 79500: 0.302842
2025-12-13 01:04:41,424 INFO     Training average positive_sample_loss at step 79500: 0.066998
2025-12-13 01:04:41,424 INFO     Training average negative_sample_loss at step 79500: 0.108953
2025-12-13 01:04:41,424 INFO     Training average loss at step 79500: 0.390817
2025-12-13 01:04:43,700 INFO     Training average regularization at step 79600: 0.302835
2025-12-13 01:04:43,700 INFO     Training average positive_sample_loss at step 79600: 0.066819
2025-12-13 01:04:43,700 INFO     Training average negative_sample_loss at step 79600: 0.111265
2025-12-13 01:04:43,700 INFO     Training average loss at step 79600: 0.391877
2025-12-13 01:04:45,890 INFO     Training average regularization at step 79700: 0.302828
2025-12-13 01:04:45,891 INFO     Training average positive_sample_loss at step 79700: 0.066812
2025-12-13 01:04:45,891 INFO     Training average negative_sample_loss at step 79700: 0.110028
2025-12-13 01:04:45,891 INFO     Training average loss at step 79700: 0.391248
2025-12-13 01:04:48,059 INFO     Training average regularization at step 79800: 0.302822
2025-12-13 01:04:48,059 INFO     Training average positive_sample_loss at step 79800: 0.068380
2025-12-13 01:04:48,059 INFO     Training average negative_sample_loss at step 79800: 0.110308
2025-12-13 01:04:48,059 INFO     Training average loss at step 79800: 0.392166
2025-12-13 01:04:50,205 INFO     Training average regularization at step 79900: 0.302817
2025-12-13 01:04:50,205 INFO     Training average positive_sample_loss at step 79900: 0.068001
2025-12-13 01:04:50,205 INFO     Training average negative_sample_loss at step 79900: 0.109071
2025-12-13 01:04:50,205 INFO     Training average loss at step 79900: 0.391353
2025-12-13 01:04:52,386 INFO     Change learning_rate to 0.000003 at step 80000
2025-12-13 01:04:53,176 INFO     Training average regularization at step 80000: 0.302813
2025-12-13 01:04:53,176 INFO     Training average positive_sample_loss at step 80000: 0.067113
2025-12-13 01:04:53,176 INFO     Training average negative_sample_loss at step 80000: 0.109696
2025-12-13 01:04:53,177 INFO     Training average loss at step 80000: 0.391217
2025-12-13 01:04:53,177 INFO     Evaluating on Valid Dataset...
2025-12-13 01:04:54,078 INFO     Evaluating the model... (0/50000)
2025-12-13 01:04:57,086 INFO     Evaluating the model... (500/50000)
2025-12-13 01:04:59,607 INFO     Evaluating the model... (1000/50000)
2025-12-13 01:05:02,084 INFO     Evaluating the model... (1500/50000)
2025-12-13 01:05:04,717 INFO     Evaluating the model... (2000/50000)
2025-12-13 01:05:07,823 INFO     Evaluating the model... (2500/50000)
2025-12-13 01:05:10,244 INFO     Evaluating the model... (3000/50000)
2025-12-13 01:05:12,727 INFO     Evaluating the model... (3500/50000)
2025-12-13 01:05:15,365 INFO     Evaluating the model... (4000/50000)
2025-12-13 01:05:17,727 INFO     Evaluating the model... (4500/50000)
2025-12-13 01:05:20,958 INFO     Evaluating the model... (5000/50000)
2025-12-13 01:05:23,306 INFO     Evaluating the model... (5500/50000)
2025-12-13 01:05:25,739 INFO     Evaluating the model... (6000/50000)
2025-12-13 01:05:28,325 INFO     Evaluating the model... (6500/50000)
2025-12-13 01:05:30,733 INFO     Evaluating the model... (7000/50000)
2025-12-13 01:05:34,402 INFO     Evaluating the model... (7500/50000)
2025-12-13 01:05:37,106 INFO     Evaluating the model... (8000/50000)
2025-12-13 01:05:39,893 INFO     Evaluating the model... (8500/50000)
2025-12-13 01:05:42,508 INFO     Evaluating the model... (9000/50000)
2025-12-13 01:05:45,163 INFO     Evaluating the model... (9500/50000)
2025-12-13 01:05:49,105 INFO     Evaluating the model... (10000/50000)
2025-12-13 01:05:51,760 INFO     Evaluating the model... (10500/50000)
2025-12-13 01:05:54,170 INFO     Evaluating the model... (11000/50000)
2025-12-13 01:05:56,559 INFO     Evaluating the model... (11500/50000)
2025-12-13 01:05:58,989 INFO     Evaluating the model... (12000/50000)
2025-12-13 01:06:02,851 INFO     Evaluating the model... (12500/50000)
2025-12-13 01:06:05,250 INFO     Evaluating the model... (13000/50000)
2025-12-13 01:06:07,854 INFO     Evaluating the model... (13500/50000)
2025-12-13 01:06:10,340 INFO     Evaluating the model... (14000/50000)
2025-12-13 01:06:12,899 INFO     Evaluating the model... (14500/50000)
2025-12-13 01:06:16,801 INFO     Evaluating the model... (15000/50000)
2025-12-13 01:06:19,292 INFO     Evaluating the model... (15500/50000)
2025-12-13 01:06:21,734 INFO     Evaluating the model... (16000/50000)
2025-12-13 01:06:24,374 INFO     Evaluating the model... (16500/50000)
2025-12-13 01:06:26,893 INFO     Evaluating the model... (17000/50000)
2025-12-13 01:06:30,644 INFO     Evaluating the model... (17500/50000)
2025-12-13 01:06:33,067 INFO     Evaluating the model... (18000/50000)
2025-12-13 01:06:35,761 INFO     Evaluating the model... (18500/50000)
2025-12-13 01:06:38,329 INFO     Evaluating the model... (19000/50000)
2025-12-13 01:06:41,991 INFO     Evaluating the model... (19500/50000)
2025-12-13 01:06:44,900 INFO     Evaluating the model... (20000/50000)
2025-12-13 01:06:47,663 INFO     Evaluating the model... (20500/50000)
2025-12-13 01:06:50,012 INFO     Evaluating the model... (21000/50000)
2025-12-13 01:06:52,453 INFO     Evaluating the model... (21500/50000)
2025-12-13 01:06:56,270 INFO     Evaluating the model... (22000/50000)
2025-12-13 01:06:58,891 INFO     Evaluating the model... (22500/50000)
2025-12-13 01:07:01,263 INFO     Evaluating the model... (23000/50000)
2025-12-13 01:07:03,639 INFO     Evaluating the model... (23500/50000)
2025-12-13 01:07:06,054 INFO     Evaluating the model... (24000/50000)
2025-12-13 01:07:10,019 INFO     Evaluating the model... (24500/50000)
2025-12-13 01:07:12,829 INFO     Evaluating the model... (25000/50000)
2025-12-13 01:07:15,324 INFO     Evaluating the model... (25500/50000)
2025-12-13 01:07:17,777 INFO     Evaluating the model... (26000/50000)
2025-12-13 01:07:20,269 INFO     Evaluating the model... (26500/50000)
2025-12-13 01:07:22,980 INFO     Evaluating the model... (27000/50000)
2025-12-13 01:07:26,103 INFO     Evaluating the model... (27500/50000)
2025-12-13 01:07:28,655 INFO     Evaluating the model... (28000/50000)
2025-12-13 01:07:31,205 INFO     Evaluating the model... (28500/50000)
2025-12-13 01:07:33,975 INFO     Evaluating the model... (29000/50000)
2025-12-13 01:07:37,286 INFO     Evaluating the model... (29500/50000)
2025-12-13 01:07:39,922 INFO     Evaluating the model... (30000/50000)
2025-12-13 01:07:42,571 INFO     Evaluating the model... (30500/50000)
2025-12-13 01:07:45,426 INFO     Evaluating the model... (31000/50000)
2025-12-13 01:07:47,945 INFO     Evaluating the model... (31500/50000)
2025-12-13 01:07:50,931 INFO     Evaluating the model... (32000/50000)
2025-12-13 01:07:53,377 INFO     Evaluating the model... (32500/50000)
2025-12-13 01:07:56,129 INFO     Evaluating the model... (33000/50000)
2025-12-13 01:07:58,655 INFO     Evaluating the model... (33500/50000)
2025-12-13 01:08:01,109 INFO     Evaluating the model... (34000/50000)
2025-12-13 01:08:04,233 INFO     Evaluating the model... (34500/50000)
2025-12-13 01:08:07,056 INFO     Evaluating the model... (35000/50000)
2025-12-13 01:08:09,621 INFO     Evaluating the model... (35500/50000)
2025-12-13 01:08:12,124 INFO     Evaluating the model... (36000/50000)
2025-12-13 01:08:14,543 INFO     Evaluating the model... (36500/50000)
2025-12-13 01:08:17,709 INFO     Evaluating the model... (37000/50000)
2025-12-13 01:08:20,318 INFO     Evaluating the model... (37500/50000)
2025-12-13 01:08:22,765 INFO     Evaluating the model... (38000/50000)
2025-12-13 01:08:25,405 INFO     Evaluating the model... (38500/50000)
2025-12-13 01:08:27,891 INFO     Evaluating the model... (39000/50000)
2025-12-13 01:08:31,280 INFO     Evaluating the model... (39500/50000)
2025-12-13 01:08:33,699 INFO     Evaluating the model... (40000/50000)
2025-12-13 01:08:36,330 INFO     Evaluating the model... (40500/50000)
2025-12-13 01:08:39,076 INFO     Evaluating the model... (41000/50000)
2025-12-13 01:08:41,940 INFO     Evaluating the model... (41500/50000)
2025-12-13 01:08:45,647 INFO     Evaluating the model... (42000/50000)
2025-12-13 01:08:48,175 INFO     Evaluating the model... (42500/50000)
2025-12-13 01:08:50,654 INFO     Evaluating the model... (43000/50000)
2025-12-13 01:08:53,433 INFO     Evaluating the model... (43500/50000)
2025-12-13 01:08:55,974 INFO     Evaluating the model... (44000/50000)
2025-12-13 01:08:59,431 INFO     Evaluating the model... (44500/50000)
2025-12-13 01:09:01,881 INFO     Evaluating the model... (45000/50000)
2025-12-13 01:09:04,549 INFO     Evaluating the model... (45500/50000)
2025-12-13 01:09:07,103 INFO     Evaluating the model... (46000/50000)
2025-12-13 01:09:09,631 INFO     Evaluating the model... (46500/50000)
2025-12-13 01:09:13,107 INFO     Evaluating the model... (47000/50000)
2025-12-13 01:09:15,839 INFO     Evaluating the model... (47500/50000)
2025-12-13 01:09:18,445 INFO     Evaluating the model... (48000/50000)
2025-12-13 01:09:20,982 INFO     Evaluating the model... (48500/50000)
2025-12-13 01:09:23,952 INFO     Evaluating the model... (49000/50000)
2025-12-13 01:09:27,293 INFO     Evaluating the model... (49500/50000)
2025-12-13 01:09:30,116 INFO     Valid MRR at step 80000: 0.627883
2025-12-13 01:09:30,116 INFO     Valid MR at step 80000: 266.144930
2025-12-13 01:09:30,116 INFO     Valid HITS@1 at step 80000: 0.541170
2025-12-13 01:09:30,116 INFO     Valid HITS@3 at step 80000: 0.680550
2025-12-13 01:09:30,116 INFO     Valid HITS@10 at step 80000: 0.782430
2025-12-13 01:09:30,904 INFO     Evaluating on Test Dataset...
2025-12-13 01:09:31,429 INFO     Evaluating the model... (0/59072)
2025-12-13 01:09:34,056 INFO     Evaluating the model... (500/59072)
2025-12-13 01:09:36,750 INFO     Evaluating the model... (1000/59072)
2025-12-13 01:09:39,675 INFO     Evaluating the model... (1500/59072)
2025-12-13 01:09:43,510 INFO     Evaluating the model... (2000/59072)
2025-12-13 01:09:46,163 INFO     Evaluating the model... (2500/59072)
2025-12-13 01:09:48,566 INFO     Evaluating the model... (3000/59072)
2025-12-13 01:09:51,266 INFO     Evaluating the model... (3500/59072)
2025-12-13 01:09:53,827 INFO     Evaluating the model... (4000/59072)
2025-12-13 01:09:56,912 INFO     Evaluating the model... (4500/59072)
2025-12-13 01:09:59,252 INFO     Evaluating the model... (5000/59072)
2025-12-13 01:10:01,859 INFO     Evaluating the model... (5500/59072)
2025-12-13 01:10:04,275 INFO     Evaluating the model... (6000/59072)
2025-12-13 01:10:07,498 INFO     Evaluating the model... (6500/59072)
2025-12-13 01:10:09,861 INFO     Evaluating the model... (7000/59072)
2025-12-13 01:10:12,224 INFO     Evaluating the model... (7500/59072)
2025-12-13 01:10:14,715 INFO     Evaluating the model... (8000/59072)
2025-12-13 01:10:17,188 INFO     Evaluating the model... (8500/59072)
2025-12-13 01:10:20,470 INFO     Evaluating the model... (9000/59072)
2025-12-13 01:10:22,818 INFO     Evaluating the model... (9500/59072)
2025-12-13 01:10:25,459 INFO     Evaluating the model... (10000/59072)
2025-12-13 01:10:27,915 INFO     Evaluating the model... (10500/59072)
2025-12-13 01:10:30,444 INFO     Evaluating the model... (11000/59072)
2025-12-13 01:10:34,093 INFO     Evaluating the model... (11500/59072)
2025-12-13 01:10:37,068 INFO     Evaluating the model... (12000/59072)
2025-12-13 01:10:39,724 INFO     Evaluating the model... (12500/59072)
2025-12-13 01:10:42,359 INFO     Evaluating the model... (13000/59072)
2025-12-13 01:10:45,085 INFO     Evaluating the model... (13500/59072)
2025-12-13 01:10:48,988 INFO     Evaluating the model... (14000/59072)
2025-12-13 01:10:51,510 INFO     Evaluating the model... (14500/59072)
2025-12-13 01:10:53,934 INFO     Evaluating the model... (15000/59072)
2025-12-13 01:10:56,453 INFO     Evaluating the model... (15500/59072)
2025-12-13 01:10:59,128 INFO     Evaluating the model... (16000/59072)
2025-12-13 01:11:02,497 INFO     Evaluating the model... (16500/59072)
2025-12-13 01:11:05,001 INFO     Evaluating the model... (17000/59072)
2025-12-13 01:11:07,440 INFO     Evaluating the model... (17500/59072)
2025-12-13 01:11:09,945 INFO     Evaluating the model... (18000/59072)
2025-12-13 01:11:12,507 INFO     Evaluating the model... (18500/59072)
2025-12-13 01:11:16,021 INFO     Evaluating the model... (19000/59072)
2025-12-13 01:11:18,432 INFO     Evaluating the model... (19500/59072)
2025-12-13 01:11:20,800 INFO     Evaluating the model... (20000/59072)
2025-12-13 01:11:23,419 INFO     Evaluating the model... (20500/59072)
2025-12-13 01:11:25,927 INFO     Evaluating the model... (21000/59072)
2025-12-13 01:11:29,534 INFO     Evaluating the model... (21500/59072)
2025-12-13 01:11:31,860 INFO     Evaluating the model... (22000/59072)
2025-12-13 01:11:34,481 INFO     Evaluating the model... (22500/59072)
2025-12-13 01:11:37,062 INFO     Evaluating the model... (23000/59072)
2025-12-13 01:11:39,634 INFO     Evaluating the model... (23500/59072)
2025-12-13 01:11:43,776 INFO     Evaluating the model... (24000/59072)
2025-12-13 01:11:46,674 INFO     Evaluating the model... (24500/59072)
2025-12-13 01:11:49,169 INFO     Evaluating the model... (25000/59072)
2025-12-13 01:11:51,593 INFO     Evaluating the model... (25500/59072)
2025-12-13 01:11:54,442 INFO     Evaluating the model... (26000/59072)
2025-12-13 01:11:57,681 INFO     Evaluating the model... (26500/59072)
2025-12-13 01:12:00,081 INFO     Evaluating the model... (27000/59072)
2025-12-13 01:12:02,565 INFO     Evaluating the model... (27500/59072)
2025-12-13 01:12:04,954 INFO     Evaluating the model... (28000/59072)
2025-12-13 01:12:08,602 INFO     Evaluating the model... (28500/59072)
2025-12-13 01:12:11,011 INFO     Evaluating the model... (29000/59072)
2025-12-13 01:12:13,459 INFO     Evaluating the model... (29500/59072)
2025-12-13 01:12:16,328 INFO     Evaluating the model... (30000/59072)
2025-12-13 01:12:18,896 INFO     Evaluating the model... (30500/59072)
2025-12-13 01:12:22,356 INFO     Evaluating the model... (31000/59072)
2025-12-13 01:12:24,779 INFO     Evaluating the model... (31500/59072)
2025-12-13 01:12:27,258 INFO     Evaluating the model... (32000/59072)
2025-12-13 01:12:29,701 INFO     Evaluating the model... (32500/59072)
2025-12-13 01:12:32,427 INFO     Evaluating the model... (33000/59072)
2025-12-13 01:12:35,393 INFO     Evaluating the model... (33500/59072)
2025-12-13 01:12:38,113 INFO     Evaluating the model... (34000/59072)
2025-12-13 01:12:40,779 INFO     Evaluating the model... (34500/59072)
2025-12-13 01:12:43,708 INFO     Evaluating the model... (35000/59072)
2025-12-13 01:12:46,188 INFO     Evaluating the model... (35500/59072)
2025-12-13 01:12:49,253 INFO     Evaluating the model... (36000/59072)
2025-12-13 01:12:51,722 INFO     Evaluating the model... (36500/59072)
2025-12-13 01:12:54,267 INFO     Evaluating the model... (37000/59072)
2025-12-13 01:12:56,823 INFO     Evaluating the model... (37500/59072)
2025-12-13 01:13:00,009 INFO     Evaluating the model... (38000/59072)
2025-12-13 01:13:02,490 INFO     Evaluating the model... (38500/59072)
2025-12-13 01:13:04,979 INFO     Evaluating the model... (39000/59072)
2025-12-13 01:13:07,602 INFO     Evaluating the model... (39500/59072)
2025-12-13 01:13:10,073 INFO     Evaluating the model... (40000/59072)
2025-12-13 01:13:13,149 INFO     Evaluating the model... (40500/59072)
2025-12-13 01:13:15,657 INFO     Evaluating the model... (41000/59072)
2025-12-13 01:13:18,357 INFO     Evaluating the model... (41500/59072)
2025-12-13 01:13:20,844 INFO     Evaluating the model... (42000/59072)
2025-12-13 01:13:23,366 INFO     Evaluating the model... (42500/59072)
2025-12-13 01:13:26,914 INFO     Evaluating the model... (43000/59072)
2025-12-13 01:13:29,654 INFO     Evaluating the model... (43500/59072)
2025-12-13 01:13:32,059 INFO     Evaluating the model... (44000/59072)
2025-12-13 01:13:34,520 INFO     Evaluating the model... (44500/59072)
2025-12-13 01:13:37,241 INFO     Evaluating the model... (45000/59072)
2025-12-13 01:13:40,906 INFO     Evaluating the model... (45500/59072)
2025-12-13 01:13:43,694 INFO     Evaluating the model... (46000/59072)
2025-12-13 01:13:46,371 INFO     Evaluating the model... (46500/59072)
2025-12-13 01:13:48,918 INFO     Evaluating the model... (47000/59072)
2025-12-13 01:13:51,516 INFO     Evaluating the model... (47500/59072)
2025-12-13 01:13:54,989 INFO     Evaluating the model... (48000/59072)
2025-12-13 01:13:57,600 INFO     Evaluating the model... (48500/59072)
2025-12-13 01:14:00,068 INFO     Evaluating the model... (49000/59072)
2025-12-13 01:14:02,571 INFO     Evaluating the model... (49500/59072)
2025-12-13 01:14:05,232 INFO     Evaluating the model... (50000/59072)
2025-12-13 01:14:08,692 INFO     Evaluating the model... (50500/59072)
2025-12-13 01:14:11,184 INFO     Evaluating the model... (51000/59072)
2025-12-13 01:14:13,675 INFO     Evaluating the model... (51500/59072)
2025-12-13 01:14:16,572 INFO     Evaluating the model... (52000/59072)
2025-12-13 01:14:19,054 INFO     Evaluating the model... (52500/59072)
2025-12-13 01:14:22,653 INFO     Evaluating the model... (53000/59072)
2025-12-13 01:14:25,262 INFO     Evaluating the model... (53500/59072)
2025-12-13 01:14:27,959 INFO     Evaluating the model... (54000/59072)
2025-12-13 01:14:30,432 INFO     Evaluating the model... (54500/59072)
2025-12-13 01:14:32,892 INFO     Evaluating the model... (55000/59072)
2025-12-13 01:14:36,858 INFO     Evaluating the model... (55500/59072)
2025-12-13 01:14:39,722 INFO     Evaluating the model... (56000/59072)
2025-12-13 01:14:42,389 INFO     Evaluating the model... (56500/59072)
2025-12-13 01:14:45,103 INFO     Evaluating the model... (57000/59072)
2025-12-13 01:14:48,980 INFO     Evaluating the model... (57500/59072)
2025-12-13 01:14:51,523 INFO     Evaluating the model... (58000/59072)
2025-12-13 01:14:53,974 INFO     Evaluating the model... (58500/59072)
2025-12-13 01:14:56,639 INFO     Evaluating the model... (59000/59072)
2025-12-13 01:14:57,354 INFO     Test MRR at step 80000: 0.623852
2025-12-13 01:14:57,355 INFO     Test MR at step 80000: 268.084483
2025-12-13 01:14:57,355 INFO     Test HITS@1 at step 80000: 0.535237
2025-12-13 01:14:57,355 INFO     Test HITS@3 at step 80000: 0.678345
2025-12-13 01:14:57,355 INFO     Test HITS@10 at step 80000: 0.780789
2025-12-13 01:14:59,517 INFO     Training average regularization at step 80100: 0.302746
2025-12-13 01:14:59,518 INFO     Training average positive_sample_loss at step 80100: 0.067570
2025-12-13 01:14:59,518 INFO     Training average negative_sample_loss at step 80100: 0.107887
2025-12-13 01:14:59,518 INFO     Training average loss at step 80100: 0.390474
2025-12-13 01:15:01,723 INFO     Training average regularization at step 80200: 0.302693
2025-12-13 01:15:01,730 INFO     Training average positive_sample_loss at step 80200: 0.066949
2025-12-13 01:15:01,730 INFO     Training average negative_sample_loss at step 80200: 0.107920
2025-12-13 01:15:01,730 INFO     Training average loss at step 80200: 0.390127
2025-12-13 01:15:03,873 INFO     Training average regularization at step 80300: 0.302668
2025-12-13 01:15:03,874 INFO     Training average positive_sample_loss at step 80300: 0.067232
2025-12-13 01:15:03,874 INFO     Training average negative_sample_loss at step 80300: 0.105365
2025-12-13 01:15:03,874 INFO     Training average loss at step 80300: 0.388966
2025-12-13 01:15:06,011 INFO     Training average regularization at step 80400: 0.302653
2025-12-13 01:15:06,011 INFO     Training average positive_sample_loss at step 80400: 0.067549
2025-12-13 01:15:06,011 INFO     Training average negative_sample_loss at step 80400: 0.109292
2025-12-13 01:15:06,011 INFO     Training average loss at step 80400: 0.391073
2025-12-13 01:15:08,156 INFO     Training average regularization at step 80500: 0.302642
2025-12-13 01:15:08,156 INFO     Training average positive_sample_loss at step 80500: 0.067991
2025-12-13 01:15:08,156 INFO     Training average negative_sample_loss at step 80500: 0.109422
2025-12-13 01:15:08,156 INFO     Training average loss at step 80500: 0.391348
2025-12-13 01:15:10,316 INFO     Training average regularization at step 80600: 0.302634
2025-12-13 01:15:10,317 INFO     Training average positive_sample_loss at step 80600: 0.068720
2025-12-13 01:15:10,317 INFO     Training average negative_sample_loss at step 80600: 0.110212
2025-12-13 01:15:10,317 INFO     Training average loss at step 80600: 0.392100
2025-12-13 01:15:12,464 INFO     Training average regularization at step 80700: 0.302628
2025-12-13 01:15:12,464 INFO     Training average positive_sample_loss at step 80700: 0.069099
2025-12-13 01:15:12,464 INFO     Training average negative_sample_loss at step 80700: 0.109449
2025-12-13 01:15:12,464 INFO     Training average loss at step 80700: 0.391902
2025-12-13 01:15:14,612 INFO     Training average regularization at step 80800: 0.302624
2025-12-13 01:15:14,612 INFO     Training average positive_sample_loss at step 80800: 0.068975
2025-12-13 01:15:14,612 INFO     Training average negative_sample_loss at step 80800: 0.106790
2025-12-13 01:15:14,612 INFO     Training average loss at step 80800: 0.390506
2025-12-13 01:15:16,736 INFO     Training average regularization at step 80900: 0.302620
2025-12-13 01:15:16,738 INFO     Training average positive_sample_loss at step 80900: 0.068321
2025-12-13 01:15:16,738 INFO     Training average negative_sample_loss at step 80900: 0.111325
2025-12-13 01:15:16,738 INFO     Training average loss at step 80900: 0.392443
2025-12-13 01:15:18,895 INFO     Training average regularization at step 81000: 0.302616
2025-12-13 01:15:18,895 INFO     Training average positive_sample_loss at step 81000: 0.067585
2025-12-13 01:15:18,895 INFO     Training average negative_sample_loss at step 81000: 0.110985
2025-12-13 01:15:18,895 INFO     Training average loss at step 81000: 0.391901
2025-12-13 01:15:21,058 INFO     Training average regularization at step 81100: 0.302613
2025-12-13 01:15:21,058 INFO     Training average positive_sample_loss at step 81100: 0.068447
2025-12-13 01:15:21,058 INFO     Training average negative_sample_loss at step 81100: 0.107998
2025-12-13 01:15:21,058 INFO     Training average loss at step 81100: 0.390836
2025-12-13 01:15:23,219 INFO     Training average regularization at step 81200: 0.302611
2025-12-13 01:15:23,219 INFO     Training average positive_sample_loss at step 81200: 0.067326
2025-12-13 01:15:23,219 INFO     Training average negative_sample_loss at step 81200: 0.106959
2025-12-13 01:15:23,219 INFO     Training average loss at step 81200: 0.389753
2025-12-13 01:15:25,377 INFO     Training average regularization at step 81300: 0.302608
2025-12-13 01:15:25,377 INFO     Training average positive_sample_loss at step 81300: 0.067168
2025-12-13 01:15:25,377 INFO     Training average negative_sample_loss at step 81300: 0.109507
2025-12-13 01:15:25,377 INFO     Training average loss at step 81300: 0.390946
2025-12-13 01:15:27,521 INFO     Training average regularization at step 81400: 0.302607
2025-12-13 01:15:27,521 INFO     Training average positive_sample_loss at step 81400: 0.067835
2025-12-13 01:15:27,521 INFO     Training average negative_sample_loss at step 81400: 0.108036
2025-12-13 01:15:27,521 INFO     Training average loss at step 81400: 0.390542
2025-12-13 01:15:29,688 INFO     Training average regularization at step 81500: 0.302605
2025-12-13 01:15:29,689 INFO     Training average positive_sample_loss at step 81500: 0.068474
2025-12-13 01:15:29,689 INFO     Training average negative_sample_loss at step 81500: 0.109323
2025-12-13 01:15:29,689 INFO     Training average loss at step 81500: 0.391503
2025-12-13 01:15:31,842 INFO     Training average regularization at step 81600: 0.302603
2025-12-13 01:15:31,842 INFO     Training average positive_sample_loss at step 81600: 0.066476
2025-12-13 01:15:31,842 INFO     Training average negative_sample_loss at step 81600: 0.109519
2025-12-13 01:15:31,842 INFO     Training average loss at step 81600: 0.390601
2025-12-13 01:15:34,030 INFO     Training average regularization at step 81700: 0.302602
2025-12-13 01:15:34,030 INFO     Training average positive_sample_loss at step 81700: 0.067937
2025-12-13 01:15:34,030 INFO     Training average negative_sample_loss at step 81700: 0.110208
2025-12-13 01:15:34,030 INFO     Training average loss at step 81700: 0.391674
2025-12-13 01:15:36,181 INFO     Training average regularization at step 81800: 0.302600
2025-12-13 01:15:36,181 INFO     Training average positive_sample_loss at step 81800: 0.066709
2025-12-13 01:15:36,181 INFO     Training average negative_sample_loss at step 81800: 0.106225
2025-12-13 01:15:36,181 INFO     Training average loss at step 81800: 0.389068
2025-12-13 01:15:38,323 INFO     Training average regularization at step 81900: 0.302599
2025-12-13 01:15:38,323 INFO     Training average positive_sample_loss at step 81900: 0.067496
2025-12-13 01:15:38,323 INFO     Training average negative_sample_loss at step 81900: 0.110918
2025-12-13 01:15:38,323 INFO     Training average loss at step 81900: 0.391806
2025-12-13 01:15:40,492 INFO     Training average regularization at step 82000: 0.302598
2025-12-13 01:15:40,493 INFO     Training average positive_sample_loss at step 82000: 0.068145
2025-12-13 01:15:40,493 INFO     Training average negative_sample_loss at step 82000: 0.108055
2025-12-13 01:15:40,493 INFO     Training average loss at step 82000: 0.390698
2025-12-13 01:15:42,663 INFO     Training average regularization at step 82100: 0.302597
2025-12-13 01:15:42,663 INFO     Training average positive_sample_loss at step 82100: 0.067481
2025-12-13 01:15:42,663 INFO     Training average negative_sample_loss at step 82100: 0.107948
2025-12-13 01:15:42,663 INFO     Training average loss at step 82100: 0.390312
2025-12-13 01:15:46,128 INFO     Training average regularization at step 82200: 0.302596
2025-12-13 01:15:46,129 INFO     Training average positive_sample_loss at step 82200: 0.067556
2025-12-13 01:15:46,129 INFO     Training average negative_sample_loss at step 82200: 0.108057
2025-12-13 01:15:46,129 INFO     Training average loss at step 82200: 0.390403
2025-12-13 01:15:48,288 INFO     Training average regularization at step 82300: 0.302595
2025-12-13 01:15:48,289 INFO     Training average positive_sample_loss at step 82300: 0.066691
2025-12-13 01:15:48,289 INFO     Training average negative_sample_loss at step 82300: 0.112705
2025-12-13 01:15:48,289 INFO     Training average loss at step 82300: 0.392293
2025-12-13 01:15:50,443 INFO     Training average regularization at step 82400: 0.302594
2025-12-13 01:15:50,443 INFO     Training average positive_sample_loss at step 82400: 0.067396
2025-12-13 01:15:50,443 INFO     Training average negative_sample_loss at step 82400: 0.111406
2025-12-13 01:15:50,443 INFO     Training average loss at step 82400: 0.391995
2025-12-13 01:15:52,598 INFO     Training average regularization at step 82500: 0.302593
2025-12-13 01:15:52,599 INFO     Training average positive_sample_loss at step 82500: 0.067669
2025-12-13 01:15:52,599 INFO     Training average negative_sample_loss at step 82500: 0.108842
2025-12-13 01:15:52,599 INFO     Training average loss at step 82500: 0.390848
2025-12-13 01:15:54,746 INFO     Training average regularization at step 82600: 0.302592
2025-12-13 01:15:54,750 INFO     Training average positive_sample_loss at step 82600: 0.067507
2025-12-13 01:15:54,750 INFO     Training average negative_sample_loss at step 82600: 0.109145
2025-12-13 01:15:54,750 INFO     Training average loss at step 82600: 0.390918
2025-12-13 01:15:56,910 INFO     Training average regularization at step 82700: 0.302591
2025-12-13 01:15:56,910 INFO     Training average positive_sample_loss at step 82700: 0.067039
2025-12-13 01:15:56,910 INFO     Training average negative_sample_loss at step 82700: 0.109365
2025-12-13 01:15:56,910 INFO     Training average loss at step 82700: 0.390793
2025-12-13 01:15:59,060 INFO     Training average regularization at step 82800: 0.302590
2025-12-13 01:15:59,060 INFO     Training average positive_sample_loss at step 82800: 0.066222
2025-12-13 01:15:59,060 INFO     Training average negative_sample_loss at step 82800: 0.106629
2025-12-13 01:15:59,060 INFO     Training average loss at step 82800: 0.389015
2025-12-13 01:16:01,207 INFO     Training average regularization at step 82900: 0.302589
2025-12-13 01:16:01,207 INFO     Training average positive_sample_loss at step 82900: 0.066201
2025-12-13 01:16:01,207 INFO     Training average negative_sample_loss at step 82900: 0.109043
2025-12-13 01:16:01,207 INFO     Training average loss at step 82900: 0.390211
2025-12-13 01:16:03,359 INFO     Training average regularization at step 83000: 0.302588
2025-12-13 01:16:03,359 INFO     Training average positive_sample_loss at step 83000: 0.065868
2025-12-13 01:16:03,359 INFO     Training average negative_sample_loss at step 83000: 0.108388
2025-12-13 01:16:03,359 INFO     Training average loss at step 83000: 0.389716
2025-12-13 01:16:05,504 INFO     Training average regularization at step 83100: 0.302587
2025-12-13 01:16:05,504 INFO     Training average positive_sample_loss at step 83100: 0.066151
2025-12-13 01:16:05,504 INFO     Training average negative_sample_loss at step 83100: 0.109266
2025-12-13 01:16:05,504 INFO     Training average loss at step 83100: 0.390295
2025-12-13 01:16:07,683 INFO     Training average regularization at step 83200: 0.302586
2025-12-13 01:16:07,683 INFO     Training average positive_sample_loss at step 83200: 0.066894
2025-12-13 01:16:07,684 INFO     Training average negative_sample_loss at step 83200: 0.109323
2025-12-13 01:16:07,684 INFO     Training average loss at step 83200: 0.390694
2025-12-13 01:16:09,831 INFO     Training average regularization at step 83300: 0.302585
2025-12-13 01:16:09,832 INFO     Training average positive_sample_loss at step 83300: 0.068062
2025-12-13 01:16:09,832 INFO     Training average negative_sample_loss at step 83300: 0.110528
2025-12-13 01:16:09,832 INFO     Training average loss at step 83300: 0.391880
2025-12-13 01:16:11,973 INFO     Training average regularization at step 83400: 0.302584
2025-12-13 01:16:11,973 INFO     Training average positive_sample_loss at step 83400: 0.066037
2025-12-13 01:16:11,973 INFO     Training average negative_sample_loss at step 83400: 0.108763
2025-12-13 01:16:11,974 INFO     Training average loss at step 83400: 0.389984
2025-12-13 01:16:14,140 INFO     Training average regularization at step 83500: 0.302583
2025-12-13 01:16:14,140 INFO     Training average positive_sample_loss at step 83500: 0.066933
2025-12-13 01:16:14,140 INFO     Training average negative_sample_loss at step 83500: 0.111612
2025-12-13 01:16:14,140 INFO     Training average loss at step 83500: 0.391855
2025-12-13 01:16:16,291 INFO     Training average regularization at step 83600: 0.302582
2025-12-13 01:16:16,291 INFO     Training average positive_sample_loss at step 83600: 0.065411
2025-12-13 01:16:16,291 INFO     Training average negative_sample_loss at step 83600: 0.108263
2025-12-13 01:16:16,291 INFO     Training average loss at step 83600: 0.389419
2025-12-13 01:16:18,455 INFO     Training average regularization at step 83700: 0.302581
2025-12-13 01:16:18,456 INFO     Training average positive_sample_loss at step 83700: 0.068008
2025-12-13 01:16:18,456 INFO     Training average negative_sample_loss at step 83700: 0.108831
2025-12-13 01:16:18,456 INFO     Training average loss at step 83700: 0.391001
2025-12-13 01:16:20,614 INFO     Training average regularization at step 83800: 0.302581
2025-12-13 01:16:20,615 INFO     Training average positive_sample_loss at step 83800: 0.068057
2025-12-13 01:16:20,615 INFO     Training average negative_sample_loss at step 83800: 0.108721
2025-12-13 01:16:20,615 INFO     Training average loss at step 83800: 0.390970
2025-12-13 01:16:22,761 INFO     Training average regularization at step 83900: 0.302580
2025-12-13 01:16:22,761 INFO     Training average positive_sample_loss at step 83900: 0.065572
2025-12-13 01:16:22,761 INFO     Training average negative_sample_loss at step 83900: 0.107852
2025-12-13 01:16:22,761 INFO     Training average loss at step 83900: 0.389292
2025-12-13 01:16:24,906 INFO     Training average regularization at step 84000: 0.302579
2025-12-13 01:16:24,906 INFO     Training average positive_sample_loss at step 84000: 0.067801
2025-12-13 01:16:24,906 INFO     Training average negative_sample_loss at step 84000: 0.109189
2025-12-13 01:16:24,906 INFO     Training average loss at step 84000: 0.391074
2025-12-13 01:16:27,081 INFO     Training average regularization at step 84100: 0.302579
2025-12-13 01:16:27,081 INFO     Training average positive_sample_loss at step 84100: 0.067409
2025-12-13 01:16:27,081 INFO     Training average negative_sample_loss at step 84100: 0.108001
2025-12-13 01:16:27,081 INFO     Training average loss at step 84100: 0.390284
2025-12-13 01:16:29,258 INFO     Training average regularization at step 84200: 0.302578
2025-12-13 01:16:29,259 INFO     Training average positive_sample_loss at step 84200: 0.066314
2025-12-13 01:16:29,259 INFO     Training average negative_sample_loss at step 84200: 0.107729
2025-12-13 01:16:29,259 INFO     Training average loss at step 84200: 0.389599
2025-12-13 01:16:31,416 INFO     Training average regularization at step 84300: 0.302577
2025-12-13 01:16:31,417 INFO     Training average positive_sample_loss at step 84300: 0.067756
2025-12-13 01:16:31,417 INFO     Training average negative_sample_loss at step 84300: 0.108359
2025-12-13 01:16:31,417 INFO     Training average loss at step 84300: 0.390635
2025-12-13 01:16:33,586 INFO     Training average regularization at step 84400: 0.302577
2025-12-13 01:16:33,586 INFO     Training average positive_sample_loss at step 84400: 0.067247
2025-12-13 01:16:33,586 INFO     Training average negative_sample_loss at step 84400: 0.109910
2025-12-13 01:16:33,586 INFO     Training average loss at step 84400: 0.391155
2025-12-13 01:16:35,800 INFO     Training average regularization at step 84500: 0.302576
2025-12-13 01:16:35,800 INFO     Training average positive_sample_loss at step 84500: 0.066951
2025-12-13 01:16:35,800 INFO     Training average negative_sample_loss at step 84500: 0.106966
2025-12-13 01:16:35,800 INFO     Training average loss at step 84500: 0.389534
2025-12-13 01:16:38,010 INFO     Training average regularization at step 84600: 0.302575
2025-12-13 01:16:38,010 INFO     Training average positive_sample_loss at step 84600: 0.066327
2025-12-13 01:16:38,010 INFO     Training average negative_sample_loss at step 84600: 0.111641
2025-12-13 01:16:38,010 INFO     Training average loss at step 84600: 0.391559
2025-12-13 01:16:40,243 INFO     Training average regularization at step 84700: 0.302575
2025-12-13 01:16:40,252 INFO     Training average positive_sample_loss at step 84700: 0.066631
2025-12-13 01:16:40,252 INFO     Training average negative_sample_loss at step 84700: 0.110610
2025-12-13 01:16:40,252 INFO     Training average loss at step 84700: 0.391195
2025-12-13 01:16:42,430 INFO     Training average regularization at step 84800: 0.302574
2025-12-13 01:16:42,430 INFO     Training average positive_sample_loss at step 84800: 0.066147
2025-12-13 01:16:42,430 INFO     Training average negative_sample_loss at step 84800: 0.109150
2025-12-13 01:16:42,430 INFO     Training average loss at step 84800: 0.390222
2025-12-13 01:16:44,620 INFO     Training average regularization at step 84900: 0.302573
2025-12-13 01:16:44,621 INFO     Training average positive_sample_loss at step 84900: 0.067251
2025-12-13 01:16:44,621 INFO     Training average negative_sample_loss at step 84900: 0.108704
2025-12-13 01:16:44,621 INFO     Training average loss at step 84900: 0.390551
2025-12-13 01:16:46,804 INFO     Training average regularization at step 85000: 0.302573
2025-12-13 01:16:46,805 INFO     Training average positive_sample_loss at step 85000: 0.066691
2025-12-13 01:16:46,805 INFO     Training average negative_sample_loss at step 85000: 0.109538
2025-12-13 01:16:46,805 INFO     Training average loss at step 85000: 0.390687
2025-12-13 01:16:48,974 INFO     Training average regularization at step 85100: 0.302572
2025-12-13 01:16:48,974 INFO     Training average positive_sample_loss at step 85100: 0.066933
2025-12-13 01:16:48,974 INFO     Training average negative_sample_loss at step 85100: 0.107379
2025-12-13 01:16:48,974 INFO     Training average loss at step 85100: 0.389728
2025-12-13 01:16:51,159 INFO     Training average regularization at step 85200: 0.302571
2025-12-13 01:16:51,159 INFO     Training average positive_sample_loss at step 85200: 0.066491
2025-12-13 01:16:51,159 INFO     Training average negative_sample_loss at step 85200: 0.108500
2025-12-13 01:16:51,159 INFO     Training average loss at step 85200: 0.390067
2025-12-13 01:16:53,329 INFO     Training average regularization at step 85300: 0.302571
2025-12-13 01:16:53,329 INFO     Training average positive_sample_loss at step 85300: 0.066411
2025-12-13 01:16:53,329 INFO     Training average negative_sample_loss at step 85300: 0.106646
2025-12-13 01:16:53,329 INFO     Training average loss at step 85300: 0.389099
2025-12-13 01:16:55,487 INFO     Training average regularization at step 85400: 0.302570
2025-12-13 01:16:55,488 INFO     Training average positive_sample_loss at step 85400: 0.066882
2025-12-13 01:16:55,488 INFO     Training average negative_sample_loss at step 85400: 0.110815
2025-12-13 01:16:55,488 INFO     Training average loss at step 85400: 0.391419
2025-12-13 01:16:57,643 INFO     Training average regularization at step 85500: 0.302570
2025-12-13 01:16:57,643 INFO     Training average positive_sample_loss at step 85500: 0.066528
2025-12-13 01:16:57,643 INFO     Training average negative_sample_loss at step 85500: 0.108871
2025-12-13 01:16:57,643 INFO     Training average loss at step 85500: 0.390269
2025-12-13 01:16:59,812 INFO     Training average regularization at step 85600: 0.302569
2025-12-13 01:16:59,813 INFO     Training average positive_sample_loss at step 85600: 0.066331
2025-12-13 01:16:59,813 INFO     Training average negative_sample_loss at step 85600: 0.109924
2025-12-13 01:16:59,813 INFO     Training average loss at step 85600: 0.390696
2025-12-13 01:17:01,975 INFO     Training average regularization at step 85700: 0.302568
2025-12-13 01:17:01,975 INFO     Training average positive_sample_loss at step 85700: 0.065955
2025-12-13 01:17:01,975 INFO     Training average negative_sample_loss at step 85700: 0.107801
2025-12-13 01:17:01,975 INFO     Training average loss at step 85700: 0.389446
2025-12-13 01:17:04,125 INFO     Training average regularization at step 85800: 0.302567
2025-12-13 01:17:04,125 INFO     Training average positive_sample_loss at step 85800: 0.066801
2025-12-13 01:17:04,125 INFO     Training average negative_sample_loss at step 85800: 0.109853
2025-12-13 01:17:04,125 INFO     Training average loss at step 85800: 0.390895
2025-12-13 01:17:06,294 INFO     Training average regularization at step 85900: 0.302567
2025-12-13 01:17:06,294 INFO     Training average positive_sample_loss at step 85900: 0.065871
2025-12-13 01:17:06,294 INFO     Training average negative_sample_loss at step 85900: 0.107370
2025-12-13 01:17:06,294 INFO     Training average loss at step 85900: 0.389188
2025-12-13 01:17:08,443 INFO     Training average regularization at step 86000: 0.302566
2025-12-13 01:17:08,443 INFO     Training average positive_sample_loss at step 86000: 0.066579
2025-12-13 01:17:08,443 INFO     Training average negative_sample_loss at step 86000: 0.112378
2025-12-13 01:17:08,443 INFO     Training average loss at step 86000: 0.392045
2025-12-13 01:17:10,581 INFO     Training average regularization at step 86100: 0.302566
2025-12-13 01:17:10,581 INFO     Training average positive_sample_loss at step 86100: 0.067335
2025-12-13 01:17:10,581 INFO     Training average negative_sample_loss at step 86100: 0.110683
2025-12-13 01:17:10,581 INFO     Training average loss at step 86100: 0.391574
2025-12-13 01:17:12,725 INFO     Training average regularization at step 86200: 0.302565
2025-12-13 01:17:12,725 INFO     Training average positive_sample_loss at step 86200: 0.066207
2025-12-13 01:17:12,725 INFO     Training average negative_sample_loss at step 86200: 0.110167
2025-12-13 01:17:12,725 INFO     Training average loss at step 86200: 0.390752
2025-12-13 01:17:14,875 INFO     Training average regularization at step 86300: 0.302564
2025-12-13 01:17:14,875 INFO     Training average positive_sample_loss at step 86300: 0.067076
2025-12-13 01:17:14,875 INFO     Training average negative_sample_loss at step 86300: 0.108280
2025-12-13 01:17:14,875 INFO     Training average loss at step 86300: 0.390242
2025-12-13 01:17:17,003 INFO     Training average regularization at step 86400: 0.302564
2025-12-13 01:17:17,003 INFO     Training average positive_sample_loss at step 86400: 0.067460
2025-12-13 01:17:17,003 INFO     Training average negative_sample_loss at step 86400: 0.109023
2025-12-13 01:17:17,003 INFO     Training average loss at step 86400: 0.390805
2025-12-13 01:17:19,160 INFO     Training average regularization at step 86500: 0.302563
2025-12-13 01:17:19,160 INFO     Training average positive_sample_loss at step 86500: 0.067221
2025-12-13 01:17:19,160 INFO     Training average negative_sample_loss at step 86500: 0.108773
2025-12-13 01:17:19,161 INFO     Training average loss at step 86500: 0.390561
2025-12-13 01:17:21,299 INFO     Training average regularization at step 86600: 0.302563
2025-12-13 01:17:21,299 INFO     Training average positive_sample_loss at step 86600: 0.066534
2025-12-13 01:17:21,299 INFO     Training average negative_sample_loss at step 86600: 0.107042
2025-12-13 01:17:21,299 INFO     Training average loss at step 86600: 0.389351
2025-12-13 01:17:23,470 INFO     Training average regularization at step 86700: 0.302562
2025-12-13 01:17:23,471 INFO     Training average positive_sample_loss at step 86700: 0.066428
2025-12-13 01:17:23,471 INFO     Training average negative_sample_loss at step 86700: 0.109773
2025-12-13 01:17:23,471 INFO     Training average loss at step 86700: 0.390662
2025-12-13 01:17:25,626 INFO     Training average regularization at step 86800: 0.302561
2025-12-13 01:17:25,627 INFO     Training average positive_sample_loss at step 86800: 0.066820
2025-12-13 01:17:25,627 INFO     Training average negative_sample_loss at step 86800: 0.108654
2025-12-13 01:17:25,627 INFO     Training average loss at step 86800: 0.390298
2025-12-13 01:17:27,756 INFO     Training average regularization at step 86900: 0.302561
2025-12-13 01:17:27,756 INFO     Training average positive_sample_loss at step 86900: 0.066657
2025-12-13 01:17:27,756 INFO     Training average negative_sample_loss at step 86900: 0.112383
2025-12-13 01:17:27,756 INFO     Training average loss at step 86900: 0.392081
2025-12-13 01:17:31,121 INFO     Training average regularization at step 87000: 0.302560
2025-12-13 01:17:31,121 INFO     Training average positive_sample_loss at step 87000: 0.066464
2025-12-13 01:17:31,121 INFO     Training average negative_sample_loss at step 87000: 0.108139
2025-12-13 01:17:31,121 INFO     Training average loss at step 87000: 0.389862
2025-12-13 01:17:33,273 INFO     Training average regularization at step 87100: 0.302559
2025-12-13 01:17:33,273 INFO     Training average positive_sample_loss at step 87100: 0.066372
2025-12-13 01:17:33,273 INFO     Training average negative_sample_loss at step 87100: 0.107780
2025-12-13 01:17:33,273 INFO     Training average loss at step 87100: 0.389635
2025-12-13 01:17:35,452 INFO     Training average regularization at step 87200: 0.302559
2025-12-13 01:17:35,452 INFO     Training average positive_sample_loss at step 87200: 0.067000
2025-12-13 01:17:35,452 INFO     Training average negative_sample_loss at step 87200: 0.109052
2025-12-13 01:17:35,452 INFO     Training average loss at step 87200: 0.390585
2025-12-13 01:17:37,666 INFO     Training average regularization at step 87300: 0.302558
2025-12-13 01:17:37,666 INFO     Training average positive_sample_loss at step 87300: 0.066461
2025-12-13 01:17:37,666 INFO     Training average negative_sample_loss at step 87300: 0.109010
2025-12-13 01:17:37,666 INFO     Training average loss at step 87300: 0.390293
2025-12-13 01:17:39,857 INFO     Training average regularization at step 87400: 0.302557
2025-12-13 01:17:39,858 INFO     Training average positive_sample_loss at step 87400: 0.067640
2025-12-13 01:17:39,858 INFO     Training average negative_sample_loss at step 87400: 0.107317
2025-12-13 01:17:39,858 INFO     Training average loss at step 87400: 0.390036
2025-12-13 01:17:42,037 INFO     Training average regularization at step 87500: 0.302557
2025-12-13 01:17:42,037 INFO     Training average positive_sample_loss at step 87500: 0.066978
2025-12-13 01:17:42,037 INFO     Training average negative_sample_loss at step 87500: 0.108976
2025-12-13 01:17:42,037 INFO     Training average loss at step 87500: 0.390533
2025-12-13 01:17:44,208 INFO     Training average regularization at step 87600: 0.302556
2025-12-13 01:17:44,209 INFO     Training average positive_sample_loss at step 87600: 0.066484
2025-12-13 01:17:44,209 INFO     Training average negative_sample_loss at step 87600: 0.108358
2025-12-13 01:17:44,209 INFO     Training average loss at step 87600: 0.389977
2025-12-13 01:17:46,382 INFO     Training average regularization at step 87700: 0.302555
2025-12-13 01:17:46,383 INFO     Training average positive_sample_loss at step 87700: 0.067338
2025-12-13 01:17:46,383 INFO     Training average negative_sample_loss at step 87700: 0.109517
2025-12-13 01:17:46,383 INFO     Training average loss at step 87700: 0.390983
2025-12-13 01:17:48,552 INFO     Training average regularization at step 87800: 0.302554
2025-12-13 01:17:48,552 INFO     Training average positive_sample_loss at step 87800: 0.066044
2025-12-13 01:17:48,552 INFO     Training average negative_sample_loss at step 87800: 0.110695
2025-12-13 01:17:48,552 INFO     Training average loss at step 87800: 0.390923
2025-12-13 01:17:50,707 INFO     Training average regularization at step 87900: 0.302553
2025-12-13 01:17:50,707 INFO     Training average positive_sample_loss at step 87900: 0.065792
2025-12-13 01:17:50,707 INFO     Training average negative_sample_loss at step 87900: 0.111463
2025-12-13 01:17:50,707 INFO     Training average loss at step 87900: 0.391180
2025-12-13 01:17:52,862 INFO     Training average regularization at step 88000: 0.302552
2025-12-13 01:17:52,862 INFO     Training average positive_sample_loss at step 88000: 0.067324
2025-12-13 01:17:52,862 INFO     Training average negative_sample_loss at step 88000: 0.110229
2025-12-13 01:17:52,862 INFO     Training average loss at step 88000: 0.391329
2025-12-13 01:17:55,009 INFO     Training average regularization at step 88100: 0.302552
2025-12-13 01:17:55,009 INFO     Training average positive_sample_loss at step 88100: 0.066157
2025-12-13 01:17:55,009 INFO     Training average negative_sample_loss at step 88100: 0.111297
2025-12-13 01:17:55,009 INFO     Training average loss at step 88100: 0.391279
2025-12-13 01:17:57,158 INFO     Training average regularization at step 88200: 0.302551
2025-12-13 01:17:57,159 INFO     Training average positive_sample_loss at step 88200: 0.066280
2025-12-13 01:17:57,159 INFO     Training average negative_sample_loss at step 88200: 0.110286
2025-12-13 01:17:57,159 INFO     Training average loss at step 88200: 0.390834
2025-12-13 01:17:59,292 INFO     Training average regularization at step 88300: 0.302550
2025-12-13 01:17:59,293 INFO     Training average positive_sample_loss at step 88300: 0.065261
2025-12-13 01:17:59,293 INFO     Training average negative_sample_loss at step 88300: 0.109911
2025-12-13 01:17:59,293 INFO     Training average loss at step 88300: 0.390136
2025-12-13 01:18:01,421 INFO     Training average regularization at step 88400: 0.302549
2025-12-13 01:18:01,421 INFO     Training average positive_sample_loss at step 88400: 0.066759
2025-12-13 01:18:01,421 INFO     Training average negative_sample_loss at step 88400: 0.106672
2025-12-13 01:18:01,421 INFO     Training average loss at step 88400: 0.389265
2025-12-13 01:18:03,562 INFO     Training average regularization at step 88500: 0.302549
2025-12-13 01:18:03,562 INFO     Training average positive_sample_loss at step 88500: 0.066822
2025-12-13 01:18:03,563 INFO     Training average negative_sample_loss at step 88500: 0.107885
2025-12-13 01:18:03,563 INFO     Training average loss at step 88500: 0.389902
2025-12-13 01:18:05,704 INFO     Training average regularization at step 88600: 0.302548
2025-12-13 01:18:05,704 INFO     Training average positive_sample_loss at step 88600: 0.067368
2025-12-13 01:18:05,704 INFO     Training average negative_sample_loss at step 88600: 0.109216
2025-12-13 01:18:05,704 INFO     Training average loss at step 88600: 0.390840
2025-12-13 01:18:07,850 INFO     Training average regularization at step 88700: 0.302547
2025-12-13 01:18:07,850 INFO     Training average positive_sample_loss at step 88700: 0.065432
2025-12-13 01:18:07,850 INFO     Training average negative_sample_loss at step 88700: 0.108876
2025-12-13 01:18:07,850 INFO     Training average loss at step 88700: 0.389702
2025-12-13 01:18:10,007 INFO     Training average regularization at step 88800: 0.302547
2025-12-13 01:18:10,007 INFO     Training average positive_sample_loss at step 88800: 0.066407
2025-12-13 01:18:10,007 INFO     Training average negative_sample_loss at step 88800: 0.109104
2025-12-13 01:18:10,007 INFO     Training average loss at step 88800: 0.390302
2025-12-13 01:18:12,154 INFO     Training average regularization at step 88900: 0.302546
2025-12-13 01:18:12,155 INFO     Training average positive_sample_loss at step 88900: 0.066912
2025-12-13 01:18:12,155 INFO     Training average negative_sample_loss at step 88900: 0.108901
2025-12-13 01:18:12,155 INFO     Training average loss at step 88900: 0.390452
2025-12-13 01:18:14,296 INFO     Training average regularization at step 89000: 0.302545
2025-12-13 01:18:14,297 INFO     Training average positive_sample_loss at step 89000: 0.066861
2025-12-13 01:18:14,297 INFO     Training average negative_sample_loss at step 89000: 0.108379
2025-12-13 01:18:14,297 INFO     Training average loss at step 89000: 0.390165
2025-12-13 01:18:16,462 INFO     Training average regularization at step 89100: 0.302545
2025-12-13 01:18:16,462 INFO     Training average positive_sample_loss at step 89100: 0.067737
2025-12-13 01:18:16,462 INFO     Training average negative_sample_loss at step 89100: 0.108318
2025-12-13 01:18:16,462 INFO     Training average loss at step 89100: 0.390572
2025-12-13 01:18:18,625 INFO     Training average regularization at step 89200: 0.302544
2025-12-13 01:18:18,625 INFO     Training average positive_sample_loss at step 89200: 0.065263
2025-12-13 01:18:18,625 INFO     Training average negative_sample_loss at step 89200: 0.109601
2025-12-13 01:18:18,625 INFO     Training average loss at step 89200: 0.389976
2025-12-13 01:18:20,747 INFO     Training average regularization at step 89300: 0.302543
2025-12-13 01:18:20,747 INFO     Training average positive_sample_loss at step 89300: 0.067067
2025-12-13 01:18:20,747 INFO     Training average negative_sample_loss at step 89300: 0.110241
2025-12-13 01:18:20,747 INFO     Training average loss at step 89300: 0.391198
2025-12-13 01:18:22,879 INFO     Training average regularization at step 89400: 0.302543
2025-12-13 01:18:22,879 INFO     Training average positive_sample_loss at step 89400: 0.066372
2025-12-13 01:18:22,879 INFO     Training average negative_sample_loss at step 89400: 0.108685
2025-12-13 01:18:22,880 INFO     Training average loss at step 89400: 0.390071
2025-12-13 01:18:25,010 INFO     Training average regularization at step 89500: 0.302542
2025-12-13 01:18:25,010 INFO     Training average positive_sample_loss at step 89500: 0.067027
2025-12-13 01:18:25,010 INFO     Training average negative_sample_loss at step 89500: 0.107465
2025-12-13 01:18:25,010 INFO     Training average loss at step 89500: 0.389788
2025-12-13 01:18:27,145 INFO     Training average regularization at step 89600: 0.302541
2025-12-13 01:18:27,145 INFO     Training average positive_sample_loss at step 89600: 0.067022
2025-12-13 01:18:27,145 INFO     Training average negative_sample_loss at step 89600: 0.107563
2025-12-13 01:18:27,145 INFO     Training average loss at step 89600: 0.389834
2025-12-13 01:18:29,294 INFO     Training average regularization at step 89700: 0.302541
2025-12-13 01:18:29,295 INFO     Training average positive_sample_loss at step 89700: 0.066924
2025-12-13 01:18:29,295 INFO     Training average negative_sample_loss at step 89700: 0.107744
2025-12-13 01:18:29,295 INFO     Training average loss at step 89700: 0.389875
2025-12-13 01:18:31,460 INFO     Training average regularization at step 89800: 0.302540
2025-12-13 01:18:31,461 INFO     Training average positive_sample_loss at step 89800: 0.064961
2025-12-13 01:18:31,461 INFO     Training average negative_sample_loss at step 89800: 0.106750
2025-12-13 01:18:31,461 INFO     Training average loss at step 89800: 0.388395
2025-12-13 01:18:33,602 INFO     Training average regularization at step 89900: 0.302539
2025-12-13 01:18:33,602 INFO     Training average positive_sample_loss at step 89900: 0.068136
2025-12-13 01:18:33,602 INFO     Training average negative_sample_loss at step 89900: 0.110678
2025-12-13 01:18:33,602 INFO     Training average loss at step 89900: 0.391947
2025-12-13 01:18:35,738 INFO     Training average regularization at step 90000: 0.302539
2025-12-13 01:18:35,738 INFO     Training average positive_sample_loss at step 90000: 0.067149
2025-12-13 01:18:35,738 INFO     Training average negative_sample_loss at step 90000: 0.107163
2025-12-13 01:18:35,738 INFO     Training average loss at step 90000: 0.389695
2025-12-13 01:18:35,738 INFO     Evaluating on Valid Dataset...
2025-12-13 01:18:36,444 INFO     Evaluating the model... (0/50000)
2025-12-13 01:18:39,176 INFO     Evaluating the model... (500/50000)
2025-12-13 01:18:43,245 INFO     Evaluating the model... (1000/50000)
2025-12-13 01:18:45,822 INFO     Evaluating the model... (1500/50000)
2025-12-13 01:18:48,258 INFO     Evaluating the model... (2000/50000)
2025-12-13 01:18:50,735 INFO     Evaluating the model... (2500/50000)
2025-12-13 01:18:53,363 INFO     Evaluating the model... (3000/50000)
2025-12-13 01:18:56,592 INFO     Evaluating the model... (3500/50000)
2025-12-13 01:18:59,071 INFO     Evaluating the model... (4000/50000)
2025-12-13 01:19:01,456 INFO     Evaluating the model... (4500/50000)
2025-12-13 01:19:03,912 INFO     Evaluating the model... (5000/50000)
2025-12-13 01:19:07,164 INFO     Evaluating the model... (5500/50000)
2025-12-13 01:19:09,650 INFO     Evaluating the model... (6000/50000)
2025-12-13 01:19:12,078 INFO     Evaluating the model... (6500/50000)
2025-12-13 01:19:14,653 INFO     Evaluating the model... (7000/50000)
2025-12-13 01:19:17,307 INFO     Evaluating the model... (7500/50000)
2025-12-13 01:19:20,232 INFO     Evaluating the model... (8000/50000)
2025-12-13 01:19:22,591 INFO     Evaluating the model... (8500/50000)
2025-12-13 01:19:25,021 INFO     Evaluating the model... (9000/50000)
2025-12-13 01:19:27,705 INFO     Evaluating the model... (9500/50000)
2025-12-13 01:19:30,208 INFO     Evaluating the model... (10000/50000)
2025-12-13 01:19:33,310 INFO     Evaluating the model... (10500/50000)
2025-12-13 01:19:35,773 INFO     Evaluating the model... (11000/50000)
2025-12-13 01:19:38,451 INFO     Evaluating the model... (11500/50000)
2025-12-13 01:19:41,253 INFO     Evaluating the model... (12000/50000)
2025-12-13 01:19:43,851 INFO     Evaluating the model... (12500/50000)
2025-12-13 01:19:47,237 INFO     Evaluating the model... (13000/50000)
2025-12-13 01:19:49,631 INFO     Evaluating the model... (13500/50000)
2025-12-13 01:19:52,233 INFO     Evaluating the model... (14000/50000)
2025-12-13 01:19:54,657 INFO     Evaluating the model... (14500/50000)
2025-12-13 01:19:57,187 INFO     Evaluating the model... (15000/50000)
2025-12-13 01:20:00,364 INFO     Evaluating the model... (15500/50000)
2025-12-13 01:20:03,021 INFO     Evaluating the model... (16000/50000)
2025-12-13 01:20:05,552 INFO     Evaluating the model... (16500/50000)
2025-12-13 01:20:08,061 INFO     Evaluating the model... (17000/50000)
2025-12-13 01:20:10,576 INFO     Evaluating the model... (17500/50000)
2025-12-13 01:20:13,985 INFO     Evaluating the model... (18000/50000)
2025-12-13 01:20:16,535 INFO     Evaluating the model... (18500/50000)
2025-12-13 01:20:18,982 INFO     Evaluating the model... (19000/50000)
2025-12-13 01:20:21,294 INFO     Evaluating the model... (19500/50000)
2025-12-13 01:20:23,628 INFO     Evaluating the model... (20000/50000)
2025-12-13 01:20:27,369 INFO     Evaluating the model... (20500/50000)
2025-12-13 01:20:29,739 INFO     Evaluating the model... (21000/50000)
2025-12-13 01:20:32,185 INFO     Evaluating the model... (21500/50000)
2025-12-13 01:20:34,497 INFO     Evaluating the model... (22000/50000)
2025-12-13 01:20:37,451 INFO     Evaluating the model... (22500/50000)
2025-12-13 01:20:41,366 INFO     Evaluating the model... (23000/50000)
2025-12-13 01:20:43,834 INFO     Evaluating the model... (23500/50000)
2025-12-13 01:20:46,396 INFO     Evaluating the model... (24000/50000)
2025-12-13 01:20:49,045 INFO     Evaluating the model... (24500/50000)
2025-12-13 01:20:52,957 INFO     Evaluating the model... (25000/50000)
2025-12-13 01:20:57,190 INFO     Evaluating the model... (25500/50000)
2025-12-13 01:20:59,990 INFO     Evaluating the model... (26000/50000)
2025-12-13 01:21:02,534 INFO     Evaluating the model... (26500/50000)
2025-12-13 01:21:05,080 INFO     Evaluating the model... (27000/50000)
2025-12-13 01:21:07,681 INFO     Evaluating the model... (27500/50000)
2025-12-13 01:21:11,058 INFO     Evaluating the model... (28000/50000)
2025-12-13 01:21:13,623 INFO     Evaluating the model... (28500/50000)
2025-12-13 01:21:16,182 INFO     Evaluating the model... (29000/50000)
2025-12-13 01:21:18,715 INFO     Evaluating the model... (29500/50000)
2025-12-13 01:21:21,223 INFO     Evaluating the model... (30000/50000)
2025-12-13 01:21:24,468 INFO     Evaluating the model... (30500/50000)
2025-12-13 01:21:27,047 INFO     Evaluating the model... (31000/50000)
2025-12-13 01:21:29,574 INFO     Evaluating the model... (31500/50000)
2025-12-13 01:21:31,959 INFO     Evaluating the model... (32000/50000)
2025-12-13 01:21:35,247 INFO     Evaluating the model... (32500/50000)
2025-12-13 01:21:37,989 INFO     Evaluating the model... (33000/50000)
2025-12-13 01:21:40,653 INFO     Evaluating the model... (33500/50000)
2025-12-13 01:21:43,320 INFO     Evaluating the model... (34000/50000)
2025-12-13 01:21:46,180 INFO     Evaluating the model... (34500/50000)
2025-12-13 01:21:49,727 INFO     Evaluating the model... (35000/50000)
2025-12-13 01:21:52,320 INFO     Evaluating the model... (35500/50000)
2025-12-13 01:21:54,820 INFO     Evaluating the model... (36000/50000)
2025-12-13 01:21:57,707 INFO     Evaluating the model... (36500/50000)
2025-12-13 01:22:00,169 INFO     Evaluating the model... (37000/50000)
2025-12-13 01:22:03,756 INFO     Evaluating the model... (37500/50000)
2025-12-13 01:22:06,290 INFO     Evaluating the model... (38000/50000)
2025-12-13 01:22:08,896 INFO     Evaluating the model... (38500/50000)
2025-12-13 01:22:11,419 INFO     Evaluating the model... (39000/50000)
2025-12-13 01:22:13,910 INFO     Evaluating the model... (39500/50000)
2025-12-13 01:22:17,293 INFO     Evaluating the model... (40000/50000)
2025-12-13 01:22:19,892 INFO     Evaluating the model... (40500/50000)
2025-12-13 01:22:22,414 INFO     Evaluating the model... (41000/50000)
2025-12-13 01:22:25,011 INFO     Evaluating the model... (41500/50000)
2025-12-13 01:22:27,569 INFO     Evaluating the model... (42000/50000)
2025-12-13 01:22:31,266 INFO     Evaluating the model... (42500/50000)
2025-12-13 01:22:33,904 INFO     Evaluating the model... (43000/50000)
2025-12-13 01:22:36,696 INFO     Evaluating the model... (43500/50000)
2025-12-13 01:22:39,472 INFO     Evaluating the model... (44000/50000)
2025-12-13 01:22:42,177 INFO     Evaluating the model... (44500/50000)
2025-12-13 01:22:46,604 INFO     Evaluating the model... (45000/50000)
2025-12-13 01:22:49,023 INFO     Evaluating the model... (45500/50000)
2025-12-13 01:22:51,645 INFO     Evaluating the model... (46000/50000)
2025-12-13 01:22:54,301 INFO     Evaluating the model... (46500/50000)
2025-12-13 01:22:56,986 INFO     Evaluating the model... (47000/50000)
2025-12-13 01:23:00,526 INFO     Evaluating the model... (47500/50000)
2025-12-13 01:23:03,097 INFO     Evaluating the model... (48000/50000)
2025-12-13 01:23:05,587 INFO     Evaluating the model... (48500/50000)
2025-12-13 01:23:08,301 INFO     Evaluating the model... (49000/50000)
2025-12-13 01:23:11,012 INFO     Evaluating the model... (49500/50000)
2025-12-13 01:23:14,750 INFO     Valid MRR at step 90000: 0.629413
2025-12-13 01:23:14,750 INFO     Valid MR at step 90000: 266.203560
2025-12-13 01:23:14,750 INFO     Valid HITS@1 at step 90000: 0.543010
2025-12-13 01:23:14,750 INFO     Valid HITS@3 at step 90000: 0.681730
2025-12-13 01:23:14,750 INFO     Valid HITS@10 at step 90000: 0.783340
2025-12-13 01:23:16,037 INFO     Evaluating on Test Dataset...
2025-12-13 01:23:16,534 INFO     Evaluating the model... (0/59072)
2025-12-13 01:23:19,165 INFO     Evaluating the model... (500/59072)
2025-12-13 01:23:21,638 INFO     Evaluating the model... (1000/59072)
2025-12-13 01:23:24,229 INFO     Evaluating the model... (1500/59072)
2025-12-13 01:23:26,795 INFO     Evaluating the model... (2000/59072)
2025-12-13 01:23:30,230 INFO     Evaluating the model... (2500/59072)
2025-12-13 01:23:32,583 INFO     Evaluating the model... (3000/59072)
2025-12-13 01:23:35,053 INFO     Evaluating the model... (3500/59072)
2025-12-13 01:23:37,670 INFO     Evaluating the model... (4000/59072)
2025-12-13 01:23:40,641 INFO     Evaluating the model... (4500/59072)
2025-12-13 01:23:44,329 INFO     Evaluating the model... (5000/59072)
2025-12-13 01:23:46,770 INFO     Evaluating the model... (5500/59072)
2025-12-13 01:23:49,195 INFO     Evaluating the model... (6000/59072)
2025-12-13 01:23:51,731 INFO     Evaluating the model... (6500/59072)
2025-12-13 01:23:54,244 INFO     Evaluating the model... (7000/59072)
2025-12-13 01:23:57,448 INFO     Evaluating the model... (7500/59072)
2025-12-13 01:24:00,009 INFO     Evaluating the model... (8000/59072)
2025-12-13 01:24:02,510 INFO     Evaluating the model... (8500/59072)
2025-12-13 01:24:05,125 INFO     Evaluating the model... (9000/59072)
2025-12-13 01:24:08,026 INFO     Evaluating the model... (9500/59072)
2025-12-13 01:24:10,606 INFO     Evaluating the model... (10000/59072)
2025-12-13 01:24:13,047 INFO     Evaluating the model... (10500/59072)
2025-12-13 01:24:15,708 INFO     Evaluating the model... (11000/59072)
2025-12-13 01:24:18,030 INFO     Evaluating the model... (11500/59072)
2025-12-13 01:24:21,074 INFO     Evaluating the model... (12000/59072)
2025-12-13 01:24:23,521 INFO     Evaluating the model... (12500/59072)
2025-12-13 01:24:26,223 INFO     Evaluating the model... (13000/59072)
2025-12-13 01:24:28,753 INFO     Evaluating the model... (13500/59072)
2025-12-13 01:24:31,146 INFO     Evaluating the model... (14000/59072)
2025-12-13 01:24:34,109 INFO     Evaluating the model... (14500/59072)
2025-12-13 01:24:36,788 INFO     Evaluating the model... (15000/59072)
2025-12-13 01:24:39,658 INFO     Evaluating the model... (15500/59072)
2025-12-13 01:24:42,236 INFO     Evaluating the model... (16000/59072)
2025-12-13 01:24:44,887 INFO     Evaluating the model... (16500/59072)
2025-12-13 01:24:48,033 INFO     Evaluating the model... (17000/59072)
2025-12-13 01:24:50,668 INFO     Evaluating the model... (17500/59072)
2025-12-13 01:24:53,057 INFO     Evaluating the model... (18000/59072)
2025-12-13 01:24:55,502 INFO     Evaluating the model... (18500/59072)
2025-12-13 01:24:57,972 INFO     Evaluating the model... (19000/59072)
2025-12-13 01:25:01,298 INFO     Evaluating the model... (19500/59072)
2025-12-13 01:25:03,611 INFO     Evaluating the model... (20000/59072)
2025-12-13 01:25:05,948 INFO     Evaluating the model... (20500/59072)
2025-12-13 01:25:08,301 INFO     Evaluating the model... (21000/59072)
2025-12-13 01:25:10,730 INFO     Evaluating the model... (21500/59072)
2025-12-13 01:25:14,099 INFO     Evaluating the model... (22000/59072)
2025-12-13 01:25:16,587 INFO     Evaluating the model... (22500/59072)
2025-12-13 01:25:18,968 INFO     Evaluating the model... (23000/59072)
2025-12-13 01:25:21,387 INFO     Evaluating the model... (23500/59072)
2025-12-13 01:25:23,929 INFO     Evaluating the model... (24000/59072)
2025-12-13 01:25:27,610 INFO     Evaluating the model... (24500/59072)
2025-12-13 01:25:30,008 INFO     Evaluating the model... (25000/59072)
2025-12-13 01:25:32,380 INFO     Evaluating the model... (25500/59072)
2025-12-13 01:25:34,842 INFO     Evaluating the model... (26000/59072)
2025-12-13 01:25:37,597 INFO     Evaluating the model... (26500/59072)
2025-12-13 01:25:41,580 INFO     Evaluating the model... (27000/59072)
2025-12-13 01:25:44,233 INFO     Evaluating the model... (27500/59072)
2025-12-13 01:25:47,003 INFO     Evaluating the model... (28000/59072)
2025-12-13 01:25:49,595 INFO     Evaluating the model... (28500/59072)
2025-12-13 01:25:52,612 INFO     Evaluating the model... (29000/59072)
2025-12-13 01:25:55,983 INFO     Evaluating the model... (29500/59072)
2025-12-13 01:25:59,123 INFO     Evaluating the model... (30000/59072)
2025-12-13 01:26:01,618 INFO     Evaluating the model... (30500/59072)
2025-12-13 01:26:04,061 INFO     Evaluating the model... (31000/59072)
2025-12-13 01:26:07,536 INFO     Evaluating the model... (31500/59072)
2025-12-13 01:26:10,136 INFO     Evaluating the model... (32000/59072)
2025-12-13 01:26:12,736 INFO     Evaluating the model... (32500/59072)
2025-12-13 01:26:15,305 INFO     Evaluating the model... (33000/59072)
2025-12-13 01:26:17,813 INFO     Evaluating the model... (33500/59072)
2025-12-13 01:26:21,055 INFO     Evaluating the model... (34000/59072)
2025-12-13 01:26:23,668 INFO     Evaluating the model... (34500/59072)
2025-12-13 01:26:26,271 INFO     Evaluating the model... (35000/59072)
2025-12-13 01:26:28,852 INFO     Evaluating the model... (35500/59072)
2025-12-13 01:26:31,301 INFO     Evaluating the model... (36000/59072)
2025-12-13 01:26:34,710 INFO     Evaluating the model... (36500/59072)
2025-12-13 01:26:37,346 INFO     Evaluating the model... (37000/59072)
2025-12-13 01:26:40,030 INFO     Evaluating the model... (37500/59072)
2025-12-13 01:26:42,815 INFO     Evaluating the model... (38000/59072)
2025-12-13 01:26:45,719 INFO     Evaluating the model... (38500/59072)
2025-12-13 01:26:48,839 INFO     Evaluating the model... (39000/59072)
2025-12-13 01:26:51,451 INFO     Evaluating the model... (39500/59072)
2025-12-13 01:26:53,957 INFO     Evaluating the model... (40000/59072)
2025-12-13 01:26:56,734 INFO     Evaluating the model... (40500/59072)
2025-12-13 01:26:59,913 INFO     Evaluating the model... (41000/59072)
2025-12-13 01:27:02,311 INFO     Evaluating the model... (41500/59072)
2025-12-13 01:27:04,811 INFO     Evaluating the model... (42000/59072)
2025-12-13 01:27:07,573 INFO     Evaluating the model... (42500/59072)
2025-12-13 01:27:10,187 INFO     Evaluating the model... (43000/59072)
2025-12-13 01:27:13,239 INFO     Evaluating the model... (43500/59072)
2025-12-13 01:27:15,707 INFO     Evaluating the model... (44000/59072)
2025-12-13 01:27:18,193 INFO     Evaluating the model... (44500/59072)
2025-12-13 01:27:20,817 INFO     Evaluating the model... (45000/59072)
2025-12-13 01:27:23,408 INFO     Evaluating the model... (45500/59072)
2025-12-13 01:27:26,764 INFO     Evaluating the model... (46000/59072)
2025-12-13 01:27:29,177 INFO     Evaluating the model... (46500/59072)
2025-12-13 01:27:31,724 INFO     Evaluating the model... (47000/59072)
2025-12-13 01:27:34,115 INFO     Evaluating the model... (47500/59072)
2025-12-13 01:27:36,890 INFO     Evaluating the model... (48000/59072)
2025-12-13 01:27:40,477 INFO     Evaluating the model... (48500/59072)
2025-12-13 01:27:43,321 INFO     Evaluating the model... (49000/59072)
2025-12-13 01:27:46,035 INFO     Evaluating the model... (49500/59072)
2025-12-13 01:27:48,533 INFO     Evaluating the model... (50000/59072)
2025-12-13 01:27:50,994 INFO     Evaluating the model... (50500/59072)
2025-12-13 01:27:54,697 INFO     Evaluating the model... (51000/59072)
2025-12-13 01:27:57,191 INFO     Evaluating the model... (51500/59072)
2025-12-13 01:27:59,674 INFO     Evaluating the model... (52000/59072)
2025-12-13 01:28:02,225 INFO     Evaluating the model... (52500/59072)
2025-12-13 01:28:04,958 INFO     Evaluating the model... (53000/59072)
2025-12-13 01:28:08,732 INFO     Evaluating the model... (53500/59072)
2025-12-13 01:28:11,198 INFO     Evaluating the model... (54000/59072)
2025-12-13 01:28:13,659 INFO     Evaluating the model... (54500/59072)
2025-12-13 01:28:16,311 INFO     Evaluating the model... (55000/59072)
2025-12-13 01:28:18,881 INFO     Evaluating the model... (55500/59072)
2025-12-13 01:28:22,497 INFO     Evaluating the model... (56000/59072)
2025-12-13 01:28:25,063 INFO     Evaluating the model... (56500/59072)
2025-12-13 01:28:27,678 INFO     Evaluating the model... (57000/59072)
2025-12-13 01:28:30,357 INFO     Evaluating the model... (57500/59072)
2025-12-13 01:28:32,775 INFO     Evaluating the model... (58000/59072)
2025-12-13 01:28:36,569 INFO     Evaluating the model... (58500/59072)
2025-12-13 01:28:39,193 INFO     Evaluating the model... (59000/59072)
2025-12-13 01:28:39,882 INFO     Test MRR at step 90000: 0.625633
2025-12-13 01:28:39,882 INFO     Test MR at step 90000: 268.228539
2025-12-13 01:28:39,882 INFO     Test HITS@1 at step 90000: 0.537260
2025-12-13 01:28:39,882 INFO     Test HITS@3 at step 90000: 0.680283
2025-12-13 01:28:39,882 INFO     Test HITS@10 at step 90000: 0.781593
2025-12-13 01:28:42,099 INFO     Training average regularization at step 90100: 0.302538
2025-12-13 01:28:42,099 INFO     Training average positive_sample_loss at step 90100: 0.066590
2025-12-13 01:28:42,099 INFO     Training average negative_sample_loss at step 90100: 0.107004
2025-12-13 01:28:42,099 INFO     Training average loss at step 90100: 0.389335
2025-12-13 01:28:44,354 INFO     Training average regularization at step 90200: 0.302538
2025-12-13 01:28:44,355 INFO     Training average positive_sample_loss at step 90200: 0.066238
2025-12-13 01:28:44,355 INFO     Training average negative_sample_loss at step 90200: 0.109321
2025-12-13 01:28:44,355 INFO     Training average loss at step 90200: 0.390317
2025-12-13 01:28:46,521 INFO     Training average regularization at step 90300: 0.302537
2025-12-13 01:28:46,522 INFO     Training average positive_sample_loss at step 90300: 0.067681
2025-12-13 01:28:46,522 INFO     Training average negative_sample_loss at step 90300: 0.109697
2025-12-13 01:28:46,522 INFO     Training average loss at step 90300: 0.391226
2025-12-13 01:28:48,668 INFO     Training average regularization at step 90400: 0.302537
2025-12-13 01:28:48,669 INFO     Training average positive_sample_loss at step 90400: 0.065915
2025-12-13 01:28:48,669 INFO     Training average negative_sample_loss at step 90400: 0.107825
2025-12-13 01:28:48,669 INFO     Training average loss at step 90400: 0.389407
2025-12-13 01:28:50,829 INFO     Training average regularization at step 90500: 0.302536
2025-12-13 01:28:50,830 INFO     Training average positive_sample_loss at step 90500: 0.065233
2025-12-13 01:28:50,830 INFO     Training average negative_sample_loss at step 90500: 0.108854
2025-12-13 01:28:50,830 INFO     Training average loss at step 90500: 0.389579
2025-12-13 01:28:52,981 INFO     Training average regularization at step 90600: 0.302535
2025-12-13 01:28:52,982 INFO     Training average positive_sample_loss at step 90600: 0.068193
2025-12-13 01:28:52,982 INFO     Training average negative_sample_loss at step 90600: 0.109092
2025-12-13 01:28:52,982 INFO     Training average loss at step 90600: 0.391178
2025-12-13 01:28:55,148 INFO     Training average regularization at step 90700: 0.302535
2025-12-13 01:28:55,148 INFO     Training average positive_sample_loss at step 90700: 0.068192
2025-12-13 01:28:55,148 INFO     Training average negative_sample_loss at step 90700: 0.110065
2025-12-13 01:28:55,148 INFO     Training average loss at step 90700: 0.391663
2025-12-13 01:28:57,283 INFO     Training average regularization at step 90800: 0.302534
2025-12-13 01:28:57,283 INFO     Training average positive_sample_loss at step 90800: 0.066989
2025-12-13 01:28:57,283 INFO     Training average negative_sample_loss at step 90800: 0.107931
2025-12-13 01:28:57,283 INFO     Training average loss at step 90800: 0.389994
2025-12-13 01:28:59,425 INFO     Training average regularization at step 90900: 0.302534
2025-12-13 01:28:59,425 INFO     Training average positive_sample_loss at step 90900: 0.068069
2025-12-13 01:28:59,425 INFO     Training average negative_sample_loss at step 90900: 0.108297
2025-12-13 01:28:59,425 INFO     Training average loss at step 90900: 0.390717
2025-12-13 01:29:01,615 INFO     Training average regularization at step 91000: 0.302533
2025-12-13 01:29:01,615 INFO     Training average positive_sample_loss at step 91000: 0.068581
2025-12-13 01:29:01,615 INFO     Training average negative_sample_loss at step 91000: 0.108459
2025-12-13 01:29:01,615 INFO     Training average loss at step 91000: 0.391053
2025-12-13 01:29:03,783 INFO     Training average regularization at step 91100: 0.302532
2025-12-13 01:29:03,783 INFO     Training average positive_sample_loss at step 91100: 0.066497
2025-12-13 01:29:03,783 INFO     Training average negative_sample_loss at step 91100: 0.110065
2025-12-13 01:29:03,783 INFO     Training average loss at step 91100: 0.390814
2025-12-13 01:29:05,927 INFO     Training average regularization at step 91200: 0.302532
2025-12-13 01:29:05,927 INFO     Training average positive_sample_loss at step 91200: 0.067120
2025-12-13 01:29:05,927 INFO     Training average negative_sample_loss at step 91200: 0.112756
2025-12-13 01:29:05,927 INFO     Training average loss at step 91200: 0.392470
2025-12-13 01:29:08,074 INFO     Training average regularization at step 91300: 0.302531
2025-12-13 01:29:08,074 INFO     Training average positive_sample_loss at step 91300: 0.066821
2025-12-13 01:29:08,074 INFO     Training average negative_sample_loss at step 91300: 0.111101
2025-12-13 01:29:08,074 INFO     Training average loss at step 91300: 0.391492
2025-12-13 01:29:10,215 INFO     Training average regularization at step 91400: 0.302531
2025-12-13 01:29:10,215 INFO     Training average positive_sample_loss at step 91400: 0.066272
2025-12-13 01:29:10,215 INFO     Training average negative_sample_loss at step 91400: 0.108837
2025-12-13 01:29:10,215 INFO     Training average loss at step 91400: 0.390085
2025-12-13 01:29:12,387 INFO     Training average regularization at step 91500: 0.302530
2025-12-13 01:29:12,387 INFO     Training average positive_sample_loss at step 91500: 0.067028
2025-12-13 01:29:12,387 INFO     Training average negative_sample_loss at step 91500: 0.109528
2025-12-13 01:29:12,387 INFO     Training average loss at step 91500: 0.390808
2025-12-13 01:29:14,580 INFO     Training average regularization at step 91600: 0.302529
2025-12-13 01:29:14,580 INFO     Training average positive_sample_loss at step 91600: 0.066626
2025-12-13 01:29:14,580 INFO     Training average negative_sample_loss at step 91600: 0.108454
2025-12-13 01:29:14,580 INFO     Training average loss at step 91600: 0.390069
2025-12-13 01:29:16,722 INFO     Training average regularization at step 91700: 0.302529
2025-12-13 01:29:16,722 INFO     Training average positive_sample_loss at step 91700: 0.067464
2025-12-13 01:29:16,722 INFO     Training average negative_sample_loss at step 91700: 0.108673
2025-12-13 01:29:16,722 INFO     Training average loss at step 91700: 0.390597
2025-12-13 01:29:19,039 INFO     Training average regularization at step 91800: 0.302528
2025-12-13 01:29:19,039 INFO     Training average positive_sample_loss at step 91800: 0.067425
2025-12-13 01:29:19,039 INFO     Training average negative_sample_loss at step 91800: 0.110433
2025-12-13 01:29:19,039 INFO     Training average loss at step 91800: 0.391458
2025-12-13 01:29:22,094 INFO     Training average regularization at step 91900: 0.302528
2025-12-13 01:29:22,095 INFO     Training average positive_sample_loss at step 91900: 0.066810
2025-12-13 01:29:22,095 INFO     Training average negative_sample_loss at step 91900: 0.108951
2025-12-13 01:29:22,095 INFO     Training average loss at step 91900: 0.390408
2025-12-13 01:29:24,290 INFO     Training average regularization at step 92000: 0.302527
2025-12-13 01:29:24,290 INFO     Training average positive_sample_loss at step 92000: 0.067000
2025-12-13 01:29:24,290 INFO     Training average negative_sample_loss at step 92000: 0.109433
2025-12-13 01:29:24,290 INFO     Training average loss at step 92000: 0.390743
2025-12-13 01:29:26,452 INFO     Training average regularization at step 92100: 0.302526
2025-12-13 01:29:26,453 INFO     Training average positive_sample_loss at step 92100: 0.067520
2025-12-13 01:29:26,453 INFO     Training average negative_sample_loss at step 92100: 0.109582
2025-12-13 01:29:26,453 INFO     Training average loss at step 92100: 0.391077
2025-12-13 01:29:28,603 INFO     Training average regularization at step 92200: 0.302526
2025-12-13 01:29:28,603 INFO     Training average positive_sample_loss at step 92200: 0.067014
2025-12-13 01:29:28,603 INFO     Training average negative_sample_loss at step 92200: 0.108559
2025-12-13 01:29:28,603 INFO     Training average loss at step 92200: 0.390312
2025-12-13 01:29:30,769 INFO     Training average regularization at step 92300: 0.302525
2025-12-13 01:29:30,770 INFO     Training average positive_sample_loss at step 92300: 0.066064
2025-12-13 01:29:30,770 INFO     Training average negative_sample_loss at step 92300: 0.108687
2025-12-13 01:29:30,770 INFO     Training average loss at step 92300: 0.389901
2025-12-13 01:29:32,914 INFO     Training average regularization at step 92400: 0.302524
2025-12-13 01:29:32,915 INFO     Training average positive_sample_loss at step 92400: 0.066851
2025-12-13 01:29:32,915 INFO     Training average negative_sample_loss at step 92400: 0.111495
2025-12-13 01:29:32,915 INFO     Training average loss at step 92400: 0.391697
2025-12-13 01:29:35,097 INFO     Training average regularization at step 92500: 0.302523
2025-12-13 01:29:35,097 INFO     Training average positive_sample_loss at step 92500: 0.066811
2025-12-13 01:29:35,097 INFO     Training average negative_sample_loss at step 92500: 0.110386
2025-12-13 01:29:35,097 INFO     Training average loss at step 92500: 0.391122
2025-12-13 01:29:37,293 INFO     Training average regularization at step 92600: 0.302523
2025-12-13 01:29:37,294 INFO     Training average positive_sample_loss at step 92600: 0.066835
2025-12-13 01:29:37,294 INFO     Training average negative_sample_loss at step 92600: 0.109274
2025-12-13 01:29:37,294 INFO     Training average loss at step 92600: 0.390577
2025-12-13 01:29:39,466 INFO     Training average regularization at step 92700: 0.302522
2025-12-13 01:29:39,466 INFO     Training average positive_sample_loss at step 92700: 0.067127
2025-12-13 01:29:39,466 INFO     Training average negative_sample_loss at step 92700: 0.108936
2025-12-13 01:29:39,466 INFO     Training average loss at step 92700: 0.390553
2025-12-13 01:29:41,664 INFO     Training average regularization at step 92800: 0.302521
2025-12-13 01:29:41,664 INFO     Training average positive_sample_loss at step 92800: 0.067064
2025-12-13 01:29:41,664 INFO     Training average negative_sample_loss at step 92800: 0.107558
2025-12-13 01:29:41,664 INFO     Training average loss at step 92800: 0.389832
2025-12-13 01:29:43,852 INFO     Training average regularization at step 92900: 0.302521
2025-12-13 01:29:43,859 INFO     Training average positive_sample_loss at step 92900: 0.067277
2025-12-13 01:29:43,859 INFO     Training average negative_sample_loss at step 92900: 0.108767
2025-12-13 01:29:43,859 INFO     Training average loss at step 92900: 0.390543
2025-12-13 01:29:46,080 INFO     Training average regularization at step 93000: 0.302520
2025-12-13 01:29:46,080 INFO     Training average positive_sample_loss at step 93000: 0.065985
2025-12-13 01:29:46,080 INFO     Training average negative_sample_loss at step 93000: 0.107730
2025-12-13 01:29:46,080 INFO     Training average loss at step 93000: 0.389377
2025-12-13 01:29:48,236 INFO     Training average regularization at step 93100: 0.302519
2025-12-13 01:29:48,236 INFO     Training average positive_sample_loss at step 93100: 0.066260
2025-12-13 01:29:48,236 INFO     Training average negative_sample_loss at step 93100: 0.108471
2025-12-13 01:29:48,236 INFO     Training average loss at step 93100: 0.389885
2025-12-13 01:29:50,389 INFO     Training average regularization at step 93200: 0.302519
2025-12-13 01:29:50,389 INFO     Training average positive_sample_loss at step 93200: 0.066224
2025-12-13 01:29:50,389 INFO     Training average negative_sample_loss at step 93200: 0.108206
2025-12-13 01:29:50,389 INFO     Training average loss at step 93200: 0.389733
2025-12-13 01:29:52,526 INFO     Training average regularization at step 93300: 0.302518
2025-12-13 01:29:52,526 INFO     Training average positive_sample_loss at step 93300: 0.067298
2025-12-13 01:29:52,526 INFO     Training average negative_sample_loss at step 93300: 0.106513
2025-12-13 01:29:52,526 INFO     Training average loss at step 93300: 0.389423
2025-12-13 01:29:54,697 INFO     Training average regularization at step 93400: 0.302517
2025-12-13 01:29:54,697 INFO     Training average positive_sample_loss at step 93400: 0.067873
2025-12-13 01:29:54,697 INFO     Training average negative_sample_loss at step 93400: 0.107833
2025-12-13 01:29:54,697 INFO     Training average loss at step 93400: 0.390370
2025-12-13 01:29:56,876 INFO     Training average regularization at step 93500: 0.302517
2025-12-13 01:29:56,877 INFO     Training average positive_sample_loss at step 93500: 0.066682
2025-12-13 01:29:56,877 INFO     Training average negative_sample_loss at step 93500: 0.110019
2025-12-13 01:29:56,877 INFO     Training average loss at step 93500: 0.390867
2025-12-13 01:29:59,042 INFO     Training average regularization at step 93600: 0.302516
2025-12-13 01:29:59,042 INFO     Training average positive_sample_loss at step 93600: 0.066834
2025-12-13 01:29:59,042 INFO     Training average negative_sample_loss at step 93600: 0.107844
2025-12-13 01:29:59,042 INFO     Training average loss at step 93600: 0.389855
2025-12-13 01:30:01,193 INFO     Training average regularization at step 93700: 0.302516
2025-12-13 01:30:01,193 INFO     Training average positive_sample_loss at step 93700: 0.067220
2025-12-13 01:30:01,193 INFO     Training average negative_sample_loss at step 93700: 0.110007
2025-12-13 01:30:01,193 INFO     Training average loss at step 93700: 0.391129
2025-12-13 01:30:03,341 INFO     Training average regularization at step 93800: 0.302515
2025-12-13 01:30:03,341 INFO     Training average positive_sample_loss at step 93800: 0.066749
2025-12-13 01:30:03,341 INFO     Training average negative_sample_loss at step 93800: 0.107632
2025-12-13 01:30:03,341 INFO     Training average loss at step 93800: 0.389705
2025-12-13 01:30:05,504 INFO     Training average regularization at step 93900: 0.302514
2025-12-13 01:30:05,504 INFO     Training average positive_sample_loss at step 93900: 0.067240
2025-12-13 01:30:05,504 INFO     Training average negative_sample_loss at step 93900: 0.107067
2025-12-13 01:30:05,504 INFO     Training average loss at step 93900: 0.389668
2025-12-13 01:30:07,691 INFO     Training average regularization at step 94000: 0.302514
2025-12-13 01:30:07,691 INFO     Training average positive_sample_loss at step 94000: 0.065929
2025-12-13 01:30:07,691 INFO     Training average negative_sample_loss at step 94000: 0.108619
2025-12-13 01:30:07,691 INFO     Training average loss at step 94000: 0.389788
2025-12-13 01:30:09,897 INFO     Training average regularization at step 94100: 0.302513
2025-12-13 01:30:09,897 INFO     Training average positive_sample_loss at step 94100: 0.066245
2025-12-13 01:30:09,897 INFO     Training average negative_sample_loss at step 94100: 0.108705
2025-12-13 01:30:09,897 INFO     Training average loss at step 94100: 0.389988
2025-12-13 01:30:12,052 INFO     Training average regularization at step 94200: 0.302512
2025-12-13 01:30:12,052 INFO     Training average positive_sample_loss at step 94200: 0.066267
2025-12-13 01:30:12,052 INFO     Training average negative_sample_loss at step 94200: 0.107753
2025-12-13 01:30:12,052 INFO     Training average loss at step 94200: 0.389522
2025-12-13 01:30:14,203 INFO     Training average regularization at step 94300: 0.302511
2025-12-13 01:30:14,203 INFO     Training average positive_sample_loss at step 94300: 0.066593
2025-12-13 01:30:14,203 INFO     Training average negative_sample_loss at step 94300: 0.108624
2025-12-13 01:30:14,203 INFO     Training average loss at step 94300: 0.390119
2025-12-13 01:30:16,347 INFO     Training average regularization at step 94400: 0.302511
2025-12-13 01:30:16,347 INFO     Training average positive_sample_loss at step 94400: 0.066016
2025-12-13 01:30:16,347 INFO     Training average negative_sample_loss at step 94400: 0.109133
2025-12-13 01:30:16,347 INFO     Training average loss at step 94400: 0.390085
2025-12-13 01:30:18,533 INFO     Training average regularization at step 94500: 0.302510
2025-12-13 01:30:18,534 INFO     Training average positive_sample_loss at step 94500: 0.067596
2025-12-13 01:30:18,534 INFO     Training average negative_sample_loss at step 94500: 0.111945
2025-12-13 01:30:18,534 INFO     Training average loss at step 94500: 0.392280
2025-12-13 01:30:20,675 INFO     Training average regularization at step 94600: 0.302509
2025-12-13 01:30:20,675 INFO     Training average positive_sample_loss at step 94600: 0.065505
2025-12-13 01:30:20,675 INFO     Training average negative_sample_loss at step 94600: 0.109218
2025-12-13 01:30:20,675 INFO     Training average loss at step 94600: 0.389871
2025-12-13 01:30:22,830 INFO     Training average regularization at step 94700: 0.302509
2025-12-13 01:30:22,830 INFO     Training average positive_sample_loss at step 94700: 0.067319
2025-12-13 01:30:22,830 INFO     Training average negative_sample_loss at step 94700: 0.110136
2025-12-13 01:30:22,830 INFO     Training average loss at step 94700: 0.391236
2025-12-13 01:30:25,001 INFO     Training average regularization at step 94800: 0.302508
2025-12-13 01:30:25,001 INFO     Training average positive_sample_loss at step 94800: 0.066343
2025-12-13 01:30:25,001 INFO     Training average negative_sample_loss at step 94800: 0.107050
2025-12-13 01:30:25,001 INFO     Training average loss at step 94800: 0.389204
2025-12-13 01:30:27,174 INFO     Training average regularization at step 94900: 0.302507
2025-12-13 01:30:27,174 INFO     Training average positive_sample_loss at step 94900: 0.066924
2025-12-13 01:30:27,174 INFO     Training average negative_sample_loss at step 94900: 0.107699
2025-12-13 01:30:27,174 INFO     Training average loss at step 94900: 0.389819
2025-12-13 01:30:29,333 INFO     Training average regularization at step 95000: 0.302507
2025-12-13 01:30:29,333 INFO     Training average positive_sample_loss at step 95000: 0.066566
2025-12-13 01:30:29,334 INFO     Training average negative_sample_loss at step 95000: 0.107346
2025-12-13 01:30:29,334 INFO     Training average loss at step 95000: 0.389463
2025-12-13 01:30:31,487 INFO     Training average regularization at step 95100: 0.302506
2025-12-13 01:30:31,487 INFO     Training average positive_sample_loss at step 95100: 0.067226
2025-12-13 01:30:31,487 INFO     Training average negative_sample_loss at step 95100: 0.110998
2025-12-13 01:30:31,487 INFO     Training average loss at step 95100: 0.391618
2025-12-13 01:30:33,640 INFO     Training average regularization at step 95200: 0.302506
2025-12-13 01:30:33,640 INFO     Training average positive_sample_loss at step 95200: 0.067060
2025-12-13 01:30:33,640 INFO     Training average negative_sample_loss at step 95200: 0.108343
2025-12-13 01:30:33,640 INFO     Training average loss at step 95200: 0.390207
2025-12-13 01:30:35,811 INFO     Training average regularization at step 95300: 0.302505
2025-12-13 01:30:35,811 INFO     Training average positive_sample_loss at step 95300: 0.066634
2025-12-13 01:30:35,811 INFO     Training average negative_sample_loss at step 95300: 0.109929
2025-12-13 01:30:35,811 INFO     Training average loss at step 95300: 0.390787
2025-12-13 01:30:37,998 INFO     Training average regularization at step 95400: 0.302505
2025-12-13 01:30:37,998 INFO     Training average positive_sample_loss at step 95400: 0.065271
2025-12-13 01:30:37,998 INFO     Training average negative_sample_loss at step 95400: 0.108682
2025-12-13 01:30:37,998 INFO     Training average loss at step 95400: 0.389481
2025-12-13 01:30:40,214 INFO     Training average regularization at step 95500: 0.302504
2025-12-13 01:30:40,214 INFO     Training average positive_sample_loss at step 95500: 0.067297
2025-12-13 01:30:40,214 INFO     Training average negative_sample_loss at step 95500: 0.108989
2025-12-13 01:30:40,214 INFO     Training average loss at step 95500: 0.390647
2025-12-13 01:30:42,407 INFO     Training average regularization at step 95600: 0.302503
2025-12-13 01:30:42,407 INFO     Training average positive_sample_loss at step 95600: 0.066069
2025-12-13 01:30:42,407 INFO     Training average negative_sample_loss at step 95600: 0.108599
2025-12-13 01:30:42,407 INFO     Training average loss at step 95600: 0.389838
2025-12-13 01:30:44,585 INFO     Training average regularization at step 95700: 0.302503
2025-12-13 01:30:44,585 INFO     Training average positive_sample_loss at step 95700: 0.067468
2025-12-13 01:30:44,586 INFO     Training average negative_sample_loss at step 95700: 0.109428
2025-12-13 01:30:44,586 INFO     Training average loss at step 95700: 0.390951
2025-12-13 01:30:46,758 INFO     Training average regularization at step 95800: 0.302502
2025-12-13 01:30:46,759 INFO     Training average positive_sample_loss at step 95800: 0.065829
2025-12-13 01:30:46,759 INFO     Training average negative_sample_loss at step 95800: 0.109750
2025-12-13 01:30:46,759 INFO     Training average loss at step 95800: 0.390291
2025-12-13 01:30:48,914 INFO     Training average regularization at step 95900: 0.302501
2025-12-13 01:30:48,914 INFO     Training average positive_sample_loss at step 95900: 0.066176
2025-12-13 01:30:48,914 INFO     Training average negative_sample_loss at step 95900: 0.111501
2025-12-13 01:30:48,914 INFO     Training average loss at step 95900: 0.391340
2025-12-13 01:30:51,067 INFO     Training average regularization at step 96000: 0.302500
2025-12-13 01:30:51,068 INFO     Training average positive_sample_loss at step 96000: 0.066123
2025-12-13 01:30:51,068 INFO     Training average negative_sample_loss at step 96000: 0.108604
2025-12-13 01:30:51,068 INFO     Training average loss at step 96000: 0.389864
2025-12-13 01:30:53,239 INFO     Training average regularization at step 96100: 0.302500
2025-12-13 01:30:53,239 INFO     Training average positive_sample_loss at step 96100: 0.067170
2025-12-13 01:30:53,239 INFO     Training average negative_sample_loss at step 96100: 0.109922
2025-12-13 01:30:53,240 INFO     Training average loss at step 96100: 0.391046
2025-12-13 01:30:55,384 INFO     Training average regularization at step 96200: 0.302499
2025-12-13 01:30:55,384 INFO     Training average positive_sample_loss at step 96200: 0.067121
2025-12-13 01:30:55,384 INFO     Training average negative_sample_loss at step 96200: 0.110625
2025-12-13 01:30:55,384 INFO     Training average loss at step 96200: 0.391372
2025-12-13 01:30:57,547 INFO     Training average regularization at step 96300: 0.302499
2025-12-13 01:30:57,547 INFO     Training average positive_sample_loss at step 96300: 0.067600
2025-12-13 01:30:57,547 INFO     Training average negative_sample_loss at step 96300: 0.109817
2025-12-13 01:30:57,547 INFO     Training average loss at step 96300: 0.391207
2025-12-13 01:30:59,708 INFO     Training average regularization at step 96400: 0.302498
2025-12-13 01:30:59,708 INFO     Training average positive_sample_loss at step 96400: 0.068033
2025-12-13 01:30:59,708 INFO     Training average negative_sample_loss at step 96400: 0.109991
2025-12-13 01:30:59,708 INFO     Training average loss at step 96400: 0.391510
2025-12-13 01:31:01,861 INFO     Training average regularization at step 96500: 0.302498
2025-12-13 01:31:01,862 INFO     Training average positive_sample_loss at step 96500: 0.066812
2025-12-13 01:31:01,862 INFO     Training average negative_sample_loss at step 96500: 0.107890
2025-12-13 01:31:01,862 INFO     Training average loss at step 96500: 0.389849
2025-12-13 01:31:04,053 INFO     Training average regularization at step 96600: 0.302497
2025-12-13 01:31:04,053 INFO     Training average positive_sample_loss at step 96600: 0.067092
2025-12-13 01:31:04,053 INFO     Training average negative_sample_loss at step 96600: 0.110597
2025-12-13 01:31:04,053 INFO     Training average loss at step 96600: 0.391341
2025-12-13 01:31:07,209 INFO     Training average regularization at step 96700: 0.302496
2025-12-13 01:31:07,209 INFO     Training average positive_sample_loss at step 96700: 0.066974
2025-12-13 01:31:07,210 INFO     Training average negative_sample_loss at step 96700: 0.109904
2025-12-13 01:31:07,210 INFO     Training average loss at step 96700: 0.390936
2025-12-13 01:31:09,357 INFO     Training average regularization at step 96800: 0.302496
2025-12-13 01:31:09,358 INFO     Training average positive_sample_loss at step 96800: 0.066754
2025-12-13 01:31:09,358 INFO     Training average negative_sample_loss at step 96800: 0.108708
2025-12-13 01:31:09,358 INFO     Training average loss at step 96800: 0.390227
2025-12-13 01:31:11,515 INFO     Training average regularization at step 96900: 0.302495
2025-12-13 01:31:11,516 INFO     Training average positive_sample_loss at step 96900: 0.066743
2025-12-13 01:31:11,516 INFO     Training average negative_sample_loss at step 96900: 0.110037
2025-12-13 01:31:11,516 INFO     Training average loss at step 96900: 0.390885
2025-12-13 01:31:13,695 INFO     Training average regularization at step 97000: 0.302494
2025-12-13 01:31:13,695 INFO     Training average positive_sample_loss at step 97000: 0.066198
2025-12-13 01:31:13,695 INFO     Training average negative_sample_loss at step 97000: 0.107300
2025-12-13 01:31:13,695 INFO     Training average loss at step 97000: 0.389243
2025-12-13 01:31:15,855 INFO     Training average regularization at step 97100: 0.302493
2025-12-13 01:31:15,855 INFO     Training average positive_sample_loss at step 97100: 0.066972
2025-12-13 01:31:15,855 INFO     Training average negative_sample_loss at step 97100: 0.107581
2025-12-13 01:31:15,855 INFO     Training average loss at step 97100: 0.389770
2025-12-13 01:31:18,010 INFO     Training average regularization at step 97200: 0.302493
2025-12-13 01:31:18,010 INFO     Training average positive_sample_loss at step 97200: 0.066658
2025-12-13 01:31:18,010 INFO     Training average negative_sample_loss at step 97200: 0.109313
2025-12-13 01:31:18,010 INFO     Training average loss at step 97200: 0.390478
2025-12-13 01:31:20,164 INFO     Training average regularization at step 97300: 0.302492
2025-12-13 01:31:20,164 INFO     Training average positive_sample_loss at step 97300: 0.066522
2025-12-13 01:31:20,164 INFO     Training average negative_sample_loss at step 97300: 0.106980
2025-12-13 01:31:20,165 INFO     Training average loss at step 97300: 0.389243
2025-12-13 01:31:22,310 INFO     Training average regularization at step 97400: 0.302491
2025-12-13 01:31:22,311 INFO     Training average positive_sample_loss at step 97400: 0.067662
2025-12-13 01:31:22,311 INFO     Training average negative_sample_loss at step 97400: 0.110656
2025-12-13 01:31:22,311 INFO     Training average loss at step 97400: 0.391651
2025-12-13 01:31:24,479 INFO     Training average regularization at step 97500: 0.302491
2025-12-13 01:31:24,479 INFO     Training average positive_sample_loss at step 97500: 0.065939
2025-12-13 01:31:24,479 INFO     Training average negative_sample_loss at step 97500: 0.108230
2025-12-13 01:31:24,479 INFO     Training average loss at step 97500: 0.389575
2025-12-13 01:31:26,680 INFO     Training average regularization at step 97600: 0.302490
2025-12-13 01:31:26,681 INFO     Training average positive_sample_loss at step 97600: 0.067246
2025-12-13 01:31:26,681 INFO     Training average negative_sample_loss at step 97600: 0.109504
2025-12-13 01:31:26,681 INFO     Training average loss at step 97600: 0.390865
2025-12-13 01:31:28,841 INFO     Training average regularization at step 97700: 0.302489
2025-12-13 01:31:28,841 INFO     Training average positive_sample_loss at step 97700: 0.066905
2025-12-13 01:31:28,841 INFO     Training average negative_sample_loss at step 97700: 0.108942
2025-12-13 01:31:28,841 INFO     Training average loss at step 97700: 0.390413
2025-12-13 01:31:30,989 INFO     Training average regularization at step 97800: 0.302489
2025-12-13 01:31:30,990 INFO     Training average positive_sample_loss at step 97800: 0.066483
2025-12-13 01:31:30,990 INFO     Training average negative_sample_loss at step 97800: 0.114490
2025-12-13 01:31:30,990 INFO     Training average loss at step 97800: 0.392975
2025-12-13 01:31:33,144 INFO     Training average regularization at step 97900: 0.302488
2025-12-13 01:31:33,144 INFO     Training average positive_sample_loss at step 97900: 0.066666
2025-12-13 01:31:33,144 INFO     Training average negative_sample_loss at step 97900: 0.109124
2025-12-13 01:31:33,144 INFO     Training average loss at step 97900: 0.390382
2025-12-13 01:31:35,310 INFO     Training average regularization at step 98000: 0.302487
2025-12-13 01:31:35,310 INFO     Training average positive_sample_loss at step 98000: 0.067730
2025-12-13 01:31:35,310 INFO     Training average negative_sample_loss at step 98000: 0.109002
2025-12-13 01:31:35,310 INFO     Training average loss at step 98000: 0.390853
2025-12-13 01:31:37,506 INFO     Training average regularization at step 98100: 0.302487
2025-12-13 01:31:37,507 INFO     Training average positive_sample_loss at step 98100: 0.066786
2025-12-13 01:31:37,507 INFO     Training average negative_sample_loss at step 98100: 0.108162
2025-12-13 01:31:37,507 INFO     Training average loss at step 98100: 0.389961
2025-12-13 01:31:39,718 INFO     Training average regularization at step 98200: 0.302486
2025-12-13 01:31:39,718 INFO     Training average positive_sample_loss at step 98200: 0.066148
2025-12-13 01:31:39,718 INFO     Training average negative_sample_loss at step 98200: 0.108549
2025-12-13 01:31:39,718 INFO     Training average loss at step 98200: 0.389834
2025-12-13 01:31:41,903 INFO     Training average regularization at step 98300: 0.302485
2025-12-13 01:31:41,903 INFO     Training average positive_sample_loss at step 98300: 0.066970
2025-12-13 01:31:41,903 INFO     Training average negative_sample_loss at step 98300: 0.108390
2025-12-13 01:31:41,903 INFO     Training average loss at step 98300: 0.390165
2025-12-13 01:31:44,063 INFO     Training average regularization at step 98400: 0.302485
2025-12-13 01:31:44,063 INFO     Training average positive_sample_loss at step 98400: 0.067027
2025-12-13 01:31:44,063 INFO     Training average negative_sample_loss at step 98400: 0.109969
2025-12-13 01:31:44,063 INFO     Training average loss at step 98400: 0.390983
2025-12-13 01:31:46,270 INFO     Training average regularization at step 98500: 0.302484
2025-12-13 01:31:46,270 INFO     Training average positive_sample_loss at step 98500: 0.065581
2025-12-13 01:31:46,270 INFO     Training average negative_sample_loss at step 98500: 0.107758
2025-12-13 01:31:46,270 INFO     Training average loss at step 98500: 0.389154
2025-12-13 01:31:48,447 INFO     Training average regularization at step 98600: 0.302483
2025-12-13 01:31:48,447 INFO     Training average positive_sample_loss at step 98600: 0.066916
2025-12-13 01:31:48,447 INFO     Training average negative_sample_loss at step 98600: 0.109021
2025-12-13 01:31:48,447 INFO     Training average loss at step 98600: 0.390451
2025-12-13 01:31:50,631 INFO     Training average regularization at step 98700: 0.302483
2025-12-13 01:31:50,631 INFO     Training average positive_sample_loss at step 98700: 0.066867
2025-12-13 01:31:50,631 INFO     Training average negative_sample_loss at step 98700: 0.109200
2025-12-13 01:31:50,631 INFO     Training average loss at step 98700: 0.390516
2025-12-13 01:31:52,786 INFO     Training average regularization at step 98800: 0.302482
2025-12-13 01:31:52,786 INFO     Training average positive_sample_loss at step 98800: 0.066847
2025-12-13 01:31:52,787 INFO     Training average negative_sample_loss at step 98800: 0.110298
2025-12-13 01:31:52,787 INFO     Training average loss at step 98800: 0.391054
2025-12-13 01:31:54,966 INFO     Training average regularization at step 98900: 0.302481
2025-12-13 01:31:54,966 INFO     Training average positive_sample_loss at step 98900: 0.066751
2025-12-13 01:31:54,966 INFO     Training average negative_sample_loss at step 98900: 0.111102
2025-12-13 01:31:54,966 INFO     Training average loss at step 98900: 0.391408
2025-12-13 01:31:57,164 INFO     Training average regularization at step 99000: 0.302480
2025-12-13 01:31:57,164 INFO     Training average positive_sample_loss at step 99000: 0.066194
2025-12-13 01:31:57,164 INFO     Training average negative_sample_loss at step 99000: 0.109716
2025-12-13 01:31:57,164 INFO     Training average loss at step 99000: 0.390435
2025-12-13 01:31:59,339 INFO     Training average regularization at step 99100: 0.302480
2025-12-13 01:31:59,339 INFO     Training average positive_sample_loss at step 99100: 0.067084
2025-12-13 01:31:59,339 INFO     Training average negative_sample_loss at step 99100: 0.108773
2025-12-13 01:31:59,339 INFO     Training average loss at step 99100: 0.390408
2025-12-13 01:32:01,512 INFO     Training average regularization at step 99200: 0.302479
2025-12-13 01:32:01,512 INFO     Training average positive_sample_loss at step 99200: 0.065114
2025-12-13 01:32:01,512 INFO     Training average negative_sample_loss at step 99200: 0.109292
2025-12-13 01:32:01,512 INFO     Training average loss at step 99200: 0.389682
2025-12-13 01:32:03,672 INFO     Training average regularization at step 99300: 0.302478
2025-12-13 01:32:03,672 INFO     Training average positive_sample_loss at step 99300: 0.064962
2025-12-13 01:32:03,672 INFO     Training average negative_sample_loss at step 99300: 0.108713
2025-12-13 01:32:03,672 INFO     Training average loss at step 99300: 0.389316
2025-12-13 01:32:05,829 INFO     Training average regularization at step 99400: 0.302478
2025-12-13 01:32:05,829 INFO     Training average positive_sample_loss at step 99400: 0.067165
2025-12-13 01:32:05,829 INFO     Training average negative_sample_loss at step 99400: 0.108251
2025-12-13 01:32:05,829 INFO     Training average loss at step 99400: 0.390185
2025-12-13 01:32:07,976 INFO     Training average regularization at step 99500: 0.302477
2025-12-13 01:32:07,977 INFO     Training average positive_sample_loss at step 99500: 0.068102
2025-12-13 01:32:07,977 INFO     Training average negative_sample_loss at step 99500: 0.110262
2025-12-13 01:32:07,977 INFO     Training average loss at step 99500: 0.391659
2025-12-13 01:32:10,145 INFO     Training average regularization at step 99600: 0.302477
2025-12-13 01:32:10,145 INFO     Training average positive_sample_loss at step 99600: 0.066807
2025-12-13 01:32:10,145 INFO     Training average negative_sample_loss at step 99600: 0.109086
2025-12-13 01:32:10,145 INFO     Training average loss at step 99600: 0.390423
2025-12-13 01:32:12,304 INFO     Training average regularization at step 99700: 0.302476
2025-12-13 01:32:12,305 INFO     Training average positive_sample_loss at step 99700: 0.066839
2025-12-13 01:32:12,305 INFO     Training average negative_sample_loss at step 99700: 0.107795
2025-12-13 01:32:12,305 INFO     Training average loss at step 99700: 0.389793
2025-12-13 01:32:14,459 INFO     Training average regularization at step 99800: 0.302475
2025-12-13 01:32:14,460 INFO     Training average positive_sample_loss at step 99800: 0.067995
2025-12-13 01:32:14,460 INFO     Training average negative_sample_loss at step 99800: 0.109427
2025-12-13 01:32:14,460 INFO     Training average loss at step 99800: 0.391186
2025-12-13 01:32:16,605 INFO     Training average regularization at step 99900: 0.302475
2025-12-13 01:32:16,605 INFO     Training average positive_sample_loss at step 99900: 0.067120
2025-12-13 01:32:16,605 INFO     Training average negative_sample_loss at step 99900: 0.107680
2025-12-13 01:32:16,605 INFO     Training average loss at step 99900: 0.389875
2025-12-13 01:32:20,066 INFO     Training average regularization at step 100000: 0.302474
2025-12-13 01:32:20,066 INFO     Training average positive_sample_loss at step 100000: 0.067766
2025-12-13 01:32:20,066 INFO     Training average negative_sample_loss at step 100000: 0.108548
2025-12-13 01:32:20,066 INFO     Training average loss at step 100000: 0.390631
2025-12-13 01:32:20,067 INFO     Evaluating on Valid Dataset...
2025-12-13 01:32:20,845 INFO     Evaluating the model... (0/50000)
2025-12-13 01:32:23,234 INFO     Evaluating the model... (500/50000)
2025-12-13 01:32:25,759 INFO     Evaluating the model... (1000/50000)
2025-12-13 01:32:29,266 INFO     Evaluating the model... (1500/50000)
2025-12-13 01:32:31,875 INFO     Evaluating the model... (2000/50000)
2025-12-13 01:32:34,454 INFO     Evaluating the model... (2500/50000)
2025-12-13 01:32:37,156 INFO     Evaluating the model... (3000/50000)
2025-12-13 01:32:39,934 INFO     Evaluating the model... (3500/50000)
2025-12-13 01:32:43,658 INFO     Evaluating the model... (4000/50000)
2025-12-13 01:32:46,269 INFO     Evaluating the model... (4500/50000)
2025-12-13 01:32:48,814 INFO     Evaluating the model... (5000/50000)
2025-12-13 01:32:51,210 INFO     Evaluating the model... (5500/50000)
2025-12-13 01:32:54,305 INFO     Evaluating the model... (6000/50000)
2025-12-13 01:32:56,815 INFO     Evaluating the model... (6500/50000)
2025-12-13 01:32:59,271 INFO     Evaluating the model... (7000/50000)
2025-12-13 01:33:01,726 INFO     Evaluating the model... (7500/50000)
2025-12-13 01:33:04,197 INFO     Evaluating the model... (8000/50000)
2025-12-13 01:33:07,567 INFO     Evaluating the model... (8500/50000)
2025-12-13 01:33:09,959 INFO     Evaluating the model... (9000/50000)
2025-12-13 01:33:12,331 INFO     Evaluating the model... (9500/50000)
2025-12-13 01:33:14,777 INFO     Evaluating the model... (10000/50000)
2025-12-13 01:33:17,362 INFO     Evaluating the model... (10500/50000)
2025-12-13 01:33:20,360 INFO     Evaluating the model... (11000/50000)
2025-12-13 01:33:22,730 INFO     Evaluating the model... (11500/50000)
2025-12-13 01:33:25,176 INFO     Evaluating the model... (12000/50000)
2025-12-13 01:33:27,557 INFO     Evaluating the model... (12500/50000)
2025-12-13 01:33:30,153 INFO     Evaluating the model... (13000/50000)
2025-12-13 01:33:33,246 INFO     Evaluating the model... (13500/50000)
2025-12-13 01:33:35,772 INFO     Evaluating the model... (14000/50000)
2025-12-13 01:33:38,338 INFO     Evaluating the model... (14500/50000)
2025-12-13 01:33:41,118 INFO     Evaluating the model... (15000/50000)
2025-12-13 01:33:43,649 INFO     Evaluating the model... (15500/50000)
2025-12-13 01:33:47,006 INFO     Evaluating the model... (16000/50000)
2025-12-13 01:33:49,473 INFO     Evaluating the model... (16500/50000)
2025-12-13 01:33:52,029 INFO     Evaluating the model... (17000/50000)
2025-12-13 01:33:54,594 INFO     Evaluating the model... (17500/50000)
2025-12-13 01:33:57,167 INFO     Evaluating the model... (18000/50000)
2025-12-13 01:34:00,429 INFO     Evaluating the model... (18500/50000)
2025-12-13 01:34:02,891 INFO     Evaluating the model... (19000/50000)
2025-12-13 01:34:05,454 INFO     Evaluating the model... (19500/50000)
2025-12-13 01:34:07,963 INFO     Evaluating the model... (20000/50000)
2025-12-13 01:34:10,318 INFO     Evaluating the model... (20500/50000)
2025-12-13 01:34:13,767 INFO     Evaluating the model... (21000/50000)
2025-12-13 01:34:16,546 INFO     Evaluating the model... (21500/50000)
2025-12-13 01:34:19,029 INFO     Evaluating the model... (22000/50000)
2025-12-13 01:34:21,397 INFO     Evaluating the model... (22500/50000)
2025-12-13 01:34:23,774 INFO     Evaluating the model... (23000/50000)
2025-12-13 01:34:27,522 INFO     Evaluating the model... (23500/50000)
2025-12-13 01:34:29,942 INFO     Evaluating the model... (24000/50000)
2025-12-13 01:34:32,463 INFO     Evaluating the model... (24500/50000)
2025-12-13 01:34:35,386 INFO     Evaluating the model... (25000/50000)
2025-12-13 01:34:38,295 INFO     Evaluating the model... (25500/50000)
2025-12-13 01:34:42,019 INFO     Evaluating the model... (26000/50000)
2025-12-13 01:34:44,737 INFO     Evaluating the model... (26500/50000)
2025-12-13 01:34:47,393 INFO     Evaluating the model... (27000/50000)
2025-12-13 01:34:50,112 INFO     Evaluating the model... (27500/50000)
2025-12-13 01:34:52,592 INFO     Evaluating the model... (28000/50000)
2025-12-13 01:34:56,432 INFO     Evaluating the model... (28500/50000)
2025-12-13 01:34:58,986 INFO     Evaluating the model... (29000/50000)
2025-12-13 01:35:01,728 INFO     Evaluating the model... (29500/50000)
2025-12-13 01:35:04,318 INFO     Evaluating the model... (30000/50000)
2025-12-13 01:35:06,915 INFO     Evaluating the model... (30500/50000)
2025-12-13 01:35:10,071 INFO     Evaluating the model... (31000/50000)
2025-12-13 01:35:12,749 INFO     Evaluating the model... (31500/50000)
2025-12-13 01:35:15,327 INFO     Evaluating the model... (32000/50000)
2025-12-13 01:35:17,795 INFO     Evaluating the model... (32500/50000)
2025-12-13 01:35:20,344 INFO     Evaluating the model... (33000/50000)
2025-12-13 01:35:23,557 INFO     Evaluating the model... (33500/50000)
2025-12-13 01:35:26,268 INFO     Evaluating the model... (34000/50000)
2025-12-13 01:35:28,807 INFO     Evaluating the model... (34500/50000)
2025-12-13 01:35:31,303 INFO     Evaluating the model... (35000/50000)
2025-12-13 01:35:34,428 INFO     Evaluating the model... (35500/50000)
2025-12-13 01:35:37,318 INFO     Evaluating the model... (36000/50000)
2025-12-13 01:35:39,975 INFO     Evaluating the model... (36500/50000)
2025-12-13 01:35:42,767 INFO     Evaluating the model... (37000/50000)
2025-12-13 01:35:45,469 INFO     Evaluating the model... (37500/50000)
2025-12-13 01:35:49,172 INFO     Evaluating the model... (38000/50000)
2025-12-13 01:35:51,711 INFO     Evaluating the model... (38500/50000)
2025-12-13 01:35:54,174 INFO     Evaluating the model... (39000/50000)
2025-12-13 01:35:56,784 INFO     Evaluating the model... (39500/50000)
2025-12-13 01:35:59,623 INFO     Evaluating the model... (40000/50000)
2025-12-13 01:36:02,944 INFO     Evaluating the model... (40500/50000)
2025-12-13 01:36:05,446 INFO     Evaluating the model... (41000/50000)
2025-12-13 01:36:07,971 INFO     Evaluating the model... (41500/50000)
2025-12-13 01:36:10,738 INFO     Evaluating the model... (42000/50000)
2025-12-13 01:36:13,256 INFO     Evaluating the model... (42500/50000)
2025-12-13 01:36:17,088 INFO     Evaluating the model... (43000/50000)
2025-12-13 01:36:19,591 INFO     Evaluating the model... (43500/50000)
2025-12-13 01:36:22,500 INFO     Evaluating the model... (44000/50000)
2025-12-13 01:36:25,008 INFO     Evaluating the model... (44500/50000)
2025-12-13 01:36:27,462 INFO     Evaluating the model... (45000/50000)
2025-12-13 01:36:31,305 INFO     Evaluating the model... (45500/50000)
2025-12-13 01:36:33,951 INFO     Evaluating the model... (46000/50000)
2025-12-13 01:36:36,571 INFO     Evaluating the model... (46500/50000)
2025-12-13 01:36:39,348 INFO     Evaluating the model... (47000/50000)
2025-12-13 01:36:42,011 INFO     Evaluating the model... (47500/50000)
2025-12-13 01:36:46,114 INFO     Evaluating the model... (48000/50000)
2025-12-13 01:36:48,506 INFO     Evaluating the model... (48500/50000)
2025-12-13 01:36:51,026 INFO     Evaluating the model... (49000/50000)
2025-12-13 01:36:53,538 INFO     Evaluating the model... (49500/50000)
2025-12-13 01:36:56,530 INFO     Valid MRR at step 100000: 0.630233
2025-12-13 01:36:56,530 INFO     Valid MR at step 100000: 266.305920
2025-12-13 01:36:56,531 INFO     Valid HITS@1 at step 100000: 0.543950
2025-12-13 01:36:56,531 INFO     Valid HITS@3 at step 100000: 0.683000
2025-12-13 01:36:56,531 INFO     Valid HITS@10 at step 100000: 0.784020
2025-12-13 01:36:58,246 INFO     Evaluating on Test Dataset...
2025-12-13 01:36:58,791 INFO     Evaluating the model... (0/59072)
2025-12-13 01:37:02,319 INFO     Evaluating the model... (500/59072)
2025-12-13 01:37:04,888 INFO     Evaluating the model... (1000/59072)
2025-12-13 01:37:07,636 INFO     Evaluating the model... (1500/59072)
2025-12-13 01:37:10,126 INFO     Evaluating the model... (2000/59072)
2025-12-13 01:37:12,828 INFO     Evaluating the model... (2500/59072)
2025-12-13 01:37:15,962 INFO     Evaluating the model... (3000/59072)
2025-12-13 01:37:18,514 INFO     Evaluating the model... (3500/59072)
2025-12-13 01:37:21,066 INFO     Evaluating the model... (4000/59072)
2025-12-13 01:37:23,653 INFO     Evaluating the model... (4500/59072)
2025-12-13 01:37:26,206 INFO     Evaluating the model... (5000/59072)
2025-12-13 01:37:29,123 INFO     Evaluating the model... (5500/59072)
2025-12-13 01:37:31,832 INFO     Evaluating the model... (6000/59072)
2025-12-13 01:37:34,293 INFO     Evaluating the model... (6500/59072)
2025-12-13 01:37:36,980 INFO     Evaluating the model... (7000/59072)
2025-12-13 01:37:39,650 INFO     Evaluating the model... (7500/59072)
2025-12-13 01:37:43,156 INFO     Evaluating the model... (8000/59072)
2025-12-13 01:37:45,927 INFO     Evaluating the model... (8500/59072)
2025-12-13 01:37:48,371 INFO     Evaluating the model... (9000/59072)
2025-12-13 01:37:50,764 INFO     Evaluating the model... (9500/59072)
2025-12-13 01:37:53,411 INFO     Evaluating the model... (10000/59072)
2025-12-13 01:37:56,687 INFO     Evaluating the model... (10500/59072)
2025-12-13 01:37:59,121 INFO     Evaluating the model... (11000/59072)
2025-12-13 01:38:01,492 INFO     Evaluating the model... (11500/59072)
2025-12-13 01:38:03,975 INFO     Evaluating the model... (12000/59072)
2025-12-13 01:38:07,222 INFO     Evaluating the model... (12500/59072)
2025-12-13 01:38:09,609 INFO     Evaluating the model... (13000/59072)
2025-12-13 01:38:12,249 INFO     Evaluating the model... (13500/59072)
2025-12-13 01:38:14,663 INFO     Evaluating the model... (14000/59072)
2025-12-13 01:38:17,317 INFO     Evaluating the model... (14500/59072)
2025-12-13 01:38:20,623 INFO     Evaluating the model... (15000/59072)
2025-12-13 01:38:23,072 INFO     Evaluating the model... (15500/59072)
2025-12-13 01:38:25,561 INFO     Evaluating the model... (16000/59072)
2025-12-13 01:38:28,158 INFO     Evaluating the model... (16500/59072)
2025-12-13 01:38:30,589 INFO     Evaluating the model... (17000/59072)
2025-12-13 01:38:33,790 INFO     Evaluating the model... (17500/59072)
2025-12-13 01:38:36,299 INFO     Evaluating the model... (18000/59072)
2025-12-13 01:38:39,428 INFO     Evaluating the model... (18500/59072)
2025-12-13 01:38:42,159 INFO     Evaluating the model... (19000/59072)
2025-12-13 01:38:44,766 INFO     Evaluating the model... (19500/59072)
2025-12-13 01:38:48,509 INFO     Evaluating the model... (20000/59072)
2025-12-13 01:38:51,127 INFO     Evaluating the model... (20500/59072)
2025-12-13 01:38:53,678 INFO     Evaluating the model... (21000/59072)
2025-12-13 01:38:56,130 INFO     Evaluating the model... (21500/59072)
2025-12-13 01:38:58,500 INFO     Evaluating the model... (22000/59072)
2025-12-13 01:39:02,065 INFO     Evaluating the model... (22500/59072)
2025-12-13 01:39:04,782 INFO     Evaluating the model... (23000/59072)
2025-12-13 01:39:07,324 INFO     Evaluating the model... (23500/59072)
2025-12-13 01:39:09,760 INFO     Evaluating the model... (24000/59072)
2025-12-13 01:39:12,211 INFO     Evaluating the model... (24500/59072)
2025-12-13 01:39:15,917 INFO     Evaluating the model... (25000/59072)
2025-12-13 01:39:18,314 INFO     Evaluating the model... (25500/59072)
2025-12-13 01:39:20,808 INFO     Evaluating the model... (26000/59072)
2025-12-13 01:39:23,238 INFO     Evaluating the model... (26500/59072)
2025-12-13 01:39:25,888 INFO     Evaluating the model... (27000/59072)
2025-12-13 01:39:29,512 INFO     Evaluating the model... (27500/59072)
2025-12-13 01:39:31,974 INFO     Evaluating the model... (28000/59072)
2025-12-13 01:39:34,401 INFO     Evaluating the model... (28500/59072)
2025-12-13 01:39:37,197 INFO     Evaluating the model... (29000/59072)
2025-12-13 01:39:39,918 INFO     Evaluating the model... (29500/59072)
2025-12-13 01:39:43,894 INFO     Evaluating the model... (30000/59072)
2025-12-13 01:39:46,626 INFO     Evaluating the model... (30500/59072)
2025-12-13 01:39:49,366 INFO     Evaluating the model... (31000/59072)
2025-12-13 01:39:51,961 INFO     Evaluating the model... (31500/59072)
2025-12-13 01:39:55,370 INFO     Evaluating the model... (32000/59072)
2025-12-13 01:39:57,876 INFO     Evaluating the model... (32500/59072)
2025-12-13 01:40:00,729 INFO     Evaluating the model... (33000/59072)
2025-12-13 01:40:03,169 INFO     Evaluating the model... (33500/59072)
2025-12-13 01:40:05,728 INFO     Evaluating the model... (34000/59072)
2025-12-13 01:40:08,999 INFO     Evaluating the model... (34500/59072)
2025-12-13 01:40:11,596 INFO     Evaluating the model... (35000/59072)
2025-12-13 01:40:14,130 INFO     Evaluating the model... (35500/59072)
2025-12-13 01:40:16,589 INFO     Evaluating the model... (36000/59072)
2025-12-13 01:40:19,005 INFO     Evaluating the model... (36500/59072)
2025-12-13 01:40:22,201 INFO     Evaluating the model... (37000/59072)
2025-12-13 01:40:24,856 INFO     Evaluating the model... (37500/59072)
2025-12-13 01:40:27,331 INFO     Evaluating the model... (38000/59072)
2025-12-13 01:40:29,738 INFO     Evaluating the model... (38500/59072)
2025-12-13 01:40:32,104 INFO     Evaluating the model... (39000/59072)
2025-12-13 01:40:35,178 INFO     Evaluating the model... (39500/59072)
2025-12-13 01:40:37,948 INFO     Evaluating the model... (40000/59072)
2025-12-13 01:40:40,645 INFO     Evaluating the model... (40500/59072)
2025-12-13 01:40:43,399 INFO     Evaluating the model... (41000/59072)
2025-12-13 01:40:46,159 INFO     Evaluating the model... (41500/59072)
2025-12-13 01:40:49,064 INFO     Evaluating the model... (42000/59072)
2025-12-13 01:40:51,536 INFO     Evaluating the model... (42500/59072)
2025-12-13 01:40:54,110 INFO     Evaluating the model... (43000/59072)
2025-12-13 01:40:56,677 INFO     Evaluating the model... (43500/59072)
2025-12-13 01:41:00,086 INFO     Evaluating the model... (44000/59072)
2025-12-13 01:41:02,508 INFO     Evaluating the model... (44500/59072)
2025-12-13 01:41:05,022 INFO     Evaluating the model... (45000/59072)
2025-12-13 01:41:07,491 INFO     Evaluating the model... (45500/59072)
2025-12-13 01:41:10,197 INFO     Evaluating the model... (46000/59072)
2025-12-13 01:41:13,514 INFO     Evaluating the model... (46500/59072)
2025-12-13 01:41:16,011 INFO     Evaluating the model... (47000/59072)
2025-12-13 01:41:18,542 INFO     Evaluating the model... (47500/59072)
2025-12-13 01:41:21,199 INFO     Evaluating the model... (48000/59072)
2025-12-13 01:41:23,656 INFO     Evaluating the model... (48500/59072)
2025-12-13 01:41:27,072 INFO     Evaluating the model... (49000/59072)
2025-12-13 01:41:29,487 INFO     Evaluating the model... (49500/59072)
2025-12-13 01:41:32,191 INFO     Evaluating the model... (50000/59072)
2025-12-13 01:41:34,801 INFO     Evaluating the model... (50500/59072)
2025-12-13 01:41:37,554 INFO     Evaluating the model... (51000/59072)
2025-12-13 01:41:41,411 INFO     Evaluating the model... (51500/59072)
2025-12-13 01:41:44,462 INFO     Evaluating the model... (52000/59072)
2025-12-13 01:41:46,990 INFO     Evaluating the model... (52500/59072)
2025-12-13 01:41:49,477 INFO     Evaluating the model... (53000/59072)
2025-12-13 01:41:51,970 INFO     Evaluating the model... (53500/59072)
2025-12-13 01:41:55,573 INFO     Evaluating the model... (54000/59072)
2025-12-13 01:41:58,049 INFO     Evaluating the model... (54500/59072)
2025-12-13 01:42:00,540 INFO     Evaluating the model... (55000/59072)
2025-12-13 01:42:02,926 INFO     Evaluating the model... (55500/59072)
2025-12-13 01:42:05,495 INFO     Evaluating the model... (56000/59072)
2025-12-13 01:42:09,152 INFO     Evaluating the model... (56500/59072)
2025-12-13 01:42:11,725 INFO     Evaluating the model... (57000/59072)
2025-12-13 01:42:14,138 INFO     Evaluating the model... (57500/59072)
2025-12-13 01:42:16,699 INFO     Evaluating the model... (58000/59072)
2025-12-13 01:42:19,330 INFO     Evaluating the model... (58500/59072)
2025-12-13 01:42:22,707 INFO     Evaluating the model... (59000/59072)
2025-12-13 01:42:23,289 INFO     Test MRR at step 100000: 0.626427
2025-12-13 01:42:23,289 INFO     Test MR at step 100000: 268.356546
2025-12-13 01:42:23,289 INFO     Test HITS@1 at step 100000: 0.538149
2025-12-13 01:42:23,289 INFO     Test HITS@3 at step 100000: 0.681460
2025-12-13 01:42:23,289 INFO     Test HITS@10 at step 100000: 0.782093
2025-12-13 01:42:25,472 INFO     Training average regularization at step 100100: 0.302473
2025-12-13 01:42:25,472 INFO     Training average positive_sample_loss at step 100100: 0.066500
2025-12-13 01:42:25,472 INFO     Training average negative_sample_loss at step 100100: 0.107110
2025-12-13 01:42:25,472 INFO     Training average loss at step 100100: 0.389279
2025-12-13 01:42:27,630 INFO     Training average regularization at step 100200: 0.302473
2025-12-13 01:42:27,632 INFO     Training average positive_sample_loss at step 100200: 0.067592
2025-12-13 01:42:27,632 INFO     Training average negative_sample_loss at step 100200: 0.110526
2025-12-13 01:42:27,632 INFO     Training average loss at step 100200: 0.391532
2025-12-13 01:42:29,775 INFO     Training average regularization at step 100300: 0.302472
2025-12-13 01:42:29,775 INFO     Training average positive_sample_loss at step 100300: 0.066745
2025-12-13 01:42:29,775 INFO     Training average negative_sample_loss at step 100300: 0.111192
2025-12-13 01:42:29,775 INFO     Training average loss at step 100300: 0.391441
2025-12-13 01:42:31,957 INFO     Training average regularization at step 100400: 0.302472
2025-12-13 01:42:31,957 INFO     Training average positive_sample_loss at step 100400: 0.066502
2025-12-13 01:42:31,957 INFO     Training average negative_sample_loss at step 100400: 0.108953
2025-12-13 01:42:31,957 INFO     Training average loss at step 100400: 0.390199
2025-12-13 01:42:34,147 INFO     Training average regularization at step 100500: 0.302471
2025-12-13 01:42:34,147 INFO     Training average positive_sample_loss at step 100500: 0.066068
2025-12-13 01:42:34,147 INFO     Training average negative_sample_loss at step 100500: 0.109758
2025-12-13 01:42:34,147 INFO     Training average loss at step 100500: 0.390384
2025-12-13 01:42:36,372 INFO     Training average regularization at step 100600: 0.302470
2025-12-13 01:42:36,373 INFO     Training average positive_sample_loss at step 100600: 0.066067
2025-12-13 01:42:36,373 INFO     Training average negative_sample_loss at step 100600: 0.107896
2025-12-13 01:42:36,373 INFO     Training average loss at step 100600: 0.389452
2025-12-13 01:42:38,584 INFO     Training average regularization at step 100700: 0.302470
2025-12-13 01:42:38,585 INFO     Training average positive_sample_loss at step 100700: 0.067310
2025-12-13 01:42:38,585 INFO     Training average negative_sample_loss at step 100700: 0.111829
2025-12-13 01:42:38,585 INFO     Training average loss at step 100700: 0.392039
2025-12-13 01:42:40,806 INFO     Training average regularization at step 100800: 0.302469
2025-12-13 01:42:40,806 INFO     Training average positive_sample_loss at step 100800: 0.066560
2025-12-13 01:42:40,806 INFO     Training average negative_sample_loss at step 100800: 0.108916
2025-12-13 01:42:40,806 INFO     Training average loss at step 100800: 0.390207
2025-12-13 01:42:42,980 INFO     Training average regularization at step 100900: 0.302469
2025-12-13 01:42:42,980 INFO     Training average positive_sample_loss at step 100900: 0.067907
2025-12-13 01:42:42,980 INFO     Training average negative_sample_loss at step 100900: 0.110459
2025-12-13 01:42:42,981 INFO     Training average loss at step 100900: 0.391651
2025-12-13 01:42:45,149 INFO     Training average regularization at step 101000: 0.302468
2025-12-13 01:42:45,149 INFO     Training average positive_sample_loss at step 101000: 0.066663
2025-12-13 01:42:45,149 INFO     Training average negative_sample_loss at step 101000: 0.107292
2025-12-13 01:42:45,149 INFO     Training average loss at step 101000: 0.389445
2025-12-13 01:42:47,329 INFO     Training average regularization at step 101100: 0.302467
2025-12-13 01:42:47,329 INFO     Training average positive_sample_loss at step 101100: 0.066157
2025-12-13 01:42:47,329 INFO     Training average negative_sample_loss at step 101100: 0.109995
2025-12-13 01:42:47,329 INFO     Training average loss at step 101100: 0.390543
2025-12-13 01:42:49,477 INFO     Training average regularization at step 101200: 0.302467
2025-12-13 01:42:49,477 INFO     Training average positive_sample_loss at step 101200: 0.066347
2025-12-13 01:42:49,477 INFO     Training average negative_sample_loss at step 101200: 0.108999
2025-12-13 01:42:49,477 INFO     Training average loss at step 101200: 0.390140
2025-12-13 01:42:51,661 INFO     Training average regularization at step 101300: 0.302466
2025-12-13 01:42:51,661 INFO     Training average positive_sample_loss at step 101300: 0.066107
2025-12-13 01:42:51,661 INFO     Training average negative_sample_loss at step 101300: 0.111815
2025-12-13 01:42:51,661 INFO     Training average loss at step 101300: 0.391427
2025-12-13 01:42:53,814 INFO     Training average regularization at step 101400: 0.302465
2025-12-13 01:42:53,814 INFO     Training average positive_sample_loss at step 101400: 0.068011
2025-12-13 01:42:53,814 INFO     Training average negative_sample_loss at step 101400: 0.108933
2025-12-13 01:42:53,814 INFO     Training average loss at step 101400: 0.390937
2025-12-13 01:42:56,929 INFO     Training average regularization at step 101500: 0.302465
2025-12-13 01:42:56,929 INFO     Training average positive_sample_loss at step 101500: 0.067314
2025-12-13 01:42:56,929 INFO     Training average negative_sample_loss at step 101500: 0.111021
2025-12-13 01:42:56,929 INFO     Training average loss at step 101500: 0.391632
2025-12-13 01:42:59,086 INFO     Training average regularization at step 101600: 0.302464
2025-12-13 01:42:59,087 INFO     Training average positive_sample_loss at step 101600: 0.065884
2025-12-13 01:42:59,087 INFO     Training average negative_sample_loss at step 101600: 0.107483
2025-12-13 01:42:59,087 INFO     Training average loss at step 101600: 0.389148
2025-12-13 01:43:01,239 INFO     Training average regularization at step 101700: 0.302463
2025-12-13 01:43:01,239 INFO     Training average positive_sample_loss at step 101700: 0.066996
2025-12-13 01:43:01,239 INFO     Training average negative_sample_loss at step 101700: 0.109117
2025-12-13 01:43:01,239 INFO     Training average loss at step 101700: 0.390520
2025-12-13 01:43:03,395 INFO     Training average regularization at step 101800: 0.302463
2025-12-13 01:43:03,395 INFO     Training average positive_sample_loss at step 101800: 0.065560
2025-12-13 01:43:03,395 INFO     Training average negative_sample_loss at step 101800: 0.106547
2025-12-13 01:43:03,395 INFO     Training average loss at step 101800: 0.388516
2025-12-13 01:43:05,535 INFO     Training average regularization at step 101900: 0.302462
2025-12-13 01:43:05,535 INFO     Training average positive_sample_loss at step 101900: 0.067104
2025-12-13 01:43:05,535 INFO     Training average negative_sample_loss at step 101900: 0.110217
2025-12-13 01:43:05,535 INFO     Training average loss at step 101900: 0.391122
2025-12-13 01:43:07,674 INFO     Training average regularization at step 102000: 0.302461
2025-12-13 01:43:07,674 INFO     Training average positive_sample_loss at step 102000: 0.066173
2025-12-13 01:43:07,675 INFO     Training average negative_sample_loss at step 102000: 0.108502
2025-12-13 01:43:07,675 INFO     Training average loss at step 102000: 0.389799
2025-12-13 01:43:09,822 INFO     Training average regularization at step 102100: 0.302460
2025-12-13 01:43:09,822 INFO     Training average positive_sample_loss at step 102100: 0.068354
2025-12-13 01:43:09,822 INFO     Training average negative_sample_loss at step 102100: 0.110277
2025-12-13 01:43:09,823 INFO     Training average loss at step 102100: 0.391775
2025-12-13 01:43:11,983 INFO     Training average regularization at step 102200: 0.302460
2025-12-13 01:43:11,983 INFO     Training average positive_sample_loss at step 102200: 0.067239
2025-12-13 01:43:11,983 INFO     Training average negative_sample_loss at step 102200: 0.108505
2025-12-13 01:43:11,983 INFO     Training average loss at step 102200: 0.390332
2025-12-13 01:43:14,138 INFO     Training average regularization at step 102300: 0.302459
2025-12-13 01:43:14,138 INFO     Training average positive_sample_loss at step 102300: 0.066838
2025-12-13 01:43:14,138 INFO     Training average negative_sample_loss at step 102300: 0.110348
2025-12-13 01:43:14,138 INFO     Training average loss at step 102300: 0.391052
2025-12-13 01:43:16,300 INFO     Training average regularization at step 102400: 0.302458
2025-12-13 01:43:16,300 INFO     Training average positive_sample_loss at step 102400: 0.065855
2025-12-13 01:43:16,300 INFO     Training average negative_sample_loss at step 102400: 0.107688
2025-12-13 01:43:16,300 INFO     Training average loss at step 102400: 0.389229
2025-12-13 01:43:18,470 INFO     Training average regularization at step 102500: 0.302457
2025-12-13 01:43:18,470 INFO     Training average positive_sample_loss at step 102500: 0.065503
2025-12-13 01:43:18,470 INFO     Training average negative_sample_loss at step 102500: 0.110189
2025-12-13 01:43:18,470 INFO     Training average loss at step 102500: 0.390303
2025-12-13 01:43:20,607 INFO     Training average regularization at step 102600: 0.302456
2025-12-13 01:43:20,608 INFO     Training average positive_sample_loss at step 102600: 0.065508
2025-12-13 01:43:20,608 INFO     Training average negative_sample_loss at step 102600: 0.106357
2025-12-13 01:43:20,608 INFO     Training average loss at step 102600: 0.388389
2025-12-13 01:43:22,755 INFO     Training average regularization at step 102700: 0.302456
2025-12-13 01:43:22,755 INFO     Training average positive_sample_loss at step 102700: 0.065707
2025-12-13 01:43:22,755 INFO     Training average negative_sample_loss at step 102700: 0.105876
2025-12-13 01:43:22,755 INFO     Training average loss at step 102700: 0.388247
2025-12-13 01:43:24,926 INFO     Training average regularization at step 102800: 0.302455
2025-12-13 01:43:24,926 INFO     Training average positive_sample_loss at step 102800: 0.066814
2025-12-13 01:43:24,926 INFO     Training average negative_sample_loss at step 102800: 0.108759
2025-12-13 01:43:24,926 INFO     Training average loss at step 102800: 0.390241
2025-12-13 01:43:27,074 INFO     Training average regularization at step 102900: 0.302454
2025-12-13 01:43:27,075 INFO     Training average positive_sample_loss at step 102900: 0.067165
2025-12-13 01:43:27,075 INFO     Training average negative_sample_loss at step 102900: 0.110096
2025-12-13 01:43:27,075 INFO     Training average loss at step 102900: 0.391085
2025-12-13 01:43:29,218 INFO     Training average regularization at step 103000: 0.302453
2025-12-13 01:43:29,219 INFO     Training average positive_sample_loss at step 103000: 0.066868
2025-12-13 01:43:29,219 INFO     Training average negative_sample_loss at step 103000: 0.108265
2025-12-13 01:43:29,219 INFO     Training average loss at step 103000: 0.390020
2025-12-13 01:43:31,372 INFO     Training average regularization at step 103100: 0.302453
2025-12-13 01:43:31,373 INFO     Training average positive_sample_loss at step 103100: 0.067925
2025-12-13 01:43:31,373 INFO     Training average negative_sample_loss at step 103100: 0.108960
2025-12-13 01:43:31,373 INFO     Training average loss at step 103100: 0.390895
2025-12-13 01:43:33,524 INFO     Training average regularization at step 103200: 0.302452
2025-12-13 01:43:33,524 INFO     Training average positive_sample_loss at step 103200: 0.065662
2025-12-13 01:43:33,524 INFO     Training average negative_sample_loss at step 103200: 0.107955
2025-12-13 01:43:33,524 INFO     Training average loss at step 103200: 0.389261
2025-12-13 01:43:35,711 INFO     Training average regularization at step 103300: 0.302451
2025-12-13 01:43:35,711 INFO     Training average positive_sample_loss at step 103300: 0.068063
2025-12-13 01:43:35,711 INFO     Training average negative_sample_loss at step 103300: 0.108357
2025-12-13 01:43:35,711 INFO     Training average loss at step 103300: 0.390661
2025-12-13 01:43:37,897 INFO     Training average regularization at step 103400: 0.302451
2025-12-13 01:43:37,965 INFO     Training average positive_sample_loss at step 103400: 0.066724
2025-12-13 01:43:37,965 INFO     Training average negative_sample_loss at step 103400: 0.107555
2025-12-13 01:43:37,965 INFO     Training average loss at step 103400: 0.389590
2025-12-13 01:43:40,141 INFO     Training average regularization at step 103500: 0.302450
2025-12-13 01:43:40,141 INFO     Training average positive_sample_loss at step 103500: 0.067143
2025-12-13 01:43:40,141 INFO     Training average negative_sample_loss at step 103500: 0.109352
2025-12-13 01:43:40,141 INFO     Training average loss at step 103500: 0.390698
2025-12-13 01:43:42,344 INFO     Training average regularization at step 103600: 0.302450
2025-12-13 01:43:42,344 INFO     Training average positive_sample_loss at step 103600: 0.066202
2025-12-13 01:43:42,344 INFO     Training average negative_sample_loss at step 103600: 0.107560
2025-12-13 01:43:42,344 INFO     Training average loss at step 103600: 0.389331
2025-12-13 01:43:44,536 INFO     Training average regularization at step 103700: 0.302449
2025-12-13 01:43:44,537 INFO     Training average positive_sample_loss at step 103700: 0.066584
2025-12-13 01:43:44,537 INFO     Training average negative_sample_loss at step 103700: 0.109300
2025-12-13 01:43:44,537 INFO     Training average loss at step 103700: 0.390391
2025-12-13 01:43:46,696 INFO     Training average regularization at step 103800: 0.302449
2025-12-13 01:43:46,696 INFO     Training average positive_sample_loss at step 103800: 0.067443
2025-12-13 01:43:46,696 INFO     Training average negative_sample_loss at step 103800: 0.110865
2025-12-13 01:43:46,696 INFO     Training average loss at step 103800: 0.391603
2025-12-13 01:43:48,831 INFO     Training average regularization at step 103900: 0.302448
2025-12-13 01:43:48,831 INFO     Training average positive_sample_loss at step 103900: 0.066998
2025-12-13 01:43:48,831 INFO     Training average negative_sample_loss at step 103900: 0.106819
2025-12-13 01:43:48,831 INFO     Training average loss at step 103900: 0.389357
2025-12-13 01:43:50,979 INFO     Training average regularization at step 104000: 0.302448
2025-12-13 01:43:50,979 INFO     Training average positive_sample_loss at step 104000: 0.065995
2025-12-13 01:43:50,979 INFO     Training average negative_sample_loss at step 104000: 0.109671
2025-12-13 01:43:50,979 INFO     Training average loss at step 104000: 0.390281
2025-12-13 01:43:53,128 INFO     Training average regularization at step 104100: 0.302447
2025-12-13 01:43:53,129 INFO     Training average positive_sample_loss at step 104100: 0.068153
2025-12-13 01:43:53,129 INFO     Training average negative_sample_loss at step 104100: 0.109512
2025-12-13 01:43:53,129 INFO     Training average loss at step 104100: 0.391280
2025-12-13 01:43:55,288 INFO     Training average regularization at step 104200: 0.302447
2025-12-13 01:43:55,288 INFO     Training average positive_sample_loss at step 104200: 0.067661
2025-12-13 01:43:55,288 INFO     Training average negative_sample_loss at step 104200: 0.108520
2025-12-13 01:43:55,288 INFO     Training average loss at step 104200: 0.390537
2025-12-13 01:43:57,449 INFO     Training average regularization at step 104300: 0.302446
2025-12-13 01:43:57,449 INFO     Training average positive_sample_loss at step 104300: 0.066631
2025-12-13 01:43:57,449 INFO     Training average negative_sample_loss at step 104300: 0.109059
2025-12-13 01:43:57,449 INFO     Training average loss at step 104300: 0.390291
2025-12-13 01:43:59,602 INFO     Training average regularization at step 104400: 0.302446
2025-12-13 01:43:59,602 INFO     Training average positive_sample_loss at step 104400: 0.067336
2025-12-13 01:43:59,602 INFO     Training average negative_sample_loss at step 104400: 0.109293
2025-12-13 01:43:59,602 INFO     Training average loss at step 104400: 0.390761
2025-12-13 01:44:01,737 INFO     Training average regularization at step 104500: 0.302445
2025-12-13 01:44:01,737 INFO     Training average positive_sample_loss at step 104500: 0.066803
2025-12-13 01:44:01,737 INFO     Training average negative_sample_loss at step 104500: 0.111942
2025-12-13 01:44:01,737 INFO     Training average loss at step 104500: 0.391818
2025-12-13 01:44:03,866 INFO     Training average regularization at step 104600: 0.302444
2025-12-13 01:44:03,866 INFO     Training average positive_sample_loss at step 104600: 0.067069
2025-12-13 01:44:03,866 INFO     Training average negative_sample_loss at step 104600: 0.109009
2025-12-13 01:44:03,866 INFO     Training average loss at step 104600: 0.390484
2025-12-13 01:44:06,009 INFO     Training average regularization at step 104700: 0.302444
2025-12-13 01:44:06,010 INFO     Training average positive_sample_loss at step 104700: 0.066226
2025-12-13 01:44:06,010 INFO     Training average negative_sample_loss at step 104700: 0.107709
2025-12-13 01:44:06,010 INFO     Training average loss at step 104700: 0.389411
2025-12-13 01:44:08,184 INFO     Training average regularization at step 104800: 0.302443
2025-12-13 01:44:08,184 INFO     Training average positive_sample_loss at step 104800: 0.066231
2025-12-13 01:44:08,184 INFO     Training average negative_sample_loss at step 104800: 0.108819
2025-12-13 01:44:08,184 INFO     Training average loss at step 104800: 0.389968
2025-12-13 01:44:10,329 INFO     Training average regularization at step 104900: 0.302443
2025-12-13 01:44:10,330 INFO     Training average positive_sample_loss at step 104900: 0.067277
2025-12-13 01:44:10,330 INFO     Training average negative_sample_loss at step 104900: 0.110202
2025-12-13 01:44:10,330 INFO     Training average loss at step 104900: 0.391182
2025-12-13 01:44:12,474 INFO     Training average regularization at step 105000: 0.302442
2025-12-13 01:44:12,474 INFO     Training average positive_sample_loss at step 105000: 0.067358
2025-12-13 01:44:12,474 INFO     Training average negative_sample_loss at step 105000: 0.109026
2025-12-13 01:44:12,474 INFO     Training average loss at step 105000: 0.390634
2025-12-13 01:44:14,616 INFO     Training average regularization at step 105100: 0.302441
2025-12-13 01:44:14,617 INFO     Training average positive_sample_loss at step 105100: 0.066500
2025-12-13 01:44:14,617 INFO     Training average negative_sample_loss at step 105100: 0.107710
2025-12-13 01:44:14,617 INFO     Training average loss at step 105100: 0.389546
2025-12-13 01:44:16,767 INFO     Training average regularization at step 105200: 0.302441
2025-12-13 01:44:16,767 INFO     Training average positive_sample_loss at step 105200: 0.066588
2025-12-13 01:44:16,768 INFO     Training average negative_sample_loss at step 105200: 0.107468
2025-12-13 01:44:16,768 INFO     Training average loss at step 105200: 0.389469
2025-12-13 01:44:18,957 INFO     Training average regularization at step 105300: 0.302440
2025-12-13 01:44:18,957 INFO     Training average positive_sample_loss at step 105300: 0.066425
2025-12-13 01:44:18,958 INFO     Training average negative_sample_loss at step 105300: 0.108305
2025-12-13 01:44:18,958 INFO     Training average loss at step 105300: 0.389805
2025-12-13 01:44:21,158 INFO     Training average regularization at step 105400: 0.302440
2025-12-13 01:44:21,158 INFO     Training average positive_sample_loss at step 105400: 0.066830
2025-12-13 01:44:21,158 INFO     Training average negative_sample_loss at step 105400: 0.108997
2025-12-13 01:44:21,158 INFO     Training average loss at step 105400: 0.390353
2025-12-13 01:44:23,308 INFO     Training average regularization at step 105500: 0.302439
2025-12-13 01:44:23,308 INFO     Training average positive_sample_loss at step 105500: 0.068073
2025-12-13 01:44:23,308 INFO     Training average negative_sample_loss at step 105500: 0.108918
2025-12-13 01:44:23,308 INFO     Training average loss at step 105500: 0.390935
2025-12-13 01:44:25,461 INFO     Training average regularization at step 105600: 0.302439
2025-12-13 01:44:25,461 INFO     Training average positive_sample_loss at step 105600: 0.067520
2025-12-13 01:44:25,461 INFO     Training average negative_sample_loss at step 105600: 0.109457
2025-12-13 01:44:25,461 INFO     Training average loss at step 105600: 0.390927
2025-12-13 01:44:27,638 INFO     Training average regularization at step 105700: 0.302438
2025-12-13 01:44:27,638 INFO     Training average positive_sample_loss at step 105700: 0.066470
2025-12-13 01:44:27,638 INFO     Training average negative_sample_loss at step 105700: 0.107931
2025-12-13 01:44:27,638 INFO     Training average loss at step 105700: 0.389639
2025-12-13 01:44:29,786 INFO     Training average regularization at step 105800: 0.302437
2025-12-13 01:44:29,786 INFO     Training average positive_sample_loss at step 105800: 0.065984
2025-12-13 01:44:29,786 INFO     Training average negative_sample_loss at step 105800: 0.108544
2025-12-13 01:44:29,786 INFO     Training average loss at step 105800: 0.389701
2025-12-13 01:44:31,969 INFO     Training average regularization at step 105900: 0.302437
2025-12-13 01:44:31,969 INFO     Training average positive_sample_loss at step 105900: 0.067746
2025-12-13 01:44:31,969 INFO     Training average negative_sample_loss at step 105900: 0.112337
2025-12-13 01:44:31,969 INFO     Training average loss at step 105900: 0.392478
2025-12-13 01:44:34,152 INFO     Training average regularization at step 106000: 0.302436
2025-12-13 01:44:34,152 INFO     Training average positive_sample_loss at step 106000: 0.066803
2025-12-13 01:44:34,152 INFO     Training average negative_sample_loss at step 106000: 0.107228
2025-12-13 01:44:34,152 INFO     Training average loss at step 106000: 0.389451
2025-12-13 01:44:36,315 INFO     Training average regularization at step 106100: 0.302436
2025-12-13 01:44:36,316 INFO     Training average positive_sample_loss at step 106100: 0.066279
2025-12-13 01:44:36,316 INFO     Training average negative_sample_loss at step 106100: 0.109194
2025-12-13 01:44:36,316 INFO     Training average loss at step 106100: 0.390172
2025-12-13 01:44:38,480 INFO     Training average regularization at step 106200: 0.302435
2025-12-13 01:44:38,480 INFO     Training average positive_sample_loss at step 106200: 0.065796
2025-12-13 01:44:38,480 INFO     Training average negative_sample_loss at step 106200: 0.110353
2025-12-13 01:44:38,481 INFO     Training average loss at step 106200: 0.390509
2025-12-13 01:44:40,788 INFO     Training average regularization at step 106300: 0.302434
2025-12-13 01:44:40,788 INFO     Training average positive_sample_loss at step 106300: 0.067629
2025-12-13 01:44:40,788 INFO     Training average negative_sample_loss at step 106300: 0.108000
2025-12-13 01:44:40,788 INFO     Training average loss at step 106300: 0.390249
2025-12-13 01:44:44,084 INFO     Training average regularization at step 106400: 0.302434
2025-12-13 01:44:44,084 INFO     Training average positive_sample_loss at step 106400: 0.067859
2025-12-13 01:44:44,084 INFO     Training average negative_sample_loss at step 106400: 0.108463
2025-12-13 01:44:44,085 INFO     Training average loss at step 106400: 0.390595
2025-12-13 01:44:46,245 INFO     Training average regularization at step 106500: 0.302433
2025-12-13 01:44:46,245 INFO     Training average positive_sample_loss at step 106500: 0.066739
2025-12-13 01:44:46,245 INFO     Training average negative_sample_loss at step 106500: 0.109696
2025-12-13 01:44:46,245 INFO     Training average loss at step 106500: 0.390650
2025-12-13 01:44:48,398 INFO     Training average regularization at step 106600: 0.302432
2025-12-13 01:44:48,398 INFO     Training average positive_sample_loss at step 106600: 0.065768
2025-12-13 01:44:48,398 INFO     Training average negative_sample_loss at step 106600: 0.107375
2025-12-13 01:44:48,398 INFO     Training average loss at step 106600: 0.389004
2025-12-13 01:44:50,552 INFO     Training average regularization at step 106700: 0.302431
2025-12-13 01:44:50,553 INFO     Training average positive_sample_loss at step 106700: 0.066012
2025-12-13 01:44:50,553 INFO     Training average negative_sample_loss at step 106700: 0.108385
2025-12-13 01:44:50,553 INFO     Training average loss at step 106700: 0.389630
2025-12-13 01:44:52,732 INFO     Training average regularization at step 106800: 0.302431
2025-12-13 01:44:52,733 INFO     Training average positive_sample_loss at step 106800: 0.067317
2025-12-13 01:44:52,733 INFO     Training average negative_sample_loss at step 106800: 0.107359
2025-12-13 01:44:52,733 INFO     Training average loss at step 106800: 0.389769
2025-12-13 01:44:54,884 INFO     Training average regularization at step 106900: 0.302430
2025-12-13 01:44:54,885 INFO     Training average positive_sample_loss at step 106900: 0.067521
2025-12-13 01:44:54,885 INFO     Training average negative_sample_loss at step 106900: 0.110125
2025-12-13 01:44:54,885 INFO     Training average loss at step 106900: 0.391253
2025-12-13 01:44:57,038 INFO     Training average regularization at step 107000: 0.302429
2025-12-13 01:44:57,038 INFO     Training average positive_sample_loss at step 107000: 0.066198
2025-12-13 01:44:57,038 INFO     Training average negative_sample_loss at step 107000: 0.108901
2025-12-13 01:44:57,038 INFO     Training average loss at step 107000: 0.389978
2025-12-13 01:44:59,188 INFO     Training average regularization at step 107100: 0.302428
2025-12-13 01:44:59,188 INFO     Training average positive_sample_loss at step 107100: 0.066400
2025-12-13 01:44:59,188 INFO     Training average negative_sample_loss at step 107100: 0.109508
2025-12-13 01:44:59,188 INFO     Training average loss at step 107100: 0.390382
2025-12-13 01:45:01,338 INFO     Training average regularization at step 107200: 0.302428
2025-12-13 01:45:01,339 INFO     Training average positive_sample_loss at step 107200: 0.066447
2025-12-13 01:45:01,339 INFO     Training average negative_sample_loss at step 107200: 0.108671
2025-12-13 01:45:01,339 INFO     Training average loss at step 107200: 0.389987
2025-12-13 01:45:03,503 INFO     Training average regularization at step 107300: 0.302427
2025-12-13 01:45:03,503 INFO     Training average positive_sample_loss at step 107300: 0.066112
2025-12-13 01:45:03,503 INFO     Training average negative_sample_loss at step 107300: 0.106345
2025-12-13 01:45:03,503 INFO     Training average loss at step 107300: 0.388655
2025-12-13 01:45:05,655 INFO     Training average regularization at step 107400: 0.302426
2025-12-13 01:45:05,655 INFO     Training average positive_sample_loss at step 107400: 0.066266
2025-12-13 01:45:05,655 INFO     Training average negative_sample_loss at step 107400: 0.107796
2025-12-13 01:45:05,655 INFO     Training average loss at step 107400: 0.389457
2025-12-13 01:45:07,816 INFO     Training average regularization at step 107500: 0.302425
2025-12-13 01:45:07,817 INFO     Training average positive_sample_loss at step 107500: 0.067015
2025-12-13 01:45:07,817 INFO     Training average negative_sample_loss at step 107500: 0.109474
2025-12-13 01:45:07,817 INFO     Training average loss at step 107500: 0.390670
2025-12-13 01:45:09,976 INFO     Training average regularization at step 107600: 0.302425
2025-12-13 01:45:09,976 INFO     Training average positive_sample_loss at step 107600: 0.065693
2025-12-13 01:45:09,976 INFO     Training average negative_sample_loss at step 107600: 0.106529
2025-12-13 01:45:09,976 INFO     Training average loss at step 107600: 0.388536
2025-12-13 01:45:12,133 INFO     Training average regularization at step 107700: 0.302424
2025-12-13 01:45:12,133 INFO     Training average positive_sample_loss at step 107700: 0.067519
2025-12-13 01:45:12,133 INFO     Training average negative_sample_loss at step 107700: 0.107950
2025-12-13 01:45:12,133 INFO     Training average loss at step 107700: 0.390159
2025-12-13 01:45:14,300 INFO     Training average regularization at step 107800: 0.302423
2025-12-13 01:45:14,301 INFO     Training average positive_sample_loss at step 107800: 0.068099
2025-12-13 01:45:14,301 INFO     Training average negative_sample_loss at step 107800: 0.109308
2025-12-13 01:45:14,301 INFO     Training average loss at step 107800: 0.391127
2025-12-13 01:45:16,491 INFO     Training average regularization at step 107900: 0.302423
2025-12-13 01:45:16,491 INFO     Training average positive_sample_loss at step 107900: 0.066174
2025-12-13 01:45:16,492 INFO     Training average negative_sample_loss at step 107900: 0.109040
2025-12-13 01:45:16,492 INFO     Training average loss at step 107900: 0.390030
2025-12-13 01:45:18,645 INFO     Training average regularization at step 108000: 0.302422
2025-12-13 01:45:18,645 INFO     Training average positive_sample_loss at step 108000: 0.066490
2025-12-13 01:45:18,645 INFO     Training average negative_sample_loss at step 108000: 0.111073
2025-12-13 01:45:18,645 INFO     Training average loss at step 108000: 0.391204
2025-12-13 01:45:20,804 INFO     Training average regularization at step 108100: 0.302421
2025-12-13 01:45:20,804 INFO     Training average positive_sample_loss at step 108100: 0.066471
2025-12-13 01:45:20,804 INFO     Training average negative_sample_loss at step 108100: 0.107492
2025-12-13 01:45:20,804 INFO     Training average loss at step 108100: 0.389403
2025-12-13 01:45:22,954 INFO     Training average regularization at step 108200: 0.302421
2025-12-13 01:45:22,954 INFO     Training average positive_sample_loss at step 108200: 0.066798
2025-12-13 01:45:22,954 INFO     Training average negative_sample_loss at step 108200: 0.111997
2025-12-13 01:45:22,954 INFO     Training average loss at step 108200: 0.391818
2025-12-13 01:45:25,116 INFO     Training average regularization at step 108300: 0.302420
2025-12-13 01:45:25,116 INFO     Training average positive_sample_loss at step 108300: 0.068805
2025-12-13 01:45:25,116 INFO     Training average negative_sample_loss at step 108300: 0.110057
2025-12-13 01:45:25,116 INFO     Training average loss at step 108300: 0.391851
2025-12-13 01:45:27,246 INFO     Training average regularization at step 108400: 0.302419
2025-12-13 01:45:27,247 INFO     Training average positive_sample_loss at step 108400: 0.066115
2025-12-13 01:45:27,247 INFO     Training average negative_sample_loss at step 108400: 0.110146
2025-12-13 01:45:27,247 INFO     Training average loss at step 108400: 0.390550
2025-12-13 01:45:29,414 INFO     Training average regularization at step 108500: 0.302419
2025-12-13 01:45:29,414 INFO     Training average positive_sample_loss at step 108500: 0.066869
2025-12-13 01:45:29,414 INFO     Training average negative_sample_loss at step 108500: 0.112735
2025-12-13 01:45:29,414 INFO     Training average loss at step 108500: 0.392221
2025-12-13 01:45:31,570 INFO     Training average regularization at step 108600: 0.302418
2025-12-13 01:45:31,570 INFO     Training average positive_sample_loss at step 108600: 0.067376
2025-12-13 01:45:31,570 INFO     Training average negative_sample_loss at step 108600: 0.108377
2025-12-13 01:45:31,570 INFO     Training average loss at step 108600: 0.390294
2025-12-13 01:45:33,726 INFO     Training average regularization at step 108700: 0.302417
2025-12-13 01:45:33,726 INFO     Training average positive_sample_loss at step 108700: 0.066656
2025-12-13 01:45:33,726 INFO     Training average negative_sample_loss at step 108700: 0.109863
2025-12-13 01:45:33,726 INFO     Training average loss at step 108700: 0.390677
2025-12-13 01:45:35,883 INFO     Training average regularization at step 108800: 0.302417
2025-12-13 01:45:35,884 INFO     Training average positive_sample_loss at step 108800: 0.065644
2025-12-13 01:45:35,884 INFO     Training average negative_sample_loss at step 108800: 0.109345
2025-12-13 01:45:35,884 INFO     Training average loss at step 108800: 0.389911
2025-12-13 01:45:38,113 INFO     Training average regularization at step 108900: 0.302416
2025-12-13 01:45:38,114 INFO     Training average positive_sample_loss at step 108900: 0.066913
2025-12-13 01:45:38,114 INFO     Training average negative_sample_loss at step 108900: 0.109357
2025-12-13 01:45:38,114 INFO     Training average loss at step 108900: 0.390551
2025-12-13 01:45:40,293 INFO     Training average regularization at step 109000: 0.302415
2025-12-13 01:45:40,293 INFO     Training average positive_sample_loss at step 109000: 0.066917
2025-12-13 01:45:40,293 INFO     Training average negative_sample_loss at step 109000: 0.107863
2025-12-13 01:45:40,293 INFO     Training average loss at step 109000: 0.389806
2025-12-13 01:45:42,478 INFO     Training average regularization at step 109100: 0.302415
2025-12-13 01:45:42,478 INFO     Training average positive_sample_loss at step 109100: 0.067044
2025-12-13 01:45:42,478 INFO     Training average negative_sample_loss at step 109100: 0.108786
2025-12-13 01:45:42,478 INFO     Training average loss at step 109100: 0.390329
2025-12-13 01:45:44,655 INFO     Training average regularization at step 109200: 0.302414
2025-12-13 01:45:44,656 INFO     Training average positive_sample_loss at step 109200: 0.067824
2025-12-13 01:45:44,656 INFO     Training average negative_sample_loss at step 109200: 0.108149
2025-12-13 01:45:44,656 INFO     Training average loss at step 109200: 0.390401
2025-12-13 01:45:46,818 INFO     Training average regularization at step 109300: 0.302414
2025-12-13 01:45:46,818 INFO     Training average positive_sample_loss at step 109300: 0.067574
2025-12-13 01:45:46,818 INFO     Training average negative_sample_loss at step 109300: 0.109505
2025-12-13 01:45:46,818 INFO     Training average loss at step 109300: 0.390953
2025-12-13 01:45:48,991 INFO     Training average regularization at step 109400: 0.302413
2025-12-13 01:45:48,992 INFO     Training average positive_sample_loss at step 109400: 0.066995
2025-12-13 01:45:48,992 INFO     Training average negative_sample_loss at step 109400: 0.110895
2025-12-13 01:45:48,992 INFO     Training average loss at step 109400: 0.391358
2025-12-13 01:45:51,153 INFO     Training average regularization at step 109500: 0.302412
2025-12-13 01:45:51,153 INFO     Training average positive_sample_loss at step 109500: 0.066737
2025-12-13 01:45:51,153 INFO     Training average negative_sample_loss at step 109500: 0.109363
2025-12-13 01:45:51,153 INFO     Training average loss at step 109500: 0.390462
2025-12-13 01:45:53,290 INFO     Training average regularization at step 109600: 0.302412
2025-12-13 01:45:53,290 INFO     Training average positive_sample_loss at step 109600: 0.066651
2025-12-13 01:45:53,290 INFO     Training average negative_sample_loss at step 109600: 0.111064
2025-12-13 01:45:53,290 INFO     Training average loss at step 109600: 0.391269
2025-12-13 01:45:55,425 INFO     Training average regularization at step 109700: 0.302411
2025-12-13 01:45:55,426 INFO     Training average positive_sample_loss at step 109700: 0.065582
2025-12-13 01:45:55,426 INFO     Training average negative_sample_loss at step 109700: 0.108950
2025-12-13 01:45:55,426 INFO     Training average loss at step 109700: 0.389678
2025-12-13 01:45:57,568 INFO     Training average regularization at step 109800: 0.302411
2025-12-13 01:45:57,568 INFO     Training average positive_sample_loss at step 109800: 0.066465
2025-12-13 01:45:57,568 INFO     Training average negative_sample_loss at step 109800: 0.108543
2025-12-13 01:45:57,568 INFO     Training average loss at step 109800: 0.389915
2025-12-13 01:45:59,728 INFO     Training average regularization at step 109900: 0.302410
2025-12-13 01:45:59,728 INFO     Training average positive_sample_loss at step 109900: 0.067021
2025-12-13 01:45:59,728 INFO     Training average negative_sample_loss at step 109900: 0.107654
2025-12-13 01:45:59,728 INFO     Training average loss at step 109900: 0.389748
2025-12-13 01:46:01,883 INFO     Training average regularization at step 110000: 0.302410
2025-12-13 01:46:01,883 INFO     Training average positive_sample_loss at step 110000: 0.066993
2025-12-13 01:46:01,883 INFO     Training average negative_sample_loss at step 110000: 0.109843
2025-12-13 01:46:01,883 INFO     Training average loss at step 110000: 0.390828
2025-12-13 01:46:01,883 INFO     Evaluating on Valid Dataset...
2025-12-13 01:46:02,551 INFO     Evaluating the model... (0/50000)
2025-12-13 01:46:05,130 INFO     Evaluating the model... (500/50000)
2025-12-13 01:46:07,625 INFO     Evaluating the model... (1000/50000)
2025-12-13 01:46:10,386 INFO     Evaluating the model... (1500/50000)
2025-12-13 01:46:13,926 INFO     Evaluating the model... (2000/50000)
2025-12-13 01:46:16,565 INFO     Evaluating the model... (2500/50000)
2025-12-13 01:46:18,991 INFO     Evaluating the model... (3000/50000)
2025-12-13 01:46:21,579 INFO     Evaluating the model... (3500/50000)
2025-12-13 01:46:24,167 INFO     Evaluating the model... (4000/50000)
2025-12-13 01:46:27,348 INFO     Evaluating the model... (4500/50000)
2025-12-13 01:46:29,815 INFO     Evaluating the model... (5000/50000)
2025-12-13 01:46:32,253 INFO     Evaluating the model... (5500/50000)
2025-12-13 01:46:35,022 INFO     Evaluating the model... (6000/50000)
2025-12-13 01:46:37,591 INFO     Evaluating the model... (6500/50000)
2025-12-13 01:46:41,154 INFO     Evaluating the model... (7000/50000)
2025-12-13 01:46:43,918 INFO     Evaluating the model... (7500/50000)
2025-12-13 01:46:46,670 INFO     Evaluating the model... (8000/50000)
2025-12-13 01:46:49,077 INFO     Evaluating the model... (8500/50000)
2025-12-13 01:46:52,039 INFO     Evaluating the model... (9000/50000)
2025-12-13 01:46:54,993 INFO     Evaluating the model... (9500/50000)
2025-12-13 01:46:57,633 INFO     Evaluating the model... (10000/50000)
2025-12-13 01:47:00,002 INFO     Evaluating the model... (10500/50000)
2025-12-13 01:47:02,390 INFO     Evaluating the model... (11000/50000)
2025-12-13 01:47:05,634 INFO     Evaluating the model... (11500/50000)
2025-12-13 01:47:08,276 INFO     Evaluating the model... (12000/50000)
2025-12-13 01:47:10,633 INFO     Evaluating the model... (12500/50000)
2025-12-13 01:47:13,080 INFO     Evaluating the model... (13000/50000)
2025-12-13 01:47:15,472 INFO     Evaluating the model... (13500/50000)
2025-12-13 01:47:18,937 INFO     Evaluating the model... (14000/50000)
2025-12-13 01:47:21,456 INFO     Evaluating the model... (14500/50000)
2025-12-13 01:47:23,853 INFO     Evaluating the model... (15000/50000)
2025-12-13 01:47:26,310 INFO     Evaluating the model... (15500/50000)
2025-12-13 01:47:28,651 INFO     Evaluating the model... (16000/50000)
2025-12-13 01:47:32,093 INFO     Evaluating the model... (16500/50000)
2025-12-13 01:47:34,373 INFO     Evaluating the model... (17000/50000)
2025-12-13 01:47:37,070 INFO     Evaluating the model... (17500/50000)
2025-12-13 01:47:39,715 INFO     Evaluating the model... (18000/50000)
2025-12-13 01:47:42,595 INFO     Evaluating the model... (18500/50000)
2025-12-13 01:47:45,959 INFO     Evaluating the model... (19000/50000)
2025-12-13 01:47:48,354 INFO     Evaluating the model... (19500/50000)
2025-12-13 01:47:50,740 INFO     Evaluating the model... (20000/50000)
2025-12-13 01:47:53,420 INFO     Evaluating the model... (20500/50000)
2025-12-13 01:47:55,943 INFO     Evaluating the model... (21000/50000)
2025-12-13 01:47:58,900 INFO     Evaluating the model... (21500/50000)
2025-12-13 01:48:01,297 INFO     Evaluating the model... (22000/50000)
2025-12-13 01:48:03,668 INFO     Evaluating the model... (22500/50000)
2025-12-13 01:48:06,367 INFO     Evaluating the model... (23000/50000)
2025-12-13 01:48:08,899 INFO     Evaluating the model... (23500/50000)
2025-12-13 01:48:12,557 INFO     Evaluating the model... (24000/50000)
2025-12-13 01:48:14,949 INFO     Evaluating the model... (24500/50000)
2025-12-13 01:48:18,185 INFO     Evaluating the model... (25000/50000)
2025-12-13 01:48:20,685 INFO     Evaluating the model... (25500/50000)
2025-12-13 01:48:23,234 INFO     Evaluating the model... (26000/50000)
2025-12-13 01:48:27,008 INFO     Evaluating the model... (26500/50000)
2025-12-13 01:48:29,912 INFO     Evaluating the model... (27000/50000)
2025-12-13 01:48:32,491 INFO     Evaluating the model... (27500/50000)
2025-12-13 01:48:34,986 INFO     Evaluating the model... (28000/50000)
2025-12-13 01:48:37,647 INFO     Evaluating the model... (28500/50000)
2025-12-13 01:48:41,632 INFO     Evaluating the model... (29000/50000)
2025-12-13 01:48:44,337 INFO     Evaluating the model... (29500/50000)
2025-12-13 01:48:46,980 INFO     Evaluating the model... (30000/50000)
2025-12-13 01:48:49,480 INFO     Evaluating the model... (30500/50000)
2025-12-13 01:48:52,136 INFO     Evaluating the model... (31000/50000)
2025-12-13 01:48:55,192 INFO     Evaluating the model... (31500/50000)
2025-12-13 01:48:57,703 INFO     Evaluating the model... (32000/50000)
2025-12-13 01:49:00,271 INFO     Evaluating the model... (32500/50000)
2025-12-13 01:49:02,897 INFO     Evaluating the model... (33000/50000)
2025-12-13 01:49:05,469 INFO     Evaluating the model... (33500/50000)
2025-12-13 01:49:08,477 INFO     Evaluating the model... (34000/50000)
2025-12-13 01:49:10,973 INFO     Evaluating the model... (34500/50000)
2025-12-13 01:49:13,434 INFO     Evaluating the model... (35000/50000)
2025-12-13 01:49:16,240 INFO     Evaluating the model... (35500/50000)
2025-12-13 01:49:19,462 INFO     Evaluating the model... (36000/50000)
2025-12-13 01:49:22,359 INFO     Evaluating the model... (36500/50000)
2025-12-13 01:49:24,857 INFO     Evaluating the model... (37000/50000)
2025-12-13 01:49:27,616 INFO     Evaluating the model... (37500/50000)
2025-12-13 01:49:30,141 INFO     Evaluating the model... (38000/50000)
2025-12-13 01:49:33,848 INFO     Evaluating the model... (38500/50000)
2025-12-13 01:49:36,486 INFO     Evaluating the model... (39000/50000)
2025-12-13 01:49:39,439 INFO     Evaluating the model... (39500/50000)
2025-12-13 01:49:42,201 INFO     Evaluating the model... (40000/50000)
2025-12-13 01:49:44,857 INFO     Evaluating the model... (40500/50000)
2025-12-13 01:49:48,774 INFO     Evaluating the model... (41000/50000)
2025-12-13 01:49:51,413 INFO     Evaluating the model... (41500/50000)
2025-12-13 01:49:54,071 INFO     Evaluating the model... (42000/50000)
2025-12-13 01:49:56,667 INFO     Evaluating the model... (42500/50000)
2025-12-13 01:49:59,264 INFO     Evaluating the model... (43000/50000)
2025-12-13 01:50:03,396 INFO     Evaluating the model... (43500/50000)
2025-12-13 01:50:05,954 INFO     Evaluating the model... (44000/50000)
2025-12-13 01:50:08,466 INFO     Evaluating the model... (44500/50000)
2025-12-13 01:50:11,092 INFO     Evaluating the model... (45000/50000)
2025-12-13 01:50:13,883 INFO     Evaluating the model... (45500/50000)
2025-12-13 01:50:17,959 INFO     Evaluating the model... (46000/50000)
2025-12-13 01:50:20,467 INFO     Evaluating the model... (46500/50000)
2025-12-13 01:50:23,112 INFO     Evaluating the model... (47000/50000)
2025-12-13 01:50:25,707 INFO     Evaluating the model... (47500/50000)
2025-12-13 01:50:28,373 INFO     Evaluating the model... (48000/50000)
2025-12-13 01:50:32,182 INFO     Evaluating the model... (48500/50000)
2025-12-13 01:50:34,946 INFO     Evaluating the model... (49000/50000)
2025-12-13 01:50:37,809 INFO     Evaluating the model... (49500/50000)
2025-12-13 01:50:40,866 INFO     Valid MRR at step 110000: 0.630895
2025-12-13 01:50:40,867 INFO     Valid MR at step 110000: 266.124480
2025-12-13 01:50:40,867 INFO     Valid HITS@1 at step 110000: 0.544730
2025-12-13 01:50:40,867 INFO     Valid HITS@3 at step 110000: 0.683850
2025-12-13 01:50:40,867 INFO     Valid HITS@10 at step 110000: 0.784250
2025-12-13 01:50:42,191 INFO     Evaluating on Test Dataset...
2025-12-13 01:50:42,750 INFO     Evaluating the model... (0/59072)
2025-12-13 01:50:45,491 INFO     Evaluating the model... (500/59072)
2025-12-13 01:50:49,379 INFO     Evaluating the model... (1000/59072)
2025-12-13 01:50:51,981 INFO     Evaluating the model... (1500/59072)
2025-12-13 01:50:54,478 INFO     Evaluating the model... (2000/59072)
2025-12-13 01:50:57,126 INFO     Evaluating the model... (2500/59072)
2025-12-13 01:50:59,700 INFO     Evaluating the model... (3000/59072)
2025-12-13 01:51:03,053 INFO     Evaluating the model... (3500/59072)
2025-12-13 01:51:05,533 INFO     Evaluating the model... (4000/59072)
2025-12-13 01:51:07,976 INFO     Evaluating the model... (4500/59072)
2025-12-13 01:51:10,708 INFO     Evaluating the model... (5000/59072)
2025-12-13 01:51:13,128 INFO     Evaluating the model... (5500/59072)
2025-12-13 01:51:16,760 INFO     Evaluating the model... (6000/59072)
2025-12-13 01:51:19,152 INFO     Evaluating the model... (6500/59072)
2025-12-13 01:51:21,694 INFO     Evaluating the model... (7000/59072)
2025-12-13 01:51:24,107 INFO     Evaluating the model... (7500/59072)
2025-12-13 01:51:26,558 INFO     Evaluating the model... (8000/59072)
2025-12-13 01:51:29,580 INFO     Evaluating the model... (8500/59072)
2025-12-13 01:51:32,271 INFO     Evaluating the model... (9000/59072)
2025-12-13 01:51:34,769 INFO     Evaluating the model... (9500/59072)
2025-12-13 01:51:37,417 INFO     Evaluating the model... (10000/59072)
2025-12-13 01:51:40,054 INFO     Evaluating the model... (10500/59072)
2025-12-13 01:51:43,321 INFO     Evaluating the model... (11000/59072)
2025-12-13 01:51:46,111 INFO     Evaluating the model... (11500/59072)
2025-12-13 01:51:48,522 INFO     Evaluating the model... (12000/59072)
2025-12-13 01:51:50,862 INFO     Evaluating the model... (12500/59072)
2025-12-13 01:51:53,904 INFO     Evaluating the model... (13000/59072)
2025-12-13 01:51:56,589 INFO     Evaluating the model... (13500/59072)
2025-12-13 01:51:58,988 INFO     Evaluating the model... (14000/59072)
2025-12-13 01:52:01,347 INFO     Evaluating the model... (14500/59072)
2025-12-13 01:52:03,768 INFO     Evaluating the model... (15000/59072)
2025-12-13 01:52:06,927 INFO     Evaluating the model... (15500/59072)
2025-12-13 01:52:09,354 INFO     Evaluating the model... (16000/59072)
2025-12-13 01:52:11,791 INFO     Evaluating the model... (16500/59072)
2025-12-13 01:52:14,172 INFO     Evaluating the model... (17000/59072)
2025-12-13 01:52:16,631 INFO     Evaluating the model... (17500/59072)
2025-12-13 01:52:19,859 INFO     Evaluating the model... (18000/59072)
2025-12-13 01:52:22,225 INFO     Evaluating the model... (18500/59072)
2025-12-13 01:52:24,702 INFO     Evaluating the model... (19000/59072)
2025-12-13 01:52:27,180 INFO     Evaluating the model... (19500/59072)
2025-12-13 01:52:29,759 INFO     Evaluating the model... (20000/59072)
2025-12-13 01:52:32,928 INFO     Evaluating the model... (20500/59072)
2025-12-13 01:52:35,319 INFO     Evaluating the model... (21000/59072)
2025-12-13 01:52:38,025 INFO     Evaluating the model... (21500/59072)
2025-12-13 01:52:40,634 INFO     Evaluating the model... (22000/59072)
2025-12-13 01:52:43,409 INFO     Evaluating the model... (22500/59072)
2025-12-13 01:52:46,914 INFO     Evaluating the model... (23000/59072)
2025-12-13 01:52:49,265 INFO     Evaluating the model... (23500/59072)
2025-12-13 01:52:51,775 INFO     Evaluating the model... (24000/59072)
2025-12-13 01:52:54,378 INFO     Evaluating the model... (24500/59072)
2025-12-13 01:52:56,859 INFO     Evaluating the model... (25000/59072)
2025-12-13 01:53:00,426 INFO     Evaluating the model... (25500/59072)
2025-12-13 01:53:02,778 INFO     Evaluating the model... (26000/59072)
2025-12-13 01:53:05,489 INFO     Evaluating the model... (26500/59072)
2025-12-13 01:53:07,929 INFO     Evaluating the model... (27000/59072)
2025-12-13 01:53:10,408 INFO     Evaluating the model... (27500/59072)
2025-12-13 01:53:14,101 INFO     Evaluating the model... (28000/59072)
2025-12-13 01:53:16,784 INFO     Evaluating the model... (28500/59072)
2025-12-13 01:53:19,159 INFO     Evaluating the model... (29000/59072)
2025-12-13 01:53:21,577 INFO     Evaluating the model... (29500/59072)
2025-12-13 01:53:25,201 INFO     Evaluating the model... (30000/59072)
2025-12-13 01:53:28,048 INFO     Evaluating the model... (30500/59072)
2025-12-13 01:53:30,643 INFO     Evaluating the model... (31000/59072)
2025-12-13 01:53:33,183 INFO     Evaluating the model... (31500/59072)
2025-12-13 01:53:35,820 INFO     Evaluating the model... (32000/59072)
2025-12-13 01:53:39,209 INFO     Evaluating the model... (32500/59072)
2025-12-13 01:53:41,947 INFO     Evaluating the model... (33000/59072)
2025-12-13 01:53:44,626 INFO     Evaluating the model... (33500/59072)
2025-12-13 01:53:47,132 INFO     Evaluating the model... (34000/59072)
2025-12-13 01:53:49,528 INFO     Evaluating the model... (34500/59072)
2025-12-13 01:53:52,769 INFO     Evaluating the model... (35000/59072)
2025-12-13 01:53:55,270 INFO     Evaluating the model... (35500/59072)
2025-12-13 01:53:57,844 INFO     Evaluating the model... (36000/59072)
2025-12-13 01:54:00,275 INFO     Evaluating the model... (36500/59072)
2025-12-13 01:54:02,975 INFO     Evaluating the model... (37000/59072)
2025-12-13 01:54:06,100 INFO     Evaluating the model... (37500/59072)
2025-12-13 01:54:08,616 INFO     Evaluating the model... (38000/59072)
2025-12-13 01:54:11,062 INFO     Evaluating the model... (38500/59072)
2025-12-13 01:54:13,762 INFO     Evaluating the model... (39000/59072)
2025-12-13 01:54:16,440 INFO     Evaluating the model... (39500/59072)
2025-12-13 01:54:19,757 INFO     Evaluating the model... (40000/59072)
2025-12-13 01:54:22,225 INFO     Evaluating the model... (40500/59072)
2025-12-13 01:54:24,713 INFO     Evaluating the model... (41000/59072)
2025-12-13 01:54:27,512 INFO     Evaluating the model... (41500/59072)
2025-12-13 01:54:30,148 INFO     Evaluating the model... (42000/59072)
2025-12-13 01:54:33,635 INFO     Evaluating the model... (42500/59072)
2025-12-13 01:54:36,318 INFO     Evaluating the model... (43000/59072)
2025-12-13 01:54:39,197 INFO     Evaluating the model... (43500/59072)
2025-12-13 01:54:41,784 INFO     Evaluating the model... (44000/59072)
2025-12-13 01:54:45,250 INFO     Evaluating the model... (44500/59072)
2025-12-13 01:54:48,177 INFO     Evaluating the model... (45000/59072)
2025-12-13 01:54:50,755 INFO     Evaluating the model... (45500/59072)
2025-12-13 01:54:53,179 INFO     Evaluating the model... (46000/59072)
2025-12-13 01:54:55,835 INFO     Evaluating the model... (46500/59072)
2025-12-13 01:54:59,662 INFO     Evaluating the model... (47000/59072)
2025-12-13 01:55:02,146 INFO     Evaluating the model... (47500/59072)
2025-12-13 01:55:04,729 INFO     Evaluating the model... (48000/59072)
2025-12-13 01:55:07,293 INFO     Evaluating the model... (48500/59072)
2025-12-13 01:55:09,802 INFO     Evaluating the model... (49000/59072)
2025-12-13 01:55:13,709 INFO     Evaluating the model... (49500/59072)
2025-12-13 01:55:16,167 INFO     Evaluating the model... (50000/59072)
2025-12-13 01:55:18,634 INFO     Evaluating the model... (50500/59072)
2025-12-13 01:55:21,001 INFO     Evaluating the model... (51000/59072)
2025-12-13 01:55:23,633 INFO     Evaluating the model... (51500/59072)
2025-12-13 01:55:27,631 INFO     Evaluating the model... (52000/59072)
2025-12-13 01:55:30,445 INFO     Evaluating the model... (52500/59072)
2025-12-13 01:55:32,829 INFO     Evaluating the model... (53000/59072)
2025-12-13 01:55:35,562 INFO     Evaluating the model... (53500/59072)
2025-12-13 01:55:38,099 INFO     Evaluating the model... (54000/59072)
2025-12-13 01:55:42,066 INFO     Evaluating the model... (54500/59072)
2025-12-13 01:55:44,775 INFO     Evaluating the model... (55000/59072)
2025-12-13 01:55:47,461 INFO     Evaluating the model... (55500/59072)
2025-12-13 01:55:49,970 INFO     Evaluating the model... (56000/59072)
2025-12-13 01:55:52,533 INFO     Evaluating the model... (56500/59072)
2025-12-13 01:55:56,404 INFO     Evaluating the model... (57000/59072)
2025-12-13 01:55:59,101 INFO     Evaluating the model... (57500/59072)
2025-12-13 01:56:01,543 INFO     Evaluating the model... (58000/59072)
2025-12-13 01:56:04,086 INFO     Evaluating the model... (58500/59072)
2025-12-13 01:56:06,717 INFO     Evaluating the model... (59000/59072)
2025-12-13 01:56:07,345 INFO     Test MRR at step 110000: 0.627329
2025-12-13 01:56:07,346 INFO     Test MR at step 110000: 268.128066
2025-12-13 01:56:07,346 INFO     Test HITS@1 at step 110000: 0.539385
2025-12-13 01:56:07,346 INFO     Test HITS@3 at step 110000: 0.682069
2025-12-13 01:56:07,346 INFO     Test HITS@10 at step 110000: 0.782651
2025-12-13 01:56:09,531 INFO     Training average regularization at step 110100: 0.302409
2025-12-13 01:56:09,531 INFO     Training average positive_sample_loss at step 110100: 0.067003
2025-12-13 01:56:09,531 INFO     Training average negative_sample_loss at step 110100: 0.107520
2025-12-13 01:56:09,531 INFO     Training average loss at step 110100: 0.389671
2025-12-13 01:56:11,690 INFO     Training average regularization at step 110200: 0.302409
2025-12-13 01:56:11,690 INFO     Training average positive_sample_loss at step 110200: 0.066703
2025-12-13 01:56:11,690 INFO     Training average negative_sample_loss at step 110200: 0.109895
2025-12-13 01:56:11,690 INFO     Training average loss at step 110200: 0.390708
2025-12-13 01:56:13,836 INFO     Training average regularization at step 110300: 0.302408
2025-12-13 01:56:13,836 INFO     Training average positive_sample_loss at step 110300: 0.068117
2025-12-13 01:56:13,836 INFO     Training average negative_sample_loss at step 110300: 0.110607
2025-12-13 01:56:13,836 INFO     Training average loss at step 110300: 0.391770
2025-12-13 01:56:15,989 INFO     Training average regularization at step 110400: 0.302408
2025-12-13 01:56:15,989 INFO     Training average positive_sample_loss at step 110400: 0.066376
2025-12-13 01:56:15,989 INFO     Training average negative_sample_loss at step 110400: 0.111086
2025-12-13 01:56:15,989 INFO     Training average loss at step 110400: 0.391139
2025-12-13 01:56:18,128 INFO     Training average regularization at step 110500: 0.302407
2025-12-13 01:56:18,128 INFO     Training average positive_sample_loss at step 110500: 0.066659
2025-12-13 01:56:18,128 INFO     Training average negative_sample_loss at step 110500: 0.110197
2025-12-13 01:56:18,128 INFO     Training average loss at step 110500: 0.390835
2025-12-13 01:56:20,278 INFO     Training average regularization at step 110600: 0.302406
2025-12-13 01:56:20,278 INFO     Training average positive_sample_loss at step 110600: 0.067208
2025-12-13 01:56:20,278 INFO     Training average negative_sample_loss at step 110600: 0.109720
2025-12-13 01:56:20,278 INFO     Training average loss at step 110600: 0.390870
2025-12-13 01:56:22,440 INFO     Training average regularization at step 110700: 0.302406
2025-12-13 01:56:22,441 INFO     Training average positive_sample_loss at step 110700: 0.066880
2025-12-13 01:56:22,441 INFO     Training average negative_sample_loss at step 110700: 0.109529
2025-12-13 01:56:22,441 INFO     Training average loss at step 110700: 0.390610
2025-12-13 01:56:24,596 INFO     Training average regularization at step 110800: 0.302405
2025-12-13 01:56:24,597 INFO     Training average positive_sample_loss at step 110800: 0.066543
2025-12-13 01:56:24,597 INFO     Training average negative_sample_loss at step 110800: 0.111400
2025-12-13 01:56:24,597 INFO     Training average loss at step 110800: 0.391376
2025-12-13 01:56:26,743 INFO     Training average regularization at step 110900: 0.302404
2025-12-13 01:56:26,744 INFO     Training average positive_sample_loss at step 110900: 0.065937
2025-12-13 01:56:26,744 INFO     Training average negative_sample_loss at step 110900: 0.107017
2025-12-13 01:56:26,744 INFO     Training average loss at step 110900: 0.388881
2025-12-13 01:56:28,885 INFO     Training average regularization at step 111000: 0.302404
2025-12-13 01:56:28,885 INFO     Training average positive_sample_loss at step 111000: 0.066014
2025-12-13 01:56:28,885 INFO     Training average negative_sample_loss at step 111000: 0.107670
2025-12-13 01:56:28,886 INFO     Training average loss at step 111000: 0.389246
2025-12-13 01:56:31,062 INFO     Training average regularization at step 111100: 0.302403
2025-12-13 01:56:31,063 INFO     Training average positive_sample_loss at step 111100: 0.067030
2025-12-13 01:56:31,063 INFO     Training average negative_sample_loss at step 111100: 0.110067
2025-12-13 01:56:31,063 INFO     Training average loss at step 111100: 0.390951
2025-12-13 01:56:34,239 INFO     Training average regularization at step 111200: 0.302402
2025-12-13 01:56:34,239 INFO     Training average positive_sample_loss at step 111200: 0.065755
2025-12-13 01:56:34,239 INFO     Training average negative_sample_loss at step 111200: 0.108291
2025-12-13 01:56:34,239 INFO     Training average loss at step 111200: 0.389425
2025-12-13 01:56:36,415 INFO     Training average regularization at step 111300: 0.302402
2025-12-13 01:56:36,415 INFO     Training average positive_sample_loss at step 111300: 0.066405
2025-12-13 01:56:36,415 INFO     Training average negative_sample_loss at step 111300: 0.109975
2025-12-13 01:56:36,415 INFO     Training average loss at step 111300: 0.390591
2025-12-13 01:56:38,590 INFO     Training average regularization at step 111400: 0.302401
2025-12-13 01:56:38,590 INFO     Training average positive_sample_loss at step 111400: 0.066359
2025-12-13 01:56:38,590 INFO     Training average negative_sample_loss at step 111400: 0.108198
2025-12-13 01:56:38,590 INFO     Training average loss at step 111400: 0.389679
2025-12-13 01:56:40,765 INFO     Training average regularization at step 111500: 0.302400
2025-12-13 01:56:40,766 INFO     Training average positive_sample_loss at step 111500: 0.067061
2025-12-13 01:56:40,766 INFO     Training average negative_sample_loss at step 111500: 0.110469
2025-12-13 01:56:40,766 INFO     Training average loss at step 111500: 0.391165
2025-12-13 01:56:42,980 INFO     Training average regularization at step 111600: 0.302399
2025-12-13 01:56:42,980 INFO     Training average positive_sample_loss at step 111600: 0.067505
2025-12-13 01:56:42,980 INFO     Training average negative_sample_loss at step 111600: 0.108892
2025-12-13 01:56:42,980 INFO     Training average loss at step 111600: 0.390598
2025-12-13 01:56:45,165 INFO     Training average regularization at step 111700: 0.302398
2025-12-13 01:56:45,166 INFO     Training average positive_sample_loss at step 111700: 0.066232
2025-12-13 01:56:45,166 INFO     Training average negative_sample_loss at step 111700: 0.108907
2025-12-13 01:56:45,166 INFO     Training average loss at step 111700: 0.389968
2025-12-13 01:56:47,343 INFO     Training average regularization at step 111800: 0.302398
2025-12-13 01:56:47,344 INFO     Training average positive_sample_loss at step 111800: 0.066297
2025-12-13 01:56:47,344 INFO     Training average negative_sample_loss at step 111800: 0.108648
2025-12-13 01:56:47,344 INFO     Training average loss at step 111800: 0.389870
2025-12-13 01:56:49,490 INFO     Training average regularization at step 111900: 0.302397
2025-12-13 01:56:49,490 INFO     Training average positive_sample_loss at step 111900: 0.067106
2025-12-13 01:56:49,490 INFO     Training average negative_sample_loss at step 111900: 0.108904
2025-12-13 01:56:49,490 INFO     Training average loss at step 111900: 0.390402
2025-12-13 01:56:51,646 INFO     Training average regularization at step 112000: 0.302396
2025-12-13 01:56:51,646 INFO     Training average positive_sample_loss at step 112000: 0.066599
2025-12-13 01:56:51,646 INFO     Training average negative_sample_loss at step 112000: 0.108762
2025-12-13 01:56:51,646 INFO     Training average loss at step 112000: 0.390077
2025-12-13 01:56:53,828 INFO     Training average regularization at step 112100: 0.302396
2025-12-13 01:56:53,828 INFO     Training average positive_sample_loss at step 112100: 0.066093
2025-12-13 01:56:53,828 INFO     Training average negative_sample_loss at step 112100: 0.109083
2025-12-13 01:56:53,828 INFO     Training average loss at step 112100: 0.389984
2025-12-13 01:56:55,986 INFO     Training average regularization at step 112200: 0.302395
2025-12-13 01:56:55,987 INFO     Training average positive_sample_loss at step 112200: 0.066923
2025-12-13 01:56:55,987 INFO     Training average negative_sample_loss at step 112200: 0.109711
2025-12-13 01:56:55,987 INFO     Training average loss at step 112200: 0.390712
2025-12-13 01:56:58,130 INFO     Training average regularization at step 112300: 0.302394
2025-12-13 01:56:58,131 INFO     Training average positive_sample_loss at step 112300: 0.064871
2025-12-13 01:56:58,131 INFO     Training average negative_sample_loss at step 112300: 0.109536
2025-12-13 01:56:58,131 INFO     Training average loss at step 112300: 0.389598
2025-12-13 01:57:00,310 INFO     Training average regularization at step 112400: 0.302393
2025-12-13 01:57:00,310 INFO     Training average positive_sample_loss at step 112400: 0.066354
2025-12-13 01:57:00,310 INFO     Training average negative_sample_loss at step 112400: 0.109580
2025-12-13 01:57:00,310 INFO     Training average loss at step 112400: 0.390360
2025-12-13 01:57:02,454 INFO     Training average regularization at step 112500: 0.302392
2025-12-13 01:57:02,454 INFO     Training average positive_sample_loss at step 112500: 0.066292
2025-12-13 01:57:02,454 INFO     Training average negative_sample_loss at step 112500: 0.108331
2025-12-13 01:57:02,455 INFO     Training average loss at step 112500: 0.389704
2025-12-13 01:57:04,661 INFO     Training average regularization at step 112600: 0.302392
2025-12-13 01:57:04,661 INFO     Training average positive_sample_loss at step 112600: 0.067643
2025-12-13 01:57:04,661 INFO     Training average negative_sample_loss at step 112600: 0.107381
2025-12-13 01:57:04,661 INFO     Training average loss at step 112600: 0.389904
2025-12-13 01:57:06,802 INFO     Training average regularization at step 112700: 0.302391
2025-12-13 01:57:06,802 INFO     Training average positive_sample_loss at step 112700: 0.067083
2025-12-13 01:57:06,802 INFO     Training average negative_sample_loss at step 112700: 0.107827
2025-12-13 01:57:06,802 INFO     Training average loss at step 112700: 0.389846
2025-12-13 01:57:08,958 INFO     Training average regularization at step 112800: 0.302391
2025-12-13 01:57:08,958 INFO     Training average positive_sample_loss at step 112800: 0.066829
2025-12-13 01:57:08,958 INFO     Training average negative_sample_loss at step 112800: 0.112286
2025-12-13 01:57:08,958 INFO     Training average loss at step 112800: 0.391948
2025-12-13 01:57:11,123 INFO     Training average regularization at step 112900: 0.302390
2025-12-13 01:57:11,123 INFO     Training average positive_sample_loss at step 112900: 0.067260
2025-12-13 01:57:11,123 INFO     Training average negative_sample_loss at step 112900: 0.110480
2025-12-13 01:57:11,123 INFO     Training average loss at step 112900: 0.391260
2025-12-13 01:57:13,293 INFO     Training average regularization at step 113000: 0.302389
2025-12-13 01:57:13,294 INFO     Training average positive_sample_loss at step 113000: 0.066001
2025-12-13 01:57:13,294 INFO     Training average negative_sample_loss at step 113000: 0.108794
2025-12-13 01:57:13,294 INFO     Training average loss at step 113000: 0.389786
2025-12-13 01:57:15,475 INFO     Training average regularization at step 113100: 0.302389
2025-12-13 01:57:15,475 INFO     Training average positive_sample_loss at step 113100: 0.067030
2025-12-13 01:57:15,475 INFO     Training average negative_sample_loss at step 113100: 0.108955
2025-12-13 01:57:15,475 INFO     Training average loss at step 113100: 0.390381
2025-12-13 01:57:17,636 INFO     Training average regularization at step 113200: 0.302388
2025-12-13 01:57:17,636 INFO     Training average positive_sample_loss at step 113200: 0.067355
2025-12-13 01:57:17,636 INFO     Training average negative_sample_loss at step 113200: 0.110738
2025-12-13 01:57:17,636 INFO     Training average loss at step 113200: 0.391435
2025-12-13 01:57:19,794 INFO     Training average regularization at step 113300: 0.302387
2025-12-13 01:57:19,794 INFO     Training average positive_sample_loss at step 113300: 0.068017
2025-12-13 01:57:19,794 INFO     Training average negative_sample_loss at step 113300: 0.112162
2025-12-13 01:57:19,794 INFO     Training average loss at step 113300: 0.392477
2025-12-13 01:57:21,971 INFO     Training average regularization at step 113400: 0.302387
2025-12-13 01:57:21,971 INFO     Training average positive_sample_loss at step 113400: 0.066618
2025-12-13 01:57:21,971 INFO     Training average negative_sample_loss at step 113400: 0.107414
2025-12-13 01:57:21,971 INFO     Training average loss at step 113400: 0.389403
2025-12-13 01:57:24,154 INFO     Training average regularization at step 113500: 0.302386
2025-12-13 01:57:24,154 INFO     Training average positive_sample_loss at step 113500: 0.067256
2025-12-13 01:57:24,154 INFO     Training average negative_sample_loss at step 113500: 0.110210
2025-12-13 01:57:24,154 INFO     Training average loss at step 113500: 0.391119
2025-12-13 01:57:26,362 INFO     Training average regularization at step 113600: 0.302386
2025-12-13 01:57:26,362 INFO     Training average positive_sample_loss at step 113600: 0.067016
2025-12-13 01:57:26,362 INFO     Training average negative_sample_loss at step 113600: 0.108391
2025-12-13 01:57:26,362 INFO     Training average loss at step 113600: 0.390089
2025-12-13 01:57:28,515 INFO     Training average regularization at step 113700: 0.302385
2025-12-13 01:57:28,515 INFO     Training average positive_sample_loss at step 113700: 0.067724
2025-12-13 01:57:28,515 INFO     Training average negative_sample_loss at step 113700: 0.106955
2025-12-13 01:57:28,515 INFO     Training average loss at step 113700: 0.389724
2025-12-13 01:57:30,663 INFO     Training average regularization at step 113800: 0.302385
2025-12-13 01:57:30,663 INFO     Training average positive_sample_loss at step 113800: 0.065995
2025-12-13 01:57:30,663 INFO     Training average negative_sample_loss at step 113800: 0.111436
2025-12-13 01:57:30,663 INFO     Training average loss at step 113800: 0.391100
2025-12-13 01:57:32,808 INFO     Training average regularization at step 113900: 0.302384
2025-12-13 01:57:32,808 INFO     Training average positive_sample_loss at step 113900: 0.067545
2025-12-13 01:57:32,808 INFO     Training average negative_sample_loss at step 113900: 0.107717
2025-12-13 01:57:32,808 INFO     Training average loss at step 113900: 0.390015
2025-12-13 01:57:34,955 INFO     Training average regularization at step 114000: 0.302384
2025-12-13 01:57:34,955 INFO     Training average positive_sample_loss at step 114000: 0.066075
2025-12-13 01:57:34,955 INFO     Training average negative_sample_loss at step 114000: 0.112258
2025-12-13 01:57:34,955 INFO     Training average loss at step 114000: 0.391550
2025-12-13 01:57:37,175 INFO     Training average regularization at step 114100: 0.302383
2025-12-13 01:57:37,175 INFO     Training average positive_sample_loss at step 114100: 0.067550
2025-12-13 01:57:37,176 INFO     Training average negative_sample_loss at step 114100: 0.109607
2025-12-13 01:57:37,176 INFO     Training average loss at step 114100: 0.390962
2025-12-13 01:57:39,374 INFO     Training average regularization at step 114200: 0.302382
2025-12-13 01:57:39,375 INFO     Training average positive_sample_loss at step 114200: 0.068066
2025-12-13 01:57:39,375 INFO     Training average negative_sample_loss at step 114200: 0.110444
2025-12-13 01:57:39,375 INFO     Training average loss at step 114200: 0.391637
2025-12-13 01:57:41,543 INFO     Training average regularization at step 114300: 0.302382
2025-12-13 01:57:41,543 INFO     Training average positive_sample_loss at step 114300: 0.066178
2025-12-13 01:57:41,543 INFO     Training average negative_sample_loss at step 114300: 0.108289
2025-12-13 01:57:41,543 INFO     Training average loss at step 114300: 0.389616
2025-12-13 01:57:43,701 INFO     Training average regularization at step 114400: 0.302381
2025-12-13 01:57:43,701 INFO     Training average positive_sample_loss at step 114400: 0.066378
2025-12-13 01:57:43,702 INFO     Training average negative_sample_loss at step 114400: 0.108365
2025-12-13 01:57:43,702 INFO     Training average loss at step 114400: 0.389752
2025-12-13 01:57:45,900 INFO     Training average regularization at step 114500: 0.302380
2025-12-13 01:57:45,900 INFO     Training average positive_sample_loss at step 114500: 0.067496
2025-12-13 01:57:45,901 INFO     Training average negative_sample_loss at step 114500: 0.109966
2025-12-13 01:57:45,901 INFO     Training average loss at step 114500: 0.391111
2025-12-13 01:57:48,101 INFO     Training average regularization at step 114600: 0.302380
2025-12-13 01:57:48,101 INFO     Training average positive_sample_loss at step 114600: 0.066608
2025-12-13 01:57:48,101 INFO     Training average negative_sample_loss at step 114600: 0.109410
2025-12-13 01:57:48,102 INFO     Training average loss at step 114600: 0.390389
2025-12-13 01:57:50,250 INFO     Training average regularization at step 114700: 0.302379
2025-12-13 01:57:50,250 INFO     Training average positive_sample_loss at step 114700: 0.067571
2025-12-13 01:57:50,250 INFO     Training average negative_sample_loss at step 114700: 0.109622
2025-12-13 01:57:50,250 INFO     Training average loss at step 114700: 0.390976
2025-12-13 01:57:52,403 INFO     Training average regularization at step 114800: 0.302379
2025-12-13 01:57:52,403 INFO     Training average positive_sample_loss at step 114800: 0.066750
2025-12-13 01:57:52,403 INFO     Training average negative_sample_loss at step 114800: 0.107229
2025-12-13 01:57:52,403 INFO     Training average loss at step 114800: 0.389368
2025-12-13 01:57:54,560 INFO     Training average regularization at step 114900: 0.302378
2025-12-13 01:57:54,560 INFO     Training average positive_sample_loss at step 114900: 0.066214
2025-12-13 01:57:54,560 INFO     Training average negative_sample_loss at step 114900: 0.108581
2025-12-13 01:57:54,560 INFO     Training average loss at step 114900: 0.389776
2025-12-13 01:57:56,710 INFO     Training average regularization at step 115000: 0.302378
2025-12-13 01:57:56,710 INFO     Training average positive_sample_loss at step 115000: 0.066046
2025-12-13 01:57:56,710 INFO     Training average negative_sample_loss at step 115000: 0.110096
2025-12-13 01:57:56,710 INFO     Training average loss at step 115000: 0.390449
2025-12-13 01:57:58,870 INFO     Training average regularization at step 115100: 0.302377
2025-12-13 01:57:58,871 INFO     Training average positive_sample_loss at step 115100: 0.066936
2025-12-13 01:57:58,871 INFO     Training average negative_sample_loss at step 115100: 0.110443
2025-12-13 01:57:58,871 INFO     Training average loss at step 115100: 0.391066
2025-12-13 01:58:01,018 INFO     Training average regularization at step 115200: 0.302376
2025-12-13 01:58:01,018 INFO     Training average positive_sample_loss at step 115200: 0.067225
2025-12-13 01:58:01,018 INFO     Training average negative_sample_loss at step 115200: 0.107891
2025-12-13 01:58:01,018 INFO     Training average loss at step 115200: 0.389934
2025-12-13 01:58:03,176 INFO     Training average regularization at step 115300: 0.302376
2025-12-13 01:58:03,176 INFO     Training average positive_sample_loss at step 115300: 0.065788
2025-12-13 01:58:03,176 INFO     Training average negative_sample_loss at step 115300: 0.109870
2025-12-13 01:58:03,176 INFO     Training average loss at step 115300: 0.390205
2025-12-13 01:58:05,320 INFO     Training average regularization at step 115400: 0.302375
2025-12-13 01:58:05,320 INFO     Training average positive_sample_loss at step 115400: 0.067194
2025-12-13 01:58:05,320 INFO     Training average negative_sample_loss at step 115400: 0.113007
2025-12-13 01:58:05,320 INFO     Training average loss at step 115400: 0.392476
2025-12-13 01:58:07,463 INFO     Training average regularization at step 115500: 0.302375
2025-12-13 01:58:07,463 INFO     Training average positive_sample_loss at step 115500: 0.066618
2025-12-13 01:58:07,463 INFO     Training average negative_sample_loss at step 115500: 0.108420
2025-12-13 01:58:07,463 INFO     Training average loss at step 115500: 0.389894
2025-12-13 01:58:09,657 INFO     Training average regularization at step 115600: 0.302374
2025-12-13 01:58:09,657 INFO     Training average positive_sample_loss at step 115600: 0.067047
2025-12-13 01:58:09,657 INFO     Training average negative_sample_loss at step 115600: 0.109622
2025-12-13 01:58:09,657 INFO     Training average loss at step 115600: 0.390708
2025-12-13 01:58:11,819 INFO     Training average regularization at step 115700: 0.302374
2025-12-13 01:58:11,819 INFO     Training average positive_sample_loss at step 115700: 0.066302
2025-12-13 01:58:11,819 INFO     Training average negative_sample_loss at step 115700: 0.110692
2025-12-13 01:58:11,819 INFO     Training average loss at step 115700: 0.390871
2025-12-13 01:58:13,972 INFO     Training average regularization at step 115800: 0.302373
2025-12-13 01:58:13,973 INFO     Training average positive_sample_loss at step 115800: 0.066720
2025-12-13 01:58:13,973 INFO     Training average negative_sample_loss at step 115800: 0.109830
2025-12-13 01:58:13,973 INFO     Training average loss at step 115800: 0.390648
2025-12-13 01:58:16,142 INFO     Training average regularization at step 115900: 0.302372
2025-12-13 01:58:16,142 INFO     Training average positive_sample_loss at step 115900: 0.066969
2025-12-13 01:58:16,142 INFO     Training average negative_sample_loss at step 115900: 0.108231
2025-12-13 01:58:16,143 INFO     Training average loss at step 115900: 0.389973
2025-12-13 01:58:19,302 INFO     Training average regularization at step 116000: 0.302372
2025-12-13 01:58:19,303 INFO     Training average positive_sample_loss at step 116000: 0.066470
2025-12-13 01:58:19,303 INFO     Training average negative_sample_loss at step 116000: 0.108172
2025-12-13 01:58:19,303 INFO     Training average loss at step 116000: 0.389692
2025-12-13 01:58:21,456 INFO     Training average regularization at step 116100: 0.302371
2025-12-13 01:58:21,457 INFO     Training average positive_sample_loss at step 116100: 0.066788
2025-12-13 01:58:21,457 INFO     Training average negative_sample_loss at step 116100: 0.107822
2025-12-13 01:58:21,457 INFO     Training average loss at step 116100: 0.389676
2025-12-13 01:58:23,605 INFO     Training average regularization at step 116200: 0.302371
2025-12-13 01:58:23,605 INFO     Training average positive_sample_loss at step 116200: 0.067159
2025-12-13 01:58:23,605 INFO     Training average negative_sample_loss at step 116200: 0.108231
2025-12-13 01:58:23,605 INFO     Training average loss at step 116200: 0.390065
2025-12-13 01:58:25,752 INFO     Training average regularization at step 116300: 0.302370
2025-12-13 01:58:25,752 INFO     Training average positive_sample_loss at step 116300: 0.067074
2025-12-13 01:58:25,752 INFO     Training average negative_sample_loss at step 116300: 0.108128
2025-12-13 01:58:25,752 INFO     Training average loss at step 116300: 0.389971
2025-12-13 01:58:27,915 INFO     Training average regularization at step 116400: 0.302369
2025-12-13 01:58:27,916 INFO     Training average positive_sample_loss at step 116400: 0.065826
2025-12-13 01:58:27,916 INFO     Training average negative_sample_loss at step 116400: 0.107829
2025-12-13 01:58:27,916 INFO     Training average loss at step 116400: 0.389197
2025-12-13 01:58:30,088 INFO     Training average regularization at step 116500: 0.302369
2025-12-13 01:58:30,088 INFO     Training average positive_sample_loss at step 116500: 0.066497
2025-12-13 01:58:30,088 INFO     Training average negative_sample_loss at step 116500: 0.110273
2025-12-13 01:58:30,088 INFO     Training average loss at step 116500: 0.390754
2025-12-13 01:58:32,276 INFO     Training average regularization at step 116600: 0.302368
2025-12-13 01:58:32,276 INFO     Training average positive_sample_loss at step 116600: 0.066653
2025-12-13 01:58:32,276 INFO     Training average negative_sample_loss at step 116600: 0.107853
2025-12-13 01:58:32,276 INFO     Training average loss at step 116600: 0.389621
2025-12-13 01:58:34,418 INFO     Training average regularization at step 116700: 0.302367
2025-12-13 01:58:34,418 INFO     Training average positive_sample_loss at step 116700: 0.066412
2025-12-13 01:58:34,418 INFO     Training average negative_sample_loss at step 116700: 0.109171
2025-12-13 01:58:34,418 INFO     Training average loss at step 116700: 0.390159
2025-12-13 01:58:36,583 INFO     Training average regularization at step 116800: 0.302366
2025-12-13 01:58:36,583 INFO     Training average positive_sample_loss at step 116800: 0.066424
2025-12-13 01:58:36,583 INFO     Training average negative_sample_loss at step 116800: 0.107413
2025-12-13 01:58:36,583 INFO     Training average loss at step 116800: 0.389285
2025-12-13 01:58:38,796 INFO     Training average regularization at step 116900: 0.302366
2025-12-13 01:58:38,796 INFO     Training average positive_sample_loss at step 116900: 0.066195
2025-12-13 01:58:38,796 INFO     Training average negative_sample_loss at step 116900: 0.109218
2025-12-13 01:58:38,797 INFO     Training average loss at step 116900: 0.390072
2025-12-13 01:58:41,011 INFO     Training average regularization at step 117000: 0.302365
2025-12-13 01:58:41,012 INFO     Training average positive_sample_loss at step 117000: 0.067680
2025-12-13 01:58:41,012 INFO     Training average negative_sample_loss at step 117000: 0.108836
2025-12-13 01:58:41,012 INFO     Training average loss at step 117000: 0.390623
2025-12-13 01:58:43,256 INFO     Training average regularization at step 117100: 0.302364
2025-12-13 01:58:43,256 INFO     Training average positive_sample_loss at step 117100: 0.066200
2025-12-13 01:58:43,257 INFO     Training average negative_sample_loss at step 117100: 0.110646
2025-12-13 01:58:43,257 INFO     Training average loss at step 117100: 0.390787
2025-12-13 01:58:45,440 INFO     Training average regularization at step 117200: 0.302364
2025-12-13 01:58:45,441 INFO     Training average positive_sample_loss at step 117200: 0.066846
2025-12-13 01:58:45,441 INFO     Training average negative_sample_loss at step 117200: 0.112478
2025-12-13 01:58:45,441 INFO     Training average loss at step 117200: 0.392025
2025-12-13 01:58:47,591 INFO     Training average regularization at step 117300: 0.302363
2025-12-13 01:58:47,591 INFO     Training average positive_sample_loss at step 117300: 0.066919
2025-12-13 01:58:47,591 INFO     Training average negative_sample_loss at step 117300: 0.108751
2025-12-13 01:58:47,591 INFO     Training average loss at step 117300: 0.390198
2025-12-13 01:58:49,735 INFO     Training average regularization at step 117400: 0.302362
2025-12-13 01:58:49,736 INFO     Training average positive_sample_loss at step 117400: 0.066508
2025-12-13 01:58:49,736 INFO     Training average negative_sample_loss at step 117400: 0.108996
2025-12-13 01:58:49,736 INFO     Training average loss at step 117400: 0.390114
2025-12-13 01:58:51,891 INFO     Training average regularization at step 117500: 0.302361
2025-12-13 01:58:51,892 INFO     Training average positive_sample_loss at step 117500: 0.065253
2025-12-13 01:58:51,892 INFO     Training average negative_sample_loss at step 117500: 0.108134
2025-12-13 01:58:51,892 INFO     Training average loss at step 117500: 0.389055
2025-12-13 01:58:54,068 INFO     Training average regularization at step 117600: 0.302361
2025-12-13 01:58:54,068 INFO     Training average positive_sample_loss at step 117600: 0.067537
2025-12-13 01:58:54,068 INFO     Training average negative_sample_loss at step 117600: 0.108084
2025-12-13 01:58:54,068 INFO     Training average loss at step 117600: 0.390171
2025-12-13 01:58:56,230 INFO     Training average regularization at step 117700: 0.302360
2025-12-13 01:58:56,230 INFO     Training average positive_sample_loss at step 117700: 0.066769
2025-12-13 01:58:56,230 INFO     Training average negative_sample_loss at step 117700: 0.110213
2025-12-13 01:58:56,231 INFO     Training average loss at step 117700: 0.390851
2025-12-13 01:58:58,357 INFO     Training average regularization at step 117800: 0.302359
2025-12-13 01:58:58,358 INFO     Training average positive_sample_loss at step 117800: 0.065742
2025-12-13 01:58:58,358 INFO     Training average negative_sample_loss at step 117800: 0.107576
2025-12-13 01:58:58,358 INFO     Training average loss at step 117800: 0.389018
2025-12-13 01:59:00,499 INFO     Training average regularization at step 117900: 0.302359
2025-12-13 01:59:00,500 INFO     Training average positive_sample_loss at step 117900: 0.066303
2025-12-13 01:59:00,500 INFO     Training average negative_sample_loss at step 117900: 0.105642
2025-12-13 01:59:00,500 INFO     Training average loss at step 117900: 0.388331
2025-12-13 01:59:02,639 INFO     Training average regularization at step 118000: 0.302358
2025-12-13 01:59:02,639 INFO     Training average positive_sample_loss at step 118000: 0.064815
2025-12-13 01:59:02,639 INFO     Training average negative_sample_loss at step 118000: 0.107945
2025-12-13 01:59:02,639 INFO     Training average loss at step 118000: 0.388738
2025-12-13 01:59:04,831 INFO     Training average regularization at step 118100: 0.302357
2025-12-13 01:59:04,831 INFO     Training average positive_sample_loss at step 118100: 0.067653
2025-12-13 01:59:04,831 INFO     Training average negative_sample_loss at step 118100: 0.108442
2025-12-13 01:59:04,831 INFO     Training average loss at step 118100: 0.390404
2025-12-13 01:59:06,964 INFO     Training average regularization at step 118200: 0.302357
2025-12-13 01:59:06,964 INFO     Training average positive_sample_loss at step 118200: 0.065338
2025-12-13 01:59:06,964 INFO     Training average negative_sample_loss at step 118200: 0.109133
2025-12-13 01:59:06,964 INFO     Training average loss at step 118200: 0.389592
2025-12-13 01:59:09,140 INFO     Training average regularization at step 118300: 0.302356
2025-12-13 01:59:09,141 INFO     Training average positive_sample_loss at step 118300: 0.067864
2025-12-13 01:59:09,141 INFO     Training average negative_sample_loss at step 118300: 0.108647
2025-12-13 01:59:09,141 INFO     Training average loss at step 118300: 0.390611
2025-12-13 01:59:11,284 INFO     Training average regularization at step 118400: 0.302355
2025-12-13 01:59:11,284 INFO     Training average positive_sample_loss at step 118400: 0.067857
2025-12-13 01:59:11,284 INFO     Training average negative_sample_loss at step 118400: 0.109461
2025-12-13 01:59:11,284 INFO     Training average loss at step 118400: 0.391014
2025-12-13 01:59:13,440 INFO     Training average regularization at step 118500: 0.302355
2025-12-13 01:59:13,440 INFO     Training average positive_sample_loss at step 118500: 0.067307
2025-12-13 01:59:13,441 INFO     Training average negative_sample_loss at step 118500: 0.109799
2025-12-13 01:59:13,441 INFO     Training average loss at step 118500: 0.390908
2025-12-13 01:59:15,650 INFO     Training average regularization at step 118600: 0.302354
2025-12-13 01:59:15,650 INFO     Training average positive_sample_loss at step 118600: 0.066875
2025-12-13 01:59:15,650 INFO     Training average negative_sample_loss at step 118600: 0.108453
2025-12-13 01:59:15,650 INFO     Training average loss at step 118600: 0.390018
2025-12-13 01:59:17,799 INFO     Training average regularization at step 118700: 0.302354
2025-12-13 01:59:17,799 INFO     Training average positive_sample_loss at step 118700: 0.067431
2025-12-13 01:59:17,799 INFO     Training average negative_sample_loss at step 118700: 0.109024
2025-12-13 01:59:17,799 INFO     Training average loss at step 118700: 0.390581
2025-12-13 01:59:19,961 INFO     Training average regularization at step 118800: 0.302353
2025-12-13 01:59:19,961 INFO     Training average positive_sample_loss at step 118800: 0.066899
2025-12-13 01:59:19,961 INFO     Training average negative_sample_loss at step 118800: 0.108273
2025-12-13 01:59:19,961 INFO     Training average loss at step 118800: 0.389939
2025-12-13 01:59:22,092 INFO     Training average regularization at step 118900: 0.302353
2025-12-13 01:59:22,092 INFO     Training average positive_sample_loss at step 118900: 0.067676
2025-12-13 01:59:22,092 INFO     Training average negative_sample_loss at step 118900: 0.107340
2025-12-13 01:59:22,093 INFO     Training average loss at step 118900: 0.389861
2025-12-13 01:59:24,240 INFO     Training average regularization at step 119000: 0.302352
2025-12-13 01:59:24,240 INFO     Training average positive_sample_loss at step 119000: 0.068280
2025-12-13 01:59:24,240 INFO     Training average negative_sample_loss at step 119000: 0.107625
2025-12-13 01:59:24,240 INFO     Training average loss at step 119000: 0.390305
2025-12-13 01:59:26,414 INFO     Training average regularization at step 119100: 0.302352
2025-12-13 01:59:26,415 INFO     Training average positive_sample_loss at step 119100: 0.067079
2025-12-13 01:59:26,415 INFO     Training average negative_sample_loss at step 119100: 0.110802
2025-12-13 01:59:26,415 INFO     Training average loss at step 119100: 0.391293
2025-12-13 01:59:28,588 INFO     Training average regularization at step 119200: 0.302351
2025-12-13 01:59:28,588 INFO     Training average positive_sample_loss at step 119200: 0.067869
2025-12-13 01:59:28,588 INFO     Training average negative_sample_loss at step 119200: 0.109772
2025-12-13 01:59:28,588 INFO     Training average loss at step 119200: 0.391172
2025-12-13 01:59:30,731 INFO     Training average regularization at step 119300: 0.302351
2025-12-13 01:59:30,731 INFO     Training average positive_sample_loss at step 119300: 0.067174
2025-12-13 01:59:30,731 INFO     Training average negative_sample_loss at step 119300: 0.109252
2025-12-13 01:59:30,731 INFO     Training average loss at step 119300: 0.390564
2025-12-13 01:59:32,877 INFO     Training average regularization at step 119400: 0.302350
2025-12-13 01:59:32,877 INFO     Training average positive_sample_loss at step 119400: 0.065912
2025-12-13 01:59:32,877 INFO     Training average negative_sample_loss at step 119400: 0.108792
2025-12-13 01:59:32,877 INFO     Training average loss at step 119400: 0.389702
2025-12-13 01:59:35,025 INFO     Training average regularization at step 119500: 0.302350
2025-12-13 01:59:35,026 INFO     Training average positive_sample_loss at step 119500: 0.066883
2025-12-13 01:59:35,026 INFO     Training average negative_sample_loss at step 119500: 0.107880
2025-12-13 01:59:35,026 INFO     Training average loss at step 119500: 0.389731
2025-12-13 01:59:37,215 INFO     Training average regularization at step 119600: 0.302349
2025-12-13 01:59:37,216 INFO     Training average positive_sample_loss at step 119600: 0.067686
2025-12-13 01:59:37,216 INFO     Training average negative_sample_loss at step 119600: 0.109625
2025-12-13 01:59:37,216 INFO     Training average loss at step 119600: 0.391005
2025-12-13 01:59:39,391 INFO     Training average regularization at step 119700: 0.302349
2025-12-13 01:59:39,392 INFO     Training average positive_sample_loss at step 119700: 0.066244
2025-12-13 01:59:39,392 INFO     Training average negative_sample_loss at step 119700: 0.110501
2025-12-13 01:59:39,392 INFO     Training average loss at step 119700: 0.390721
2025-12-13 01:59:41,593 INFO     Training average regularization at step 119800: 0.302348
2025-12-13 01:59:41,593 INFO     Training average positive_sample_loss at step 119800: 0.067061
2025-12-13 01:59:41,593 INFO     Training average negative_sample_loss at step 119800: 0.107326
2025-12-13 01:59:41,593 INFO     Training average loss at step 119800: 0.389542
2025-12-13 01:59:43,796 INFO     Training average regularization at step 119900: 0.302347
2025-12-13 01:59:43,796 INFO     Training average positive_sample_loss at step 119900: 0.068128
2025-12-13 01:59:43,796 INFO     Training average negative_sample_loss at step 119900: 0.108512
2025-12-13 01:59:43,796 INFO     Training average loss at step 119900: 0.390668
2025-12-13 01:59:47,435 INFO     Training average regularization at step 120000: 0.302347
2025-12-13 01:59:47,436 INFO     Training average positive_sample_loss at step 120000: 0.067152
2025-12-13 01:59:47,436 INFO     Training average negative_sample_loss at step 120000: 0.109729
2025-12-13 01:59:47,436 INFO     Training average loss at step 120000: 0.390788
2025-12-13 01:59:47,436 INFO     Evaluating on Valid Dataset...
2025-12-13 01:59:48,237 INFO     Evaluating the model... (0/50000)
2025-12-13 01:59:50,951 INFO     Evaluating the model... (500/50000)
2025-12-13 01:59:53,353 INFO     Evaluating the model... (1000/50000)
2025-12-13 01:59:55,856 INFO     Evaluating the model... (1500/50000)
2025-12-13 01:59:58,217 INFO     Evaluating the model... (2000/50000)
2025-12-13 02:00:01,584 INFO     Evaluating the model... (2500/50000)
2025-12-13 02:00:03,978 INFO     Evaluating the model... (3000/50000)
2025-12-13 02:00:06,555 INFO     Evaluating the model... (3500/50000)
2025-12-13 02:00:08,947 INFO     Evaluating the model... (4000/50000)
2025-12-13 02:00:11,463 INFO     Evaluating the model... (4500/50000)
2025-12-13 02:00:14,834 INFO     Evaluating the model... (5000/50000)
2025-12-13 02:00:17,300 INFO     Evaluating the model... (5500/50000)
2025-12-13 02:00:19,692 INFO     Evaluating the model... (6000/50000)
2025-12-13 02:00:22,016 INFO     Evaluating the model... (6500/50000)
2025-12-13 02:00:24,652 INFO     Evaluating the model... (7000/50000)
2025-12-13 02:00:27,823 INFO     Evaluating the model... (7500/50000)
2025-12-13 02:00:30,327 INFO     Evaluating the model... (8000/50000)
2025-12-13 02:00:32,739 INFO     Evaluating the model... (8500/50000)
2025-12-13 02:00:35,425 INFO     Evaluating the model... (9000/50000)
2025-12-13 02:00:38,085 INFO     Evaluating the model... (9500/50000)
2025-12-13 02:00:41,266 INFO     Evaluating the model... (10000/50000)
2025-12-13 02:00:43,921 INFO     Evaluating the model... (10500/50000)
2025-12-13 02:00:46,867 INFO     Evaluating the model... (11000/50000)
2025-12-13 02:00:49,323 INFO     Evaluating the model... (11500/50000)
2025-12-13 02:00:52,603 INFO     Evaluating the model... (12000/50000)
2025-12-13 02:00:55,053 INFO     Evaluating the model... (12500/50000)
2025-12-13 02:00:57,464 INFO     Evaluating the model... (13000/50000)
2025-12-13 02:01:00,032 INFO     Evaluating the model... (13500/50000)
2025-12-13 02:01:02,406 INFO     Evaluating the model... (14000/50000)
2025-12-13 02:01:05,616 INFO     Evaluating the model... (14500/50000)
2025-12-13 02:01:08,004 INFO     Evaluating the model... (15000/50000)
2025-12-13 02:01:10,678 INFO     Evaluating the model... (15500/50000)
2025-12-13 02:01:13,057 INFO     Evaluating the model... (16000/50000)
2025-12-13 02:01:15,584 INFO     Evaluating the model... (16500/50000)
2025-12-13 02:01:18,784 INFO     Evaluating the model... (17000/50000)
2025-12-13 02:01:21,383 INFO     Evaluating the model... (17500/50000)
2025-12-13 02:01:23,800 INFO     Evaluating the model... (18000/50000)
2025-12-13 02:01:26,313 INFO     Evaluating the model... (18500/50000)
2025-12-13 02:01:28,701 INFO     Evaluating the model... (19000/50000)
2025-12-13 02:01:31,911 INFO     Evaluating the model... (19500/50000)
2025-12-13 02:01:34,593 INFO     Evaluating the model... (20000/50000)
2025-12-13 02:01:37,327 INFO     Evaluating the model... (20500/50000)
2025-12-13 02:01:39,924 INFO     Evaluating the model... (21000/50000)
2025-12-13 02:01:42,420 INFO     Evaluating the model... (21500/50000)
2025-12-13 02:01:46,243 INFO     Evaluating the model... (22000/50000)
2025-12-13 02:01:48,678 INFO     Evaluating the model... (22500/50000)
2025-12-13 02:01:51,199 INFO     Evaluating the model... (23000/50000)
2025-12-13 02:01:53,619 INFO     Evaluating the model... (23500/50000)
2025-12-13 02:01:56,383 INFO     Evaluating the model... (24000/50000)
2025-12-13 02:01:59,961 INFO     Evaluating the model... (24500/50000)
2025-12-13 02:02:02,786 INFO     Evaluating the model... (25000/50000)
2025-12-13 02:02:05,371 INFO     Evaluating the model... (25500/50000)
2025-12-13 02:02:08,168 INFO     Evaluating the model... (26000/50000)
2025-12-13 02:02:10,713 INFO     Evaluating the model... (26500/50000)
2025-12-13 02:02:14,184 INFO     Evaluating the model... (27000/50000)
2025-12-13 02:02:16,784 INFO     Evaluating the model... (27500/50000)
2025-12-13 02:02:19,543 INFO     Evaluating the model... (28000/50000)
2025-12-13 02:02:22,087 INFO     Evaluating the model... (28500/50000)
2025-12-13 02:02:24,529 INFO     Evaluating the model... (29000/50000)
2025-12-13 02:02:27,624 INFO     Evaluating the model... (29500/50000)
2025-12-13 02:02:30,361 INFO     Evaluating the model... (30000/50000)
2025-12-13 02:02:32,809 INFO     Evaluating the model... (30500/50000)
2025-12-13 02:02:35,310 INFO     Evaluating the model... (31000/50000)
2025-12-13 02:02:38,022 INFO     Evaluating the model... (31500/50000)
2025-12-13 02:02:41,421 INFO     Evaluating the model... (32000/50000)
2025-12-13 02:02:44,229 INFO     Evaluating the model... (32500/50000)
2025-12-13 02:02:46,918 INFO     Evaluating the model... (33000/50000)
2025-12-13 02:02:49,501 INFO     Evaluating the model... (33500/50000)
2025-12-13 02:02:52,065 INFO     Evaluating the model... (34000/50000)
2025-12-13 02:02:55,371 INFO     Evaluating the model... (34500/50000)
2025-12-13 02:02:57,972 INFO     Evaluating the model... (35000/50000)
2025-12-13 02:03:00,464 INFO     Evaluating the model... (35500/50000)
2025-12-13 02:03:03,046 INFO     Evaluating the model... (36000/50000)
2025-12-13 02:03:05,949 INFO     Evaluating the model... (36500/50000)
2025-12-13 02:03:09,143 INFO     Evaluating the model... (37000/50000)
2025-12-13 02:03:11,649 INFO     Evaluating the model... (37500/50000)
2025-12-13 02:03:14,030 INFO     Evaluating the model... (38000/50000)
2025-12-13 02:03:16,637 INFO     Evaluating the model... (38500/50000)
2025-12-13 02:03:19,777 INFO     Evaluating the model... (39000/50000)
2025-12-13 02:03:22,220 INFO     Evaluating the model... (39500/50000)
2025-12-13 02:03:24,703 INFO     Evaluating the model... (40000/50000)
2025-12-13 02:03:27,546 INFO     Evaluating the model... (40500/50000)
2025-12-13 02:03:30,087 INFO     Evaluating the model... (41000/50000)
2025-12-13 02:03:33,242 INFO     Evaluating the model... (41500/50000)
2025-12-13 02:03:35,901 INFO     Evaluating the model... (42000/50000)
2025-12-13 02:03:38,758 INFO     Evaluating the model... (42500/50000)
2025-12-13 02:03:41,590 INFO     Evaluating the model... (43000/50000)
2025-12-13 02:03:44,328 INFO     Evaluating the model... (43500/50000)
2025-12-13 02:03:47,762 INFO     Evaluating the model... (44000/50000)
2025-12-13 02:03:50,328 INFO     Evaluating the model... (44500/50000)
2025-12-13 02:03:52,900 INFO     Evaluating the model... (45000/50000)
2025-12-13 02:03:55,383 INFO     Evaluating the model... (45500/50000)
2025-12-13 02:03:57,902 INFO     Evaluating the model... (46000/50000)
2025-12-13 02:04:01,656 INFO     Evaluating the model... (46500/50000)
2025-12-13 02:04:04,124 INFO     Evaluating the model... (47000/50000)
2025-12-13 02:04:06,730 INFO     Evaluating the model... (47500/50000)
2025-12-13 02:04:09,305 INFO     Evaluating the model... (48000/50000)
2025-12-13 02:04:11,804 INFO     Evaluating the model... (48500/50000)
2025-12-13 02:04:15,563 INFO     Evaluating the model... (49000/50000)
2025-12-13 02:04:18,026 INFO     Evaluating the model... (49500/50000)
2025-12-13 02:04:20,836 INFO     Valid MRR at step 120000: 0.631388
2025-12-13 02:04:20,836 INFO     Valid MR at step 120000: 266.338510
2025-12-13 02:04:20,836 INFO     Valid HITS@1 at step 120000: 0.545370
2025-12-13 02:04:20,836 INFO     Valid HITS@3 at step 120000: 0.684290
2025-12-13 02:04:20,836 INFO     Valid HITS@10 at step 120000: 0.784450
2025-12-13 02:04:21,997 INFO     Evaluating on Test Dataset...
2025-12-13 02:04:22,549 INFO     Evaluating the model... (0/59072)
2025-12-13 02:04:25,498 INFO     Evaluating the model... (500/59072)
2025-12-13 02:04:28,087 INFO     Evaluating the model... (1000/59072)
2025-12-13 02:04:31,805 INFO     Evaluating the model... (1500/59072)
2025-12-13 02:04:34,304 INFO     Evaluating the model... (2000/59072)
2025-12-13 02:04:37,270 INFO     Evaluating the model... (2500/59072)
2025-12-13 02:04:39,959 INFO     Evaluating the model... (3000/59072)
2025-12-13 02:04:42,621 INFO     Evaluating the model... (3500/59072)
2025-12-13 02:04:46,100 INFO     Evaluating the model... (4000/59072)
2025-12-13 02:04:48,732 INFO     Evaluating the model... (4500/59072)
2025-12-13 02:04:51,170 INFO     Evaluating the model... (5000/59072)
2025-12-13 02:04:53,745 INFO     Evaluating the model... (5500/59072)
2025-12-13 02:04:56,111 INFO     Evaluating the model... (6000/59072)
2025-12-13 02:04:59,553 INFO     Evaluating the model... (6500/59072)
2025-12-13 02:05:02,017 INFO     Evaluating the model... (7000/59072)
2025-12-13 02:05:04,536 INFO     Evaluating the model... (7500/59072)
2025-12-13 02:05:06,890 INFO     Evaluating the model... (8000/59072)
2025-12-13 02:05:09,234 INFO     Evaluating the model... (8500/59072)
2025-12-13 02:05:12,444 INFO     Evaluating the model... (9000/59072)
2025-12-13 02:05:14,888 INFO     Evaluating the model... (9500/59072)
2025-12-13 02:05:17,395 INFO     Evaluating the model... (10000/59072)
2025-12-13 02:05:19,743 INFO     Evaluating the model... (10500/59072)
2025-12-13 02:05:22,413 INFO     Evaluating the model... (11000/59072)
2025-12-13 02:05:25,612 INFO     Evaluating the model... (11500/59072)
2025-12-13 02:05:28,113 INFO     Evaluating the model... (12000/59072)
2025-12-13 02:05:30,529 INFO     Evaluating the model... (12500/59072)
2025-12-13 02:05:32,954 INFO     Evaluating the model... (13000/59072)
2025-12-13 02:05:35,709 INFO     Evaluating the model... (13500/59072)
2025-12-13 02:05:38,817 INFO     Evaluating the model... (14000/59072)
2025-12-13 02:05:41,445 INFO     Evaluating the model... (14500/59072)
2025-12-13 02:05:44,300 INFO     Evaluating the model... (15000/59072)
2025-12-13 02:05:46,990 INFO     Evaluating the model... (15500/59072)
2025-12-13 02:05:49,395 INFO     Evaluating the model... (16000/59072)
2025-12-13 02:05:52,470 INFO     Evaluating the model... (16500/59072)
2025-12-13 02:05:55,064 INFO     Evaluating the model... (17000/59072)
2025-12-13 02:05:57,684 INFO     Evaluating the model... (17500/59072)
2025-12-13 02:06:00,043 INFO     Evaluating the model... (18000/59072)
2025-12-13 02:06:03,441 INFO     Evaluating the model... (18500/59072)
2025-12-13 02:06:05,926 INFO     Evaluating the model... (19000/59072)
2025-12-13 02:06:08,520 INFO     Evaluating the model... (19500/59072)
2025-12-13 02:06:11,024 INFO     Evaluating the model... (20000/59072)
2025-12-13 02:06:13,545 INFO     Evaluating the model... (20500/59072)
2025-12-13 02:06:17,066 INFO     Evaluating the model... (21000/59072)
2025-12-13 02:06:19,629 INFO     Evaluating the model... (21500/59072)
2025-12-13 02:06:22,252 INFO     Evaluating the model... (22000/59072)
2025-12-13 02:06:24,733 INFO     Evaluating the model... (22500/59072)
2025-12-13 02:06:27,279 INFO     Evaluating the model... (23000/59072)
2025-12-13 02:06:30,672 INFO     Evaluating the model... (23500/59072)
2025-12-13 02:06:33,279 INFO     Evaluating the model... (24000/59072)
2025-12-13 02:06:35,999 INFO     Evaluating the model... (24500/59072)
2025-12-13 02:06:38,766 INFO     Evaluating the model... (25000/59072)
2025-12-13 02:06:41,271 INFO     Evaluating the model... (25500/59072)
2025-12-13 02:06:45,219 INFO     Evaluating the model... (26000/59072)
2025-12-13 02:06:47,680 INFO     Evaluating the model... (26500/59072)
2025-12-13 02:06:50,192 INFO     Evaluating the model... (27000/59072)
2025-12-13 02:06:52,679 INFO     Evaluating the model... (27500/59072)
2025-12-13 02:06:55,338 INFO     Evaluating the model... (28000/59072)
2025-12-13 02:06:58,511 INFO     Evaluating the model... (28500/59072)
2025-12-13 02:07:01,035 INFO     Evaluating the model... (29000/59072)
2025-12-13 02:07:03,533 INFO     Evaluating the model... (29500/59072)
2025-12-13 02:07:06,663 INFO     Evaluating the model... (30000/59072)
2025-12-13 02:07:10,459 INFO     Evaluating the model... (30500/59072)
2025-12-13 02:07:12,988 INFO     Evaluating the model... (31000/59072)
2025-12-13 02:07:15,588 INFO     Evaluating the model... (31500/59072)
2025-12-13 02:07:18,298 INFO     Evaluating the model... (32000/59072)
2025-12-13 02:07:20,767 INFO     Evaluating the model... (32500/59072)
2025-12-13 02:07:24,420 INFO     Evaluating the model... (33000/59072)
2025-12-13 02:07:26,905 INFO     Evaluating the model... (33500/59072)
2025-12-13 02:07:29,658 INFO     Evaluating the model... (34000/59072)
2025-12-13 02:07:32,130 INFO     Evaluating the model... (34500/59072)
2025-12-13 02:07:34,668 INFO     Evaluating the model... (35000/59072)
2025-12-13 02:07:38,176 INFO     Evaluating the model... (35500/59072)
2025-12-13 02:07:41,073 INFO     Evaluating the model... (36000/59072)
2025-12-13 02:07:43,690 INFO     Evaluating the model... (36500/59072)
2025-12-13 02:07:46,353 INFO     Evaluating the model... (37000/59072)
2025-12-13 02:07:48,893 INFO     Evaluating the model... (37500/59072)
2025-12-13 02:07:52,213 INFO     Evaluating the model... (38000/59072)
2025-12-13 02:07:54,715 INFO     Evaluating the model... (38500/59072)
2025-12-13 02:07:57,333 INFO     Evaluating the model... (39000/59072)
2025-12-13 02:07:59,712 INFO     Evaluating the model... (39500/59072)
2025-12-13 02:08:02,147 INFO     Evaluating the model... (40000/59072)
2025-12-13 02:08:05,326 INFO     Evaluating the model... (40500/59072)
2025-12-13 02:08:07,806 INFO     Evaluating the model... (41000/59072)
2025-12-13 02:08:10,316 INFO     Evaluating the model... (41500/59072)
2025-12-13 02:08:13,070 INFO     Evaluating the model... (42000/59072)
2025-12-13 02:08:15,896 INFO     Evaluating the model... (42500/59072)
2025-12-13 02:08:19,202 INFO     Evaluating the model... (43000/59072)
2025-12-13 02:08:21,608 INFO     Evaluating the model... (43500/59072)
2025-12-13 02:08:24,050 INFO     Evaluating the model... (44000/59072)
2025-12-13 02:08:26,860 INFO     Evaluating the model... (44500/59072)
2025-12-13 02:08:29,393 INFO     Evaluating the model... (45000/59072)
2025-12-13 02:08:32,677 INFO     Evaluating the model... (45500/59072)
2025-12-13 02:08:35,115 INFO     Evaluating the model... (46000/59072)
2025-12-13 02:08:38,067 INFO     Evaluating the model... (46500/59072)
2025-12-13 02:08:40,952 INFO     Evaluating the model... (47000/59072)
2025-12-13 02:08:44,575 INFO     Evaluating the model... (47500/59072)
2025-12-13 02:08:47,169 INFO     Evaluating the model... (48000/59072)
2025-12-13 02:08:49,907 INFO     Evaluating the model... (48500/59072)
2025-12-13 02:08:52,362 INFO     Evaluating the model... (49000/59072)
2025-12-13 02:08:54,818 INFO     Evaluating the model... (49500/59072)
2025-12-13 02:08:58,393 INFO     Evaluating the model... (50000/59072)
2025-12-13 02:09:00,972 INFO     Evaluating the model... (50500/59072)
2025-12-13 02:09:03,482 INFO     Evaluating the model... (51000/59072)
2025-12-13 02:09:06,039 INFO     Evaluating the model... (51500/59072)
2025-12-13 02:09:08,565 INFO     Evaluating the model... (52000/59072)
2025-12-13 02:09:12,348 INFO     Evaluating the model... (52500/59072)
2025-12-13 02:09:14,924 INFO     Evaluating the model... (53000/59072)
2025-12-13 02:09:17,398 INFO     Evaluating the model... (53500/59072)
2025-12-13 02:09:19,979 INFO     Evaluating the model... (54000/59072)
2025-12-13 02:09:22,612 INFO     Evaluating the model... (54500/59072)
2025-12-13 02:09:26,309 INFO     Evaluating the model... (55000/59072)
2025-12-13 02:09:28,807 INFO     Evaluating the model... (55500/59072)
2025-12-13 02:09:31,350 INFO     Evaluating the model... (56000/59072)
2025-12-13 02:09:33,810 INFO     Evaluating the model... (56500/59072)
2025-12-13 02:09:36,726 INFO     Evaluating the model... (57000/59072)
2025-12-13 02:09:40,359 INFO     Evaluating the model... (57500/59072)
2025-12-13 02:09:43,177 INFO     Evaluating the model... (58000/59072)
2025-12-13 02:09:45,956 INFO     Evaluating the model... (58500/59072)
2025-12-13 02:09:48,641 INFO     Evaluating the model... (59000/59072)
2025-12-13 02:09:49,390 INFO     Test MRR at step 120000: 0.627915
2025-12-13 02:09:49,390 INFO     Test MR at step 120000: 268.401390
2025-12-13 02:09:49,390 INFO     Test HITS@1 at step 120000: 0.540180
2025-12-13 02:09:49,390 INFO     Test HITS@3 at step 120000: 0.682560
2025-12-13 02:09:49,390 INFO     Test HITS@10 at step 120000: 0.782541
2025-12-13 02:09:51,567 INFO     Training average regularization at step 120100: 0.302346
2025-12-13 02:09:51,567 INFO     Training average positive_sample_loss at step 120100: 0.066783
2025-12-13 02:09:51,567 INFO     Training average negative_sample_loss at step 120100: 0.107771
2025-12-13 02:09:51,567 INFO     Training average loss at step 120100: 0.389623
2025-12-13 02:09:53,755 INFO     Training average regularization at step 120200: 0.302346
2025-12-13 02:09:53,757 INFO     Training average positive_sample_loss at step 120200: 0.065601
2025-12-13 02:09:53,757 INFO     Training average negative_sample_loss at step 120200: 0.107877
2025-12-13 02:09:53,757 INFO     Training average loss at step 120200: 0.389084
2025-12-13 02:09:55,899 INFO     Training average regularization at step 120300: 0.302345
2025-12-13 02:09:55,899 INFO     Training average positive_sample_loss at step 120300: 0.066382
2025-12-13 02:09:55,899 INFO     Training average negative_sample_loss at step 120300: 0.108941
2025-12-13 02:09:55,899 INFO     Training average loss at step 120300: 0.390007
2025-12-13 02:09:58,074 INFO     Training average regularization at step 120400: 0.302345
2025-12-13 02:09:58,074 INFO     Training average positive_sample_loss at step 120400: 0.066925
2025-12-13 02:09:58,074 INFO     Training average negative_sample_loss at step 120400: 0.108752
2025-12-13 02:09:58,074 INFO     Training average loss at step 120400: 0.390183
2025-12-13 02:10:00,201 INFO     Training average regularization at step 120500: 0.302344
2025-12-13 02:10:00,203 INFO     Training average positive_sample_loss at step 120500: 0.066295
2025-12-13 02:10:00,203 INFO     Training average negative_sample_loss at step 120500: 0.110287
2025-12-13 02:10:00,203 INFO     Training average loss at step 120500: 0.390635
2025-12-13 02:10:02,352 INFO     Training average regularization at step 120600: 0.302343
2025-12-13 02:10:02,352 INFO     Training average positive_sample_loss at step 120600: 0.065456
2025-12-13 02:10:02,352 INFO     Training average negative_sample_loss at step 120600: 0.108365
2025-12-13 02:10:02,352 INFO     Training average loss at step 120600: 0.389254
2025-12-13 02:10:04,472 INFO     Training average regularization at step 120700: 0.302343
2025-12-13 02:10:04,472 INFO     Training average positive_sample_loss at step 120700: 0.066321
2025-12-13 02:10:04,472 INFO     Training average negative_sample_loss at step 120700: 0.115336
2025-12-13 02:10:04,472 INFO     Training average loss at step 120700: 0.393171
2025-12-13 02:10:06,733 INFO     Training average regularization at step 120800: 0.302342
2025-12-13 02:10:06,733 INFO     Training average positive_sample_loss at step 120800: 0.067475
2025-12-13 02:10:06,733 INFO     Training average negative_sample_loss at step 120800: 0.110107
2025-12-13 02:10:06,733 INFO     Training average loss at step 120800: 0.391133
2025-12-13 02:10:09,818 INFO     Training average regularization at step 120900: 0.302341
2025-12-13 02:10:09,819 INFO     Training average positive_sample_loss at step 120900: 0.066998
2025-12-13 02:10:09,819 INFO     Training average negative_sample_loss at step 120900: 0.110193
2025-12-13 02:10:09,819 INFO     Training average loss at step 120900: 0.390937
2025-12-13 02:10:11,986 INFO     Training average regularization at step 121000: 0.302340
2025-12-13 02:10:11,986 INFO     Training average positive_sample_loss at step 121000: 0.066510
2025-12-13 02:10:11,986 INFO     Training average negative_sample_loss at step 121000: 0.108190
2025-12-13 02:10:11,986 INFO     Training average loss at step 121000: 0.389691
2025-12-13 02:10:14,159 INFO     Training average regularization at step 121100: 0.302340
2025-12-13 02:10:14,160 INFO     Training average positive_sample_loss at step 121100: 0.066859
2025-12-13 02:10:14,160 INFO     Training average negative_sample_loss at step 121100: 0.108319
2025-12-13 02:10:14,160 INFO     Training average loss at step 121100: 0.389929
2025-12-13 02:10:16,320 INFO     Training average regularization at step 121200: 0.302339
2025-12-13 02:10:16,321 INFO     Training average positive_sample_loss at step 121200: 0.067158
2025-12-13 02:10:16,321 INFO     Training average negative_sample_loss at step 121200: 0.108590
2025-12-13 02:10:16,321 INFO     Training average loss at step 121200: 0.390213
2025-12-13 02:10:18,463 INFO     Training average regularization at step 121300: 0.302338
2025-12-13 02:10:18,463 INFO     Training average positive_sample_loss at step 121300: 0.065676
2025-12-13 02:10:18,463 INFO     Training average negative_sample_loss at step 121300: 0.108595
2025-12-13 02:10:18,463 INFO     Training average loss at step 121300: 0.389474
2025-12-13 02:10:20,602 INFO     Training average regularization at step 121400: 0.302337
2025-12-13 02:10:20,602 INFO     Training average positive_sample_loss at step 121400: 0.065405
2025-12-13 02:10:20,603 INFO     Training average negative_sample_loss at step 121400: 0.107501
2025-12-13 02:10:20,603 INFO     Training average loss at step 121400: 0.388791
2025-12-13 02:10:22,734 INFO     Training average regularization at step 121500: 0.302337
2025-12-13 02:10:22,734 INFO     Training average positive_sample_loss at step 121500: 0.067249
2025-12-13 02:10:22,734 INFO     Training average negative_sample_loss at step 121500: 0.108595
2025-12-13 02:10:22,734 INFO     Training average loss at step 121500: 0.390259
2025-12-13 02:10:24,836 INFO     Training average regularization at step 121600: 0.302336
2025-12-13 02:10:24,836 INFO     Training average positive_sample_loss at step 121600: 0.065930
2025-12-13 02:10:24,836 INFO     Training average negative_sample_loss at step 121600: 0.109170
2025-12-13 02:10:24,836 INFO     Training average loss at step 121600: 0.389886
2025-12-13 02:10:26,956 INFO     Training average regularization at step 121700: 0.302335
2025-12-13 02:10:26,956 INFO     Training average positive_sample_loss at step 121700: 0.067095
2025-12-13 02:10:26,956 INFO     Training average negative_sample_loss at step 121700: 0.105978
2025-12-13 02:10:26,956 INFO     Training average loss at step 121700: 0.388872
2025-12-13 02:10:29,055 INFO     Training average regularization at step 121800: 0.302335
2025-12-13 02:10:29,055 INFO     Training average positive_sample_loss at step 121800: 0.067244
2025-12-13 02:10:29,055 INFO     Training average negative_sample_loss at step 121800: 0.107144
2025-12-13 02:10:29,055 INFO     Training average loss at step 121800: 0.389528
2025-12-13 02:10:31,182 INFO     Training average regularization at step 121900: 0.302334
2025-12-13 02:10:31,182 INFO     Training average positive_sample_loss at step 121900: 0.066836
2025-12-13 02:10:31,182 INFO     Training average negative_sample_loss at step 121900: 0.108001
2025-12-13 02:10:31,182 INFO     Training average loss at step 121900: 0.389752
2025-12-13 02:10:33,302 INFO     Training average regularization at step 122000: 0.302334
2025-12-13 02:10:33,303 INFO     Training average positive_sample_loss at step 122000: 0.065874
2025-12-13 02:10:33,303 INFO     Training average negative_sample_loss at step 122000: 0.107903
2025-12-13 02:10:33,303 INFO     Training average loss at step 122000: 0.389222
2025-12-13 02:10:35,442 INFO     Training average regularization at step 122100: 0.302333
2025-12-13 02:10:35,442 INFO     Training average positive_sample_loss at step 122100: 0.066420
2025-12-13 02:10:35,442 INFO     Training average negative_sample_loss at step 122100: 0.107966
2025-12-13 02:10:35,442 INFO     Training average loss at step 122100: 0.389526
2025-12-13 02:10:37,635 INFO     Training average regularization at step 122200: 0.302332
2025-12-13 02:10:37,636 INFO     Training average positive_sample_loss at step 122200: 0.066912
2025-12-13 02:10:37,636 INFO     Training average negative_sample_loss at step 122200: 0.108782
2025-12-13 02:10:37,636 INFO     Training average loss at step 122200: 0.390179
2025-12-13 02:10:39,787 INFO     Training average regularization at step 122300: 0.302332
2025-12-13 02:10:39,787 INFO     Training average positive_sample_loss at step 122300: 0.066629
2025-12-13 02:10:39,787 INFO     Training average negative_sample_loss at step 122300: 0.106862
2025-12-13 02:10:39,787 INFO     Training average loss at step 122300: 0.389077
2025-12-13 02:10:41,979 INFO     Training average regularization at step 122400: 0.302331
2025-12-13 02:10:41,979 INFO     Training average positive_sample_loss at step 122400: 0.067513
2025-12-13 02:10:41,979 INFO     Training average negative_sample_loss at step 122400: 0.109653
2025-12-13 02:10:41,980 INFO     Training average loss at step 122400: 0.390914
2025-12-13 02:10:44,157 INFO     Training average regularization at step 122500: 0.302330
2025-12-13 02:10:44,157 INFO     Training average positive_sample_loss at step 122500: 0.068124
2025-12-13 02:10:44,157 INFO     Training average negative_sample_loss at step 122500: 0.112499
2025-12-13 02:10:44,157 INFO     Training average loss at step 122500: 0.392642
2025-12-13 02:10:46,349 INFO     Training average regularization at step 122600: 0.302330
2025-12-13 02:10:46,349 INFO     Training average positive_sample_loss at step 122600: 0.067325
2025-12-13 02:10:46,349 INFO     Training average negative_sample_loss at step 122600: 0.111786
2025-12-13 02:10:46,349 INFO     Training average loss at step 122600: 0.391885
2025-12-13 02:10:48,503 INFO     Training average regularization at step 122700: 0.302329
2025-12-13 02:10:48,503 INFO     Training average positive_sample_loss at step 122700: 0.065896
2025-12-13 02:10:48,503 INFO     Training average negative_sample_loss at step 122700: 0.106155
2025-12-13 02:10:48,503 INFO     Training average loss at step 122700: 0.388354
2025-12-13 02:10:50,652 INFO     Training average regularization at step 122800: 0.302328
2025-12-13 02:10:50,712 INFO     Training average positive_sample_loss at step 122800: 0.065718
2025-12-13 02:10:50,712 INFO     Training average negative_sample_loss at step 122800: 0.107923
2025-12-13 02:10:50,712 INFO     Training average loss at step 122800: 0.389149
2025-12-13 02:10:52,878 INFO     Training average regularization at step 122900: 0.302328
2025-12-13 02:10:52,878 INFO     Training average positive_sample_loss at step 122900: 0.066648
2025-12-13 02:10:52,878 INFO     Training average negative_sample_loss at step 122900: 0.107983
2025-12-13 02:10:52,878 INFO     Training average loss at step 122900: 0.389643
2025-12-13 02:10:55,016 INFO     Training average regularization at step 123000: 0.302327
2025-12-13 02:10:55,016 INFO     Training average positive_sample_loss at step 123000: 0.066857
2025-12-13 02:10:55,016 INFO     Training average negative_sample_loss at step 123000: 0.109365
2025-12-13 02:10:55,016 INFO     Training average loss at step 123000: 0.390438
2025-12-13 02:10:57,177 INFO     Training average regularization at step 123100: 0.302326
2025-12-13 02:10:57,178 INFO     Training average positive_sample_loss at step 123100: 0.066473
2025-12-13 02:10:57,178 INFO     Training average negative_sample_loss at step 123100: 0.109001
2025-12-13 02:10:57,178 INFO     Training average loss at step 123100: 0.390063
2025-12-13 02:10:59,355 INFO     Training average regularization at step 123200: 0.302325
2025-12-13 02:10:59,355 INFO     Training average positive_sample_loss at step 123200: 0.066541
2025-12-13 02:10:59,355 INFO     Training average negative_sample_loss at step 123200: 0.109471
2025-12-13 02:10:59,355 INFO     Training average loss at step 123200: 0.390332
2025-12-13 02:11:01,513 INFO     Training average regularization at step 123300: 0.302325
2025-12-13 02:11:01,514 INFO     Training average positive_sample_loss at step 123300: 0.067434
2025-12-13 02:11:01,514 INFO     Training average negative_sample_loss at step 123300: 0.108970
2025-12-13 02:11:01,514 INFO     Training average loss at step 123300: 0.390527
2025-12-13 02:11:03,662 INFO     Training average regularization at step 123400: 0.302324
2025-12-13 02:11:03,662 INFO     Training average positive_sample_loss at step 123400: 0.066894
2025-12-13 02:11:03,662 INFO     Training average negative_sample_loss at step 123400: 0.108404
2025-12-13 02:11:03,662 INFO     Training average loss at step 123400: 0.389973
2025-12-13 02:11:05,845 INFO     Training average regularization at step 123500: 0.302324
2025-12-13 02:11:05,846 INFO     Training average positive_sample_loss at step 123500: 0.066328
2025-12-13 02:11:05,846 INFO     Training average negative_sample_loss at step 123500: 0.108044
2025-12-13 02:11:05,846 INFO     Training average loss at step 123500: 0.389510
2025-12-13 02:11:08,038 INFO     Training average regularization at step 123600: 0.302323
2025-12-13 02:11:08,038 INFO     Training average positive_sample_loss at step 123600: 0.066369
2025-12-13 02:11:08,038 INFO     Training average negative_sample_loss at step 123600: 0.109229
2025-12-13 02:11:08,038 INFO     Training average loss at step 123600: 0.390122
2025-12-13 02:11:10,182 INFO     Training average regularization at step 123700: 0.302322
2025-12-13 02:11:10,182 INFO     Training average positive_sample_loss at step 123700: 0.065418
2025-12-13 02:11:10,182 INFO     Training average negative_sample_loss at step 123700: 0.110525
2025-12-13 02:11:10,182 INFO     Training average loss at step 123700: 0.390294
2025-12-13 02:11:12,335 INFO     Training average regularization at step 123800: 0.302322
2025-12-13 02:11:12,335 INFO     Training average positive_sample_loss at step 123800: 0.067410
2025-12-13 02:11:12,335 INFO     Training average negative_sample_loss at step 123800: 0.109212
2025-12-13 02:11:12,336 INFO     Training average loss at step 123800: 0.390632
2025-12-13 02:11:14,464 INFO     Training average regularization at step 123900: 0.302321
2025-12-13 02:11:14,464 INFO     Training average positive_sample_loss at step 123900: 0.067221
2025-12-13 02:11:14,464 INFO     Training average negative_sample_loss at step 123900: 0.110093
2025-12-13 02:11:14,464 INFO     Training average loss at step 123900: 0.390978
2025-12-13 02:11:16,615 INFO     Training average regularization at step 124000: 0.302321
2025-12-13 02:11:16,615 INFO     Training average positive_sample_loss at step 124000: 0.066282
2025-12-13 02:11:16,615 INFO     Training average negative_sample_loss at step 124000: 0.109861
2025-12-13 02:11:16,615 INFO     Training average loss at step 124000: 0.390392
2025-12-13 02:11:18,770 INFO     Training average regularization at step 124100: 0.302320
2025-12-13 02:11:18,770 INFO     Training average positive_sample_loss at step 124100: 0.067420
2025-12-13 02:11:18,770 INFO     Training average negative_sample_loss at step 124100: 0.109463
2025-12-13 02:11:18,770 INFO     Training average loss at step 124100: 0.390762
2025-12-13 02:11:20,886 INFO     Training average regularization at step 124200: 0.302319
2025-12-13 02:11:20,887 INFO     Training average positive_sample_loss at step 124200: 0.067285
2025-12-13 02:11:20,887 INFO     Training average negative_sample_loss at step 124200: 0.118397
2025-12-13 02:11:20,887 INFO     Training average loss at step 124200: 0.395160
2025-12-13 02:11:23,014 INFO     Training average regularization at step 124300: 0.302319
2025-12-13 02:11:23,014 INFO     Training average positive_sample_loss at step 124300: 0.067660
2025-12-13 02:11:23,014 INFO     Training average negative_sample_loss at step 124300: 0.109980
2025-12-13 02:11:23,014 INFO     Training average loss at step 124300: 0.391139
2025-12-13 02:11:25,136 INFO     Training average regularization at step 124400: 0.302318
2025-12-13 02:11:25,136 INFO     Training average positive_sample_loss at step 124400: 0.067607
2025-12-13 02:11:25,136 INFO     Training average negative_sample_loss at step 124400: 0.110363
2025-12-13 02:11:25,136 INFO     Training average loss at step 124400: 0.391303
2025-12-13 02:11:27,296 INFO     Training average regularization at step 124500: 0.302318
2025-12-13 02:11:27,297 INFO     Training average positive_sample_loss at step 124500: 0.066473
2025-12-13 02:11:27,297 INFO     Training average negative_sample_loss at step 124500: 0.109543
2025-12-13 02:11:27,297 INFO     Training average loss at step 124500: 0.390326
2025-12-13 02:11:29,421 INFO     Training average regularization at step 124600: 0.302317
2025-12-13 02:11:29,421 INFO     Training average positive_sample_loss at step 124600: 0.066964
2025-12-13 02:11:29,421 INFO     Training average negative_sample_loss at step 124600: 0.108541
2025-12-13 02:11:29,421 INFO     Training average loss at step 124600: 0.390070
2025-12-13 02:11:31,539 INFO     Training average regularization at step 124700: 0.302317
2025-12-13 02:11:31,539 INFO     Training average positive_sample_loss at step 124700: 0.066567
2025-12-13 02:11:31,539 INFO     Training average negative_sample_loss at step 124700: 0.108796
2025-12-13 02:11:31,539 INFO     Training average loss at step 124700: 0.389998
2025-12-13 02:11:33,681 INFO     Training average regularization at step 124800: 0.302316
2025-12-13 02:11:33,681 INFO     Training average positive_sample_loss at step 124800: 0.067585
2025-12-13 02:11:33,681 INFO     Training average negative_sample_loss at step 124800: 0.110829
2025-12-13 02:11:33,681 INFO     Training average loss at step 124800: 0.391523
2025-12-13 02:11:35,814 INFO     Training average regularization at step 124900: 0.302315
2025-12-13 02:11:35,814 INFO     Training average positive_sample_loss at step 124900: 0.065870
2025-12-13 02:11:35,814 INFO     Training average negative_sample_loss at step 124900: 0.108385
2025-12-13 02:11:35,814 INFO     Training average loss at step 124900: 0.389443
2025-12-13 02:11:37,984 INFO     Training average regularization at step 125000: 0.302315
2025-12-13 02:11:37,984 INFO     Training average positive_sample_loss at step 125000: 0.066135
2025-12-13 02:11:37,984 INFO     Training average negative_sample_loss at step 125000: 0.109100
2025-12-13 02:11:37,984 INFO     Training average loss at step 125000: 0.389932
2025-12-13 02:11:40,112 INFO     Training average regularization at step 125100: 0.302314
2025-12-13 02:11:40,112 INFO     Training average positive_sample_loss at step 125100: 0.067057
2025-12-13 02:11:40,112 INFO     Training average negative_sample_loss at step 125100: 0.107557
2025-12-13 02:11:40,112 INFO     Training average loss at step 125100: 0.389621
2025-12-13 02:11:42,264 INFO     Training average regularization at step 125200: 0.302314
2025-12-13 02:11:42,264 INFO     Training average positive_sample_loss at step 125200: 0.066859
2025-12-13 02:11:42,264 INFO     Training average negative_sample_loss at step 125200: 0.108935
2025-12-13 02:11:42,264 INFO     Training average loss at step 125200: 0.390211
2025-12-13 02:11:44,385 INFO     Training average regularization at step 125300: 0.302313
2025-12-13 02:11:44,385 INFO     Training average positive_sample_loss at step 125300: 0.067190
2025-12-13 02:11:44,385 INFO     Training average negative_sample_loss at step 125300: 0.107587
2025-12-13 02:11:44,385 INFO     Training average loss at step 125300: 0.389702
2025-12-13 02:11:46,527 INFO     Training average regularization at step 125400: 0.302313
2025-12-13 02:11:46,528 INFO     Training average positive_sample_loss at step 125400: 0.066429
2025-12-13 02:11:46,528 INFO     Training average negative_sample_loss at step 125400: 0.110303
2025-12-13 02:11:46,528 INFO     Training average loss at step 125400: 0.390679
2025-12-13 02:11:48,661 INFO     Training average regularization at step 125500: 0.302312
2025-12-13 02:11:48,661 INFO     Training average positive_sample_loss at step 125500: 0.068039
2025-12-13 02:11:48,661 INFO     Training average negative_sample_loss at step 125500: 0.108679
2025-12-13 02:11:48,661 INFO     Training average loss at step 125500: 0.390671
2025-12-13 02:11:50,774 INFO     Training average regularization at step 125600: 0.302312
2025-12-13 02:11:50,775 INFO     Training average positive_sample_loss at step 125600: 0.067161
2025-12-13 02:11:50,775 INFO     Training average negative_sample_loss at step 125600: 0.108920
2025-12-13 02:11:50,775 INFO     Training average loss at step 125600: 0.390352
2025-12-13 02:11:53,879 INFO     Training average regularization at step 125700: 0.302311
2025-12-13 02:11:53,879 INFO     Training average positive_sample_loss at step 125700: 0.066117
2025-12-13 02:11:53,879 INFO     Training average negative_sample_loss at step 125700: 0.110794
2025-12-13 02:11:53,879 INFO     Training average loss at step 125700: 0.390766
2025-12-13 02:11:56,029 INFO     Training average regularization at step 125800: 0.302310
2025-12-13 02:11:56,036 INFO     Training average positive_sample_loss at step 125800: 0.067849
2025-12-13 02:11:56,036 INFO     Training average negative_sample_loss at step 125800: 0.108405
2025-12-13 02:11:56,036 INFO     Training average loss at step 125800: 0.390437
2025-12-13 02:11:58,144 INFO     Training average regularization at step 125900: 0.302310
2025-12-13 02:11:58,144 INFO     Training average positive_sample_loss at step 125900: 0.067099
2025-12-13 02:11:58,144 INFO     Training average negative_sample_loss at step 125900: 0.111184
2025-12-13 02:11:58,144 INFO     Training average loss at step 125900: 0.391451
2025-12-13 02:12:00,287 INFO     Training average regularization at step 126000: 0.302309
2025-12-13 02:12:00,287 INFO     Training average positive_sample_loss at step 126000: 0.068101
2025-12-13 02:12:00,287 INFO     Training average negative_sample_loss at step 126000: 0.109957
2025-12-13 02:12:00,287 INFO     Training average loss at step 126000: 0.391338
2025-12-13 02:12:02,386 INFO     Training average regularization at step 126100: 0.302308
2025-12-13 02:12:02,386 INFO     Training average positive_sample_loss at step 126100: 0.067107
2025-12-13 02:12:02,387 INFO     Training average negative_sample_loss at step 126100: 0.108799
2025-12-13 02:12:02,387 INFO     Training average loss at step 126100: 0.390262
2025-12-13 02:12:04,495 INFO     Training average regularization at step 126200: 0.302308
2025-12-13 02:12:04,495 INFO     Training average positive_sample_loss at step 126200: 0.068096
2025-12-13 02:12:04,495 INFO     Training average negative_sample_loss at step 126200: 0.110551
2025-12-13 02:12:04,495 INFO     Training average loss at step 126200: 0.391631
2025-12-13 02:12:06,610 INFO     Training average regularization at step 126300: 0.302307
2025-12-13 02:12:06,610 INFO     Training average positive_sample_loss at step 126300: 0.066203
2025-12-13 02:12:06,610 INFO     Training average negative_sample_loss at step 126300: 0.109237
2025-12-13 02:12:06,610 INFO     Training average loss at step 126300: 0.390027
2025-12-13 02:12:08,717 INFO     Training average regularization at step 126400: 0.302306
2025-12-13 02:12:08,717 INFO     Training average positive_sample_loss at step 126400: 0.065465
2025-12-13 02:12:08,717 INFO     Training average negative_sample_loss at step 126400: 0.106520
2025-12-13 02:12:08,717 INFO     Training average loss at step 126400: 0.388299
2025-12-13 02:12:10,866 INFO     Training average regularization at step 126500: 0.302305
2025-12-13 02:12:10,866 INFO     Training average positive_sample_loss at step 126500: 0.066505
2025-12-13 02:12:10,866 INFO     Training average negative_sample_loss at step 126500: 0.110636
2025-12-13 02:12:10,866 INFO     Training average loss at step 126500: 0.390876
2025-12-13 02:12:12,945 INFO     Training average regularization at step 126600: 0.302305
2025-12-13 02:12:12,946 INFO     Training average positive_sample_loss at step 126600: 0.065874
2025-12-13 02:12:12,946 INFO     Training average negative_sample_loss at step 126600: 0.106299
2025-12-13 02:12:12,946 INFO     Training average loss at step 126600: 0.388391
2025-12-13 02:12:15,055 INFO     Training average regularization at step 126700: 0.302304
2025-12-13 02:12:15,055 INFO     Training average positive_sample_loss at step 126700: 0.066496
2025-12-13 02:12:15,055 INFO     Training average negative_sample_loss at step 126700: 0.107107
2025-12-13 02:12:15,056 INFO     Training average loss at step 126700: 0.389105
2025-12-13 02:12:17,149 INFO     Training average regularization at step 126800: 0.302303
2025-12-13 02:12:17,149 INFO     Training average positive_sample_loss at step 126800: 0.066401
2025-12-13 02:12:17,149 INFO     Training average negative_sample_loss at step 126800: 0.106197
2025-12-13 02:12:17,149 INFO     Training average loss at step 126800: 0.388602
2025-12-13 02:12:19,246 INFO     Training average regularization at step 126900: 0.302303
2025-12-13 02:12:19,246 INFO     Training average positive_sample_loss at step 126900: 0.067091
2025-12-13 02:12:19,247 INFO     Training average negative_sample_loss at step 126900: 0.108510
2025-12-13 02:12:19,247 INFO     Training average loss at step 126900: 0.390103
2025-12-13 02:12:21,372 INFO     Training average regularization at step 127000: 0.302302
2025-12-13 02:12:21,372 INFO     Training average positive_sample_loss at step 127000: 0.066608
2025-12-13 02:12:21,372 INFO     Training average negative_sample_loss at step 127000: 0.109163
2025-12-13 02:12:21,372 INFO     Training average loss at step 127000: 0.390188
2025-12-13 02:12:23,464 INFO     Training average regularization at step 127100: 0.302301
2025-12-13 02:12:23,465 INFO     Training average positive_sample_loss at step 127100: 0.066719
2025-12-13 02:12:23,465 INFO     Training average negative_sample_loss at step 127100: 0.106523
2025-12-13 02:12:23,465 INFO     Training average loss at step 127100: 0.388922
2025-12-13 02:12:25,616 INFO     Training average regularization at step 127200: 0.302301
2025-12-13 02:12:25,617 INFO     Training average positive_sample_loss at step 127200: 0.066441
2025-12-13 02:12:25,617 INFO     Training average negative_sample_loss at step 127200: 0.108574
2025-12-13 02:12:25,617 INFO     Training average loss at step 127200: 0.389809
2025-12-13 02:12:27,732 INFO     Training average regularization at step 127300: 0.302300
2025-12-13 02:12:27,733 INFO     Training average positive_sample_loss at step 127300: 0.066961
2025-12-13 02:12:27,733 INFO     Training average negative_sample_loss at step 127300: 0.109523
2025-12-13 02:12:27,733 INFO     Training average loss at step 127300: 0.390543
2025-12-13 02:12:29,818 INFO     Training average regularization at step 127400: 0.302299
2025-12-13 02:12:29,818 INFO     Training average positive_sample_loss at step 127400: 0.065700
2025-12-13 02:12:29,818 INFO     Training average negative_sample_loss at step 127400: 0.106737
2025-12-13 02:12:29,818 INFO     Training average loss at step 127400: 0.388518
2025-12-13 02:12:31,949 INFO     Training average regularization at step 127500: 0.302299
2025-12-13 02:12:31,949 INFO     Training average positive_sample_loss at step 127500: 0.067610
2025-12-13 02:12:31,949 INFO     Training average negative_sample_loss at step 127500: 0.108265
2025-12-13 02:12:31,950 INFO     Training average loss at step 127500: 0.390236
2025-12-13 02:12:34,085 INFO     Training average regularization at step 127600: 0.302298
2025-12-13 02:12:34,085 INFO     Training average positive_sample_loss at step 127600: 0.067153
2025-12-13 02:12:34,085 INFO     Training average negative_sample_loss at step 127600: 0.110711
2025-12-13 02:12:34,085 INFO     Training average loss at step 127600: 0.391230
2025-12-13 02:12:36,263 INFO     Training average regularization at step 127700: 0.302297
2025-12-13 02:12:36,263 INFO     Training average positive_sample_loss at step 127700: 0.066119
2025-12-13 02:12:36,263 INFO     Training average negative_sample_loss at step 127700: 0.107104
2025-12-13 02:12:36,263 INFO     Training average loss at step 127700: 0.388909
2025-12-13 02:12:38,429 INFO     Training average regularization at step 127800: 0.302297
2025-12-13 02:12:38,434 INFO     Training average positive_sample_loss at step 127800: 0.066624
2025-12-13 02:12:38,434 INFO     Training average negative_sample_loss at step 127800: 0.108884
2025-12-13 02:12:38,434 INFO     Training average loss at step 127800: 0.390051
2025-12-13 02:12:40,566 INFO     Training average regularization at step 127900: 0.302296
2025-12-13 02:12:40,566 INFO     Training average positive_sample_loss at step 127900: 0.066478
2025-12-13 02:12:40,566 INFO     Training average negative_sample_loss at step 127900: 0.110145
2025-12-13 02:12:40,566 INFO     Training average loss at step 127900: 0.390607
2025-12-13 02:12:42,724 INFO     Training average regularization at step 128000: 0.302295
2025-12-13 02:12:42,724 INFO     Training average positive_sample_loss at step 128000: 0.065739
2025-12-13 02:12:42,724 INFO     Training average negative_sample_loss at step 128000: 0.109943
2025-12-13 02:12:42,724 INFO     Training average loss at step 128000: 0.390137
2025-12-13 02:12:44,871 INFO     Training average regularization at step 128100: 0.302295
2025-12-13 02:12:44,871 INFO     Training average positive_sample_loss at step 128100: 0.067948
2025-12-13 02:12:44,871 INFO     Training average negative_sample_loss at step 128100: 0.110973
2025-12-13 02:12:44,871 INFO     Training average loss at step 128100: 0.391756
2025-12-13 02:12:46,967 INFO     Training average regularization at step 128200: 0.302294
2025-12-13 02:12:46,967 INFO     Training average positive_sample_loss at step 128200: 0.066634
2025-12-13 02:12:46,967 INFO     Training average negative_sample_loss at step 128200: 0.109864
2025-12-13 02:12:46,967 INFO     Training average loss at step 128200: 0.390543
2025-12-13 02:12:49,054 INFO     Training average regularization at step 128300: 0.302294
2025-12-13 02:12:49,055 INFO     Training average positive_sample_loss at step 128300: 0.066009
2025-12-13 02:12:49,055 INFO     Training average negative_sample_loss at step 128300: 0.108234
2025-12-13 02:12:49,055 INFO     Training average loss at step 128300: 0.389415
2025-12-13 02:12:51,164 INFO     Training average regularization at step 128400: 0.302293
2025-12-13 02:12:51,164 INFO     Training average positive_sample_loss at step 128400: 0.066825
2025-12-13 02:12:51,164 INFO     Training average negative_sample_loss at step 128400: 0.106815
2025-12-13 02:12:51,164 INFO     Training average loss at step 128400: 0.389113
2025-12-13 02:12:53,248 INFO     Training average regularization at step 128500: 0.302292
2025-12-13 02:12:53,248 INFO     Training average positive_sample_loss at step 128500: 0.065247
2025-12-13 02:12:53,248 INFO     Training average negative_sample_loss at step 128500: 0.107427
2025-12-13 02:12:53,248 INFO     Training average loss at step 128500: 0.388630
2025-12-13 02:12:55,400 INFO     Training average regularization at step 128600: 0.302292
2025-12-13 02:12:55,401 INFO     Training average positive_sample_loss at step 128600: 0.065525
2025-12-13 02:12:55,401 INFO     Training average negative_sample_loss at step 128600: 0.106512
2025-12-13 02:12:55,401 INFO     Training average loss at step 128600: 0.388310
2025-12-13 02:12:57,487 INFO     Training average regularization at step 128700: 0.302291
2025-12-13 02:12:57,487 INFO     Training average positive_sample_loss at step 128700: 0.066149
2025-12-13 02:12:57,487 INFO     Training average negative_sample_loss at step 128700: 0.110374
2025-12-13 02:12:57,487 INFO     Training average loss at step 128700: 0.390553
2025-12-13 02:12:59,578 INFO     Training average regularization at step 128800: 0.302290
2025-12-13 02:12:59,578 INFO     Training average positive_sample_loss at step 128800: 0.066048
2025-12-13 02:12:59,578 INFO     Training average negative_sample_loss at step 128800: 0.108635
2025-12-13 02:12:59,578 INFO     Training average loss at step 128800: 0.389632
2025-12-13 02:13:01,668 INFO     Training average regularization at step 128900: 0.302290
2025-12-13 02:13:01,668 INFO     Training average positive_sample_loss at step 128900: 0.067864
2025-12-13 02:13:01,668 INFO     Training average negative_sample_loss at step 128900: 0.110287
2025-12-13 02:13:01,668 INFO     Training average loss at step 128900: 0.391365
2025-12-13 02:13:03,753 INFO     Training average regularization at step 129000: 0.302289
2025-12-13 02:13:03,754 INFO     Training average positive_sample_loss at step 129000: 0.067146
2025-12-13 02:13:03,754 INFO     Training average negative_sample_loss at step 129000: 0.108646
2025-12-13 02:13:03,754 INFO     Training average loss at step 129000: 0.390185
2025-12-13 02:13:05,940 INFO     Training average regularization at step 129100: 0.302289
2025-12-13 02:13:05,940 INFO     Training average positive_sample_loss at step 129100: 0.066535
2025-12-13 02:13:05,940 INFO     Training average negative_sample_loss at step 129100: 0.108179
2025-12-13 02:13:05,940 INFO     Training average loss at step 129100: 0.389646
2025-12-13 02:13:08,114 INFO     Training average regularization at step 129200: 0.302288
2025-12-13 02:13:08,114 INFO     Training average positive_sample_loss at step 129200: 0.066711
2025-12-13 02:13:08,114 INFO     Training average negative_sample_loss at step 129200: 0.107890
2025-12-13 02:13:08,114 INFO     Training average loss at step 129200: 0.389589
2025-12-13 02:13:10,223 INFO     Training average regularization at step 129300: 0.302287
2025-12-13 02:13:10,223 INFO     Training average positive_sample_loss at step 129300: 0.066538
2025-12-13 02:13:10,223 INFO     Training average negative_sample_loss at step 129300: 0.108311
2025-12-13 02:13:10,223 INFO     Training average loss at step 129300: 0.389711
2025-12-13 02:13:12,314 INFO     Training average regularization at step 129400: 0.302287
2025-12-13 02:13:12,314 INFO     Training average positive_sample_loss at step 129400: 0.067815
2025-12-13 02:13:12,314 INFO     Training average negative_sample_loss at step 129400: 0.109078
2025-12-13 02:13:12,314 INFO     Training average loss at step 129400: 0.390733
2025-12-13 02:13:14,414 INFO     Training average regularization at step 129500: 0.302286
2025-12-13 02:13:14,414 INFO     Training average positive_sample_loss at step 129500: 0.066382
2025-12-13 02:13:14,414 INFO     Training average negative_sample_loss at step 129500: 0.109404
2025-12-13 02:13:14,414 INFO     Training average loss at step 129500: 0.390179
2025-12-13 02:13:16,599 INFO     Training average regularization at step 129600: 0.302286
2025-12-13 02:13:16,599 INFO     Training average positive_sample_loss at step 129600: 0.066325
2025-12-13 02:13:16,599 INFO     Training average negative_sample_loss at step 129600: 0.107249
2025-12-13 02:13:16,599 INFO     Training average loss at step 129600: 0.389073
2025-12-13 02:13:18,738 INFO     Training average regularization at step 129700: 0.302285
2025-12-13 02:13:18,738 INFO     Training average positive_sample_loss at step 129700: 0.066333
2025-12-13 02:13:18,738 INFO     Training average negative_sample_loss at step 129700: 0.108696
2025-12-13 02:13:18,738 INFO     Training average loss at step 129700: 0.389800
2025-12-13 02:13:20,843 INFO     Training average regularization at step 129800: 0.302285
2025-12-13 02:13:20,844 INFO     Training average positive_sample_loss at step 129800: 0.066862
2025-12-13 02:13:20,844 INFO     Training average negative_sample_loss at step 129800: 0.110625
2025-12-13 02:13:20,844 INFO     Training average loss at step 129800: 0.391028
2025-12-13 02:13:22,950 INFO     Training average regularization at step 129900: 0.302284
2025-12-13 02:13:22,951 INFO     Training average positive_sample_loss at step 129900: 0.068041
2025-12-13 02:13:22,951 INFO     Training average negative_sample_loss at step 129900: 0.109892
2025-12-13 02:13:22,951 INFO     Training average loss at step 129900: 0.391251
2025-12-13 02:13:25,058 INFO     Training average regularization at step 130000: 0.302284
2025-12-13 02:13:25,058 INFO     Training average positive_sample_loss at step 130000: 0.067490
2025-12-13 02:13:25,058 INFO     Training average negative_sample_loss at step 130000: 0.106921
2025-12-13 02:13:25,058 INFO     Training average loss at step 130000: 0.389489
2025-12-13 02:13:25,058 INFO     Evaluating on Valid Dataset...
2025-12-13 02:13:25,664 INFO     Evaluating the model... (0/50000)
2025-12-13 02:13:29,052 INFO     Evaluating the model... (500/50000)
2025-12-13 02:13:31,657 INFO     Evaluating the model... (1000/50000)
2025-12-13 02:13:34,222 INFO     Evaluating the model... (1500/50000)
2025-12-13 02:13:37,028 INFO     Evaluating the model... (2000/50000)
2025-12-13 02:13:40,101 INFO     Evaluating the model... (2500/50000)
2025-12-13 02:13:43,647 INFO     Evaluating the model... (3000/50000)
2025-12-13 02:13:46,170 INFO     Evaluating the model... (3500/50000)
2025-12-13 02:13:48,687 INFO     Evaluating the model... (4000/50000)
2025-12-13 02:13:51,298 INFO     Evaluating the model... (4500/50000)
2025-12-13 02:13:53,697 INFO     Evaluating the model... (5000/50000)
2025-12-13 02:13:56,760 INFO     Evaluating the model... (5500/50000)
2025-12-13 02:13:59,192 INFO     Evaluating the model... (6000/50000)
2025-12-13 02:14:01,790 INFO     Evaluating the model... (6500/50000)
2025-12-13 02:14:04,352 INFO     Evaluating the model... (7000/50000)
2025-12-13 02:14:06,821 INFO     Evaluating the model... (7500/50000)
2025-12-13 02:14:09,644 INFO     Evaluating the model... (8000/50000)
2025-12-13 02:14:12,019 INFO     Evaluating the model... (8500/50000)
2025-12-13 02:14:14,748 INFO     Evaluating the model... (9000/50000)
2025-12-13 02:14:17,208 INFO     Evaluating the model... (9500/50000)
2025-12-13 02:14:19,675 INFO     Evaluating the model... (10000/50000)
2025-12-13 02:14:22,334 INFO     Evaluating the model... (10500/50000)
2025-12-13 02:14:24,920 INFO     Evaluating the model... (11000/50000)
2025-12-13 02:14:27,511 INFO     Evaluating the model... (11500/50000)
2025-12-13 02:14:29,961 INFO     Evaluating the model... (12000/50000)
2025-12-13 02:14:32,314 INFO     Evaluating the model... (12500/50000)
2025-12-13 02:14:35,404 INFO     Evaluating the model... (13000/50000)
2025-12-13 02:14:38,267 INFO     Evaluating the model... (13500/50000)
2025-12-13 02:14:40,888 INFO     Evaluating the model... (14000/50000)
2025-12-13 02:14:43,456 INFO     Evaluating the model... (14500/50000)
2025-12-13 02:14:46,453 INFO     Evaluating the model... (15000/50000)
2025-12-13 02:14:49,133 INFO     Evaluating the model... (15500/50000)
2025-12-13 02:14:51,504 INFO     Evaluating the model... (16000/50000)
2025-12-13 02:14:53,807 INFO     Evaluating the model... (16500/50000)
2025-12-13 02:14:56,237 INFO     Evaluating the model... (17000/50000)
2025-12-13 02:14:59,286 INFO     Evaluating the model... (17500/50000)
2025-12-13 02:15:01,821 INFO     Evaluating the model... (18000/50000)
2025-12-13 02:15:04,355 INFO     Evaluating the model... (18500/50000)
2025-12-13 02:15:06,934 INFO     Evaluating the model... (19000/50000)
2025-12-13 02:15:09,409 INFO     Evaluating the model... (19500/50000)
2025-12-13 02:15:12,803 INFO     Evaluating the model... (20000/50000)
2025-12-13 02:15:15,182 INFO     Evaluating the model... (20500/50000)
2025-12-13 02:15:17,798 INFO     Evaluating the model... (21000/50000)
2025-12-13 02:15:20,279 INFO     Evaluating the model... (21500/50000)
2025-12-13 02:15:22,827 INFO     Evaluating the model... (22000/50000)
2025-12-13 02:15:26,719 INFO     Evaluating the model... (22500/50000)
2025-12-13 02:15:29,343 INFO     Evaluating the model... (23000/50000)
2025-12-13 02:15:31,739 INFO     Evaluating the model... (23500/50000)
2025-12-13 02:15:34,299 INFO     Evaluating the model... (24000/50000)
2025-12-13 02:15:37,028 INFO     Evaluating the model... (24500/50000)
2025-12-13 02:15:41,159 INFO     Evaluating the model... (25000/50000)
2025-12-13 02:15:43,831 INFO     Evaluating the model... (25500/50000)
2025-12-13 02:15:46,634 INFO     Evaluating the model... (26000/50000)
2025-12-13 02:15:49,207 INFO     Evaluating the model... (26500/50000)
2025-12-13 02:15:51,687 INFO     Evaluating the model... (27000/50000)
2025-12-13 02:15:55,218 INFO     Evaluating the model... (27500/50000)
2025-12-13 02:15:58,011 INFO     Evaluating the model... (28000/50000)
2025-12-13 02:16:00,468 INFO     Evaluating the model... (28500/50000)
2025-12-13 02:16:02,924 INFO     Evaluating the model... (29000/50000)
2025-12-13 02:16:05,422 INFO     Evaluating the model... (29500/50000)
2025-12-13 02:16:08,972 INFO     Evaluating the model... (30000/50000)
2025-12-13 02:16:11,510 INFO     Evaluating the model... (30500/50000)
2025-12-13 02:16:13,986 INFO     Evaluating the model... (31000/50000)
2025-12-13 02:16:16,522 INFO     Evaluating the model... (31500/50000)
2025-12-13 02:16:18,999 INFO     Evaluating the model... (32000/50000)
2025-12-13 02:16:22,058 INFO     Evaluating the model... (32500/50000)
2025-12-13 02:16:24,525 INFO     Evaluating the model... (33000/50000)
2025-12-13 02:16:27,152 INFO     Evaluating the model... (33500/50000)
2025-12-13 02:16:29,589 INFO     Evaluating the model... (34000/50000)
2025-12-13 02:16:32,299 INFO     Evaluating the model... (34500/50000)
2025-12-13 02:16:35,468 INFO     Evaluating the model... (35000/50000)
2025-12-13 02:16:38,181 INFO     Evaluating the model... (35500/50000)
2025-12-13 02:16:40,915 INFO     Evaluating the model... (36000/50000)
2025-12-13 02:16:43,789 INFO     Evaluating the model... (36500/50000)
2025-12-13 02:16:46,546 INFO     Evaluating the model... (37000/50000)
2025-12-13 02:16:49,756 INFO     Evaluating the model... (37500/50000)
2025-12-13 02:16:52,234 INFO     Evaluating the model... (38000/50000)
2025-12-13 02:16:54,896 INFO     Evaluating the model... (38500/50000)
2025-12-13 02:16:57,414 INFO     Evaluating the model... (39000/50000)
2025-12-13 02:16:59,904 INFO     Evaluating the model... (39500/50000)
2025-12-13 02:17:03,092 INFO     Evaluating the model... (40000/50000)
2025-12-13 02:17:05,708 INFO     Evaluating the model... (40500/50000)
2025-12-13 02:17:08,432 INFO     Evaluating the model... (41000/50000)
2025-12-13 02:17:10,856 INFO     Evaluating the model... (41500/50000)
2025-12-13 02:17:13,767 INFO     Evaluating the model... (42000/50000)
2025-12-13 02:17:16,304 INFO     Evaluating the model... (42500/50000)
2025-12-13 02:17:19,006 INFO     Evaluating the model... (43000/50000)
2025-12-13 02:17:21,519 INFO     Evaluating the model... (43500/50000)
2025-12-13 02:17:24,037 INFO     Evaluating the model... (44000/50000)
2025-12-13 02:17:27,308 INFO     Evaluating the model... (44500/50000)
2025-12-13 02:17:29,864 INFO     Evaluating the model... (45000/50000)
2025-12-13 02:17:32,380 INFO     Evaluating the model... (45500/50000)
2025-12-13 02:17:34,894 INFO     Evaluating the model... (46000/50000)
2025-12-13 02:17:37,636 INFO     Evaluating the model... (46500/50000)
2025-12-13 02:17:41,015 INFO     Evaluating the model... (47000/50000)
2025-12-13 02:17:43,872 INFO     Evaluating the model... (47500/50000)
2025-12-13 02:17:46,500 INFO     Evaluating the model... (48000/50000)
2025-12-13 02:17:49,008 INFO     Evaluating the model... (48500/50000)
2025-12-13 02:17:51,612 INFO     Evaluating the model... (49000/50000)
2025-12-13 02:17:55,088 INFO     Evaluating the model... (49500/50000)
2025-12-13 02:17:57,863 INFO     Valid MRR at step 130000: 0.631924
2025-12-13 02:17:57,864 INFO     Valid MR at step 130000: 266.463910
2025-12-13 02:17:57,864 INFO     Valid HITS@1 at step 130000: 0.546070
2025-12-13 02:17:57,864 INFO     Valid HITS@3 at step 130000: 0.684830
2025-12-13 02:17:57,864 INFO     Valid HITS@10 at step 130000: 0.784460
2025-12-13 02:17:59,608 INFO     Evaluating on Test Dataset...
2025-12-13 02:18:00,123 INFO     Evaluating the model... (0/59072)
2025-12-13 02:18:02,708 INFO     Evaluating the model... (500/59072)
2025-12-13 02:18:05,575 INFO     Evaluating the model... (1000/59072)
2025-12-13 02:18:08,008 INFO     Evaluating the model... (1500/59072)
2025-12-13 02:18:11,768 INFO     Evaluating the model... (2000/59072)
2025-12-13 02:18:14,245 INFO     Evaluating the model... (2500/59072)
2025-12-13 02:18:17,066 INFO     Evaluating the model... (3000/59072)
2025-12-13 02:18:19,500 INFO     Evaluating the model... (3500/59072)
2025-12-13 02:18:21,871 INFO     Evaluating the model... (4000/59072)
2025-12-13 02:18:24,923 INFO     Evaluating the model... (4500/59072)
2025-12-13 02:18:27,658 INFO     Evaluating the model... (5000/59072)
2025-12-13 02:18:30,259 INFO     Evaluating the model... (5500/59072)
2025-12-13 02:18:32,674 INFO     Evaluating the model... (6000/59072)
2025-12-13 02:18:35,207 INFO     Evaluating the model... (6500/59072)
2025-12-13 02:18:38,797 INFO     Evaluating the model... (7000/59072)
2025-12-13 02:18:41,588 INFO     Evaluating the model... (7500/59072)
2025-12-13 02:18:44,240 INFO     Evaluating the model... (8000/59072)
2025-12-13 02:18:46,720 INFO     Evaluating the model... (8500/59072)
2025-12-13 02:18:49,107 INFO     Evaluating the model... (9000/59072)
2025-12-13 02:18:52,381 INFO     Evaluating the model... (9500/59072)
2025-12-13 02:18:54,735 INFO     Evaluating the model... (10000/59072)
2025-12-13 02:18:57,271 INFO     Evaluating the model... (10500/59072)
2025-12-13 02:18:59,748 INFO     Evaluating the model... (11000/59072)
2025-12-13 02:19:02,352 INFO     Evaluating the model... (11500/59072)
2025-12-13 02:19:05,713 INFO     Evaluating the model... (12000/59072)
2025-12-13 02:19:08,028 INFO     Evaluating the model... (12500/59072)
2025-12-13 02:19:10,418 INFO     Evaluating the model... (13000/59072)
2025-12-13 02:19:12,918 INFO     Evaluating the model... (13500/59072)
2025-12-13 02:19:15,516 INFO     Evaluating the model... (14000/59072)
2025-12-13 02:19:18,982 INFO     Evaluating the model... (14500/59072)
2025-12-13 02:19:21,400 INFO     Evaluating the model... (15000/59072)
2025-12-13 02:19:23,862 INFO     Evaluating the model... (15500/59072)
2025-12-13 02:19:26,520 INFO     Evaluating the model... (16000/59072)
2025-12-13 02:19:28,863 INFO     Evaluating the model... (16500/59072)
2025-12-13 02:19:31,978 INFO     Evaluating the model... (17000/59072)
2025-12-13 02:19:34,497 INFO     Evaluating the model... (17500/59072)
2025-12-13 02:19:37,333 INFO     Evaluating the model... (18000/59072)
2025-12-13 02:19:39,831 INFO     Evaluating the model... (18500/59072)
2025-12-13 02:19:42,418 INFO     Evaluating the model... (19000/59072)
2025-12-13 02:19:45,533 INFO     Evaluating the model... (19500/59072)
2025-12-13 02:19:48,246 INFO     Evaluating the model... (20000/59072)
2025-12-13 02:19:50,631 INFO     Evaluating the model... (20500/59072)
2025-12-13 02:19:52,931 INFO     Evaluating the model... (21000/59072)
2025-12-13 02:19:55,954 INFO     Evaluating the model... (21500/59072)
2025-12-13 02:19:58,331 INFO     Evaluating the model... (22000/59072)
2025-12-13 02:20:00,860 INFO     Evaluating the model... (22500/59072)
2025-12-13 02:20:03,338 INFO     Evaluating the model... (23000/59072)
2025-12-13 02:20:05,842 INFO     Evaluating the model... (23500/59072)
2025-12-13 02:20:09,286 INFO     Evaluating the model... (24000/59072)
2025-12-13 02:20:11,872 INFO     Evaluating the model... (24500/59072)
2025-12-13 02:20:14,297 INFO     Evaluating the model... (25000/59072)
2025-12-13 02:20:16,780 INFO     Evaluating the model... (25500/59072)
2025-12-13 02:20:19,282 INFO     Evaluating the model... (26000/59072)
2025-12-13 02:20:22,629 INFO     Evaluating the model... (26500/59072)
2025-12-13 02:20:25,108 INFO     Evaluating the model... (27000/59072)
2025-12-13 02:20:27,546 INFO     Evaluating the model... (27500/59072)
2025-12-13 02:20:30,035 INFO     Evaluating the model... (28000/59072)
2025-12-13 02:20:32,397 INFO     Evaluating the model... (28500/59072)
2025-12-13 02:20:36,160 INFO     Evaluating the model... (29000/59072)
2025-12-13 02:20:38,875 INFO     Evaluating the model... (29500/59072)
2025-12-13 02:20:41,839 INFO     Evaluating the model... (30000/59072)
2025-12-13 02:20:44,506 INFO     Evaluating the model... (30500/59072)
2025-12-13 02:20:48,412 INFO     Evaluating the model... (31000/59072)
2025-12-13 02:20:50,827 INFO     Evaluating the model... (31500/59072)
2025-12-13 02:20:53,370 INFO     Evaluating the model... (32000/59072)
2025-12-13 02:20:56,108 INFO     Evaluating the model... (32500/59072)
2025-12-13 02:20:58,849 INFO     Evaluating the model... (33000/59072)
2025-12-13 02:21:02,159 INFO     Evaluating the model... (33500/59072)
2025-12-13 02:21:04,749 INFO     Evaluating the model... (34000/59072)
2025-12-13 02:21:07,417 INFO     Evaluating the model... (34500/59072)
2025-12-13 02:21:10,102 INFO     Evaluating the model... (35000/59072)
2025-12-13 02:21:12,512 INFO     Evaluating the model... (35500/59072)
2025-12-13 02:21:15,943 INFO     Evaluating the model... (36000/59072)
2025-12-13 02:21:18,402 INFO     Evaluating the model... (36500/59072)
2025-12-13 02:21:21,148 INFO     Evaluating the model... (37000/59072)
2025-12-13 02:21:23,694 INFO     Evaluating the model... (37500/59072)
2025-12-13 02:21:26,244 INFO     Evaluating the model... (38000/59072)
2025-12-13 02:21:29,342 INFO     Evaluating the model... (38500/59072)
2025-12-13 02:21:32,004 INFO     Evaluating the model... (39000/59072)
2025-12-13 02:21:34,564 INFO     Evaluating the model... (39500/59072)
2025-12-13 02:21:37,413 INFO     Evaluating the model... (40000/59072)
2025-12-13 02:21:40,236 INFO     Evaluating the model... (40500/59072)
2025-12-13 02:21:43,723 INFO     Evaluating the model... (41000/59072)
2025-12-13 02:21:46,329 INFO     Evaluating the model... (41500/59072)
2025-12-13 02:21:48,913 INFO     Evaluating the model... (42000/59072)
2025-12-13 02:21:51,484 INFO     Evaluating the model... (42500/59072)
2025-12-13 02:21:54,253 INFO     Evaluating the model... (43000/59072)
2025-12-13 02:21:57,628 INFO     Evaluating the model... (43500/59072)
2025-12-13 02:22:00,088 INFO     Evaluating the model... (44000/59072)
2025-12-13 02:22:02,664 INFO     Evaluating the model... (44500/59072)
2025-12-13 02:22:05,326 INFO     Evaluating the model... (45000/59072)
2025-12-13 02:22:07,985 INFO     Evaluating the model... (45500/59072)
2025-12-13 02:22:11,751 INFO     Evaluating the model... (46000/59072)
2025-12-13 02:22:14,335 INFO     Evaluating the model... (46500/59072)
2025-12-13 02:22:16,997 INFO     Evaluating the model... (47000/59072)
2025-12-13 02:22:19,561 INFO     Evaluating the model... (47500/59072)
2025-12-13 02:22:22,022 INFO     Evaluating the model... (48000/59072)
2025-12-13 02:22:25,487 INFO     Evaluating the model... (48500/59072)
2025-12-13 02:22:27,918 INFO     Evaluating the model... (49000/59072)
2025-12-13 02:22:30,524 INFO     Evaluating the model... (49500/59072)
2025-12-13 02:22:32,995 INFO     Evaluating the model... (50000/59072)
2025-12-13 02:22:35,830 INFO     Evaluating the model... (50500/59072)
2025-12-13 02:22:39,609 INFO     Evaluating the model... (51000/59072)
2025-12-13 02:22:42,576 INFO     Evaluating the model... (51500/59072)
2025-12-13 02:22:45,226 INFO     Evaluating the model... (52000/59072)
2025-12-13 02:22:47,758 INFO     Evaluating the model... (52500/59072)
2025-12-13 02:22:51,192 INFO     Evaluating the model... (53000/59072)
2025-12-13 02:22:53,944 INFO     Evaluating the model... (53500/59072)
2025-12-13 02:22:56,553 INFO     Evaluating the model... (54000/59072)
2025-12-13 02:22:59,109 INFO     Evaluating the model... (54500/59072)
2025-12-13 02:23:01,601 INFO     Evaluating the model... (55000/59072)
2025-12-13 02:23:05,316 INFO     Evaluating the model... (55500/59072)
2025-12-13 02:23:07,717 INFO     Evaluating the model... (56000/59072)
2025-12-13 02:23:10,268 INFO     Evaluating the model... (56500/59072)
2025-12-13 02:23:12,807 INFO     Evaluating the model... (57000/59072)
2025-12-13 02:23:15,473 INFO     Evaluating the model... (57500/59072)
2025-12-13 02:23:19,040 INFO     Evaluating the model... (58000/59072)
2025-12-13 02:23:21,483 INFO     Evaluating the model... (58500/59072)
2025-12-13 02:23:23,905 INFO     Evaluating the model... (59000/59072)
2025-12-13 02:23:24,501 INFO     Test MRR at step 130000: 0.628587
2025-12-13 02:23:24,501 INFO     Test MR at step 130000: 268.541941
2025-12-13 02:23:24,501 INFO     Test HITS@1 at step 130000: 0.541010
2025-12-13 02:23:24,501 INFO     Test HITS@3 at step 130000: 0.683356
2025-12-13 02:23:24,501 INFO     Test HITS@10 at step 130000: 0.782567
2025-12-13 02:23:26,632 INFO     Training average regularization at step 130100: 0.302283
2025-12-13 02:23:26,632 INFO     Training average positive_sample_loss at step 130100: 0.067624
2025-12-13 02:23:26,632 INFO     Training average negative_sample_loss at step 130100: 0.109458
2025-12-13 02:23:26,632 INFO     Training average loss at step 130100: 0.390824
2025-12-13 02:23:28,757 INFO     Training average regularization at step 130200: 0.302283
2025-12-13 02:23:28,757 INFO     Training average positive_sample_loss at step 130200: 0.066934
2025-12-13 02:23:28,757 INFO     Training average negative_sample_loss at step 130200: 0.107492
2025-12-13 02:23:28,757 INFO     Training average loss at step 130200: 0.389496
2025-12-13 02:23:30,876 INFO     Training average regularization at step 130300: 0.302282
2025-12-13 02:23:30,876 INFO     Training average positive_sample_loss at step 130300: 0.067287
2025-12-13 02:23:30,876 INFO     Training average negative_sample_loss at step 130300: 0.108913
2025-12-13 02:23:30,876 INFO     Training average loss at step 130300: 0.390382
2025-12-13 02:23:33,049 INFO     Training average regularization at step 130400: 0.302282
2025-12-13 02:23:33,049 INFO     Training average positive_sample_loss at step 130400: 0.067242
2025-12-13 02:23:33,049 INFO     Training average negative_sample_loss at step 130400: 0.110670
2025-12-13 02:23:33,049 INFO     Training average loss at step 130400: 0.391237
2025-12-13 02:23:36,267 INFO     Training average regularization at step 130500: 0.302281
2025-12-13 02:23:36,268 INFO     Training average positive_sample_loss at step 130500: 0.068103
2025-12-13 02:23:36,268 INFO     Training average negative_sample_loss at step 130500: 0.109432
2025-12-13 02:23:36,268 INFO     Training average loss at step 130500: 0.391049
2025-12-13 02:23:38,459 INFO     Training average regularization at step 130600: 0.302281
2025-12-13 02:23:38,459 INFO     Training average positive_sample_loss at step 130600: 0.065409
2025-12-13 02:23:38,459 INFO     Training average negative_sample_loss at step 130600: 0.107011
2025-12-13 02:23:38,459 INFO     Training average loss at step 130600: 0.388491
2025-12-13 02:23:40,577 INFO     Training average regularization at step 130700: 0.302280
2025-12-13 02:23:40,577 INFO     Training average positive_sample_loss at step 130700: 0.067075
2025-12-13 02:23:40,577 INFO     Training average negative_sample_loss at step 130700: 0.109347
2025-12-13 02:23:40,577 INFO     Training average loss at step 130700: 0.390491
2025-12-13 02:23:42,722 INFO     Training average regularization at step 130800: 0.302279
2025-12-13 02:23:42,722 INFO     Training average positive_sample_loss at step 130800: 0.066104
2025-12-13 02:23:42,722 INFO     Training average negative_sample_loss at step 130800: 0.107611
2025-12-13 02:23:42,722 INFO     Training average loss at step 130800: 0.389137
2025-12-13 02:23:44,915 INFO     Training average regularization at step 130900: 0.302278
2025-12-13 02:23:44,916 INFO     Training average positive_sample_loss at step 130900: 0.066641
2025-12-13 02:23:44,916 INFO     Training average negative_sample_loss at step 130900: 0.108646
2025-12-13 02:23:44,916 INFO     Training average loss at step 130900: 0.389922
2025-12-13 02:23:47,102 INFO     Training average regularization at step 131000: 0.302278
2025-12-13 02:23:47,102 INFO     Training average positive_sample_loss at step 131000: 0.065789
2025-12-13 02:23:47,102 INFO     Training average negative_sample_loss at step 131000: 0.107467
2025-12-13 02:23:47,102 INFO     Training average loss at step 131000: 0.388906
2025-12-13 02:23:49,230 INFO     Training average regularization at step 131100: 0.302277
2025-12-13 02:23:49,231 INFO     Training average positive_sample_loss at step 131100: 0.066831
2025-12-13 02:23:49,231 INFO     Training average negative_sample_loss at step 131100: 0.105311
2025-12-13 02:23:49,231 INFO     Training average loss at step 131100: 0.388348
2025-12-13 02:23:51,349 INFO     Training average regularization at step 131200: 0.302276
2025-12-13 02:23:51,349 INFO     Training average positive_sample_loss at step 131200: 0.066711
2025-12-13 02:23:51,349 INFO     Training average negative_sample_loss at step 131200: 0.109860
2025-12-13 02:23:51,349 INFO     Training average loss at step 131200: 0.390562
2025-12-13 02:23:53,494 INFO     Training average regularization at step 131300: 0.302276
2025-12-13 02:23:53,494 INFO     Training average positive_sample_loss at step 131300: 0.067904
2025-12-13 02:23:53,495 INFO     Training average negative_sample_loss at step 131300: 0.111882
2025-12-13 02:23:53,495 INFO     Training average loss at step 131300: 0.392169
2025-12-13 02:23:55,644 INFO     Training average regularization at step 131400: 0.302275
2025-12-13 02:23:55,645 INFO     Training average positive_sample_loss at step 131400: 0.066576
2025-12-13 02:23:55,645 INFO     Training average negative_sample_loss at step 131400: 0.109858
2025-12-13 02:23:55,645 INFO     Training average loss at step 131400: 0.390492
2025-12-13 02:23:57,810 INFO     Training average regularization at step 131500: 0.302274
2025-12-13 02:23:57,811 INFO     Training average positive_sample_loss at step 131500: 0.066087
2025-12-13 02:23:57,811 INFO     Training average negative_sample_loss at step 131500: 0.109159
2025-12-13 02:23:57,811 INFO     Training average loss at step 131500: 0.389897
2025-12-13 02:24:00,021 INFO     Training average regularization at step 131600: 0.302274
2025-12-13 02:24:00,021 INFO     Training average positive_sample_loss at step 131600: 0.066770
2025-12-13 02:24:00,021 INFO     Training average negative_sample_loss at step 131600: 0.106557
2025-12-13 02:24:00,021 INFO     Training average loss at step 131600: 0.388937
2025-12-13 02:24:02,145 INFO     Training average regularization at step 131700: 0.302273
2025-12-13 02:24:02,147 INFO     Training average positive_sample_loss at step 131700: 0.066053
2025-12-13 02:24:02,147 INFO     Training average negative_sample_loss at step 131700: 0.109857
2025-12-13 02:24:02,147 INFO     Training average loss at step 131700: 0.390228
2025-12-13 02:24:04,279 INFO     Training average regularization at step 131800: 0.302272
2025-12-13 02:24:04,279 INFO     Training average positive_sample_loss at step 131800: 0.066731
2025-12-13 02:24:04,279 INFO     Training average negative_sample_loss at step 131800: 0.104945
2025-12-13 02:24:04,279 INFO     Training average loss at step 131800: 0.388110
2025-12-13 02:24:06,456 INFO     Training average regularization at step 131900: 0.302272
2025-12-13 02:24:06,456 INFO     Training average positive_sample_loss at step 131900: 0.067231
2025-12-13 02:24:06,456 INFO     Training average negative_sample_loss at step 131900: 0.106051
2025-12-13 02:24:06,456 INFO     Training average loss at step 131900: 0.388912
2025-12-13 02:24:08,608 INFO     Training average regularization at step 132000: 0.302271
2025-12-13 02:24:08,608 INFO     Training average positive_sample_loss at step 132000: 0.066163
2025-12-13 02:24:08,608 INFO     Training average negative_sample_loss at step 132000: 0.106607
2025-12-13 02:24:08,608 INFO     Training average loss at step 132000: 0.388656
2025-12-13 02:24:10,771 INFO     Training average regularization at step 132100: 0.302270
2025-12-13 02:24:10,772 INFO     Training average positive_sample_loss at step 132100: 0.066289
2025-12-13 02:24:10,772 INFO     Training average negative_sample_loss at step 132100: 0.108535
2025-12-13 02:24:10,772 INFO     Training average loss at step 132100: 0.389682
2025-12-13 02:24:12,875 INFO     Training average regularization at step 132200: 0.302269
2025-12-13 02:24:12,876 INFO     Training average positive_sample_loss at step 132200: 0.066356
2025-12-13 02:24:12,876 INFO     Training average negative_sample_loss at step 132200: 0.109493
2025-12-13 02:24:12,876 INFO     Training average loss at step 132200: 0.390193
2025-12-13 02:24:14,966 INFO     Training average regularization at step 132300: 0.302269
2025-12-13 02:24:14,967 INFO     Training average positive_sample_loss at step 132300: 0.066720
2025-12-13 02:24:14,967 INFO     Training average negative_sample_loss at step 132300: 0.107819
2025-12-13 02:24:14,967 INFO     Training average loss at step 132300: 0.389538
2025-12-13 02:24:17,078 INFO     Training average regularization at step 132400: 0.302268
2025-12-13 02:24:17,079 INFO     Training average positive_sample_loss at step 132400: 0.066240
2025-12-13 02:24:17,079 INFO     Training average negative_sample_loss at step 132400: 0.110886
2025-12-13 02:24:17,079 INFO     Training average loss at step 132400: 0.390831
2025-12-13 02:24:19,178 INFO     Training average regularization at step 132500: 0.302267
2025-12-13 02:24:19,178 INFO     Training average positive_sample_loss at step 132500: 0.067550
2025-12-13 02:24:19,178 INFO     Training average negative_sample_loss at step 132500: 0.109305
2025-12-13 02:24:19,178 INFO     Training average loss at step 132500: 0.390694
2025-12-13 02:24:21,370 INFO     Training average regularization at step 132600: 0.302267
2025-12-13 02:24:21,371 INFO     Training average positive_sample_loss at step 132600: 0.067122
2025-12-13 02:24:21,371 INFO     Training average negative_sample_loss at step 132600: 0.107317
2025-12-13 02:24:21,371 INFO     Training average loss at step 132600: 0.389486
2025-12-13 02:24:23,510 INFO     Training average regularization at step 132700: 0.302266
2025-12-13 02:24:23,510 INFO     Training average positive_sample_loss at step 132700: 0.066925
2025-12-13 02:24:23,510 INFO     Training average negative_sample_loss at step 132700: 0.110567
2025-12-13 02:24:23,510 INFO     Training average loss at step 132700: 0.391012
2025-12-13 02:24:25,631 INFO     Training average regularization at step 132800: 0.302266
2025-12-13 02:24:25,631 INFO     Training average positive_sample_loss at step 132800: 0.067130
2025-12-13 02:24:25,631 INFO     Training average negative_sample_loss at step 132800: 0.106512
2025-12-13 02:24:25,631 INFO     Training average loss at step 132800: 0.389086
2025-12-13 02:24:27,769 INFO     Training average regularization at step 132900: 0.302265
2025-12-13 02:24:27,769 INFO     Training average positive_sample_loss at step 132900: 0.066323
2025-12-13 02:24:27,769 INFO     Training average negative_sample_loss at step 132900: 0.109301
2025-12-13 02:24:27,769 INFO     Training average loss at step 132900: 0.390077
2025-12-13 02:24:29,876 INFO     Training average regularization at step 133000: 0.302264
2025-12-13 02:24:29,876 INFO     Training average positive_sample_loss at step 133000: 0.065590
2025-12-13 02:24:29,876 INFO     Training average negative_sample_loss at step 133000: 0.109181
2025-12-13 02:24:29,876 INFO     Training average loss at step 133000: 0.389650
2025-12-13 02:24:32,011 INFO     Training average regularization at step 133100: 0.302263
2025-12-13 02:24:32,011 INFO     Training average positive_sample_loss at step 133100: 0.065943
2025-12-13 02:24:32,011 INFO     Training average negative_sample_loss at step 133100: 0.105816
2025-12-13 02:24:32,011 INFO     Training average loss at step 133100: 0.388143
2025-12-13 02:24:34,113 INFO     Training average regularization at step 133200: 0.302263
2025-12-13 02:24:34,113 INFO     Training average positive_sample_loss at step 133200: 0.066658
2025-12-13 02:24:34,113 INFO     Training average negative_sample_loss at step 133200: 0.108790
2025-12-13 02:24:34,113 INFO     Training average loss at step 133200: 0.389987
2025-12-13 02:24:36,244 INFO     Training average regularization at step 133300: 0.302262
2025-12-13 02:24:36,244 INFO     Training average positive_sample_loss at step 133300: 0.066617
2025-12-13 02:24:36,244 INFO     Training average negative_sample_loss at step 133300: 0.110068
2025-12-13 02:24:36,244 INFO     Training average loss at step 133300: 0.390604
2025-12-13 02:24:38,372 INFO     Training average regularization at step 133400: 0.302261
2025-12-13 02:24:38,372 INFO     Training average positive_sample_loss at step 133400: 0.066333
2025-12-13 02:24:38,372 INFO     Training average negative_sample_loss at step 133400: 0.111812
2025-12-13 02:24:38,372 INFO     Training average loss at step 133400: 0.391334
2025-12-13 02:24:40,576 INFO     Training average regularization at step 133500: 0.302261
2025-12-13 02:24:40,576 INFO     Training average positive_sample_loss at step 133500: 0.067753
2025-12-13 02:24:40,576 INFO     Training average negative_sample_loss at step 133500: 0.109407
2025-12-13 02:24:40,576 INFO     Training average loss at step 133500: 0.390841
2025-12-13 02:24:42,721 INFO     Training average regularization at step 133600: 0.302260
2025-12-13 02:24:42,722 INFO     Training average positive_sample_loss at step 133600: 0.067349
2025-12-13 02:24:42,722 INFO     Training average negative_sample_loss at step 133600: 0.108181
2025-12-13 02:24:42,722 INFO     Training average loss at step 133600: 0.390025
2025-12-13 02:24:44,862 INFO     Training average regularization at step 133700: 0.302260
2025-12-13 02:24:44,866 INFO     Training average positive_sample_loss at step 133700: 0.067265
2025-12-13 02:24:44,866 INFO     Training average negative_sample_loss at step 133700: 0.112170
2025-12-13 02:24:44,866 INFO     Training average loss at step 133700: 0.391977
2025-12-13 02:24:47,021 INFO     Training average regularization at step 133800: 0.302259
2025-12-13 02:24:47,021 INFO     Training average positive_sample_loss at step 133800: 0.067013
2025-12-13 02:24:47,021 INFO     Training average negative_sample_loss at step 133800: 0.109690
2025-12-13 02:24:47,021 INFO     Training average loss at step 133800: 0.390611
2025-12-13 02:24:49,139 INFO     Training average regularization at step 133900: 0.302259
2025-12-13 02:24:49,140 INFO     Training average positive_sample_loss at step 133900: 0.066854
2025-12-13 02:24:49,140 INFO     Training average negative_sample_loss at step 133900: 0.110663
2025-12-13 02:24:49,140 INFO     Training average loss at step 133900: 0.391017
2025-12-13 02:24:51,224 INFO     Training average regularization at step 134000: 0.302258
2025-12-13 02:24:51,224 INFO     Training average positive_sample_loss at step 134000: 0.066016
2025-12-13 02:24:51,224 INFO     Training average negative_sample_loss at step 134000: 0.106967
2025-12-13 02:24:51,224 INFO     Training average loss at step 134000: 0.388749
2025-12-13 02:24:53,346 INFO     Training average regularization at step 134100: 0.302257
2025-12-13 02:24:53,346 INFO     Training average positive_sample_loss at step 134100: 0.066220
2025-12-13 02:24:53,347 INFO     Training average negative_sample_loss at step 134100: 0.110007
2025-12-13 02:24:53,347 INFO     Training average loss at step 134100: 0.390371
2025-12-13 02:24:55,496 INFO     Training average regularization at step 134200: 0.302257
2025-12-13 02:24:55,496 INFO     Training average positive_sample_loss at step 134200: 0.067410
2025-12-13 02:24:55,497 INFO     Training average negative_sample_loss at step 134200: 0.107678
2025-12-13 02:24:55,497 INFO     Training average loss at step 134200: 0.389801
2025-12-13 02:24:57,654 INFO     Training average regularization at step 134300: 0.302256
2025-12-13 02:24:57,654 INFO     Training average positive_sample_loss at step 134300: 0.069071
2025-12-13 02:24:57,654 INFO     Training average negative_sample_loss at step 134300: 0.109714
2025-12-13 02:24:57,654 INFO     Training average loss at step 134300: 0.391649
2025-12-13 02:24:59,755 INFO     Training average regularization at step 134400: 0.302256
2025-12-13 02:24:59,755 INFO     Training average positive_sample_loss at step 134400: 0.067134
2025-12-13 02:24:59,755 INFO     Training average negative_sample_loss at step 134400: 0.109113
2025-12-13 02:24:59,755 INFO     Training average loss at step 134400: 0.390380
2025-12-13 02:25:01,876 INFO     Training average regularization at step 134500: 0.302255
2025-12-13 02:25:01,877 INFO     Training average positive_sample_loss at step 134500: 0.066566
2025-12-13 02:25:01,877 INFO     Training average negative_sample_loss at step 134500: 0.109269
2025-12-13 02:25:01,877 INFO     Training average loss at step 134500: 0.390173
2025-12-13 02:25:03,984 INFO     Training average regularization at step 134600: 0.302255
2025-12-13 02:25:03,984 INFO     Training average positive_sample_loss at step 134600: 0.067638
2025-12-13 02:25:03,984 INFO     Training average negative_sample_loss at step 134600: 0.108791
2025-12-13 02:25:03,984 INFO     Training average loss at step 134600: 0.390469
2025-12-13 02:25:06,152 INFO     Training average regularization at step 134700: 0.302254
2025-12-13 02:25:06,152 INFO     Training average positive_sample_loss at step 134700: 0.067448
2025-12-13 02:25:06,152 INFO     Training average negative_sample_loss at step 134700: 0.110246
2025-12-13 02:25:06,152 INFO     Training average loss at step 134700: 0.391102
2025-12-13 02:25:08,262 INFO     Training average regularization at step 134800: 0.302254
2025-12-13 02:25:08,262 INFO     Training average positive_sample_loss at step 134800: 0.067465
2025-12-13 02:25:08,262 INFO     Training average negative_sample_loss at step 134800: 0.111034
2025-12-13 02:25:08,262 INFO     Training average loss at step 134800: 0.391504
2025-12-13 02:25:10,406 INFO     Training average regularization at step 134900: 0.302253
2025-12-13 02:25:10,407 INFO     Training average positive_sample_loss at step 134900: 0.065757
2025-12-13 02:25:10,407 INFO     Training average negative_sample_loss at step 134900: 0.108962
2025-12-13 02:25:10,407 INFO     Training average loss at step 134900: 0.389613
2025-12-13 02:25:12,571 INFO     Training average regularization at step 135000: 0.302253
2025-12-13 02:25:12,571 INFO     Training average positive_sample_loss at step 135000: 0.067058
2025-12-13 02:25:12,571 INFO     Training average negative_sample_loss at step 135000: 0.110597
2025-12-13 02:25:12,571 INFO     Training average loss at step 135000: 0.391080
2025-12-13 02:25:14,720 INFO     Training average regularization at step 135100: 0.302252
2025-12-13 02:25:14,721 INFO     Training average positive_sample_loss at step 135100: 0.066196
2025-12-13 02:25:14,721 INFO     Training average negative_sample_loss at step 135100: 0.107278
2025-12-13 02:25:14,721 INFO     Training average loss at step 135100: 0.388989
2025-12-13 02:25:16,882 INFO     Training average regularization at step 135200: 0.302252
2025-12-13 02:25:16,882 INFO     Training average positive_sample_loss at step 135200: 0.067883
2025-12-13 02:25:16,882 INFO     Training average negative_sample_loss at step 135200: 0.107677
2025-12-13 02:25:16,882 INFO     Training average loss at step 135200: 0.390032
2025-12-13 02:25:20,117 INFO     Training average regularization at step 135300: 0.302251
2025-12-13 02:25:20,118 INFO     Training average positive_sample_loss at step 135300: 0.066497
2025-12-13 02:25:20,118 INFO     Training average negative_sample_loss at step 135300: 0.106928
2025-12-13 02:25:20,118 INFO     Training average loss at step 135300: 0.388964
2025-12-13 02:25:22,259 INFO     Training average regularization at step 135400: 0.302251
2025-12-13 02:25:22,260 INFO     Training average positive_sample_loss at step 135400: 0.067243
2025-12-13 02:25:22,260 INFO     Training average negative_sample_loss at step 135400: 0.107743
2025-12-13 02:25:22,260 INFO     Training average loss at step 135400: 0.389744
2025-12-13 02:25:24,407 INFO     Training average regularization at step 135500: 0.302250
2025-12-13 02:25:24,407 INFO     Training average positive_sample_loss at step 135500: 0.066621
2025-12-13 02:25:24,407 INFO     Training average negative_sample_loss at step 135500: 0.110337
2025-12-13 02:25:24,407 INFO     Training average loss at step 135500: 0.390730
2025-12-13 02:25:26,582 INFO     Training average regularization at step 135600: 0.302249
2025-12-13 02:25:26,582 INFO     Training average positive_sample_loss at step 135600: 0.066229
2025-12-13 02:25:26,582 INFO     Training average negative_sample_loss at step 135600: 0.107078
2025-12-13 02:25:26,582 INFO     Training average loss at step 135600: 0.388903
2025-12-13 02:25:28,720 INFO     Training average regularization at step 135700: 0.302249
2025-12-13 02:25:28,720 INFO     Training average positive_sample_loss at step 135700: 0.066555
2025-12-13 02:25:28,721 INFO     Training average negative_sample_loss at step 135700: 0.107854
2025-12-13 02:25:28,721 INFO     Training average loss at step 135700: 0.389453
2025-12-13 02:25:30,824 INFO     Training average regularization at step 135800: 0.302248
2025-12-13 02:25:30,824 INFO     Training average positive_sample_loss at step 135800: 0.066275
2025-12-13 02:25:30,824 INFO     Training average negative_sample_loss at step 135800: 0.108820
2025-12-13 02:25:30,824 INFO     Training average loss at step 135800: 0.389796
2025-12-13 02:25:32,947 INFO     Training average regularization at step 135900: 0.302247
2025-12-13 02:25:32,949 INFO     Training average positive_sample_loss at step 135900: 0.066113
2025-12-13 02:25:32,949 INFO     Training average negative_sample_loss at step 135900: 0.107148
2025-12-13 02:25:32,949 INFO     Training average loss at step 135900: 0.388878
2025-12-13 02:25:35,084 INFO     Training average regularization at step 136000: 0.302246
2025-12-13 02:25:35,084 INFO     Training average positive_sample_loss at step 136000: 0.065247
2025-12-13 02:25:35,084 INFO     Training average negative_sample_loss at step 136000: 0.110094
2025-12-13 02:25:35,084 INFO     Training average loss at step 136000: 0.389917
2025-12-13 02:25:37,287 INFO     Training average regularization at step 136100: 0.302245
2025-12-13 02:25:37,287 INFO     Training average positive_sample_loss at step 136100: 0.066194
2025-12-13 02:25:37,287 INFO     Training average negative_sample_loss at step 136100: 0.107232
2025-12-13 02:25:37,287 INFO     Training average loss at step 136100: 0.388958
2025-12-13 02:25:39,481 INFO     Training average regularization at step 136200: 0.302245
2025-12-13 02:25:39,482 INFO     Training average positive_sample_loss at step 136200: 0.066476
2025-12-13 02:25:39,482 INFO     Training average negative_sample_loss at step 136200: 0.109268
2025-12-13 02:25:39,482 INFO     Training average loss at step 136200: 0.390116
2025-12-13 02:25:41,641 INFO     Training average regularization at step 136300: 0.302244
2025-12-13 02:25:41,641 INFO     Training average positive_sample_loss at step 136300: 0.067114
2025-12-13 02:25:41,641 INFO     Training average negative_sample_loss at step 136300: 0.107914
2025-12-13 02:25:41,642 INFO     Training average loss at step 136300: 0.389758
2025-12-13 02:25:43,792 INFO     Training average regularization at step 136400: 0.302243
2025-12-13 02:25:43,792 INFO     Training average positive_sample_loss at step 136400: 0.066399
2025-12-13 02:25:43,792 INFO     Training average negative_sample_loss at step 136400: 0.108891
2025-12-13 02:25:43,792 INFO     Training average loss at step 136400: 0.389888
2025-12-13 02:25:45,927 INFO     Training average regularization at step 136500: 0.302242
2025-12-13 02:25:45,934 INFO     Training average positive_sample_loss at step 136500: 0.066700
2025-12-13 02:25:45,934 INFO     Training average negative_sample_loss at step 136500: 0.110674
2025-12-13 02:25:45,934 INFO     Training average loss at step 136500: 0.390929
2025-12-13 02:25:48,038 INFO     Training average regularization at step 136600: 0.302242
2025-12-13 02:25:48,038 INFO     Training average positive_sample_loss at step 136600: 0.065505
2025-12-13 02:25:48,038 INFO     Training average negative_sample_loss at step 136600: 0.108180
2025-12-13 02:25:48,038 INFO     Training average loss at step 136600: 0.389084
2025-12-13 02:25:50,182 INFO     Training average regularization at step 136700: 0.302241
2025-12-13 02:25:50,182 INFO     Training average positive_sample_loss at step 136700: 0.067609
2025-12-13 02:25:50,182 INFO     Training average negative_sample_loss at step 136700: 0.106412
2025-12-13 02:25:50,182 INFO     Training average loss at step 136700: 0.389252
2025-12-13 02:25:52,283 INFO     Training average regularization at step 136800: 0.302240
2025-12-13 02:25:52,283 INFO     Training average positive_sample_loss at step 136800: 0.067042
2025-12-13 02:25:52,283 INFO     Training average negative_sample_loss at step 136800: 0.108035
2025-12-13 02:25:52,284 INFO     Training average loss at step 136800: 0.389779
2025-12-13 02:25:54,373 INFO     Training average regularization at step 136900: 0.302240
2025-12-13 02:25:54,373 INFO     Training average positive_sample_loss at step 136900: 0.066225
2025-12-13 02:25:54,373 INFO     Training average negative_sample_loss at step 136900: 0.108119
2025-12-13 02:25:54,373 INFO     Training average loss at step 136900: 0.389412
2025-12-13 02:25:56,539 INFO     Training average regularization at step 137000: 0.302239
2025-12-13 02:25:56,539 INFO     Training average positive_sample_loss at step 137000: 0.067059
2025-12-13 02:25:56,539 INFO     Training average negative_sample_loss at step 137000: 0.107294
2025-12-13 02:25:56,539 INFO     Training average loss at step 137000: 0.389416
2025-12-13 02:25:58,667 INFO     Training average regularization at step 137100: 0.302239
2025-12-13 02:25:58,667 INFO     Training average positive_sample_loss at step 137100: 0.066747
2025-12-13 02:25:58,667 INFO     Training average negative_sample_loss at step 137100: 0.107767
2025-12-13 02:25:58,667 INFO     Training average loss at step 137100: 0.389495
2025-12-13 02:26:00,770 INFO     Training average regularization at step 137200: 0.302238
2025-12-13 02:26:00,770 INFO     Training average positive_sample_loss at step 137200: 0.067757
2025-12-13 02:26:00,770 INFO     Training average negative_sample_loss at step 137200: 0.108417
2025-12-13 02:26:00,770 INFO     Training average loss at step 137200: 0.390325
2025-12-13 02:26:02,872 INFO     Training average regularization at step 137300: 0.302237
2025-12-13 02:26:02,873 INFO     Training average positive_sample_loss at step 137300: 0.066727
2025-12-13 02:26:02,873 INFO     Training average negative_sample_loss at step 137300: 0.108886
2025-12-13 02:26:02,873 INFO     Training average loss at step 137300: 0.390044
2025-12-13 02:26:04,954 INFO     Training average regularization at step 137400: 0.302237
2025-12-13 02:26:04,954 INFO     Training average positive_sample_loss at step 137400: 0.066374
2025-12-13 02:26:04,954 INFO     Training average negative_sample_loss at step 137400: 0.108443
2025-12-13 02:26:04,954 INFO     Training average loss at step 137400: 0.389646
2025-12-13 02:26:07,040 INFO     Training average regularization at step 137500: 0.302236
2025-12-13 02:26:07,040 INFO     Training average positive_sample_loss at step 137500: 0.067255
2025-12-13 02:26:07,040 INFO     Training average negative_sample_loss at step 137500: 0.106130
2025-12-13 02:26:07,040 INFO     Training average loss at step 137500: 0.388929
2025-12-13 02:26:09,171 INFO     Training average regularization at step 137600: 0.302236
2025-12-13 02:26:09,171 INFO     Training average positive_sample_loss at step 137600: 0.066683
2025-12-13 02:26:09,171 INFO     Training average negative_sample_loss at step 137600: 0.108054
2025-12-13 02:26:09,171 INFO     Training average loss at step 137600: 0.389604
2025-12-13 02:26:11,309 INFO     Training average regularization at step 137700: 0.302235
2025-12-13 02:26:11,309 INFO     Training average positive_sample_loss at step 137700: 0.066738
2025-12-13 02:26:11,309 INFO     Training average negative_sample_loss at step 137700: 0.110990
2025-12-13 02:26:11,309 INFO     Training average loss at step 137700: 0.391099
2025-12-13 02:26:13,417 INFO     Training average regularization at step 137800: 0.302235
2025-12-13 02:26:13,417 INFO     Training average positive_sample_loss at step 137800: 0.066601
2025-12-13 02:26:13,417 INFO     Training average negative_sample_loss at step 137800: 0.107796
2025-12-13 02:26:13,417 INFO     Training average loss at step 137800: 0.389433
2025-12-13 02:26:15,550 INFO     Training average regularization at step 137900: 0.302234
2025-12-13 02:26:15,551 INFO     Training average positive_sample_loss at step 137900: 0.067919
2025-12-13 02:26:15,551 INFO     Training average negative_sample_loss at step 137900: 0.109241
2025-12-13 02:26:15,551 INFO     Training average loss at step 137900: 0.390814
2025-12-13 02:26:17,670 INFO     Training average regularization at step 138000: 0.302234
2025-12-13 02:26:17,670 INFO     Training average positive_sample_loss at step 138000: 0.067182
2025-12-13 02:26:17,670 INFO     Training average negative_sample_loss at step 138000: 0.107667
2025-12-13 02:26:17,670 INFO     Training average loss at step 138000: 0.389658
2025-12-13 02:26:19,760 INFO     Training average regularization at step 138100: 0.302233
2025-12-13 02:26:19,760 INFO     Training average positive_sample_loss at step 138100: 0.066550
2025-12-13 02:26:19,761 INFO     Training average negative_sample_loss at step 138100: 0.108179
2025-12-13 02:26:19,761 INFO     Training average loss at step 138100: 0.389597
2025-12-13 02:26:21,918 INFO     Training average regularization at step 138200: 0.302232
2025-12-13 02:26:21,919 INFO     Training average positive_sample_loss at step 138200: 0.067416
2025-12-13 02:26:21,919 INFO     Training average negative_sample_loss at step 138200: 0.109031
2025-12-13 02:26:21,919 INFO     Training average loss at step 138200: 0.390456
2025-12-13 02:26:24,057 INFO     Training average regularization at step 138300: 0.302232
2025-12-13 02:26:24,058 INFO     Training average positive_sample_loss at step 138300: 0.066016
2025-12-13 02:26:24,058 INFO     Training average negative_sample_loss at step 138300: 0.111476
2025-12-13 02:26:24,058 INFO     Training average loss at step 138300: 0.390978
2025-12-13 02:26:26,156 INFO     Training average regularization at step 138400: 0.302231
2025-12-13 02:26:26,161 INFO     Training average positive_sample_loss at step 138400: 0.067942
2025-12-13 02:26:26,161 INFO     Training average negative_sample_loss at step 138400: 0.110073
2025-12-13 02:26:26,162 INFO     Training average loss at step 138400: 0.391239
2025-12-13 02:26:28,238 INFO     Training average regularization at step 138500: 0.302231
2025-12-13 02:26:28,238 INFO     Training average positive_sample_loss at step 138500: 0.066998
2025-12-13 02:26:28,238 INFO     Training average negative_sample_loss at step 138500: 0.107658
2025-12-13 02:26:28,238 INFO     Training average loss at step 138500: 0.389558
2025-12-13 02:26:30,334 INFO     Training average regularization at step 138600: 0.302230
2025-12-13 02:26:30,334 INFO     Training average positive_sample_loss at step 138600: 0.066486
2025-12-13 02:26:30,334 INFO     Training average negative_sample_loss at step 138600: 0.110573
2025-12-13 02:26:30,334 INFO     Training average loss at step 138600: 0.390759
2025-12-13 02:26:32,500 INFO     Training average regularization at step 138700: 0.302229
2025-12-13 02:26:32,501 INFO     Training average positive_sample_loss at step 138700: 0.066565
2025-12-13 02:26:32,501 INFO     Training average negative_sample_loss at step 138700: 0.111953
2025-12-13 02:26:32,501 INFO     Training average loss at step 138700: 0.391488
2025-12-13 02:26:34,655 INFO     Training average regularization at step 138800: 0.302229
2025-12-13 02:26:34,655 INFO     Training average positive_sample_loss at step 138800: 0.067360
2025-12-13 02:26:34,655 INFO     Training average negative_sample_loss at step 138800: 0.108822
2025-12-13 02:26:34,655 INFO     Training average loss at step 138800: 0.390320
2025-12-13 02:26:36,840 INFO     Training average regularization at step 138900: 0.302229
2025-12-13 02:26:36,840 INFO     Training average positive_sample_loss at step 138900: 0.068224
2025-12-13 02:26:36,840 INFO     Training average negative_sample_loss at step 138900: 0.109341
2025-12-13 02:26:36,840 INFO     Training average loss at step 138900: 0.391011
2025-12-13 02:26:38,953 INFO     Training average regularization at step 139000: 0.302228
2025-12-13 02:26:38,953 INFO     Training average positive_sample_loss at step 139000: 0.066318
2025-12-13 02:26:38,954 INFO     Training average negative_sample_loss at step 139000: 0.108241
2025-12-13 02:26:38,954 INFO     Training average loss at step 139000: 0.389508
2025-12-13 02:26:41,086 INFO     Training average regularization at step 139100: 0.302228
2025-12-13 02:26:41,087 INFO     Training average positive_sample_loss at step 139100: 0.067738
2025-12-13 02:26:41,087 INFO     Training average negative_sample_loss at step 139100: 0.111185
2025-12-13 02:26:41,087 INFO     Training average loss at step 139100: 0.391689
2025-12-13 02:26:43,248 INFO     Training average regularization at step 139200: 0.302227
2025-12-13 02:26:43,248 INFO     Training average positive_sample_loss at step 139200: 0.066264
2025-12-13 02:26:43,249 INFO     Training average negative_sample_loss at step 139200: 0.106734
2025-12-13 02:26:43,249 INFO     Training average loss at step 139200: 0.388726
2025-12-13 02:26:45,412 INFO     Training average regularization at step 139300: 0.302227
2025-12-13 02:26:45,413 INFO     Training average positive_sample_loss at step 139300: 0.067010
2025-12-13 02:26:45,413 INFO     Training average negative_sample_loss at step 139300: 0.106552
2025-12-13 02:26:45,413 INFO     Training average loss at step 139300: 0.389008
2025-12-13 02:26:47,524 INFO     Training average regularization at step 139400: 0.302226
2025-12-13 02:26:47,524 INFO     Training average positive_sample_loss at step 139400: 0.066741
2025-12-13 02:26:47,524 INFO     Training average negative_sample_loss at step 139400: 0.107388
2025-12-13 02:26:47,524 INFO     Training average loss at step 139400: 0.389290
2025-12-13 02:26:49,628 INFO     Training average regularization at step 139500: 0.302226
2025-12-13 02:26:49,628 INFO     Training average positive_sample_loss at step 139500: 0.066159
2025-12-13 02:26:49,628 INFO     Training average negative_sample_loss at step 139500: 0.108154
2025-12-13 02:26:49,628 INFO     Training average loss at step 139500: 0.389382
2025-12-13 02:26:51,791 INFO     Training average regularization at step 139600: 0.302225
2025-12-13 02:26:51,791 INFO     Training average positive_sample_loss at step 139600: 0.066047
2025-12-13 02:26:51,791 INFO     Training average negative_sample_loss at step 139600: 0.107998
2025-12-13 02:26:51,791 INFO     Training average loss at step 139600: 0.389248
2025-12-13 02:26:53,923 INFO     Training average regularization at step 139700: 0.302224
2025-12-13 02:26:53,923 INFO     Training average positive_sample_loss at step 139700: 0.066215
2025-12-13 02:26:53,923 INFO     Training average negative_sample_loss at step 139700: 0.110955
2025-12-13 02:26:53,923 INFO     Training average loss at step 139700: 0.390810
2025-12-13 02:26:56,047 INFO     Training average regularization at step 139800: 0.302224
2025-12-13 02:26:56,047 INFO     Training average positive_sample_loss at step 139800: 0.066792
2025-12-13 02:26:56,047 INFO     Training average negative_sample_loss at step 139800: 0.110220
2025-12-13 02:26:56,047 INFO     Training average loss at step 139800: 0.390729
2025-12-13 02:26:58,139 INFO     Training average regularization at step 139900: 0.302223
2025-12-13 02:26:58,139 INFO     Training average positive_sample_loss at step 139900: 0.067436
2025-12-13 02:26:58,139 INFO     Training average negative_sample_loss at step 139900: 0.106714
2025-12-13 02:26:58,139 INFO     Training average loss at step 139900: 0.389298
2025-12-13 02:27:01,676 INFO     Training average regularization at step 140000: 0.302223
2025-12-13 02:27:01,676 INFO     Training average positive_sample_loss at step 140000: 0.068087
2025-12-13 02:27:01,676 INFO     Training average negative_sample_loss at step 140000: 0.107846
2025-12-13 02:27:01,677 INFO     Training average loss at step 140000: 0.390189
2025-12-13 02:27:01,677 INFO     Evaluating on Valid Dataset...
2025-12-13 02:27:02,246 INFO     Evaluating the model... (0/50000)
2025-12-13 02:27:04,786 INFO     Evaluating the model... (500/50000)
2025-12-13 02:27:08,629 INFO     Evaluating the model... (1000/50000)
2025-12-13 02:27:11,229 INFO     Evaluating the model... (1500/50000)
2025-12-13 02:27:13,719 INFO     Evaluating the model... (2000/50000)
2025-12-13 02:27:16,257 INFO     Evaluating the model... (2500/50000)
2025-12-13 02:27:18,920 INFO     Evaluating the model... (3000/50000)
2025-12-13 02:27:22,167 INFO     Evaluating the model... (3500/50000)
2025-12-13 02:27:24,656 INFO     Evaluating the model... (4000/50000)
2025-12-13 02:27:27,158 INFO     Evaluating the model... (4500/50000)
2025-12-13 02:27:29,670 INFO     Evaluating the model... (5000/50000)
2025-12-13 02:27:32,211 INFO     Evaluating the model... (5500/50000)
2025-12-13 02:27:35,447 INFO     Evaluating the model... (6000/50000)
2025-12-13 02:27:38,256 INFO     Evaluating the model... (6500/50000)
2025-12-13 02:27:41,106 INFO     Evaluating the model... (7000/50000)
2025-12-13 02:27:43,910 INFO     Evaluating the model... (7500/50000)
2025-12-13 02:27:46,505 INFO     Evaluating the model... (8000/50000)
2025-12-13 02:27:49,859 INFO     Evaluating the model... (8500/50000)
2025-12-13 02:27:52,448 INFO     Evaluating the model... (9000/50000)
2025-12-13 02:27:54,956 INFO     Evaluating the model... (9500/50000)
2025-12-13 02:27:57,608 INFO     Evaluating the model... (10000/50000)
2025-12-13 02:28:00,002 INFO     Evaluating the model... (10500/50000)
2025-12-13 02:28:03,269 INFO     Evaluating the model... (11000/50000)
2025-12-13 02:28:05,912 INFO     Evaluating the model... (11500/50000)
2025-12-13 02:28:08,314 INFO     Evaluating the model... (12000/50000)
2025-12-13 02:28:10,777 INFO     Evaluating the model... (12500/50000)
2025-12-13 02:28:13,164 INFO     Evaluating the model... (13000/50000)
2025-12-13 02:28:16,836 INFO     Evaluating the model... (13500/50000)
2025-12-13 02:28:19,301 INFO     Evaluating the model... (14000/50000)
2025-12-13 02:28:21,715 INFO     Evaluating the model... (14500/50000)
2025-12-13 02:28:24,024 INFO     Evaluating the model... (15000/50000)
2025-12-13 02:28:26,514 INFO     Evaluating the model... (15500/50000)
2025-12-13 02:28:29,921 INFO     Evaluating the model... (16000/50000)
2025-12-13 02:28:32,370 INFO     Evaluating the model... (16500/50000)
2025-12-13 02:28:34,788 INFO     Evaluating the model... (17000/50000)
2025-12-13 02:28:37,533 INFO     Evaluating the model... (17500/50000)
2025-12-13 02:28:41,390 INFO     Evaluating the model... (18000/50000)
2025-12-13 02:28:43,956 INFO     Evaluating the model... (18500/50000)
2025-12-13 02:28:46,584 INFO     Evaluating the model... (19000/50000)
2025-12-13 02:28:48,946 INFO     Evaluating the model... (19500/50000)
2025-12-13 02:28:51,648 INFO     Evaluating the model... (20000/50000)
2025-12-13 02:28:55,092 INFO     Evaluating the model... (20500/50000)
2025-12-13 02:28:57,657 INFO     Evaluating the model... (21000/50000)
2025-12-13 02:29:00,103 INFO     Evaluating the model... (21500/50000)
2025-12-13 02:29:02,820 INFO     Evaluating the model... (22000/50000)
2025-12-13 02:29:05,260 INFO     Evaluating the model... (22500/50000)
2025-12-13 02:29:08,575 INFO     Evaluating the model... (23000/50000)
2025-12-13 02:29:11,018 INFO     Evaluating the model... (23500/50000)
2025-12-13 02:29:13,761 INFO     Evaluating the model... (24000/50000)
2025-12-13 02:29:16,381 INFO     Evaluating the model... (24500/50000)
2025-12-13 02:29:19,167 INFO     Evaluating the model... (25000/50000)
2025-12-13 02:29:22,722 INFO     Evaluating the model... (25500/50000)
2025-12-13 02:29:25,629 INFO     Evaluating the model... (26000/50000)
2025-12-13 02:29:28,127 INFO     Evaluating the model... (26500/50000)
2025-12-13 02:29:30,687 INFO     Evaluating the model... (27000/50000)
2025-12-13 02:29:33,144 INFO     Evaluating the model... (27500/50000)
2025-12-13 02:29:36,809 INFO     Evaluating the model... (28000/50000)
2025-12-13 02:29:39,499 INFO     Evaluating the model... (28500/50000)
2025-12-13 02:29:42,216 INFO     Evaluating the model... (29000/50000)
2025-12-13 02:29:44,996 INFO     Evaluating the model... (29500/50000)
2025-12-13 02:29:47,765 INFO     Evaluating the model... (30000/50000)
2025-12-13 02:29:51,360 INFO     Evaluating the model... (30500/50000)
2025-12-13 02:29:53,829 INFO     Evaluating the model... (31000/50000)
2025-12-13 02:29:56,524 INFO     Evaluating the model... (31500/50000)
2025-12-13 02:29:59,225 INFO     Evaluating the model... (32000/50000)
2025-12-13 02:30:01,740 INFO     Evaluating the model... (32500/50000)
2025-12-13 02:30:04,662 INFO     Evaluating the model... (33000/50000)
2025-12-13 02:30:07,283 INFO     Evaluating the model... (33500/50000)
2025-12-13 02:30:09,950 INFO     Evaluating the model... (34000/50000)
2025-12-13 02:30:12,746 INFO     Evaluating the model... (34500/50000)
2025-12-13 02:30:15,247 INFO     Evaluating the model... (35000/50000)
2025-12-13 02:30:18,160 INFO     Evaluating the model... (35500/50000)
2025-12-13 02:30:20,667 INFO     Evaluating the model... (36000/50000)
2025-12-13 02:30:23,378 INFO     Evaluating the model... (36500/50000)
2025-12-13 02:30:25,902 INFO     Evaluating the model... (37000/50000)
2025-12-13 02:30:28,373 INFO     Evaluating the model... (37500/50000)
2025-12-13 02:30:31,342 INFO     Evaluating the model... (38000/50000)
2025-12-13 02:30:33,941 INFO     Evaluating the model... (38500/50000)
2025-12-13 02:30:36,657 INFO     Evaluating the model... (39000/50000)
2025-12-13 02:30:39,463 INFO     Evaluating the model... (39500/50000)
2025-12-13 02:30:42,181 INFO     Evaluating the model... (40000/50000)
2025-12-13 02:30:46,017 INFO     Evaluating the model... (40500/50000)
2025-12-13 02:30:48,608 INFO     Evaluating the model... (41000/50000)
2025-12-13 02:30:51,154 INFO     Evaluating the model... (41500/50000)
2025-12-13 02:30:53,663 INFO     Evaluating the model... (42000/50000)
2025-12-13 02:30:56,145 INFO     Evaluating the model... (42500/50000)
2025-12-13 02:30:59,856 INFO     Evaluating the model... (43000/50000)
2025-12-13 02:31:02,311 INFO     Evaluating the model... (43500/50000)
2025-12-13 02:31:04,844 INFO     Evaluating the model... (44000/50000)
2025-12-13 02:31:07,364 INFO     Evaluating the model... (44500/50000)
2025-12-13 02:31:10,602 INFO     Evaluating the model... (45000/50000)
2025-12-13 02:31:13,734 INFO     Evaluating the model... (45500/50000)
2025-12-13 02:31:16,265 INFO     Evaluating the model... (46000/50000)
2025-12-13 02:31:18,748 INFO     Evaluating the model... (46500/50000)
2025-12-13 02:31:21,466 INFO     Evaluating the model... (47000/50000)
2025-12-13 02:31:24,984 INFO     Evaluating the model... (47500/50000)
2025-12-13 02:31:27,443 INFO     Evaluating the model... (48000/50000)
2025-12-13 02:31:29,995 INFO     Evaluating the model... (48500/50000)
2025-12-13 02:31:32,710 INFO     Evaluating the model... (49000/50000)
2025-12-13 02:31:35,131 INFO     Evaluating the model... (49500/50000)
2025-12-13 02:31:39,282 INFO     Valid MRR at step 140000: 0.632453
2025-12-13 02:31:39,283 INFO     Valid MR at step 140000: 266.216930
2025-12-13 02:31:39,283 INFO     Valid HITS@1 at step 140000: 0.546670
2025-12-13 02:31:39,283 INFO     Valid HITS@3 at step 140000: 0.685370
2025-12-13 02:31:39,283 INFO     Valid HITS@10 at step 140000: 0.784920
2025-12-13 02:31:40,517 INFO     Evaluating on Test Dataset...
2025-12-13 02:31:41,138 INFO     Evaluating the model... (0/59072)
2025-12-13 02:31:44,988 INFO     Evaluating the model... (500/59072)
2025-12-13 02:31:47,524 INFO     Evaluating the model... (1000/59072)
2025-12-13 02:31:50,099 INFO     Evaluating the model... (1500/59072)
2025-12-13 02:31:52,662 INFO     Evaluating the model... (2000/59072)
2025-12-13 02:31:56,086 INFO     Evaluating the model... (2500/59072)
2025-12-13 02:31:58,564 INFO     Evaluating the model... (3000/59072)
2025-12-13 02:32:01,011 INFO     Evaluating the model... (3500/59072)
2025-12-13 02:32:03,819 INFO     Evaluating the model... (4000/59072)
2025-12-13 02:32:06,420 INFO     Evaluating the model... (4500/59072)
2025-12-13 02:32:09,444 INFO     Evaluating the model... (5000/59072)
2025-12-13 02:32:11,862 INFO     Evaluating the model... (5500/59072)
2025-12-13 02:32:14,252 INFO     Evaluating the model... (6000/59072)
2025-12-13 02:32:16,903 INFO     Evaluating the model... (6500/59072)
2025-12-13 02:32:19,290 INFO     Evaluating the model... (7000/59072)
2025-12-13 02:32:22,385 INFO     Evaluating the model... (7500/59072)
2025-12-13 02:32:24,699 INFO     Evaluating the model... (8000/59072)
2025-12-13 02:32:27,091 INFO     Evaluating the model... (8500/59072)
2025-12-13 02:32:29,737 INFO     Evaluating the model... (9000/59072)
2025-12-13 02:32:32,188 INFO     Evaluating the model... (9500/59072)
2025-12-13 02:32:35,223 INFO     Evaluating the model... (10000/59072)
2025-12-13 02:32:38,014 INFO     Evaluating the model... (10500/59072)
2025-12-13 02:32:40,915 INFO     Evaluating the model... (11000/59072)
2025-12-13 02:32:43,592 INFO     Evaluating the model... (11500/59072)
2025-12-13 02:32:46,230 INFO     Evaluating the model... (12000/59072)
2025-12-13 02:32:49,419 INFO     Evaluating the model... (12500/59072)
2025-12-13 02:32:52,029 INFO     Evaluating the model... (13000/59072)
2025-12-13 02:32:54,483 INFO     Evaluating the model... (13500/59072)
2025-12-13 02:32:57,021 INFO     Evaluating the model... (14000/59072)
2025-12-13 02:32:59,390 INFO     Evaluating the model... (14500/59072)
2025-12-13 02:33:02,689 INFO     Evaluating the model... (15000/59072)
2025-12-13 02:33:05,321 INFO     Evaluating the model... (15500/59072)
2025-12-13 02:33:07,821 INFO     Evaluating the model... (16000/59072)
2025-12-13 02:33:10,264 INFO     Evaluating the model... (16500/59072)
2025-12-13 02:33:12,671 INFO     Evaluating the model... (17000/59072)
2025-12-13 02:33:16,594 INFO     Evaluating the model... (17500/59072)
2025-12-13 02:33:19,148 INFO     Evaluating the model... (18000/59072)
2025-12-13 02:33:21,624 INFO     Evaluating the model... (18500/59072)
2025-12-13 02:33:24,014 INFO     Evaluating the model... (19000/59072)
2025-12-13 02:33:26,739 INFO     Evaluating the model... (19500/59072)
2025-12-13 02:33:30,309 INFO     Evaluating the model... (20000/59072)
2025-12-13 02:33:32,738 INFO     Evaluating the model... (20500/59072)
2025-12-13 02:33:35,151 INFO     Evaluating the model... (21000/59072)
2025-12-13 02:33:38,099 INFO     Evaluating the model... (21500/59072)
2025-12-13 02:33:41,605 INFO     Evaluating the model... (22000/59072)
2025-12-13 02:33:44,537 INFO     Evaluating the model... (22500/59072)
2025-12-13 02:33:47,002 INFO     Evaluating the model... (23000/59072)
2025-12-13 02:33:49,597 INFO     Evaluating the model... (23500/59072)
2025-12-13 02:33:52,039 INFO     Evaluating the model... (24000/59072)
2025-12-13 02:33:55,320 INFO     Evaluating the model... (24500/59072)
2025-12-13 02:33:57,717 INFO     Evaluating the model... (25000/59072)
2025-12-13 02:34:00,425 INFO     Evaluating the model... (25500/59072)
2025-12-13 02:34:03,048 INFO     Evaluating the model... (26000/59072)
2025-12-13 02:34:05,490 INFO     Evaluating the model... (26500/59072)
2025-12-13 02:34:09,158 INFO     Evaluating the model... (27000/59072)
2025-12-13 02:34:11,803 INFO     Evaluating the model... (27500/59072)
2025-12-13 02:34:14,529 INFO     Evaluating the model... (28000/59072)
2025-12-13 02:34:17,042 INFO     Evaluating the model... (28500/59072)
2025-12-13 02:34:19,444 INFO     Evaluating the model... (29000/59072)
2025-12-13 02:34:23,076 INFO     Evaluating the model... (29500/59072)
2025-12-13 02:34:25,936 INFO     Evaluating the model... (30000/59072)
2025-12-13 02:34:28,403 INFO     Evaluating the model... (30500/59072)
2025-12-13 02:34:30,935 INFO     Evaluating the model... (31000/59072)
2025-12-13 02:34:33,477 INFO     Evaluating the model... (31500/59072)
2025-12-13 02:34:37,323 INFO     Evaluating the model... (32000/59072)
2025-12-13 02:34:40,040 INFO     Evaluating the model... (32500/59072)
2025-12-13 02:34:42,789 INFO     Evaluating the model... (33000/59072)
2025-12-13 02:34:45,607 INFO     Evaluating the model... (33500/59072)
2025-12-13 02:34:48,284 INFO     Evaluating the model... (34000/59072)
2025-12-13 02:34:51,505 INFO     Evaluating the model... (34500/59072)
2025-12-13 02:34:53,917 INFO     Evaluating the model... (35000/59072)
2025-12-13 02:34:56,444 INFO     Evaluating the model... (35500/59072)
2025-12-13 02:34:59,271 INFO     Evaluating the model... (36000/59072)
2025-12-13 02:35:02,623 INFO     Evaluating the model... (36500/59072)
2025-12-13 02:35:05,142 INFO     Evaluating the model... (37000/59072)
2025-12-13 02:35:07,724 INFO     Evaluating the model... (37500/59072)
2025-12-13 02:35:10,465 INFO     Evaluating the model... (38000/59072)
2025-12-13 02:35:12,970 INFO     Evaluating the model... (38500/59072)
2025-12-13 02:35:16,547 INFO     Evaluating the model... (39000/59072)
2025-12-13 02:35:18,949 INFO     Evaluating the model... (39500/59072)
2025-12-13 02:35:21,630 INFO     Evaluating the model... (40000/59072)
2025-12-13 02:35:24,088 INFO     Evaluating the model... (40500/59072)
2025-12-13 02:35:26,607 INFO     Evaluating the model... (41000/59072)
2025-12-13 02:35:29,891 INFO     Evaluating the model... (41500/59072)
2025-12-13 02:35:32,338 INFO     Evaluating the model... (42000/59072)
2025-12-13 02:35:34,986 INFO     Evaluating the model... (42500/59072)
2025-12-13 02:35:37,672 INFO     Evaluating the model... (43000/59072)
2025-12-13 02:35:40,376 INFO     Evaluating the model... (43500/59072)
2025-12-13 02:35:44,141 INFO     Evaluating the model... (44000/59072)
2025-12-13 02:35:46,892 INFO     Evaluating the model... (44500/59072)
2025-12-13 02:35:49,330 INFO     Evaluating the model... (45000/59072)
2025-12-13 02:35:51,776 INFO     Evaluating the model... (45500/59072)
2025-12-13 02:35:54,237 INFO     Evaluating the model... (46000/59072)
2025-12-13 02:35:57,573 INFO     Evaluating the model... (46500/59072)
2025-12-13 02:36:00,096 INFO     Evaluating the model... (47000/59072)
2025-12-13 02:36:02,541 INFO     Evaluating the model... (47500/59072)
2025-12-13 02:36:05,081 INFO     Evaluating the model... (48000/59072)
2025-12-13 02:36:07,690 INFO     Evaluating the model... (48500/59072)
2025-12-13 02:36:11,008 INFO     Evaluating the model... (49000/59072)
2025-12-13 02:36:13,490 INFO     Evaluating the model... (49500/59072)
2025-12-13 02:36:16,096 INFO     Evaluating the model... (50000/59072)
2025-12-13 02:36:18,591 INFO     Evaluating the model... (50500/59072)
2025-12-13 02:36:21,283 INFO     Evaluating the model... (51000/59072)
2025-12-13 02:36:24,745 INFO     Evaluating the model... (51500/59072)
2025-12-13 02:36:27,311 INFO     Evaluating the model... (52000/59072)
2025-12-13 02:36:29,815 INFO     Evaluating the model... (52500/59072)
2025-12-13 02:36:32,386 INFO     Evaluating the model... (53000/59072)
2025-12-13 02:36:34,839 INFO     Evaluating the model... (53500/59072)
2025-12-13 02:36:38,507 INFO     Evaluating the model... (54000/59072)
2025-12-13 02:36:41,222 INFO     Evaluating the model... (54500/59072)
2025-12-13 02:36:44,184 INFO     Evaluating the model... (55000/59072)
2025-12-13 02:36:46,865 INFO     Evaluating the model... (55500/59072)
2025-12-13 02:36:50,588 INFO     Evaluating the model... (56000/59072)
2025-12-13 02:36:52,987 INFO     Evaluating the model... (56500/59072)
2025-12-13 02:36:55,691 INFO     Evaluating the model... (57000/59072)
2025-12-13 02:36:58,267 INFO     Evaluating the model... (57500/59072)
2025-12-13 02:37:00,854 INFO     Evaluating the model... (58000/59072)
2025-12-13 02:37:04,524 INFO     Evaluating the model... (58500/59072)
2025-12-13 02:37:07,228 INFO     Evaluating the model... (59000/59072)
2025-12-13 02:37:07,864 INFO     Test MRR at step 140000: 0.629264
2025-12-13 02:37:07,864 INFO     Test MR at step 140000: 268.229910
2025-12-13 02:37:07,864 INFO     Test HITS@1 at step 140000: 0.541941
2025-12-13 02:37:07,864 INFO     Test HITS@3 at step 140000: 0.683762
2025-12-13 02:37:07,864 INFO     Test HITS@10 at step 140000: 0.782778
2025-12-13 02:37:10,010 INFO     Training average regularization at step 140100: 0.302222
2025-12-13 02:37:10,010 INFO     Training average positive_sample_loss at step 140100: 0.066442
2025-12-13 02:37:10,010 INFO     Training average negative_sample_loss at step 140100: 0.107940
2025-12-13 02:37:10,010 INFO     Training average loss at step 140100: 0.389413
2025-12-13 02:37:13,145 INFO     Training average regularization at step 140200: 0.302222
2025-12-13 02:37:13,146 INFO     Training average positive_sample_loss at step 140200: 0.065196
2025-12-13 02:37:13,146 INFO     Training average negative_sample_loss at step 140200: 0.109503
2025-12-13 02:37:13,146 INFO     Training average loss at step 140200: 0.389571
2025-12-13 02:37:15,313 INFO     Training average regularization at step 140300: 0.302221
2025-12-13 02:37:15,315 INFO     Training average positive_sample_loss at step 140300: 0.067241
2025-12-13 02:37:15,315 INFO     Training average negative_sample_loss at step 140300: 0.108176
2025-12-13 02:37:15,315 INFO     Training average loss at step 140300: 0.389929
2025-12-13 02:37:17,479 INFO     Training average regularization at step 140400: 0.302220
2025-12-13 02:37:17,479 INFO     Training average positive_sample_loss at step 140400: 0.066975
2025-12-13 02:37:17,479 INFO     Training average negative_sample_loss at step 140400: 0.109566
2025-12-13 02:37:17,479 INFO     Training average loss at step 140400: 0.390491
2025-12-13 02:37:19,639 INFO     Training average regularization at step 140500: 0.302219
2025-12-13 02:37:19,639 INFO     Training average positive_sample_loss at step 140500: 0.066095
2025-12-13 02:37:19,639 INFO     Training average negative_sample_loss at step 140500: 0.111249
2025-12-13 02:37:19,639 INFO     Training average loss at step 140500: 0.390891
2025-12-13 02:37:21,820 INFO     Training average regularization at step 140600: 0.302219
2025-12-13 02:37:21,821 INFO     Training average positive_sample_loss at step 140600: 0.067364
2025-12-13 02:37:21,821 INFO     Training average negative_sample_loss at step 140600: 0.109713
2025-12-13 02:37:21,821 INFO     Training average loss at step 140600: 0.390757
2025-12-13 02:37:24,000 INFO     Training average regularization at step 140700: 0.302218
2025-12-13 02:37:24,000 INFO     Training average positive_sample_loss at step 140700: 0.066722
2025-12-13 02:37:24,000 INFO     Training average negative_sample_loss at step 140700: 0.106320
2025-12-13 02:37:24,000 INFO     Training average loss at step 140700: 0.388739
2025-12-13 02:37:26,158 INFO     Training average regularization at step 140800: 0.302217
2025-12-13 02:37:26,158 INFO     Training average positive_sample_loss at step 140800: 0.066540
2025-12-13 02:37:26,158 INFO     Training average negative_sample_loss at step 140800: 0.106630
2025-12-13 02:37:26,158 INFO     Training average loss at step 140800: 0.388802
2025-12-13 02:37:28,329 INFO     Training average regularization at step 140900: 0.302216
2025-12-13 02:37:28,329 INFO     Training average positive_sample_loss at step 140900: 0.065820
2025-12-13 02:37:28,329 INFO     Training average negative_sample_loss at step 140900: 0.108847
2025-12-13 02:37:28,329 INFO     Training average loss at step 140900: 0.389550
2025-12-13 02:37:30,486 INFO     Training average regularization at step 141000: 0.302216
2025-12-13 02:37:30,486 INFO     Training average positive_sample_loss at step 141000: 0.066770
2025-12-13 02:37:30,486 INFO     Training average negative_sample_loss at step 141000: 0.110434
2025-12-13 02:37:30,486 INFO     Training average loss at step 141000: 0.390818
2025-12-13 02:37:32,638 INFO     Training average regularization at step 141100: 0.302215
2025-12-13 02:37:32,639 INFO     Training average positive_sample_loss at step 141100: 0.065921
2025-12-13 02:37:32,640 INFO     Training average negative_sample_loss at step 141100: 0.110231
2025-12-13 02:37:32,640 INFO     Training average loss at step 141100: 0.390291
2025-12-13 02:37:34,786 INFO     Training average regularization at step 141200: 0.302215
2025-12-13 02:37:34,786 INFO     Training average positive_sample_loss at step 141200: 0.068217
2025-12-13 02:37:34,786 INFO     Training average negative_sample_loss at step 141200: 0.110556
2025-12-13 02:37:34,786 INFO     Training average loss at step 141200: 0.391601
2025-12-13 02:37:36,979 INFO     Training average regularization at step 141300: 0.302214
2025-12-13 02:37:36,979 INFO     Training average positive_sample_loss at step 141300: 0.066364
2025-12-13 02:37:36,979 INFO     Training average negative_sample_loss at step 141300: 0.109309
2025-12-13 02:37:36,979 INFO     Training average loss at step 141300: 0.390050
2025-12-13 02:37:39,188 INFO     Training average regularization at step 141400: 0.302213
2025-12-13 02:37:39,191 INFO     Training average positive_sample_loss at step 141400: 0.067032
2025-12-13 02:37:39,191 INFO     Training average negative_sample_loss at step 141400: 0.108111
2025-12-13 02:37:39,191 INFO     Training average loss at step 141400: 0.389785
2025-12-13 02:37:41,416 INFO     Training average regularization at step 141500: 0.302213
2025-12-13 02:37:41,416 INFO     Training average positive_sample_loss at step 141500: 0.067073
2025-12-13 02:37:41,416 INFO     Training average negative_sample_loss at step 141500: 0.112750
2025-12-13 02:37:41,416 INFO     Training average loss at step 141500: 0.392124
2025-12-13 02:37:43,589 INFO     Training average regularization at step 141600: 0.302212
2025-12-13 02:37:43,589 INFO     Training average positive_sample_loss at step 141600: 0.067048
2025-12-13 02:37:43,589 INFO     Training average negative_sample_loss at step 141600: 0.107992
2025-12-13 02:37:43,589 INFO     Training average loss at step 141600: 0.389732
2025-12-13 02:37:45,767 INFO     Training average regularization at step 141700: 0.302212
2025-12-13 02:37:45,768 INFO     Training average positive_sample_loss at step 141700: 0.066840
2025-12-13 02:37:45,768 INFO     Training average negative_sample_loss at step 141700: 0.108228
2025-12-13 02:37:45,768 INFO     Training average loss at step 141700: 0.389745
2025-12-13 02:37:47,933 INFO     Training average regularization at step 141800: 0.302211
2025-12-13 02:37:47,933 INFO     Training average positive_sample_loss at step 141800: 0.066532
2025-12-13 02:37:47,933 INFO     Training average negative_sample_loss at step 141800: 0.111190
2025-12-13 02:37:47,933 INFO     Training average loss at step 141800: 0.391072
2025-12-13 02:37:50,119 INFO     Training average regularization at step 141900: 0.302210
2025-12-13 02:37:50,119 INFO     Training average positive_sample_loss at step 141900: 0.067085
2025-12-13 02:37:50,119 INFO     Training average negative_sample_loss at step 141900: 0.107421
2025-12-13 02:37:50,119 INFO     Training average loss at step 141900: 0.389463
2025-12-13 02:37:52,281 INFO     Training average regularization at step 142000: 0.302210
2025-12-13 02:37:52,282 INFO     Training average positive_sample_loss at step 142000: 0.066404
2025-12-13 02:37:52,282 INFO     Training average negative_sample_loss at step 142000: 0.110462
2025-12-13 02:37:52,282 INFO     Training average loss at step 142000: 0.390643
2025-12-13 02:37:54,453 INFO     Training average regularization at step 142100: 0.302209
2025-12-13 02:37:54,453 INFO     Training average positive_sample_loss at step 142100: 0.066788
2025-12-13 02:37:54,453 INFO     Training average negative_sample_loss at step 142100: 0.108728
2025-12-13 02:37:54,453 INFO     Training average loss at step 142100: 0.389967
2025-12-13 02:37:56,599 INFO     Training average regularization at step 142200: 0.302208
2025-12-13 02:37:56,599 INFO     Training average positive_sample_loss at step 142200: 0.067277
2025-12-13 02:37:56,599 INFO     Training average negative_sample_loss at step 142200: 0.111996
2025-12-13 02:37:56,599 INFO     Training average loss at step 142200: 0.391845
2025-12-13 02:37:58,753 INFO     Training average regularization at step 142300: 0.302208
2025-12-13 02:37:58,753 INFO     Training average positive_sample_loss at step 142300: 0.067304
2025-12-13 02:37:58,754 INFO     Training average negative_sample_loss at step 142300: 0.110296
2025-12-13 02:37:58,754 INFO     Training average loss at step 142300: 0.391008
2025-12-13 02:38:00,940 INFO     Training average regularization at step 142400: 0.302207
2025-12-13 02:38:00,940 INFO     Training average positive_sample_loss at step 142400: 0.067064
2025-12-13 02:38:00,940 INFO     Training average negative_sample_loss at step 142400: 0.108776
2025-12-13 02:38:00,940 INFO     Training average loss at step 142400: 0.390127
2025-12-13 02:38:03,082 INFO     Training average regularization at step 142500: 0.302207
2025-12-13 02:38:03,082 INFO     Training average positive_sample_loss at step 142500: 0.066841
2025-12-13 02:38:03,082 INFO     Training average negative_sample_loss at step 142500: 0.105392
2025-12-13 02:38:03,082 INFO     Training average loss at step 142500: 0.388323
2025-12-13 02:38:05,229 INFO     Training average regularization at step 142600: 0.302206
2025-12-13 02:38:05,229 INFO     Training average positive_sample_loss at step 142600: 0.067005
2025-12-13 02:38:05,229 INFO     Training average negative_sample_loss at step 142600: 0.109857
2025-12-13 02:38:05,229 INFO     Training average loss at step 142600: 0.390637
2025-12-13 02:38:07,375 INFO     Training average regularization at step 142700: 0.302205
2025-12-13 02:38:07,376 INFO     Training average positive_sample_loss at step 142700: 0.065968
2025-12-13 02:38:07,376 INFO     Training average negative_sample_loss at step 142700: 0.108332
2025-12-13 02:38:07,377 INFO     Training average loss at step 142700: 0.389355
2025-12-13 02:38:09,537 INFO     Training average regularization at step 142800: 0.302205
2025-12-13 02:38:09,537 INFO     Training average positive_sample_loss at step 142800: 0.066540
2025-12-13 02:38:09,537 INFO     Training average negative_sample_loss at step 142800: 0.110775
2025-12-13 02:38:09,537 INFO     Training average loss at step 142800: 0.390862
2025-12-13 02:38:11,713 INFO     Training average regularization at step 142900: 0.302204
2025-12-13 02:38:11,714 INFO     Training average positive_sample_loss at step 142900: 0.067039
2025-12-13 02:38:11,714 INFO     Training average negative_sample_loss at step 142900: 0.108445
2025-12-13 02:38:11,714 INFO     Training average loss at step 142900: 0.389946
2025-12-13 02:38:13,861 INFO     Training average regularization at step 143000: 0.302204
2025-12-13 02:38:13,864 INFO     Training average positive_sample_loss at step 143000: 0.067468
2025-12-13 02:38:13,864 INFO     Training average negative_sample_loss at step 143000: 0.105608
2025-12-13 02:38:13,864 INFO     Training average loss at step 143000: 0.388741
2025-12-13 02:38:16,001 INFO     Training average regularization at step 143100: 0.302203
2025-12-13 02:38:16,001 INFO     Training average positive_sample_loss at step 143100: 0.066185
2025-12-13 02:38:16,001 INFO     Training average negative_sample_loss at step 143100: 0.107675
2025-12-13 02:38:16,001 INFO     Training average loss at step 143100: 0.389133
2025-12-13 02:38:18,127 INFO     Training average regularization at step 143200: 0.302202
2025-12-13 02:38:18,127 INFO     Training average positive_sample_loss at step 143200: 0.066574
2025-12-13 02:38:18,127 INFO     Training average negative_sample_loss at step 143200: 0.107983
2025-12-13 02:38:18,127 INFO     Training average loss at step 143200: 0.389481
2025-12-13 02:38:20,262 INFO     Training average regularization at step 143300: 0.302202
2025-12-13 02:38:20,262 INFO     Training average positive_sample_loss at step 143300: 0.066022
2025-12-13 02:38:20,262 INFO     Training average negative_sample_loss at step 143300: 0.108900
2025-12-13 02:38:20,262 INFO     Training average loss at step 143300: 0.389663
2025-12-13 02:38:22,441 INFO     Training average regularization at step 143400: 0.302201
2025-12-13 02:38:22,441 INFO     Training average positive_sample_loss at step 143400: 0.066511
2025-12-13 02:38:22,441 INFO     Training average negative_sample_loss at step 143400: 0.107052
2025-12-13 02:38:22,441 INFO     Training average loss at step 143400: 0.388983
2025-12-13 02:38:24,612 INFO     Training average regularization at step 143500: 0.302201
2025-12-13 02:38:24,612 INFO     Training average positive_sample_loss at step 143500: 0.065752
2025-12-13 02:38:24,612 INFO     Training average negative_sample_loss at step 143500: 0.108239
2025-12-13 02:38:24,612 INFO     Training average loss at step 143500: 0.389197
2025-12-13 02:38:26,770 INFO     Training average regularization at step 143600: 0.302200
2025-12-13 02:38:26,771 INFO     Training average positive_sample_loss at step 143600: 0.066470
2025-12-13 02:38:26,771 INFO     Training average negative_sample_loss at step 143600: 0.108294
2025-12-13 02:38:26,771 INFO     Training average loss at step 143600: 0.389583
2025-12-13 02:38:28,913 INFO     Training average regularization at step 143700: 0.302200
2025-12-13 02:38:28,913 INFO     Training average positive_sample_loss at step 143700: 0.067488
2025-12-13 02:38:28,914 INFO     Training average negative_sample_loss at step 143700: 0.109685
2025-12-13 02:38:28,914 INFO     Training average loss at step 143700: 0.390786
2025-12-13 02:38:31,068 INFO     Training average regularization at step 143800: 0.302199
2025-12-13 02:38:31,069 INFO     Training average positive_sample_loss at step 143800: 0.067933
2025-12-13 02:38:31,069 INFO     Training average negative_sample_loss at step 143800: 0.109837
2025-12-13 02:38:31,069 INFO     Training average loss at step 143800: 0.391084
2025-12-13 02:38:33,225 INFO     Training average regularization at step 143900: 0.302199
2025-12-13 02:38:33,226 INFO     Training average positive_sample_loss at step 143900: 0.067840
2025-12-13 02:38:33,226 INFO     Training average negative_sample_loss at step 143900: 0.111371
2025-12-13 02:38:33,226 INFO     Training average loss at step 143900: 0.391804
2025-12-13 02:38:35,381 INFO     Training average regularization at step 144000: 0.302198
2025-12-13 02:38:35,381 INFO     Training average positive_sample_loss at step 144000: 0.066395
2025-12-13 02:38:35,381 INFO     Training average negative_sample_loss at step 144000: 0.109892
2025-12-13 02:38:35,381 INFO     Training average loss at step 144000: 0.390342
2025-12-13 02:38:37,553 INFO     Training average regularization at step 144100: 0.302198
2025-12-13 02:38:37,554 INFO     Training average positive_sample_loss at step 144100: 0.066016
2025-12-13 02:38:37,554 INFO     Training average negative_sample_loss at step 144100: 0.107677
2025-12-13 02:38:37,554 INFO     Training average loss at step 144100: 0.389045
2025-12-13 02:38:39,730 INFO     Training average regularization at step 144200: 0.302197
2025-12-13 02:38:39,731 INFO     Training average positive_sample_loss at step 144200: 0.066956
2025-12-13 02:38:39,731 INFO     Training average negative_sample_loss at step 144200: 0.115007
2025-12-13 02:38:39,731 INFO     Training average loss at step 144200: 0.393179
2025-12-13 02:38:41,912 INFO     Training average regularization at step 144300: 0.302196
2025-12-13 02:38:41,912 INFO     Training average positive_sample_loss at step 144300: 0.067906
2025-12-13 02:38:41,912 INFO     Training average negative_sample_loss at step 144300: 0.109993
2025-12-13 02:38:41,912 INFO     Training average loss at step 144300: 0.391146
2025-12-13 02:38:44,096 INFO     Training average regularization at step 144400: 0.302196
2025-12-13 02:38:44,096 INFO     Training average positive_sample_loss at step 144400: 0.066270
2025-12-13 02:38:44,096 INFO     Training average negative_sample_loss at step 144400: 0.108540
2025-12-13 02:38:44,096 INFO     Training average loss at step 144400: 0.389601
2025-12-13 02:38:46,270 INFO     Training average regularization at step 144500: 0.302196
2025-12-13 02:38:46,270 INFO     Training average positive_sample_loss at step 144500: 0.067539
2025-12-13 02:38:46,270 INFO     Training average negative_sample_loss at step 144500: 0.109313
2025-12-13 02:38:46,270 INFO     Training average loss at step 144500: 0.390621
2025-12-13 02:38:48,406 INFO     Training average regularization at step 144600: 0.302195
2025-12-13 02:38:48,407 INFO     Training average positive_sample_loss at step 144600: 0.066130
2025-12-13 02:38:48,407 INFO     Training average negative_sample_loss at step 144600: 0.108282
2025-12-13 02:38:48,407 INFO     Training average loss at step 144600: 0.389401
2025-12-13 02:38:50,559 INFO     Training average regularization at step 144700: 0.302194
2025-12-13 02:38:50,559 INFO     Training average positive_sample_loss at step 144700: 0.067120
2025-12-13 02:38:50,559 INFO     Training average negative_sample_loss at step 144700: 0.109081
2025-12-13 02:38:50,559 INFO     Training average loss at step 144700: 0.390295
2025-12-13 02:38:52,707 INFO     Training average regularization at step 144800: 0.302194
2025-12-13 02:38:52,707 INFO     Training average positive_sample_loss at step 144800: 0.066956
2025-12-13 02:38:52,707 INFO     Training average negative_sample_loss at step 144800: 0.109215
2025-12-13 02:38:52,707 INFO     Training average loss at step 144800: 0.390279
2025-12-13 02:38:54,858 INFO     Training average regularization at step 144900: 0.302193
2025-12-13 02:38:54,858 INFO     Training average positive_sample_loss at step 144900: 0.066511
2025-12-13 02:38:54,858 INFO     Training average negative_sample_loss at step 144900: 0.107840
2025-12-13 02:38:54,858 INFO     Training average loss at step 144900: 0.389369
2025-12-13 02:38:58,149 INFO     Training average regularization at step 145000: 0.302193
2025-12-13 02:38:58,149 INFO     Training average positive_sample_loss at step 145000: 0.067513
2025-12-13 02:38:58,149 INFO     Training average negative_sample_loss at step 145000: 0.109127
2025-12-13 02:38:58,149 INFO     Training average loss at step 145000: 0.390513
2025-12-13 02:39:00,293 INFO     Training average regularization at step 145100: 0.302192
2025-12-13 02:39:00,294 INFO     Training average positive_sample_loss at step 145100: 0.066321
2025-12-13 02:39:00,294 INFO     Training average negative_sample_loss at step 145100: 0.107357
2025-12-13 02:39:00,294 INFO     Training average loss at step 145100: 0.389031
2025-12-13 02:39:02,438 INFO     Training average regularization at step 145200: 0.302191
2025-12-13 02:39:02,438 INFO     Training average positive_sample_loss at step 145200: 0.065980
2025-12-13 02:39:02,438 INFO     Training average negative_sample_loss at step 145200: 0.108124
2025-12-13 02:39:02,438 INFO     Training average loss at step 145200: 0.389243
2025-12-13 02:39:04,583 INFO     Training average regularization at step 145300: 0.302190
2025-12-13 02:39:04,583 INFO     Training average positive_sample_loss at step 145300: 0.067735
2025-12-13 02:39:04,583 INFO     Training average negative_sample_loss at step 145300: 0.109182
2025-12-13 02:39:04,583 INFO     Training average loss at step 145300: 0.390649
2025-12-13 02:39:06,757 INFO     Training average regularization at step 145400: 0.302190
2025-12-13 02:39:06,757 INFO     Training average positive_sample_loss at step 145400: 0.067248
2025-12-13 02:39:06,757 INFO     Training average negative_sample_loss at step 145400: 0.108480
2025-12-13 02:39:06,757 INFO     Training average loss at step 145400: 0.390054
2025-12-13 02:39:08,911 INFO     Training average regularization at step 145500: 0.302189
2025-12-13 02:39:08,911 INFO     Training average positive_sample_loss at step 145500: 0.067203
2025-12-13 02:39:08,911 INFO     Training average negative_sample_loss at step 145500: 0.108707
2025-12-13 02:39:08,911 INFO     Training average loss at step 145500: 0.390144
2025-12-13 02:39:11,053 INFO     Training average regularization at step 145600: 0.302189
2025-12-13 02:39:11,053 INFO     Training average positive_sample_loss at step 145600: 0.066908
2025-12-13 02:39:11,053 INFO     Training average negative_sample_loss at step 145600: 0.106854
2025-12-13 02:39:11,053 INFO     Training average loss at step 145600: 0.389070
2025-12-13 02:39:13,210 INFO     Training average regularization at step 145700: 0.302188
2025-12-13 02:39:13,210 INFO     Training average positive_sample_loss at step 145700: 0.065888
2025-12-13 02:39:13,210 INFO     Training average negative_sample_loss at step 145700: 0.106973
2025-12-13 02:39:13,210 INFO     Training average loss at step 145700: 0.388618
2025-12-13 02:39:15,359 INFO     Training average regularization at step 145800: 0.302187
2025-12-13 02:39:15,359 INFO     Training average positive_sample_loss at step 145800: 0.067595
2025-12-13 02:39:15,359 INFO     Training average negative_sample_loss at step 145800: 0.108810
2025-12-13 02:39:15,359 INFO     Training average loss at step 145800: 0.390390
2025-12-13 02:39:17,529 INFO     Training average regularization at step 145900: 0.302187
2025-12-13 02:39:17,529 INFO     Training average positive_sample_loss at step 145900: 0.066093
2025-12-13 02:39:17,529 INFO     Training average negative_sample_loss at step 145900: 0.110929
2025-12-13 02:39:17,529 INFO     Training average loss at step 145900: 0.390698
2025-12-13 02:39:19,677 INFO     Training average regularization at step 146000: 0.302186
2025-12-13 02:39:19,677 INFO     Training average positive_sample_loss at step 146000: 0.067290
2025-12-13 02:39:19,677 INFO     Training average negative_sample_loss at step 146000: 0.108384
2025-12-13 02:39:19,678 INFO     Training average loss at step 146000: 0.390023
2025-12-13 02:39:21,817 INFO     Training average regularization at step 146100: 0.302186
2025-12-13 02:39:21,818 INFO     Training average positive_sample_loss at step 146100: 0.066949
2025-12-13 02:39:21,818 INFO     Training average negative_sample_loss at step 146100: 0.110388
2025-12-13 02:39:21,818 INFO     Training average loss at step 146100: 0.390854
2025-12-13 02:39:23,959 INFO     Training average regularization at step 146200: 0.302185
2025-12-13 02:39:23,959 INFO     Training average positive_sample_loss at step 146200: 0.065631
2025-12-13 02:39:23,959 INFO     Training average negative_sample_loss at step 146200: 0.109709
2025-12-13 02:39:23,959 INFO     Training average loss at step 146200: 0.389855
2025-12-13 02:39:26,134 INFO     Training average regularization at step 146300: 0.302184
2025-12-13 02:39:26,137 INFO     Training average positive_sample_loss at step 146300: 0.066162
2025-12-13 02:39:26,137 INFO     Training average negative_sample_loss at step 146300: 0.111416
2025-12-13 02:39:26,137 INFO     Training average loss at step 146300: 0.390973
2025-12-13 02:39:28,332 INFO     Training average regularization at step 146400: 0.302183
2025-12-13 02:39:28,332 INFO     Training average positive_sample_loss at step 146400: 0.066883
2025-12-13 02:39:28,332 INFO     Training average negative_sample_loss at step 146400: 0.109972
2025-12-13 02:39:28,332 INFO     Training average loss at step 146400: 0.390611
2025-12-13 02:39:30,493 INFO     Training average regularization at step 146500: 0.302183
2025-12-13 02:39:30,493 INFO     Training average positive_sample_loss at step 146500: 0.065625
2025-12-13 02:39:30,493 INFO     Training average negative_sample_loss at step 146500: 0.107150
2025-12-13 02:39:30,493 INFO     Training average loss at step 146500: 0.388570
2025-12-13 02:39:32,668 INFO     Training average regularization at step 146600: 0.302182
2025-12-13 02:39:32,668 INFO     Training average positive_sample_loss at step 146600: 0.065677
2025-12-13 02:39:32,668 INFO     Training average negative_sample_loss at step 146600: 0.107844
2025-12-13 02:39:32,668 INFO     Training average loss at step 146600: 0.388942
2025-12-13 02:39:34,833 INFO     Training average regularization at step 146700: 0.302181
2025-12-13 02:39:34,834 INFO     Training average positive_sample_loss at step 146700: 0.066322
2025-12-13 02:39:34,834 INFO     Training average negative_sample_loss at step 146700: 0.109842
2025-12-13 02:39:34,834 INFO     Training average loss at step 146700: 0.390263
2025-12-13 02:39:37,030 INFO     Training average regularization at step 146800: 0.302180
2025-12-13 02:39:37,031 INFO     Training average positive_sample_loss at step 146800: 0.067100
2025-12-13 02:39:37,031 INFO     Training average negative_sample_loss at step 146800: 0.108329
2025-12-13 02:39:37,031 INFO     Training average loss at step 146800: 0.389895
2025-12-13 02:39:39,232 INFO     Training average regularization at step 146900: 0.302180
2025-12-13 02:39:39,232 INFO     Training average positive_sample_loss at step 146900: 0.067436
2025-12-13 02:39:39,233 INFO     Training average negative_sample_loss at step 146900: 0.110501
2025-12-13 02:39:39,233 INFO     Training average loss at step 146900: 0.391149
2025-12-13 02:39:41,454 INFO     Training average regularization at step 147000: 0.302179
2025-12-13 02:39:41,454 INFO     Training average positive_sample_loss at step 147000: 0.068256
2025-12-13 02:39:41,454 INFO     Training average negative_sample_loss at step 147000: 0.108253
2025-12-13 02:39:41,454 INFO     Training average loss at step 147000: 0.390434
2025-12-13 02:39:43,659 INFO     Training average regularization at step 147100: 0.302179
2025-12-13 02:39:43,660 INFO     Training average positive_sample_loss at step 147100: 0.067400
2025-12-13 02:39:43,660 INFO     Training average negative_sample_loss at step 147100: 0.110021
2025-12-13 02:39:43,660 INFO     Training average loss at step 147100: 0.390890
2025-12-13 02:39:45,837 INFO     Training average regularization at step 147200: 0.302178
2025-12-13 02:39:45,837 INFO     Training average positive_sample_loss at step 147200: 0.066587
2025-12-13 02:39:45,837 INFO     Training average negative_sample_loss at step 147200: 0.110121
2025-12-13 02:39:45,837 INFO     Training average loss at step 147200: 0.390533
2025-12-13 02:39:48,037 INFO     Training average regularization at step 147300: 0.302178
2025-12-13 02:39:48,038 INFO     Training average positive_sample_loss at step 147300: 0.067349
2025-12-13 02:39:48,038 INFO     Training average negative_sample_loss at step 147300: 0.109891
2025-12-13 02:39:48,038 INFO     Training average loss at step 147300: 0.390798
2025-12-13 02:39:50,204 INFO     Training average regularization at step 147400: 0.302177
2025-12-13 02:39:50,204 INFO     Training average positive_sample_loss at step 147400: 0.067201
2025-12-13 02:39:50,204 INFO     Training average negative_sample_loss at step 147400: 0.110061
2025-12-13 02:39:50,204 INFO     Training average loss at step 147400: 0.390808
2025-12-13 02:39:52,393 INFO     Training average regularization at step 147500: 0.302177
2025-12-13 02:39:52,393 INFO     Training average positive_sample_loss at step 147500: 0.065926
2025-12-13 02:39:52,393 INFO     Training average negative_sample_loss at step 147500: 0.108113
2025-12-13 02:39:52,393 INFO     Training average loss at step 147500: 0.389196
2025-12-13 02:39:54,557 INFO     Training average regularization at step 147600: 0.302176
2025-12-13 02:39:54,557 INFO     Training average positive_sample_loss at step 147600: 0.065579
2025-12-13 02:39:54,557 INFO     Training average negative_sample_loss at step 147600: 0.107421
2025-12-13 02:39:54,557 INFO     Training average loss at step 147600: 0.388676
2025-12-13 02:39:56,733 INFO     Training average regularization at step 147700: 0.302175
2025-12-13 02:39:56,735 INFO     Training average positive_sample_loss at step 147700: 0.066124
2025-12-13 02:39:56,735 INFO     Training average negative_sample_loss at step 147700: 0.110477
2025-12-13 02:39:56,735 INFO     Training average loss at step 147700: 0.390476
2025-12-13 02:39:58,903 INFO     Training average regularization at step 147800: 0.302175
2025-12-13 02:39:58,904 INFO     Training average positive_sample_loss at step 147800: 0.068274
2025-12-13 02:39:58,904 INFO     Training average negative_sample_loss at step 147800: 0.110069
2025-12-13 02:39:58,904 INFO     Training average loss at step 147800: 0.391346
2025-12-13 02:40:01,059 INFO     Training average regularization at step 147900: 0.302174
2025-12-13 02:40:01,059 INFO     Training average positive_sample_loss at step 147900: 0.065948
2025-12-13 02:40:01,059 INFO     Training average negative_sample_loss at step 147900: 0.110357
2025-12-13 02:40:01,059 INFO     Training average loss at step 147900: 0.390327
2025-12-13 02:40:03,247 INFO     Training average regularization at step 148000: 0.302173
2025-12-13 02:40:03,247 INFO     Training average positive_sample_loss at step 148000: 0.065945
2025-12-13 02:40:03,247 INFO     Training average negative_sample_loss at step 148000: 0.109455
2025-12-13 02:40:03,247 INFO     Training average loss at step 148000: 0.389873
2025-12-13 02:40:05,404 INFO     Training average regularization at step 148100: 0.302173
2025-12-13 02:40:05,404 INFO     Training average positive_sample_loss at step 148100: 0.066067
2025-12-13 02:40:05,404 INFO     Training average negative_sample_loss at step 148100: 0.108938
2025-12-13 02:40:05,404 INFO     Training average loss at step 148100: 0.389676
2025-12-13 02:40:07,565 INFO     Training average regularization at step 148200: 0.302172
2025-12-13 02:40:07,566 INFO     Training average positive_sample_loss at step 148200: 0.067358
2025-12-13 02:40:07,566 INFO     Training average negative_sample_loss at step 148200: 0.109525
2025-12-13 02:40:07,566 INFO     Training average loss at step 148200: 0.390614
2025-12-13 02:40:09,729 INFO     Training average regularization at step 148300: 0.302172
2025-12-13 02:40:09,729 INFO     Training average positive_sample_loss at step 148300: 0.066894
2025-12-13 02:40:09,729 INFO     Training average negative_sample_loss at step 148300: 0.107020
2025-12-13 02:40:09,729 INFO     Training average loss at step 148300: 0.389129
2025-12-13 02:40:11,894 INFO     Training average regularization at step 148400: 0.302171
2025-12-13 02:40:11,894 INFO     Training average positive_sample_loss at step 148400: 0.066916
2025-12-13 02:40:11,894 INFO     Training average negative_sample_loss at step 148400: 0.108145
2025-12-13 02:40:11,894 INFO     Training average loss at step 148400: 0.389702
2025-12-13 02:40:14,107 INFO     Training average regularization at step 148500: 0.302170
2025-12-13 02:40:14,108 INFO     Training average positive_sample_loss at step 148500: 0.066931
2025-12-13 02:40:14,108 INFO     Training average negative_sample_loss at step 148500: 0.110571
2025-12-13 02:40:14,108 INFO     Training average loss at step 148500: 0.390922
2025-12-13 02:40:16,270 INFO     Training average regularization at step 148600: 0.302170
2025-12-13 02:40:16,270 INFO     Training average positive_sample_loss at step 148600: 0.066745
2025-12-13 02:40:16,270 INFO     Training average negative_sample_loss at step 148600: 0.108026
2025-12-13 02:40:16,270 INFO     Training average loss at step 148600: 0.389555
2025-12-13 02:40:18,437 INFO     Training average regularization at step 148700: 0.302169
2025-12-13 02:40:18,438 INFO     Training average positive_sample_loss at step 148700: 0.066520
2025-12-13 02:40:18,438 INFO     Training average negative_sample_loss at step 148700: 0.108132
2025-12-13 02:40:18,438 INFO     Training average loss at step 148700: 0.389495
2025-12-13 02:40:20,591 INFO     Training average regularization at step 148800: 0.302169
2025-12-13 02:40:20,592 INFO     Training average positive_sample_loss at step 148800: 0.067251
2025-12-13 02:40:20,592 INFO     Training average negative_sample_loss at step 148800: 0.107841
2025-12-13 02:40:20,592 INFO     Training average loss at step 148800: 0.389715
2025-12-13 02:40:22,747 INFO     Training average regularization at step 148900: 0.302168
2025-12-13 02:40:22,747 INFO     Training average positive_sample_loss at step 148900: 0.066413
2025-12-13 02:40:22,748 INFO     Training average negative_sample_loss at step 148900: 0.110154
2025-12-13 02:40:22,748 INFO     Training average loss at step 148900: 0.390452
2025-12-13 02:40:24,945 INFO     Training average regularization at step 149000: 0.302167
2025-12-13 02:40:24,946 INFO     Training average positive_sample_loss at step 149000: 0.066738
2025-12-13 02:40:24,946 INFO     Training average negative_sample_loss at step 149000: 0.107972
2025-12-13 02:40:24,946 INFO     Training average loss at step 149000: 0.389522
2025-12-13 02:40:27,112 INFO     Training average regularization at step 149100: 0.302167
2025-12-13 02:40:27,113 INFO     Training average positive_sample_loss at step 149100: 0.066169
2025-12-13 02:40:27,113 INFO     Training average negative_sample_loss at step 149100: 0.107580
2025-12-13 02:40:27,113 INFO     Training average loss at step 149100: 0.389041
2025-12-13 02:40:29,268 INFO     Training average regularization at step 149200: 0.302166
2025-12-13 02:40:29,269 INFO     Training average positive_sample_loss at step 149200: 0.067196
2025-12-13 02:40:29,269 INFO     Training average negative_sample_loss at step 149200: 0.109560
2025-12-13 02:40:29,269 INFO     Training average loss at step 149200: 0.390544
2025-12-13 02:40:31,435 INFO     Training average regularization at step 149300: 0.302166
2025-12-13 02:40:31,436 INFO     Training average positive_sample_loss at step 149300: 0.066450
2025-12-13 02:40:31,436 INFO     Training average negative_sample_loss at step 149300: 0.108365
2025-12-13 02:40:31,436 INFO     Training average loss at step 149300: 0.389573
2025-12-13 02:40:33,601 INFO     Training average regularization at step 149400: 0.302165
2025-12-13 02:40:33,602 INFO     Training average positive_sample_loss at step 149400: 0.067498
2025-12-13 02:40:33,602 INFO     Training average negative_sample_loss at step 149400: 0.108920
2025-12-13 02:40:33,602 INFO     Training average loss at step 149400: 0.390374
2025-12-13 02:40:35,784 INFO     Training average regularization at step 149500: 0.302165
2025-12-13 02:40:35,784 INFO     Training average positive_sample_loss at step 149500: 0.066968
2025-12-13 02:40:35,784 INFO     Training average negative_sample_loss at step 149500: 0.107397
2025-12-13 02:40:35,784 INFO     Training average loss at step 149500: 0.389347
2025-12-13 02:40:37,970 INFO     Training average regularization at step 149600: 0.302164
2025-12-13 02:40:37,971 INFO     Training average positive_sample_loss at step 149600: 0.067627
2025-12-13 02:40:37,971 INFO     Training average negative_sample_loss at step 149600: 0.109974
2025-12-13 02:40:37,971 INFO     Training average loss at step 149600: 0.390965
2025-12-13 02:40:40,162 INFO     Training average regularization at step 149700: 0.302164
2025-12-13 02:40:40,162 INFO     Training average positive_sample_loss at step 149700: 0.067106
2025-12-13 02:40:40,162 INFO     Training average negative_sample_loss at step 149700: 0.108438
2025-12-13 02:40:40,162 INFO     Training average loss at step 149700: 0.389936
2025-12-13 02:40:43,717 INFO     Training average regularization at step 149800: 0.302163
2025-12-13 02:40:43,717 INFO     Training average positive_sample_loss at step 149800: 0.066140
2025-12-13 02:40:43,717 INFO     Training average negative_sample_loss at step 149800: 0.109223
2025-12-13 02:40:43,717 INFO     Training average loss at step 149800: 0.389845
2025-12-13 02:40:45,887 INFO     Training average regularization at step 149900: 0.302162
2025-12-13 02:40:45,887 INFO     Training average positive_sample_loss at step 149900: 0.066360
2025-12-13 02:40:45,888 INFO     Training average negative_sample_loss at step 149900: 0.107201
2025-12-13 02:40:45,888 INFO     Training average loss at step 149900: 0.388943
2025-12-13 02:40:48,063 INFO     Training average regularization at step 150000: 0.302162
2025-12-13 02:40:48,063 INFO     Training average positive_sample_loss at step 150000: 0.066784
2025-12-13 02:40:48,063 INFO     Training average negative_sample_loss at step 150000: 0.108328
2025-12-13 02:40:48,063 INFO     Training average loss at step 150000: 0.389718
2025-12-13 02:40:48,064 INFO     Evaluating on Valid Dataset...
2025-12-13 02:40:48,764 INFO     Evaluating the model... (0/50000)
2025-12-13 02:40:51,317 INFO     Evaluating the model... (500/50000)
2025-12-13 02:40:53,820 INFO     Evaluating the model... (1000/50000)
2025-12-13 02:40:57,082 INFO     Evaluating the model... (1500/50000)
2025-12-13 02:40:59,752 INFO     Evaluating the model... (2000/50000)
2025-12-13 02:41:02,094 INFO     Evaluating the model... (2500/50000)
2025-12-13 02:41:04,510 INFO     Evaluating the model... (3000/50000)
2025-12-13 02:41:07,115 INFO     Evaluating the model... (3500/50000)
2025-12-13 02:41:10,337 INFO     Evaluating the model... (4000/50000)
2025-12-13 02:41:12,747 INFO     Evaluating the model... (4500/50000)
2025-12-13 02:41:15,180 INFO     Evaluating the model... (5000/50000)
2025-12-13 02:41:17,564 INFO     Evaluating the model... (5500/50000)
2025-12-13 02:41:20,078 INFO     Evaluating the model... (6000/50000)
2025-12-13 02:41:23,389 INFO     Evaluating the model... (6500/50000)
2025-12-13 02:41:25,872 INFO     Evaluating the model... (7000/50000)
2025-12-13 02:41:28,417 INFO     Evaluating the model... (7500/50000)
2025-12-13 02:41:30,967 INFO     Evaluating the model... (8000/50000)
2025-12-13 02:41:33,608 INFO     Evaluating the model... (8500/50000)
2025-12-13 02:41:36,616 INFO     Evaluating the model... (9000/50000)
2025-12-13 02:41:39,129 INFO     Evaluating the model... (9500/50000)
2025-12-13 02:41:41,864 INFO     Evaluating the model... (10000/50000)
2025-12-13 02:41:44,861 INFO     Evaluating the model... (10500/50000)
2025-12-13 02:41:47,263 INFO     Evaluating the model... (11000/50000)
2025-12-13 02:41:50,508 INFO     Evaluating the model... (11500/50000)
2025-12-13 02:41:53,056 INFO     Evaluating the model... (12000/50000)
2025-12-13 02:41:55,723 INFO     Evaluating the model... (12500/50000)
2025-12-13 02:41:58,164 INFO     Evaluating the model... (13000/50000)
2025-12-13 02:42:00,725 INFO     Evaluating the model... (13500/50000)
2025-12-13 02:42:04,070 INFO     Evaluating the model... (14000/50000)
2025-12-13 02:42:06,701 INFO     Evaluating the model... (14500/50000)
2025-12-13 02:42:09,217 INFO     Evaluating the model... (15000/50000)
2025-12-13 02:42:11,685 INFO     Evaluating the model... (15500/50000)
2025-12-13 02:42:14,127 INFO     Evaluating the model... (16000/50000)
2025-12-13 02:42:17,655 INFO     Evaluating the model... (16500/50000)
2025-12-13 02:42:20,345 INFO     Evaluating the model... (17000/50000)
2025-12-13 02:42:22,727 INFO     Evaluating the model... (17500/50000)
2025-12-13 02:42:25,131 INFO     Evaluating the model... (18000/50000)
2025-12-13 02:42:28,431 INFO     Evaluating the model... (18500/50000)
2025-12-13 02:42:31,135 INFO     Evaluating the model... (19000/50000)
2025-12-13 02:42:33,542 INFO     Evaluating the model... (19500/50000)
2025-12-13 02:42:36,060 INFO     Evaluating the model... (20000/50000)
2025-12-13 02:42:38,675 INFO     Evaluating the model... (20500/50000)
2025-12-13 02:42:42,306 INFO     Evaluating the model... (21000/50000)
2025-12-13 02:42:44,845 INFO     Evaluating the model... (21500/50000)
2025-12-13 02:42:47,310 INFO     Evaluating the model... (22000/50000)
2025-12-13 02:42:49,727 INFO     Evaluating the model... (22500/50000)
2025-12-13 02:42:52,274 INFO     Evaluating the model... (23000/50000)
2025-12-13 02:42:55,633 INFO     Evaluating the model... (23500/50000)
2025-12-13 02:42:58,030 INFO     Evaluating the model... (24000/50000)
2025-12-13 02:43:00,461 INFO     Evaluating the model... (24500/50000)
2025-12-13 02:43:03,424 INFO     Evaluating the model... (25000/50000)
2025-12-13 02:43:05,993 INFO     Evaluating the model... (25500/50000)
2025-12-13 02:43:08,526 INFO     Evaluating the model... (26000/50000)
2025-12-13 02:43:11,742 INFO     Evaluating the model... (26500/50000)
2025-12-13 02:43:14,190 INFO     Evaluating the model... (27000/50000)
2025-12-13 02:43:16,901 INFO     Evaluating the model... (27500/50000)
2025-12-13 02:43:19,435 INFO     Evaluating the model... (28000/50000)
2025-12-13 02:43:22,527 INFO     Evaluating the model... (28500/50000)
2025-12-13 02:43:25,021 INFO     Evaluating the model... (29000/50000)
2025-12-13 02:43:27,831 INFO     Evaluating the model... (29500/50000)
2025-12-13 02:43:30,303 INFO     Evaluating the model... (30000/50000)
2025-12-13 02:43:32,750 INFO     Evaluating the model... (30500/50000)
2025-12-13 02:43:35,883 INFO     Evaluating the model... (31000/50000)
2025-12-13 02:43:38,818 INFO     Evaluating the model... (31500/50000)
2025-12-13 02:43:41,590 INFO     Evaluating the model... (32000/50000)
2025-12-13 02:43:44,177 INFO     Evaluating the model... (32500/50000)
2025-12-13 02:43:46,768 INFO     Evaluating the model... (33000/50000)
2025-12-13 02:43:49,917 INFO     Evaluating the model... (33500/50000)
2025-12-13 02:43:52,425 INFO     Evaluating the model... (34000/50000)
2025-12-13 02:43:54,824 INFO     Evaluating the model... (34500/50000)
2025-12-13 02:43:57,475 INFO     Evaluating the model... (35000/50000)
2025-12-13 02:43:59,975 INFO     Evaluating the model... (35500/50000)
2025-12-13 02:44:03,459 INFO     Evaluating the model... (36000/50000)
2025-12-13 02:44:05,974 INFO     Evaluating the model... (36500/50000)
2025-12-13 02:44:08,420 INFO     Evaluating the model... (37000/50000)
2025-12-13 02:44:10,895 INFO     Evaluating the model... (37500/50000)
2025-12-13 02:44:13,480 INFO     Evaluating the model... (38000/50000)
2025-12-13 02:44:16,808 INFO     Evaluating the model... (38500/50000)
2025-12-13 02:44:19,175 INFO     Evaluating the model... (39000/50000)
2025-12-13 02:44:21,611 INFO     Evaluating the model... (39500/50000)
2025-12-13 02:44:24,239 INFO     Evaluating the model... (40000/50000)
2025-12-13 02:44:26,956 INFO     Evaluating the model... (40500/50000)
2025-12-13 02:44:30,658 INFO     Evaluating the model... (41000/50000)
2025-12-13 02:44:33,123 INFO     Evaluating the model... (41500/50000)
2025-12-13 02:44:35,968 INFO     Evaluating the model... (42000/50000)
2025-12-13 02:44:38,819 INFO     Evaluating the model... (42500/50000)
2025-12-13 02:44:41,457 INFO     Evaluating the model... (43000/50000)
2025-12-13 02:44:45,236 INFO     Evaluating the model... (43500/50000)
2025-12-13 02:44:47,908 INFO     Evaluating the model... (44000/50000)
2025-12-13 02:44:50,515 INFO     Evaluating the model... (44500/50000)
2025-12-13 02:44:52,976 INFO     Evaluating the model... (45000/50000)
2025-12-13 02:44:55,418 INFO     Evaluating the model... (45500/50000)
2025-12-13 02:44:59,309 INFO     Evaluating the model... (46000/50000)
2025-12-13 02:45:01,806 INFO     Evaluating the model... (46500/50000)
2025-12-13 02:45:04,308 INFO     Evaluating the model... (47000/50000)
2025-12-13 02:45:06,818 INFO     Evaluating the model... (47500/50000)
2025-12-13 02:45:10,481 INFO     Evaluating the model... (48000/50000)
2025-12-13 02:45:12,885 INFO     Evaluating the model... (48500/50000)
2025-12-13 02:45:15,570 INFO     Evaluating the model... (49000/50000)
2025-12-13 02:45:18,042 INFO     Evaluating the model... (49500/50000)
2025-12-13 02:45:20,804 INFO     Valid MRR at step 150000: 0.632847
2025-12-13 02:45:20,804 INFO     Valid MR at step 150000: 266.519450
2025-12-13 02:45:20,804 INFO     Valid HITS@1 at step 150000: 0.547120
2025-12-13 02:45:20,804 INFO     Valid HITS@3 at step 150000: 0.685880
2025-12-13 02:45:20,804 INFO     Valid HITS@10 at step 150000: 0.784820
2025-12-13 02:45:22,132 INFO     Evaluating on Test Dataset...
2025-12-13 02:45:22,667 INFO     Evaluating the model... (0/59072)
2025-12-13 02:45:25,170 INFO     Evaluating the model... (500/59072)
2025-12-13 02:45:28,824 INFO     Evaluating the model... (1000/59072)
2025-12-13 02:45:31,445 INFO     Evaluating the model... (1500/59072)
2025-12-13 02:45:34,163 INFO     Evaluating the model... (2000/59072)
2025-12-13 02:45:36,913 INFO     Evaluating the model... (2500/59072)
2025-12-13 02:45:39,612 INFO     Evaluating the model... (3000/59072)
2025-12-13 02:45:43,060 INFO     Evaluating the model... (3500/59072)
2025-12-13 02:45:45,834 INFO     Evaluating the model... (4000/59072)
2025-12-13 02:45:48,291 INFO     Evaluating the model... (4500/59072)
2025-12-13 02:45:50,708 INFO     Evaluating the model... (5000/59072)
2025-12-13 02:45:53,692 INFO     Evaluating the model... (5500/59072)
2025-12-13 02:45:56,319 INFO     Evaluating the model... (6000/59072)
2025-12-13 02:45:58,681 INFO     Evaluating the model... (6500/59072)
2025-12-13 02:46:01,100 INFO     Evaluating the model... (7000/59072)
2025-12-13 02:46:03,505 INFO     Evaluating the model... (7500/59072)
2025-12-13 02:46:06,619 INFO     Evaluating the model... (8000/59072)
2025-12-13 02:46:09,186 INFO     Evaluating the model... (8500/59072)
2025-12-13 02:46:11,572 INFO     Evaluating the model... (9000/59072)
2025-12-13 02:46:14,037 INFO     Evaluating the model... (9500/59072)
2025-12-13 02:46:16,584 INFO     Evaluating the model... (10000/59072)
2025-12-13 02:46:19,580 INFO     Evaluating the model... (10500/59072)
2025-12-13 02:46:22,055 INFO     Evaluating the model... (11000/59072)
2025-12-13 02:46:24,453 INFO     Evaluating the model... (11500/59072)
2025-12-13 02:46:26,989 INFO     Evaluating the model... (12000/59072)
2025-12-13 02:46:29,425 INFO     Evaluating the model... (12500/59072)
2025-12-13 02:46:32,703 INFO     Evaluating the model... (13000/59072)
2025-12-13 02:46:35,262 INFO     Evaluating the model... (13500/59072)
2025-12-13 02:46:37,862 INFO     Evaluating the model... (14000/59072)
2025-12-13 02:46:40,466 INFO     Evaluating the model... (14500/59072)
2025-12-13 02:46:43,459 INFO     Evaluating the model... (15000/59072)
2025-12-13 02:46:46,586 INFO     Evaluating the model... (15500/59072)
2025-12-13 02:46:48,980 INFO     Evaluating the model... (16000/59072)
2025-12-13 02:46:51,418 INFO     Evaluating the model... (16500/59072)
2025-12-13 02:46:53,978 INFO     Evaluating the model... (17000/59072)
2025-12-13 02:46:56,535 INFO     Evaluating the model... (17500/59072)
2025-12-13 02:46:59,778 INFO     Evaluating the model... (18000/59072)
2025-12-13 02:47:02,281 INFO     Evaluating the model... (18500/59072)
2025-12-13 02:47:04,781 INFO     Evaluating the model... (19000/59072)
2025-12-13 02:47:07,259 INFO     Evaluating the model... (19500/59072)
2025-12-13 02:47:09,704 INFO     Evaluating the model... (20000/59072)
2025-12-13 02:47:12,952 INFO     Evaluating the model... (20500/59072)
2025-12-13 02:47:15,493 INFO     Evaluating the model... (21000/59072)
2025-12-13 02:47:18,129 INFO     Evaluating the model... (21500/59072)
2025-12-13 02:47:20,613 INFO     Evaluating the model... (22000/59072)
2025-12-13 02:47:22,922 INFO     Evaluating the model... (22500/59072)
2025-12-13 02:47:26,546 INFO     Evaluating the model... (23000/59072)
2025-12-13 02:47:29,174 INFO     Evaluating the model... (23500/59072)
2025-12-13 02:47:31,607 INFO     Evaluating the model... (24000/59072)
2025-12-13 02:47:34,095 INFO     Evaluating the model... (24500/59072)
2025-12-13 02:47:37,743 INFO     Evaluating the model... (25000/59072)
2025-12-13 02:47:40,555 INFO     Evaluating the model... (25500/59072)
2025-12-13 02:47:43,127 INFO     Evaluating the model... (26000/59072)
2025-12-13 02:47:45,633 INFO     Evaluating the model... (26500/59072)
2025-12-13 02:47:48,045 INFO     Evaluating the model... (27000/59072)
2025-12-13 02:47:51,655 INFO     Evaluating the model... (27500/59072)
2025-12-13 02:47:53,998 INFO     Evaluating the model... (28000/59072)
2025-12-13 02:47:56,519 INFO     Evaluating the model... (28500/59072)
2025-12-13 02:47:58,938 INFO     Evaluating the model... (29000/59072)
2025-12-13 02:48:01,345 INFO     Evaluating the model... (29500/59072)
2025-12-13 02:48:05,363 INFO     Evaluating the model... (30000/59072)
2025-12-13 02:48:07,879 INFO     Evaluating the model... (30500/59072)
2025-12-13 02:48:10,350 INFO     Evaluating the model... (31000/59072)
2025-12-13 02:48:12,809 INFO     Evaluating the model... (31500/59072)
2025-12-13 02:48:15,487 INFO     Evaluating the model... (32000/59072)
2025-12-13 02:48:18,876 INFO     Evaluating the model... (32500/59072)
2025-12-13 02:48:21,451 INFO     Evaluating the model... (33000/59072)
2025-12-13 02:48:23,937 INFO     Evaluating the model... (33500/59072)
2025-12-13 02:48:26,697 INFO     Evaluating the model... (34000/59072)
2025-12-13 02:48:29,195 INFO     Evaluating the model... (34500/59072)
2025-12-13 02:48:32,344 INFO     Evaluating the model... (35000/59072)
2025-12-13 02:48:35,229 INFO     Evaluating the model... (35500/59072)
2025-12-13 02:48:38,178 INFO     Evaluating the model... (36000/59072)
2025-12-13 02:48:40,902 INFO     Evaluating the model... (36500/59072)
2025-12-13 02:48:44,410 INFO     Evaluating the model... (37000/59072)
2025-12-13 02:48:46,913 INFO     Evaluating the model... (37500/59072)
2025-12-13 02:48:49,721 INFO     Evaluating the model... (38000/59072)
2025-12-13 02:48:52,163 INFO     Evaluating the model... (38500/59072)
2025-12-13 02:48:54,557 INFO     Evaluating the model... (39000/59072)
2025-12-13 02:48:58,171 INFO     Evaluating the model... (39500/59072)
2025-12-13 02:49:00,818 INFO     Evaluating the model... (40000/59072)
2025-12-13 02:49:03,441 INFO     Evaluating the model... (40500/59072)
2025-12-13 02:49:06,003 INFO     Evaluating the model... (41000/59072)
2025-12-13 02:49:08,471 INFO     Evaluating the model... (41500/59072)
2025-12-13 02:49:12,024 INFO     Evaluating the model... (42000/59072)
2025-12-13 02:49:14,535 INFO     Evaluating the model... (42500/59072)
2025-12-13 02:49:17,106 INFO     Evaluating the model... (43000/59072)
2025-12-13 02:49:19,660 INFO     Evaluating the model... (43500/59072)
2025-12-13 02:49:22,218 INFO     Evaluating the model... (44000/59072)
2025-12-13 02:49:25,976 INFO     Evaluating the model... (44500/59072)
2025-12-13 02:49:28,403 INFO     Evaluating the model... (45000/59072)
2025-12-13 02:49:30,922 INFO     Evaluating the model... (45500/59072)
2025-12-13 02:49:33,563 INFO     Evaluating the model... (46000/59072)
2025-12-13 02:49:36,345 INFO     Evaluating the model... (46500/59072)
2025-12-13 02:49:39,816 INFO     Evaluating the model... (47000/59072)
2025-12-13 02:49:42,489 INFO     Evaluating the model... (47500/59072)
2025-12-13 02:49:45,271 INFO     Evaluating the model... (48000/59072)
2025-12-13 02:49:47,950 INFO     Evaluating the model... (48500/59072)
2025-12-13 02:49:50,577 INFO     Evaluating the model... (49000/59072)
2025-12-13 02:49:53,691 INFO     Evaluating the model... (49500/59072)
2025-12-13 02:49:56,399 INFO     Evaluating the model... (50000/59072)
2025-12-13 02:49:59,033 INFO     Evaluating the model... (50500/59072)
2025-12-13 02:50:01,594 INFO     Evaluating the model... (51000/59072)
2025-12-13 02:50:04,098 INFO     Evaluating the model... (51500/59072)
2025-12-13 02:50:07,332 INFO     Evaluating the model... (52000/59072)
2025-12-13 02:50:10,018 INFO     Evaluating the model... (52500/59072)
2025-12-13 02:50:12,549 INFO     Evaluating the model... (53000/59072)
2025-12-13 02:50:14,998 INFO     Evaluating the model... (53500/59072)
2025-12-13 02:50:17,637 INFO     Evaluating the model... (54000/59072)
2025-12-13 02:50:21,077 INFO     Evaluating the model... (54500/59072)
2025-12-13 02:50:23,607 INFO     Evaluating the model... (55000/59072)
2025-12-13 02:50:26,176 INFO     Evaluating the model... (55500/59072)
2025-12-13 02:50:28,672 INFO     Evaluating the model... (56000/59072)
2025-12-13 02:50:32,199 INFO     Evaluating the model... (56500/59072)
2025-12-13 02:50:34,659 INFO     Evaluating the model... (57000/59072)
2025-12-13 02:50:37,289 INFO     Evaluating the model... (57500/59072)
2025-12-13 02:50:40,167 INFO     Evaluating the model... (58000/59072)
2025-12-13 02:50:42,920 INFO     Evaluating the model... (58500/59072)
2025-12-13 02:50:46,888 INFO     Evaluating the model... (59000/59072)
2025-12-13 02:50:47,497 INFO     Test MRR at step 150000: 0.629689
2025-12-13 02:50:47,497 INFO     Test MR at step 150000: 268.524936
2025-12-13 02:50:47,497 INFO     Test HITS@1 at step 150000: 0.542508
2025-12-13 02:50:47,497 INFO     Test HITS@3 at step 150000: 0.683957
2025-12-13 02:50:47,497 INFO     Test HITS@10 at step 150000: 0.782931
2025-12-13 02:50:49,669 INFO     Training average regularization at step 150100: 0.302161
2025-12-13 02:50:49,691 INFO     Training average positive_sample_loss at step 150100: 0.064941
2025-12-13 02:50:49,691 INFO     Training average negative_sample_loss at step 150100: 0.108617
2025-12-13 02:50:49,691 INFO     Training average loss at step 150100: 0.388940
2025-12-13 02:50:51,891 INFO     Training average regularization at step 150200: 0.302160
2025-12-13 02:50:51,892 INFO     Training average positive_sample_loss at step 150200: 0.066579
2025-12-13 02:50:51,892 INFO     Training average negative_sample_loss at step 150200: 0.110509
2025-12-13 02:50:51,892 INFO     Training average loss at step 150200: 0.390704
2025-12-13 02:50:54,069 INFO     Training average regularization at step 150300: 0.302159
2025-12-13 02:50:54,069 INFO     Training average positive_sample_loss at step 150300: 0.066493
2025-12-13 02:50:54,069 INFO     Training average negative_sample_loss at step 150300: 0.109027
2025-12-13 02:50:54,069 INFO     Training average loss at step 150300: 0.389919
2025-12-13 02:50:56,248 INFO     Training average regularization at step 150400: 0.302159
2025-12-13 02:50:56,248 INFO     Training average positive_sample_loss at step 150400: 0.066242
2025-12-13 02:50:56,248 INFO     Training average negative_sample_loss at step 150400: 0.111199
2025-12-13 02:50:56,248 INFO     Training average loss at step 150400: 0.390879
2025-12-13 02:50:58,431 INFO     Training average regularization at step 150500: 0.302158
2025-12-13 02:50:58,432 INFO     Training average positive_sample_loss at step 150500: 0.066584
2025-12-13 02:50:58,432 INFO     Training average negative_sample_loss at step 150500: 0.108420
2025-12-13 02:50:58,432 INFO     Training average loss at step 150500: 0.389659
2025-12-13 02:51:00,615 INFO     Training average regularization at step 150600: 0.302157
2025-12-13 02:51:00,616 INFO     Training average positive_sample_loss at step 150600: 0.066561
2025-12-13 02:51:00,616 INFO     Training average negative_sample_loss at step 150600: 0.110139
2025-12-13 02:51:00,616 INFO     Training average loss at step 150600: 0.390507
2025-12-13 02:51:02,798 INFO     Training average regularization at step 150700: 0.302156
2025-12-13 02:51:02,798 INFO     Training average positive_sample_loss at step 150700: 0.068620
2025-12-13 02:51:02,798 INFO     Training average negative_sample_loss at step 150700: 0.109623
2025-12-13 02:51:02,798 INFO     Training average loss at step 150700: 0.391278
2025-12-13 02:51:04,967 INFO     Training average regularization at step 150800: 0.302156
2025-12-13 02:51:04,967 INFO     Training average positive_sample_loss at step 150800: 0.066871
2025-12-13 02:51:04,967 INFO     Training average negative_sample_loss at step 150800: 0.110117
2025-12-13 02:51:04,967 INFO     Training average loss at step 150800: 0.390650
2025-12-13 02:51:07,095 INFO     Training average regularization at step 150900: 0.302155
2025-12-13 02:51:07,095 INFO     Training average positive_sample_loss at step 150900: 0.065769
2025-12-13 02:51:07,095 INFO     Training average negative_sample_loss at step 150900: 0.109970
2025-12-13 02:51:07,095 INFO     Training average loss at step 150900: 0.390025
2025-12-13 02:51:09,229 INFO     Training average regularization at step 151000: 0.302154
2025-12-13 02:51:09,230 INFO     Training average positive_sample_loss at step 151000: 0.066751
2025-12-13 02:51:09,230 INFO     Training average negative_sample_loss at step 151000: 0.109615
2025-12-13 02:51:09,230 INFO     Training average loss at step 151000: 0.390337
2025-12-13 02:51:11,387 INFO     Training average regularization at step 151100: 0.302154
2025-12-13 02:51:11,387 INFO     Training average positive_sample_loss at step 151100: 0.066743
2025-12-13 02:51:11,388 INFO     Training average negative_sample_loss at step 151100: 0.105624
2025-12-13 02:51:11,388 INFO     Training average loss at step 151100: 0.388337
2025-12-13 02:51:13,553 INFO     Training average regularization at step 151200: 0.302153
2025-12-13 02:51:13,553 INFO     Training average positive_sample_loss at step 151200: 0.068144
2025-12-13 02:51:13,553 INFO     Training average negative_sample_loss at step 151200: 0.106982
2025-12-13 02:51:13,553 INFO     Training average loss at step 151200: 0.389716
2025-12-13 02:51:15,729 INFO     Training average regularization at step 151300: 0.302152
2025-12-13 02:51:15,729 INFO     Training average positive_sample_loss at step 151300: 0.066508
2025-12-13 02:51:15,729 INFO     Training average negative_sample_loss at step 151300: 0.108266
2025-12-13 02:51:15,729 INFO     Training average loss at step 151300: 0.389540
2025-12-13 02:51:17,883 INFO     Training average regularization at step 151400: 0.302152
2025-12-13 02:51:17,884 INFO     Training average positive_sample_loss at step 151400: 0.067836
2025-12-13 02:51:17,884 INFO     Training average negative_sample_loss at step 151400: 0.109859
2025-12-13 02:51:17,884 INFO     Training average loss at step 151400: 0.390999
2025-12-13 02:51:19,982 INFO     Training average regularization at step 151500: 0.302151
2025-12-13 02:51:19,983 INFO     Training average positive_sample_loss at step 151500: 0.065740
2025-12-13 02:51:19,983 INFO     Training average negative_sample_loss at step 151500: 0.107997
2025-12-13 02:51:19,983 INFO     Training average loss at step 151500: 0.389019
2025-12-13 02:51:22,088 INFO     Training average regularization at step 151600: 0.302150
2025-12-13 02:51:22,088 INFO     Training average positive_sample_loss at step 151600: 0.066602
2025-12-13 02:51:22,088 INFO     Training average negative_sample_loss at step 151600: 0.110549
2025-12-13 02:51:22,088 INFO     Training average loss at step 151600: 0.390726
2025-12-13 02:51:24,186 INFO     Training average regularization at step 151700: 0.302150
2025-12-13 02:51:24,186 INFO     Training average positive_sample_loss at step 151700: 0.066986
2025-12-13 02:51:24,187 INFO     Training average negative_sample_loss at step 151700: 0.108134
2025-12-13 02:51:24,187 INFO     Training average loss at step 151700: 0.389710
2025-12-13 02:51:26,286 INFO     Training average regularization at step 151800: 0.302149
2025-12-13 02:51:26,286 INFO     Training average positive_sample_loss at step 151800: 0.066687
2025-12-13 02:51:26,286 INFO     Training average negative_sample_loss at step 151800: 0.108368
2025-12-13 02:51:26,286 INFO     Training average loss at step 151800: 0.389677
2025-12-13 02:51:28,402 INFO     Training average regularization at step 151900: 0.302149
2025-12-13 02:51:28,402 INFO     Training average positive_sample_loss at step 151900: 0.067253
2025-12-13 02:51:28,402 INFO     Training average negative_sample_loss at step 151900: 0.109526
2025-12-13 02:51:28,402 INFO     Training average loss at step 151900: 0.390538
2025-12-13 02:51:30,512 INFO     Training average regularization at step 152000: 0.302148
2025-12-13 02:51:30,512 INFO     Training average positive_sample_loss at step 152000: 0.066925
2025-12-13 02:51:30,512 INFO     Training average negative_sample_loss at step 152000: 0.110604
2025-12-13 02:51:30,512 INFO     Training average loss at step 152000: 0.390913
2025-12-13 02:51:32,634 INFO     Training average regularization at step 152100: 0.302147
2025-12-13 02:51:32,634 INFO     Training average positive_sample_loss at step 152100: 0.066036
2025-12-13 02:51:32,634 INFO     Training average negative_sample_loss at step 152100: 0.109257
2025-12-13 02:51:32,634 INFO     Training average loss at step 152100: 0.389794
2025-12-13 02:51:34,751 INFO     Training average regularization at step 152200: 0.302147
2025-12-13 02:51:34,751 INFO     Training average positive_sample_loss at step 152200: 0.065878
2025-12-13 02:51:34,751 INFO     Training average negative_sample_loss at step 152200: 0.108330
2025-12-13 02:51:34,751 INFO     Training average loss at step 152200: 0.389251
2025-12-13 02:51:36,969 INFO     Training average regularization at step 152300: 0.302146
2025-12-13 02:51:36,971 INFO     Training average positive_sample_loss at step 152300: 0.067771
2025-12-13 02:51:36,971 INFO     Training average negative_sample_loss at step 152300: 0.107609
2025-12-13 02:51:36,971 INFO     Training average loss at step 152300: 0.389836
2025-12-13 02:51:39,170 INFO     Training average regularization at step 152400: 0.302146
2025-12-13 02:51:39,170 INFO     Training average positive_sample_loss at step 152400: 0.067311
2025-12-13 02:51:39,170 INFO     Training average negative_sample_loss at step 152400: 0.109838
2025-12-13 02:51:39,170 INFO     Training average loss at step 152400: 0.390720
2025-12-13 02:51:41,273 INFO     Training average regularization at step 152500: 0.302145
2025-12-13 02:51:41,273 INFO     Training average positive_sample_loss at step 152500: 0.067946
2025-12-13 02:51:41,273 INFO     Training average negative_sample_loss at step 152500: 0.108300
2025-12-13 02:51:41,273 INFO     Training average loss at step 152500: 0.390268
2025-12-13 02:51:43,411 INFO     Training average regularization at step 152600: 0.302145
2025-12-13 02:51:43,411 INFO     Training average positive_sample_loss at step 152600: 0.066554
2025-12-13 02:51:43,411 INFO     Training average negative_sample_loss at step 152600: 0.112833
2025-12-13 02:51:43,411 INFO     Training average loss at step 152600: 0.391838
2025-12-13 02:51:45,553 INFO     Training average regularization at step 152700: 0.302144
2025-12-13 02:51:45,553 INFO     Training average positive_sample_loss at step 152700: 0.065359
2025-12-13 02:51:45,553 INFO     Training average negative_sample_loss at step 152700: 0.110424
2025-12-13 02:51:45,553 INFO     Training average loss at step 152700: 0.390036
2025-12-13 02:51:47,707 INFO     Training average regularization at step 152800: 0.302143
2025-12-13 02:51:47,708 INFO     Training average positive_sample_loss at step 152800: 0.066609
2025-12-13 02:51:47,708 INFO     Training average negative_sample_loss at step 152800: 0.110465
2025-12-13 02:51:47,708 INFO     Training average loss at step 152800: 0.390680
2025-12-13 02:51:49,861 INFO     Training average regularization at step 152900: 0.302143
2025-12-13 02:51:49,861 INFO     Training average positive_sample_loss at step 152900: 0.067550
2025-12-13 02:51:49,861 INFO     Training average negative_sample_loss at step 152900: 0.107242
2025-12-13 02:51:49,861 INFO     Training average loss at step 152900: 0.389539
2025-12-13 02:51:52,050 INFO     Training average regularization at step 153000: 0.302142
2025-12-13 02:51:52,050 INFO     Training average positive_sample_loss at step 153000: 0.067105
2025-12-13 02:51:52,050 INFO     Training average negative_sample_loss at step 153000: 0.110314
2025-12-13 02:51:52,050 INFO     Training average loss at step 153000: 0.390852
2025-12-13 02:51:54,146 INFO     Training average regularization at step 153100: 0.302142
2025-12-13 02:51:54,146 INFO     Training average positive_sample_loss at step 153100: 0.067397
2025-12-13 02:51:54,146 INFO     Training average negative_sample_loss at step 153100: 0.110660
2025-12-13 02:51:54,146 INFO     Training average loss at step 153100: 0.391171
2025-12-13 02:51:56,243 INFO     Training average regularization at step 153200: 0.302141
2025-12-13 02:51:56,243 INFO     Training average positive_sample_loss at step 153200: 0.066780
2025-12-13 02:51:56,243 INFO     Training average negative_sample_loss at step 153200: 0.109005
2025-12-13 02:51:56,243 INFO     Training average loss at step 153200: 0.390033
2025-12-13 02:51:58,318 INFO     Training average regularization at step 153300: 0.302141
2025-12-13 02:51:58,319 INFO     Training average positive_sample_loss at step 153300: 0.065273
2025-12-13 02:51:58,319 INFO     Training average negative_sample_loss at step 153300: 0.106706
2025-12-13 02:51:58,319 INFO     Training average loss at step 153300: 0.388130
2025-12-13 02:52:00,413 INFO     Training average regularization at step 153400: 0.302140
2025-12-13 02:52:00,413 INFO     Training average positive_sample_loss at step 153400: 0.067476
2025-12-13 02:52:00,413 INFO     Training average negative_sample_loss at step 153400: 0.107196
2025-12-13 02:52:00,413 INFO     Training average loss at step 153400: 0.389476
2025-12-13 02:52:02,592 INFO     Training average regularization at step 153500: 0.302140
2025-12-13 02:52:02,593 INFO     Training average positive_sample_loss at step 153500: 0.066650
2025-12-13 02:52:02,593 INFO     Training average negative_sample_loss at step 153500: 0.109015
2025-12-13 02:52:02,593 INFO     Training average loss at step 153500: 0.389972
2025-12-13 02:52:04,745 INFO     Training average regularization at step 153600: 0.302139
2025-12-13 02:52:04,745 INFO     Training average positive_sample_loss at step 153600: 0.066719
2025-12-13 02:52:04,745 INFO     Training average negative_sample_loss at step 153600: 0.108101
2025-12-13 02:52:04,745 INFO     Training average loss at step 153600: 0.389549
2025-12-13 02:52:06,844 INFO     Training average regularization at step 153700: 0.302138
2025-12-13 02:52:06,844 INFO     Training average positive_sample_loss at step 153700: 0.065855
2025-12-13 02:52:06,844 INFO     Training average negative_sample_loss at step 153700: 0.107018
2025-12-13 02:52:06,844 INFO     Training average loss at step 153700: 0.388575
2025-12-13 02:52:08,962 INFO     Training average regularization at step 153800: 0.302138
2025-12-13 02:52:08,962 INFO     Training average positive_sample_loss at step 153800: 0.066850
2025-12-13 02:52:08,962 INFO     Training average negative_sample_loss at step 153800: 0.109290
2025-12-13 02:52:08,962 INFO     Training average loss at step 153800: 0.390208
2025-12-13 02:52:11,082 INFO     Training average regularization at step 153900: 0.302137
2025-12-13 02:52:11,083 INFO     Training average positive_sample_loss at step 153900: 0.067692
2025-12-13 02:52:11,083 INFO     Training average negative_sample_loss at step 153900: 0.110450
2025-12-13 02:52:11,083 INFO     Training average loss at step 153900: 0.391208
2025-12-13 02:52:13,182 INFO     Training average regularization at step 154000: 0.302137
2025-12-13 02:52:13,182 INFO     Training average positive_sample_loss at step 154000: 0.067100
2025-12-13 02:52:13,182 INFO     Training average negative_sample_loss at step 154000: 0.107056
2025-12-13 02:52:13,182 INFO     Training average loss at step 154000: 0.389215
2025-12-13 02:52:15,287 INFO     Training average regularization at step 154100: 0.302136
2025-12-13 02:52:15,287 INFO     Training average positive_sample_loss at step 154100: 0.068039
2025-12-13 02:52:15,287 INFO     Training average negative_sample_loss at step 154100: 0.107682
2025-12-13 02:52:15,287 INFO     Training average loss at step 154100: 0.389997
2025-12-13 02:52:17,404 INFO     Training average regularization at step 154200: 0.302136
2025-12-13 02:52:17,404 INFO     Training average positive_sample_loss at step 154200: 0.067572
2025-12-13 02:52:17,404 INFO     Training average negative_sample_loss at step 154200: 0.109812
2025-12-13 02:52:17,404 INFO     Training average loss at step 154200: 0.390828
2025-12-13 02:52:19,528 INFO     Training average regularization at step 154300: 0.302135
2025-12-13 02:52:19,529 INFO     Training average positive_sample_loss at step 154300: 0.065804
2025-12-13 02:52:19,529 INFO     Training average negative_sample_loss at step 154300: 0.110340
2025-12-13 02:52:19,529 INFO     Training average loss at step 154300: 0.390207
2025-12-13 02:52:21,628 INFO     Training average regularization at step 154400: 0.302135
2025-12-13 02:52:21,628 INFO     Training average positive_sample_loss at step 154400: 0.067452
2025-12-13 02:52:21,628 INFO     Training average negative_sample_loss at step 154400: 0.110587
2025-12-13 02:52:21,628 INFO     Training average loss at step 154400: 0.391154
2025-12-13 02:52:23,768 INFO     Training average regularization at step 154500: 0.302134
2025-12-13 02:52:23,768 INFO     Training average positive_sample_loss at step 154500: 0.065870
2025-12-13 02:52:23,768 INFO     Training average negative_sample_loss at step 154500: 0.108863
2025-12-13 02:52:23,768 INFO     Training average loss at step 154500: 0.389501
2025-12-13 02:52:25,902 INFO     Training average regularization at step 154600: 0.302134
2025-12-13 02:52:25,902 INFO     Training average positive_sample_loss at step 154600: 0.066955
2025-12-13 02:52:25,902 INFO     Training average negative_sample_loss at step 154600: 0.108370
2025-12-13 02:52:25,902 INFO     Training average loss at step 154600: 0.389796
2025-12-13 02:52:28,980 INFO     Training average regularization at step 154700: 0.302133
2025-12-13 02:52:28,980 INFO     Training average positive_sample_loss at step 154700: 0.066117
2025-12-13 02:52:28,980 INFO     Training average negative_sample_loss at step 154700: 0.108743
2025-12-13 02:52:28,980 INFO     Training average loss at step 154700: 0.389564
2025-12-13 02:52:31,137 INFO     Training average regularization at step 154800: 0.302133
2025-12-13 02:52:31,138 INFO     Training average positive_sample_loss at step 154800: 0.067133
2025-12-13 02:52:31,138 INFO     Training average negative_sample_loss at step 154800: 0.110024
2025-12-13 02:52:31,138 INFO     Training average loss at step 154800: 0.390711
2025-12-13 02:52:33,285 INFO     Training average regularization at step 154900: 0.302132
2025-12-13 02:52:33,285 INFO     Training average positive_sample_loss at step 154900: 0.066841
2025-12-13 02:52:33,285 INFO     Training average negative_sample_loss at step 154900: 0.109361
2025-12-13 02:52:33,285 INFO     Training average loss at step 154900: 0.390233
2025-12-13 02:52:35,442 INFO     Training average regularization at step 155000: 0.302131
2025-12-13 02:52:35,442 INFO     Training average positive_sample_loss at step 155000: 0.066463
2025-12-13 02:52:35,442 INFO     Training average negative_sample_loss at step 155000: 0.108109
2025-12-13 02:52:35,442 INFO     Training average loss at step 155000: 0.389417
2025-12-13 02:52:37,643 INFO     Training average regularization at step 155100: 0.302130
2025-12-13 02:52:37,644 INFO     Training average positive_sample_loss at step 155100: 0.066316
2025-12-13 02:52:37,644 INFO     Training average negative_sample_loss at step 155100: 0.108941
2025-12-13 02:52:37,644 INFO     Training average loss at step 155100: 0.389759
2025-12-13 02:52:39,877 INFO     Training average regularization at step 155200: 0.302130
2025-12-13 02:52:39,878 INFO     Training average positive_sample_loss at step 155200: 0.066831
2025-12-13 02:52:39,878 INFO     Training average negative_sample_loss at step 155200: 0.107877
2025-12-13 02:52:39,878 INFO     Training average loss at step 155200: 0.389483
2025-12-13 02:52:42,108 INFO     Training average regularization at step 155300: 0.302129
2025-12-13 02:52:42,108 INFO     Training average positive_sample_loss at step 155300: 0.065602
2025-12-13 02:52:42,108 INFO     Training average negative_sample_loss at step 155300: 0.107663
2025-12-13 02:52:42,108 INFO     Training average loss at step 155300: 0.388761
2025-12-13 02:52:44,350 INFO     Training average regularization at step 155400: 0.302128
2025-12-13 02:52:44,351 INFO     Training average positive_sample_loss at step 155400: 0.066170
2025-12-13 02:52:44,351 INFO     Training average negative_sample_loss at step 155400: 0.107975
2025-12-13 02:52:44,351 INFO     Training average loss at step 155400: 0.389201
2025-12-13 02:52:46,551 INFO     Training average regularization at step 155500: 0.302127
2025-12-13 02:52:46,551 INFO     Training average positive_sample_loss at step 155500: 0.066964
2025-12-13 02:52:46,551 INFO     Training average negative_sample_loss at step 155500: 0.109177
2025-12-13 02:52:46,551 INFO     Training average loss at step 155500: 0.390198
2025-12-13 02:52:48,727 INFO     Training average regularization at step 155600: 0.302127
2025-12-13 02:52:48,727 INFO     Training average positive_sample_loss at step 155600: 0.066744
2025-12-13 02:52:48,727 INFO     Training average negative_sample_loss at step 155600: 0.112273
2025-12-13 02:52:48,727 INFO     Training average loss at step 155600: 0.391635
2025-12-13 02:52:50,887 INFO     Training average regularization at step 155700: 0.302126
2025-12-13 02:52:50,888 INFO     Training average positive_sample_loss at step 155700: 0.067917
2025-12-13 02:52:50,888 INFO     Training average negative_sample_loss at step 155700: 0.110269
2025-12-13 02:52:50,888 INFO     Training average loss at step 155700: 0.391219
2025-12-13 02:52:53,049 INFO     Training average regularization at step 155800: 0.302125
2025-12-13 02:52:53,049 INFO     Training average positive_sample_loss at step 155800: 0.067243
2025-12-13 02:52:53,049 INFO     Training average negative_sample_loss at step 155800: 0.108668
2025-12-13 02:52:53,049 INFO     Training average loss at step 155800: 0.390081
2025-12-13 02:52:55,218 INFO     Training average regularization at step 155900: 0.302125
2025-12-13 02:52:55,218 INFO     Training average positive_sample_loss at step 155900: 0.066675
2025-12-13 02:52:55,218 INFO     Training average negative_sample_loss at step 155900: 0.110085
2025-12-13 02:52:55,218 INFO     Training average loss at step 155900: 0.390505
2025-12-13 02:52:57,422 INFO     Training average regularization at step 156000: 0.302124
2025-12-13 02:52:57,423 INFO     Training average positive_sample_loss at step 156000: 0.067226
2025-12-13 02:52:57,423 INFO     Training average negative_sample_loss at step 156000: 0.110170
2025-12-13 02:52:57,423 INFO     Training average loss at step 156000: 0.390822
2025-12-13 02:52:59,584 INFO     Training average regularization at step 156100: 0.302123
2025-12-13 02:52:59,584 INFO     Training average positive_sample_loss at step 156100: 0.066327
2025-12-13 02:52:59,584 INFO     Training average negative_sample_loss at step 156100: 0.109490
2025-12-13 02:52:59,584 INFO     Training average loss at step 156100: 0.390032
2025-12-13 02:53:01,766 INFO     Training average regularization at step 156200: 0.302122
2025-12-13 02:53:01,766 INFO     Training average positive_sample_loss at step 156200: 0.066434
2025-12-13 02:53:01,766 INFO     Training average negative_sample_loss at step 156200: 0.112907
2025-12-13 02:53:01,766 INFO     Training average loss at step 156200: 0.391793
2025-12-13 02:53:03,932 INFO     Training average regularization at step 156300: 0.302122
2025-12-13 02:53:03,932 INFO     Training average positive_sample_loss at step 156300: 0.066655
2025-12-13 02:53:03,932 INFO     Training average negative_sample_loss at step 156300: 0.109275
2025-12-13 02:53:03,932 INFO     Training average loss at step 156300: 0.390086
2025-12-13 02:53:06,101 INFO     Training average regularization at step 156400: 0.302121
2025-12-13 02:53:06,101 INFO     Training average positive_sample_loss at step 156400: 0.065415
2025-12-13 02:53:06,101 INFO     Training average negative_sample_loss at step 156400: 0.108459
2025-12-13 02:53:06,101 INFO     Training average loss at step 156400: 0.389058
2025-12-13 02:53:08,281 INFO     Training average regularization at step 156500: 0.302120
2025-12-13 02:53:08,281 INFO     Training average positive_sample_loss at step 156500: 0.067062
2025-12-13 02:53:08,281 INFO     Training average negative_sample_loss at step 156500: 0.109259
2025-12-13 02:53:08,281 INFO     Training average loss at step 156500: 0.390281
2025-12-13 02:53:10,438 INFO     Training average regularization at step 156600: 0.302119
2025-12-13 02:53:10,438 INFO     Training average positive_sample_loss at step 156600: 0.066593
2025-12-13 02:53:10,438 INFO     Training average negative_sample_loss at step 156600: 0.111211
2025-12-13 02:53:10,438 INFO     Training average loss at step 156600: 0.391022
2025-12-13 02:53:12,581 INFO     Training average regularization at step 156700: 0.302119
2025-12-13 02:53:12,582 INFO     Training average positive_sample_loss at step 156700: 0.066563
2025-12-13 02:53:12,582 INFO     Training average negative_sample_loss at step 156700: 0.108089
2025-12-13 02:53:12,582 INFO     Training average loss at step 156700: 0.389444
2025-12-13 02:53:14,736 INFO     Training average regularization at step 156800: 0.302118
2025-12-13 02:53:14,738 INFO     Training average positive_sample_loss at step 156800: 0.066985
2025-12-13 02:53:14,738 INFO     Training average negative_sample_loss at step 156800: 0.108237
2025-12-13 02:53:14,738 INFO     Training average loss at step 156800: 0.389729
2025-12-13 02:53:16,963 INFO     Training average regularization at step 156900: 0.302117
2025-12-13 02:53:16,963 INFO     Training average positive_sample_loss at step 156900: 0.068568
2025-12-13 02:53:16,963 INFO     Training average negative_sample_loss at step 156900: 0.110523
2025-12-13 02:53:16,963 INFO     Training average loss at step 156900: 0.391663
2025-12-13 02:53:19,159 INFO     Training average regularization at step 157000: 0.302117
2025-12-13 02:53:19,159 INFO     Training average positive_sample_loss at step 157000: 0.067370
2025-12-13 02:53:19,159 INFO     Training average negative_sample_loss at step 157000: 0.109638
2025-12-13 02:53:19,159 INFO     Training average loss at step 157000: 0.390621
2025-12-13 02:53:21,353 INFO     Training average regularization at step 157100: 0.302117
2025-12-13 02:53:21,353 INFO     Training average positive_sample_loss at step 157100: 0.067413
2025-12-13 02:53:21,353 INFO     Training average negative_sample_loss at step 157100: 0.107011
2025-12-13 02:53:21,353 INFO     Training average loss at step 157100: 0.389329
2025-12-13 02:53:23,525 INFO     Training average regularization at step 157200: 0.302116
2025-12-13 02:53:23,525 INFO     Training average positive_sample_loss at step 157200: 0.065670
2025-12-13 02:53:23,525 INFO     Training average negative_sample_loss at step 157200: 0.110660
2025-12-13 02:53:23,525 INFO     Training average loss at step 157200: 0.390281
2025-12-13 02:53:25,716 INFO     Training average regularization at step 157300: 0.302115
2025-12-13 02:53:25,716 INFO     Training average positive_sample_loss at step 157300: 0.066076
2025-12-13 02:53:25,716 INFO     Training average negative_sample_loss at step 157300: 0.113161
2025-12-13 02:53:25,716 INFO     Training average loss at step 157300: 0.391734
2025-12-13 02:53:27,890 INFO     Training average regularization at step 157400: 0.302115
2025-12-13 02:53:27,890 INFO     Training average positive_sample_loss at step 157400: 0.067401
2025-12-13 02:53:27,890 INFO     Training average negative_sample_loss at step 157400: 0.108195
2025-12-13 02:53:27,890 INFO     Training average loss at step 157400: 0.389913
2025-12-13 02:53:30,072 INFO     Training average regularization at step 157500: 0.302114
2025-12-13 02:53:30,072 INFO     Training average positive_sample_loss at step 157500: 0.066714
2025-12-13 02:53:30,072 INFO     Training average negative_sample_loss at step 157500: 0.109292
2025-12-13 02:53:30,072 INFO     Training average loss at step 157500: 0.390117
2025-12-13 02:53:32,228 INFO     Training average regularization at step 157600: 0.302114
2025-12-13 02:53:32,228 INFO     Training average positive_sample_loss at step 157600: 0.066909
2025-12-13 02:53:32,228 INFO     Training average negative_sample_loss at step 157600: 0.110231
2025-12-13 02:53:32,228 INFO     Training average loss at step 157600: 0.390684
2025-12-13 02:53:34,389 INFO     Training average regularization at step 157700: 0.302113
2025-12-13 02:53:34,390 INFO     Training average positive_sample_loss at step 157700: 0.066130
2025-12-13 02:53:34,390 INFO     Training average negative_sample_loss at step 157700: 0.108716
2025-12-13 02:53:34,390 INFO     Training average loss at step 157700: 0.389536
2025-12-13 02:53:36,559 INFO     Training average regularization at step 157800: 0.302112
2025-12-13 02:53:36,559 INFO     Training average positive_sample_loss at step 157800: 0.067205
2025-12-13 02:53:36,559 INFO     Training average negative_sample_loss at step 157800: 0.109833
2025-12-13 02:53:36,559 INFO     Training average loss at step 157800: 0.390631
2025-12-13 02:53:38,737 INFO     Training average regularization at step 157900: 0.302112
2025-12-13 02:53:38,737 INFO     Training average positive_sample_loss at step 157900: 0.067146
2025-12-13 02:53:38,737 INFO     Training average negative_sample_loss at step 157900: 0.110537
2025-12-13 02:53:38,738 INFO     Training average loss at step 157900: 0.390953
2025-12-13 02:53:40,964 INFO     Training average regularization at step 158000: 0.302111
2025-12-13 02:53:40,964 INFO     Training average positive_sample_loss at step 158000: 0.066434
2025-12-13 02:53:40,964 INFO     Training average negative_sample_loss at step 158000: 0.108702
2025-12-13 02:53:40,964 INFO     Training average loss at step 158000: 0.389680
2025-12-13 02:53:43,186 INFO     Training average regularization at step 158100: 0.302111
2025-12-13 02:53:43,187 INFO     Training average positive_sample_loss at step 158100: 0.067282
2025-12-13 02:53:43,187 INFO     Training average negative_sample_loss at step 158100: 0.110744
2025-12-13 02:53:43,187 INFO     Training average loss at step 158100: 0.391124
2025-12-13 02:53:45,361 INFO     Training average regularization at step 158200: 0.302110
2025-12-13 02:53:45,361 INFO     Training average positive_sample_loss at step 158200: 0.066671
2025-12-13 02:53:45,361 INFO     Training average negative_sample_loss at step 158200: 0.109790
2025-12-13 02:53:45,361 INFO     Training average loss at step 158200: 0.390341
2025-12-13 02:53:47,534 INFO     Training average regularization at step 158300: 0.302110
2025-12-13 02:53:47,534 INFO     Training average positive_sample_loss at step 158300: 0.066314
2025-12-13 02:53:47,534 INFO     Training average negative_sample_loss at step 158300: 0.108812
2025-12-13 02:53:47,534 INFO     Training average loss at step 158300: 0.389673
2025-12-13 02:53:49,684 INFO     Training average regularization at step 158400: 0.302109
2025-12-13 02:53:49,685 INFO     Training average positive_sample_loss at step 158400: 0.067983
2025-12-13 02:53:49,685 INFO     Training average negative_sample_loss at step 158400: 0.109407
2025-12-13 02:53:49,685 INFO     Training average loss at step 158400: 0.390804
2025-12-13 02:53:51,879 INFO     Training average regularization at step 158500: 0.302109
2025-12-13 02:53:51,879 INFO     Training average positive_sample_loss at step 158500: 0.067686
2025-12-13 02:53:51,879 INFO     Training average negative_sample_loss at step 158500: 0.106176
2025-12-13 02:53:51,879 INFO     Training average loss at step 158500: 0.389040
2025-12-13 02:53:54,042 INFO     Training average regularization at step 158600: 0.302109
2025-12-13 02:53:54,042 INFO     Training average positive_sample_loss at step 158600: 0.067876
2025-12-13 02:53:54,042 INFO     Training average negative_sample_loss at step 158600: 0.109919
2025-12-13 02:53:54,042 INFO     Training average loss at step 158600: 0.391006
2025-12-13 02:53:56,207 INFO     Training average regularization at step 158700: 0.302108
2025-12-13 02:53:56,208 INFO     Training average positive_sample_loss at step 158700: 0.067765
2025-12-13 02:53:56,208 INFO     Training average negative_sample_loss at step 158700: 0.105730
2025-12-13 02:53:56,208 INFO     Training average loss at step 158700: 0.388856
2025-12-13 02:53:58,356 INFO     Training average regularization at step 158800: 0.302108
2025-12-13 02:53:58,356 INFO     Training average positive_sample_loss at step 158800: 0.066667
2025-12-13 02:53:58,356 INFO     Training average negative_sample_loss at step 158800: 0.107574
2025-12-13 02:53:58,356 INFO     Training average loss at step 158800: 0.389228
2025-12-13 02:54:00,514 INFO     Training average regularization at step 158900: 0.302107
2025-12-13 02:54:00,515 INFO     Training average positive_sample_loss at step 158900: 0.066776
2025-12-13 02:54:00,515 INFO     Training average negative_sample_loss at step 158900: 0.107423
2025-12-13 02:54:00,515 INFO     Training average loss at step 158900: 0.389206
2025-12-13 02:54:02,719 INFO     Training average regularization at step 159000: 0.302106
2025-12-13 02:54:02,719 INFO     Training average positive_sample_loss at step 159000: 0.066467
2025-12-13 02:54:02,720 INFO     Training average negative_sample_loss at step 159000: 0.109875
2025-12-13 02:54:02,720 INFO     Training average loss at step 159000: 0.390277
2025-12-13 02:54:04,874 INFO     Training average regularization at step 159100: 0.302106
2025-12-13 02:54:04,874 INFO     Training average positive_sample_loss at step 159100: 0.065648
2025-12-13 02:54:04,874 INFO     Training average negative_sample_loss at step 159100: 0.110374
2025-12-13 02:54:04,874 INFO     Training average loss at step 159100: 0.390117
2025-12-13 02:54:07,044 INFO     Training average regularization at step 159200: 0.302105
2025-12-13 02:54:07,044 INFO     Training average positive_sample_loss at step 159200: 0.065899
2025-12-13 02:54:07,044 INFO     Training average negative_sample_loss at step 159200: 0.106773
2025-12-13 02:54:07,044 INFO     Training average loss at step 159200: 0.388441
2025-12-13 02:54:09,203 INFO     Training average regularization at step 159300: 0.302105
2025-12-13 02:54:09,203 INFO     Training average positive_sample_loss at step 159300: 0.066426
2025-12-13 02:54:09,203 INFO     Training average negative_sample_loss at step 159300: 0.111544
2025-12-13 02:54:09,203 INFO     Training average loss at step 159300: 0.391090
2025-12-13 02:54:11,356 INFO     Training average regularization at step 159400: 0.302104
2025-12-13 02:54:11,356 INFO     Training average positive_sample_loss at step 159400: 0.066420
2025-12-13 02:54:11,356 INFO     Training average negative_sample_loss at step 159400: 0.110277
2025-12-13 02:54:11,356 INFO     Training average loss at step 159400: 0.390452
2025-12-13 02:54:14,599 INFO     Training average regularization at step 159500: 0.302104
2025-12-13 02:54:14,599 INFO     Training average positive_sample_loss at step 159500: 0.068201
2025-12-13 02:54:14,599 INFO     Training average negative_sample_loss at step 159500: 0.111655
2025-12-13 02:54:14,599 INFO     Training average loss at step 159500: 0.392032
2025-12-13 02:54:16,756 INFO     Training average regularization at step 159600: 0.302103
2025-12-13 02:54:16,757 INFO     Training average positive_sample_loss at step 159600: 0.066007
2025-12-13 02:54:16,757 INFO     Training average negative_sample_loss at step 159600: 0.109438
2025-12-13 02:54:16,757 INFO     Training average loss at step 159600: 0.389826
2025-12-13 02:54:18,893 INFO     Training average regularization at step 159700: 0.302102
2025-12-13 02:54:18,893 INFO     Training average positive_sample_loss at step 159700: 0.066676
2025-12-13 02:54:18,893 INFO     Training average negative_sample_loss at step 159700: 0.107947
2025-12-13 02:54:18,893 INFO     Training average loss at step 159700: 0.389414
2025-12-13 02:54:21,038 INFO     Training average regularization at step 159800: 0.302102
2025-12-13 02:54:21,038 INFO     Training average positive_sample_loss at step 159800: 0.067804
2025-12-13 02:54:21,038 INFO     Training average negative_sample_loss at step 159800: 0.108602
2025-12-13 02:54:21,038 INFO     Training average loss at step 159800: 0.390305
2025-12-13 02:54:23,195 INFO     Training average regularization at step 159900: 0.302101
2025-12-13 02:54:23,195 INFO     Training average positive_sample_loss at step 159900: 0.065745
2025-12-13 02:54:23,195 INFO     Training average negative_sample_loss at step 159900: 0.107028
2025-12-13 02:54:23,195 INFO     Training average loss at step 159900: 0.388487
2025-12-13 02:54:25,393 INFO     Change learning_rate to 0.000000 at step 160000
2025-12-13 02:54:26,179 INFO     Training average regularization at step 160000: 0.302100
2025-12-13 02:54:26,179 INFO     Training average positive_sample_loss at step 160000: 0.067070
2025-12-13 02:54:26,179 INFO     Training average negative_sample_loss at step 160000: 0.107239
2025-12-13 02:54:26,179 INFO     Training average loss at step 160000: 0.389254
2025-12-13 02:54:26,179 INFO     Evaluating on Valid Dataset...
2025-12-13 02:54:26,760 INFO     Evaluating the model... (0/50000)
2025-12-13 02:54:29,344 INFO     Evaluating the model... (500/50000)
2025-12-13 02:54:31,722 INFO     Evaluating the model... (1000/50000)
2025-12-13 02:54:34,210 INFO     Evaluating the model... (1500/50000)
2025-12-13 02:54:37,993 INFO     Evaluating the model... (2000/50000)
2025-12-13 02:54:40,715 INFO     Evaluating the model... (2500/50000)
2025-12-13 02:54:43,245 INFO     Evaluating the model... (3000/50000)
2025-12-13 02:54:45,894 INFO     Evaluating the model... (3500/50000)
2025-12-13 02:54:48,616 INFO     Evaluating the model... (4000/50000)
2025-12-13 02:54:51,765 INFO     Evaluating the model... (4500/50000)
2025-12-13 02:54:54,328 INFO     Evaluating the model... (5000/50000)
2025-12-13 02:54:56,774 INFO     Evaluating the model... (5500/50000)
2025-12-13 02:54:59,371 INFO     Evaluating the model... (6000/50000)
2025-12-13 02:55:01,849 INFO     Evaluating the model... (6500/50000)
2025-12-13 02:55:04,767 INFO     Evaluating the model... (7000/50000)
2025-12-13 02:55:07,135 INFO     Evaluating the model... (7500/50000)
2025-12-13 02:55:09,507 INFO     Evaluating the model... (8000/50000)
2025-12-13 02:55:12,027 INFO     Evaluating the model... (8500/50000)
2025-12-13 02:55:14,439 INFO     Evaluating the model... (9000/50000)
2025-12-13 02:55:17,756 INFO     Evaluating the model... (9500/50000)
2025-12-13 02:55:20,076 INFO     Evaluating the model... (10000/50000)
2025-12-13 02:55:22,671 INFO     Evaluating the model... (10500/50000)
2025-12-13 02:55:25,106 INFO     Evaluating the model... (11000/50000)
2025-12-13 02:55:27,635 INFO     Evaluating the model... (11500/50000)
2025-12-13 02:55:30,911 INFO     Evaluating the model... (12000/50000)
2025-12-13 02:55:33,464 INFO     Evaluating the model... (12500/50000)
2025-12-13 02:55:36,146 INFO     Evaluating the model... (13000/50000)
2025-12-13 02:55:38,760 INFO     Evaluating the model... (13500/50000)
2025-12-13 02:55:41,330 INFO     Evaluating the model... (14000/50000)
2025-12-13 02:55:45,089 INFO     Evaluating the model... (14500/50000)
2025-12-13 02:55:47,714 INFO     Evaluating the model... (15000/50000)
2025-12-13 02:55:50,116 INFO     Evaluating the model... (15500/50000)
2025-12-13 02:55:52,568 INFO     Evaluating the model... (16000/50000)
2025-12-13 02:55:54,879 INFO     Evaluating the model... (16500/50000)
2025-12-13 02:55:58,396 INFO     Evaluating the model... (17000/50000)
2025-12-13 02:56:00,828 INFO     Evaluating the model... (17500/50000)
2025-12-13 02:56:03,338 INFO     Evaluating the model... (18000/50000)
2025-12-13 02:56:05,785 INFO     Evaluating the model... (18500/50000)
2025-12-13 02:56:08,816 INFO     Evaluating the model... (19000/50000)
2025-12-13 02:56:11,822 INFO     Evaluating the model... (19500/50000)
2025-12-13 02:56:14,120 INFO     Evaluating the model... (20000/50000)
2025-12-13 02:56:16,601 INFO     Evaluating the model... (20500/50000)
2025-12-13 02:56:19,105 INFO     Evaluating the model... (21000/50000)
2025-12-13 02:56:22,787 INFO     Evaluating the model... (21500/50000)
2025-12-13 02:56:25,144 INFO     Evaluating the model... (22000/50000)
2025-12-13 02:56:27,532 INFO     Evaluating the model... (22500/50000)
2025-12-13 02:56:29,928 INFO     Evaluating the model... (23000/50000)
2025-12-13 02:56:32,534 INFO     Evaluating the model... (23500/50000)
2025-12-13 02:56:35,996 INFO     Evaluating the model... (24000/50000)
2025-12-13 02:56:38,536 INFO     Evaluating the model... (24500/50000)
2025-12-13 02:56:41,661 INFO     Evaluating the model... (25000/50000)
2025-12-13 02:56:44,706 INFO     Evaluating the model... (25500/50000)
2025-12-13 02:56:47,268 INFO     Evaluating the model... (26000/50000)
2025-12-13 02:56:49,834 INFO     Evaluating the model... (26500/50000)
2025-12-13 02:56:53,321 INFO     Evaluating the model... (27000/50000)
2025-12-13 02:56:55,980 INFO     Evaluating the model... (27500/50000)
2025-12-13 02:56:58,548 INFO     Evaluating the model... (28000/50000)
2025-12-13 02:57:01,086 INFO     Evaluating the model... (28500/50000)
2025-12-13 02:57:04,171 INFO     Evaluating the model... (29000/50000)
2025-12-13 02:57:06,925 INFO     Evaluating the model... (29500/50000)
2025-12-13 02:57:09,399 INFO     Evaluating the model... (30000/50000)
2025-12-13 02:57:11,860 INFO     Evaluating the model... (30500/50000)
2025-12-13 02:57:14,324 INFO     Evaluating the model... (31000/50000)
2025-12-13 02:57:17,609 INFO     Evaluating the model... (31500/50000)
2025-12-13 02:57:20,089 INFO     Evaluating the model... (32000/50000)
2025-12-13 02:57:22,628 INFO     Evaluating the model... (32500/50000)
2025-12-13 02:57:25,130 INFO     Evaluating the model... (33000/50000)
2025-12-13 02:57:27,700 INFO     Evaluating the model... (33500/50000)
2025-12-13 02:57:31,230 INFO     Evaluating the model... (34000/50000)
2025-12-13 02:57:33,774 INFO     Evaluating the model... (34500/50000)
2025-12-13 02:57:36,437 INFO     Evaluating the model... (35000/50000)
2025-12-13 02:57:39,128 INFO     Evaluating the model... (35500/50000)
2025-12-13 02:57:42,127 INFO     Evaluating the model... (36000/50000)
2025-12-13 02:57:46,026 INFO     Evaluating the model... (36500/50000)
2025-12-13 02:57:48,558 INFO     Evaluating the model... (37000/50000)
2025-12-13 02:57:51,116 INFO     Evaluating the model... (37500/50000)
2025-12-13 02:57:53,768 INFO     Evaluating the model... (38000/50000)
2025-12-13 02:57:56,318 INFO     Evaluating the model... (38500/50000)
2025-12-13 02:57:59,964 INFO     Evaluating the model... (39000/50000)
2025-12-13 02:58:02,455 INFO     Evaluating the model... (39500/50000)
2025-12-13 02:58:05,193 INFO     Evaluating the model... (40000/50000)
2025-12-13 02:58:07,668 INFO     Evaluating the model... (40500/50000)
2025-12-13 02:58:10,089 INFO     Evaluating the model... (41000/50000)
2025-12-13 02:58:13,592 INFO     Evaluating the model... (41500/50000)
2025-12-13 02:58:16,268 INFO     Evaluating the model... (42000/50000)
2025-12-13 02:58:18,784 INFO     Evaluating the model... (42500/50000)
2025-12-13 02:58:21,158 INFO     Evaluating the model... (43000/50000)
2025-12-13 02:58:23,636 INFO     Evaluating the model... (43500/50000)
2025-12-13 02:58:27,432 INFO     Evaluating the model... (44000/50000)
2025-12-13 02:58:29,917 INFO     Evaluating the model... (44500/50000)
2025-12-13 02:58:32,427 INFO     Evaluating the model... (45000/50000)
2025-12-13 02:58:34,962 INFO     Evaluating the model... (45500/50000)
2025-12-13 02:58:37,896 INFO     Evaluating the model... (46000/50000)
2025-12-13 02:58:41,947 INFO     Evaluating the model... (46500/50000)
2025-12-13 02:58:44,657 INFO     Evaluating the model... (47000/50000)
2025-12-13 02:58:47,183 INFO     Evaluating the model... (47500/50000)
2025-12-13 02:58:49,879 INFO     Evaluating the model... (48000/50000)
2025-12-13 02:58:53,331 INFO     Evaluating the model... (48500/50000)
2025-12-13 02:58:55,852 INFO     Evaluating the model... (49000/50000)
2025-12-13 02:58:58,245 INFO     Evaluating the model... (49500/50000)
2025-12-13 02:59:01,329 INFO     Valid MRR at step 160000: 0.632904
2025-12-13 02:59:01,330 INFO     Valid MR at step 160000: 266.714590
2025-12-13 02:59:01,330 INFO     Valid HITS@1 at step 160000: 0.547080
2025-12-13 02:59:01,330 INFO     Valid HITS@3 at step 160000: 0.686010
2025-12-13 02:59:01,330 INFO     Valid HITS@10 at step 160000: 0.784740
2025-12-13 02:59:02,099 INFO     Evaluating on Test Dataset...
2025-12-13 02:59:02,532 INFO     Evaluating the model... (0/59072)
2025-12-13 02:59:05,065 INFO     Evaluating the model... (500/59072)
2025-12-13 02:59:07,604 INFO     Evaluating the model... (1000/59072)
2025-12-13 02:59:11,044 INFO     Evaluating the model... (1500/59072)
2025-12-13 02:59:13,662 INFO     Evaluating the model... (2000/59072)
2025-12-13 02:59:16,215 INFO     Evaluating the model... (2500/59072)
2025-12-13 02:59:18,760 INFO     Evaluating the model... (3000/59072)
2025-12-13 02:59:21,289 INFO     Evaluating the model... (3500/59072)
2025-12-13 02:59:24,597 INFO     Evaluating the model... (4000/59072)
2025-12-13 02:59:27,141 INFO     Evaluating the model... (4500/59072)
2025-12-13 02:59:29,657 INFO     Evaluating the model... (5000/59072)
2025-12-13 02:59:32,173 INFO     Evaluating the model... (5500/59072)
2025-12-13 02:59:34,724 INFO     Evaluating the model... (6000/59072)
2025-12-13 02:59:38,050 INFO     Evaluating the model... (6500/59072)
2025-12-13 02:59:40,655 INFO     Evaluating the model... (7000/59072)
2025-12-13 02:59:43,251 INFO     Evaluating the model... (7500/59072)
2025-12-13 02:59:45,818 INFO     Evaluating the model... (8000/59072)
2025-12-13 02:59:49,334 INFO     Evaluating the model... (8500/59072)
2025-12-13 02:59:51,855 INFO     Evaluating the model... (9000/59072)
2025-12-13 02:59:54,252 INFO     Evaluating the model... (9500/59072)
2025-12-13 02:59:56,687 INFO     Evaluating the model... (10000/59072)
2025-12-13 02:59:59,407 INFO     Evaluating the model... (10500/59072)
2025-12-13 03:00:02,846 INFO     Evaluating the model... (11000/59072)
2025-12-13 03:00:05,380 INFO     Evaluating the model... (11500/59072)
2025-12-13 03:00:07,892 INFO     Evaluating the model... (12000/59072)
2025-12-13 03:00:10,515 INFO     Evaluating the model... (12500/59072)
2025-12-13 03:00:12,879 INFO     Evaluating the model... (13000/59072)
2025-12-13 03:00:16,341 INFO     Evaluating the model... (13500/59072)
2025-12-13 03:00:18,788 INFO     Evaluating the model... (14000/59072)
2025-12-13 03:00:21,575 INFO     Evaluating the model... (14500/59072)
2025-12-13 03:00:24,141 INFO     Evaluating the model... (15000/59072)
2025-12-13 03:00:26,580 INFO     Evaluating the model... (15500/59072)
2025-12-13 03:00:30,228 INFO     Evaluating the model... (16000/59072)
2025-12-13 03:00:32,918 INFO     Evaluating the model... (16500/59072)
2025-12-13 03:00:35,466 INFO     Evaluating the model... (17000/59072)
2025-12-13 03:00:38,195 INFO     Evaluating the model... (17500/59072)
2025-12-13 03:00:40,859 INFO     Evaluating the model... (18000/59072)
2025-12-13 03:00:44,778 INFO     Evaluating the model... (18500/59072)
2025-12-13 03:00:47,181 INFO     Evaluating the model... (19000/59072)
2025-12-13 03:00:49,578 INFO     Evaluating the model... (19500/59072)
2025-12-13 03:00:51,978 INFO     Evaluating the model... (20000/59072)
2025-12-13 03:00:54,367 INFO     Evaluating the model... (20500/59072)
2025-12-13 03:00:58,216 INFO     Evaluating the model... (21000/59072)
2025-12-13 03:01:00,634 INFO     Evaluating the model... (21500/59072)
2025-12-13 03:01:03,127 INFO     Evaluating the model... (22000/59072)
2025-12-13 03:01:05,619 INFO     Evaluating the model... (22500/59072)
2025-12-13 03:01:08,281 INFO     Evaluating the model... (23000/59072)
2025-12-13 03:01:12,078 INFO     Evaluating the model... (23500/59072)
2025-12-13 03:01:14,572 INFO     Evaluating the model... (24000/59072)
2025-12-13 03:01:17,068 INFO     Evaluating the model... (24500/59072)
2025-12-13 03:01:19,730 INFO     Evaluating the model... (25000/59072)
2025-12-13 03:01:22,252 INFO     Evaluating the model... (25500/59072)
2025-12-13 03:01:26,003 INFO     Evaluating the model... (26000/59072)
2025-12-13 03:01:28,494 INFO     Evaluating the model... (26500/59072)
2025-12-13 03:01:31,263 INFO     Evaluating the model... (27000/59072)
2025-12-13 03:01:33,774 INFO     Evaluating the model... (27500/59072)
2025-12-13 03:01:37,751 INFO     Evaluating the model... (28000/59072)
2025-12-13 03:01:40,342 INFO     Evaluating the model... (28500/59072)
2025-12-13 03:01:43,201 INFO     Evaluating the model... (29000/59072)
2025-12-13 03:01:45,798 INFO     Evaluating the model... (29500/59072)
2025-12-13 03:01:48,693 INFO     Evaluating the model... (30000/59072)
2025-12-13 03:01:52,139 INFO     Evaluating the model... (30500/59072)
2025-12-13 03:01:54,798 INFO     Evaluating the model... (31000/59072)
2025-12-13 03:01:57,376 INFO     Evaluating the model... (31500/59072)
2025-12-13 03:01:59,898 INFO     Evaluating the model... (32000/59072)
2025-12-13 03:02:02,439 INFO     Evaluating the model... (32500/59072)
2025-12-13 03:02:05,808 INFO     Evaluating the model... (33000/59072)
2025-12-13 03:02:08,325 INFO     Evaluating the model... (33500/59072)
2025-12-13 03:02:10,773 INFO     Evaluating the model... (34000/59072)
2025-12-13 03:02:13,265 INFO     Evaluating the model... (34500/59072)
2025-12-13 03:02:15,844 INFO     Evaluating the model... (35000/59072)
2025-12-13 03:02:19,038 INFO     Evaluating the model... (35500/59072)
2025-12-13 03:02:21,581 INFO     Evaluating the model... (36000/59072)
2025-12-13 03:02:24,062 INFO     Evaluating the model... (36500/59072)
2025-12-13 03:02:26,737 INFO     Evaluating the model... (37000/59072)
2025-12-13 03:02:29,984 INFO     Evaluating the model... (37500/59072)
2025-12-13 03:02:32,529 INFO     Evaluating the model... (38000/59072)
2025-12-13 03:02:35,118 INFO     Evaluating the model... (38500/59072)
2025-12-13 03:02:37,823 INFO     Evaluating the model... (39000/59072)
2025-12-13 03:02:40,789 INFO     Evaluating the model... (39500/59072)
2025-12-13 03:02:44,428 INFO     Evaluating the model... (40000/59072)
2025-12-13 03:02:47,017 INFO     Evaluating the model... (40500/59072)
2025-12-13 03:02:49,475 INFO     Evaluating the model... (41000/59072)
2025-12-13 03:02:52,071 INFO     Evaluating the model... (41500/59072)
2025-12-13 03:02:54,494 INFO     Evaluating the model... (42000/59072)
2025-12-13 03:02:58,194 INFO     Evaluating the model... (42500/59072)
2025-12-13 03:03:00,673 INFO     Evaluating the model... (43000/59072)
2025-12-13 03:03:03,312 INFO     Evaluating the model... (43500/59072)
2025-12-13 03:03:05,815 INFO     Evaluating the model... (44000/59072)
2025-12-13 03:03:08,233 INFO     Evaluating the model... (44500/59072)
2025-12-13 03:03:12,078 INFO     Evaluating the model... (45000/59072)
2025-12-13 03:03:14,691 INFO     Evaluating the model... (45500/59072)
2025-12-13 03:03:17,253 INFO     Evaluating the model... (46000/59072)
2025-12-13 03:03:19,883 INFO     Evaluating the model... (46500/59072)
2025-12-13 03:03:22,436 INFO     Evaluating the model... (47000/59072)
2025-12-13 03:03:26,437 INFO     Evaluating the model... (47500/59072)
2025-12-13 03:03:28,890 INFO     Evaluating the model... (48000/59072)
2025-12-13 03:03:31,426 INFO     Evaluating the model... (48500/59072)
2025-12-13 03:03:33,867 INFO     Evaluating the model... (49000/59072)
2025-12-13 03:03:36,667 INFO     Evaluating the model... (49500/59072)
2025-12-13 03:03:40,546 INFO     Evaluating the model... (50000/59072)
2025-12-13 03:03:43,233 INFO     Evaluating the model... (50500/59072)
2025-12-13 03:03:45,834 INFO     Evaluating the model... (51000/59072)
2025-12-13 03:03:48,374 INFO     Evaluating the model... (51500/59072)
2025-12-13 03:03:50,867 INFO     Evaluating the model... (52000/59072)
2025-12-13 03:03:54,431 INFO     Evaluating the model... (52500/59072)
2025-12-13 03:03:56,910 INFO     Evaluating the model... (53000/59072)
2025-12-13 03:03:59,565 INFO     Evaluating the model... (53500/59072)
2025-12-13 03:04:02,072 INFO     Evaluating the model... (54000/59072)
2025-12-13 03:04:04,606 INFO     Evaluating the model... (54500/59072)
2025-12-13 03:04:08,376 INFO     Evaluating the model... (55000/59072)
2025-12-13 03:04:10,931 INFO     Evaluating the model... (55500/59072)
2025-12-13 03:04:13,479 INFO     Evaluating the model... (56000/59072)
2025-12-13 03:04:15,949 INFO     Evaluating the model... (56500/59072)
2025-12-13 03:04:19,228 INFO     Evaluating the model... (57000/59072)
2025-12-13 03:04:22,449 INFO     Evaluating the model... (57500/59072)
2025-12-13 03:04:25,001 INFO     Evaluating the model... (58000/59072)
2025-12-13 03:04:27,618 INFO     Evaluating the model... (58500/59072)
2025-12-13 03:04:30,118 INFO     Evaluating the model... (59000/59072)
2025-12-13 03:04:30,724 INFO     Test MRR at step 160000: 0.629843
2025-12-13 03:04:30,724 INFO     Test MR at step 160000: 268.682687
2025-12-13 03:04:30,724 INFO     Test HITS@1 at step 160000: 0.542737
2025-12-13 03:04:30,724 INFO     Test HITS@3 at step 160000: 0.684211
2025-12-13 03:04:30,724 INFO     Test HITS@10 at step 160000: 0.782948
2025-12-13 03:04:32,900 INFO     Training average regularization at step 160100: 0.302094
2025-12-13 03:04:32,900 INFO     Training average positive_sample_loss at step 160100: 0.067498
2025-12-13 03:04:32,900 INFO     Training average negative_sample_loss at step 160100: 0.107997
2025-12-13 03:04:32,900 INFO     Training average loss at step 160100: 0.389841
2025-12-13 03:04:35,097 INFO     Training average regularization at step 160200: 0.302088
2025-12-13 03:04:35,098 INFO     Training average positive_sample_loss at step 160200: 0.066430
2025-12-13 03:04:35,098 INFO     Training average negative_sample_loss at step 160200: 0.110300
2025-12-13 03:04:35,098 INFO     Training average loss at step 160200: 0.390453
2025-12-13 03:04:37,327 INFO     Training average regularization at step 160300: 0.302086
2025-12-13 03:04:37,328 INFO     Training average positive_sample_loss at step 160300: 0.066236
2025-12-13 03:04:37,328 INFO     Training average negative_sample_loss at step 160300: 0.107691
2025-12-13 03:04:37,328 INFO     Training average loss at step 160300: 0.389049
2025-12-13 03:04:39,534 INFO     Training average regularization at step 160400: 0.302084
2025-12-13 03:04:39,534 INFO     Training average positive_sample_loss at step 160400: 0.067017
2025-12-13 03:04:39,534 INFO     Training average negative_sample_loss at step 160400: 0.109136
2025-12-13 03:04:39,534 INFO     Training average loss at step 160400: 0.390161
2025-12-13 03:04:41,769 INFO     Training average regularization at step 160500: 0.302083
2025-12-13 03:04:41,770 INFO     Training average positive_sample_loss at step 160500: 0.066162
2025-12-13 03:04:41,770 INFO     Training average negative_sample_loss at step 160500: 0.106545
2025-12-13 03:04:41,770 INFO     Training average loss at step 160500: 0.388437
2025-12-13 03:04:44,004 INFO     Training average regularization at step 160600: 0.302082
2025-12-13 03:04:44,004 INFO     Training average positive_sample_loss at step 160600: 0.065709
2025-12-13 03:04:44,004 INFO     Training average negative_sample_loss at step 160600: 0.109429
2025-12-13 03:04:44,004 INFO     Training average loss at step 160600: 0.389651
2025-12-13 03:04:46,225 INFO     Training average regularization at step 160700: 0.302082
2025-12-13 03:04:46,225 INFO     Training average positive_sample_loss at step 160700: 0.065995
2025-12-13 03:04:46,225 INFO     Training average negative_sample_loss at step 160700: 0.108974
2025-12-13 03:04:46,225 INFO     Training average loss at step 160700: 0.389566
2025-12-13 03:04:48,395 INFO     Training average regularization at step 160800: 0.302081
2025-12-13 03:04:48,395 INFO     Training average positive_sample_loss at step 160800: 0.066985
2025-12-13 03:04:48,395 INFO     Training average negative_sample_loss at step 160800: 0.106168
2025-12-13 03:04:48,395 INFO     Training average loss at step 160800: 0.388658
2025-12-13 03:04:50,557 INFO     Training average regularization at step 160900: 0.302081
2025-12-13 03:04:50,557 INFO     Training average positive_sample_loss at step 160900: 0.066935
2025-12-13 03:04:50,558 INFO     Training average negative_sample_loss at step 160900: 0.107833
2025-12-13 03:04:50,558 INFO     Training average loss at step 160900: 0.389465
2025-12-13 03:04:52,710 INFO     Training average regularization at step 161000: 0.302081
2025-12-13 03:04:52,710 INFO     Training average positive_sample_loss at step 161000: 0.066862
2025-12-13 03:04:52,710 INFO     Training average negative_sample_loss at step 161000: 0.108196
2025-12-13 03:04:52,710 INFO     Training average loss at step 161000: 0.389610
2025-12-13 03:04:54,876 INFO     Training average regularization at step 161100: 0.302080
2025-12-13 03:04:54,876 INFO     Training average positive_sample_loss at step 161100: 0.065325
2025-12-13 03:04:54,877 INFO     Training average negative_sample_loss at step 161100: 0.110579
2025-12-13 03:04:54,877 INFO     Training average loss at step 161100: 0.390032
2025-12-13 03:04:57,055 INFO     Training average regularization at step 161200: 0.302080
2025-12-13 03:04:57,056 INFO     Training average positive_sample_loss at step 161200: 0.066919
2025-12-13 03:04:57,056 INFO     Training average negative_sample_loss at step 161200: 0.107850
2025-12-13 03:04:57,056 INFO     Training average loss at step 161200: 0.389464
2025-12-13 03:04:59,214 INFO     Training average regularization at step 161300: 0.302080
2025-12-13 03:04:59,214 INFO     Training average positive_sample_loss at step 161300: 0.066134
2025-12-13 03:04:59,214 INFO     Training average negative_sample_loss at step 161300: 0.108759
2025-12-13 03:04:59,214 INFO     Training average loss at step 161300: 0.389526
2025-12-13 03:05:01,362 INFO     Training average regularization at step 161400: 0.302080
2025-12-13 03:05:01,362 INFO     Training average positive_sample_loss at step 161400: 0.066936
2025-12-13 03:05:01,362 INFO     Training average negative_sample_loss at step 161400: 0.110318
2025-12-13 03:05:01,362 INFO     Training average loss at step 161400: 0.390706
2025-12-13 03:05:03,518 INFO     Training average regularization at step 161500: 0.302079
2025-12-13 03:05:03,518 INFO     Training average positive_sample_loss at step 161500: 0.066836
2025-12-13 03:05:03,518 INFO     Training average negative_sample_loss at step 161500: 0.112190
2025-12-13 03:05:03,518 INFO     Training average loss at step 161500: 0.391592
2025-12-13 03:05:05,697 INFO     Training average regularization at step 161600: 0.302079
2025-12-13 03:05:05,697 INFO     Training average positive_sample_loss at step 161600: 0.066318
2025-12-13 03:05:05,697 INFO     Training average negative_sample_loss at step 161600: 0.105937
2025-12-13 03:05:05,697 INFO     Training average loss at step 161600: 0.388206
2025-12-13 03:05:07,898 INFO     Training average regularization at step 161700: 0.302079
2025-12-13 03:05:07,898 INFO     Training average positive_sample_loss at step 161700: 0.066468
2025-12-13 03:05:07,898 INFO     Training average negative_sample_loss at step 161700: 0.108040
2025-12-13 03:05:07,898 INFO     Training average loss at step 161700: 0.389333
2025-12-13 03:05:10,051 INFO     Training average regularization at step 161800: 0.302079
2025-12-13 03:05:10,052 INFO     Training average positive_sample_loss at step 161800: 0.066198
2025-12-13 03:05:10,052 INFO     Training average negative_sample_loss at step 161800: 0.108088
2025-12-13 03:05:10,052 INFO     Training average loss at step 161800: 0.389222
2025-12-13 03:05:12,210 INFO     Training average regularization at step 161900: 0.302079
2025-12-13 03:05:12,210 INFO     Training average positive_sample_loss at step 161900: 0.067228
2025-12-13 03:05:12,210 INFO     Training average negative_sample_loss at step 161900: 0.109161
2025-12-13 03:05:12,210 INFO     Training average loss at step 161900: 0.390273
2025-12-13 03:05:14,368 INFO     Training average regularization at step 162000: 0.302079
2025-12-13 03:05:14,369 INFO     Training average positive_sample_loss at step 162000: 0.066472
2025-12-13 03:05:14,369 INFO     Training average negative_sample_loss at step 162000: 0.109215
2025-12-13 03:05:14,369 INFO     Training average loss at step 162000: 0.389922
2025-12-13 03:05:16,525 INFO     Training average regularization at step 162100: 0.302079
2025-12-13 03:05:16,525 INFO     Training average positive_sample_loss at step 162100: 0.066825
2025-12-13 03:05:16,526 INFO     Training average negative_sample_loss at step 162100: 0.107481
2025-12-13 03:05:16,526 INFO     Training average loss at step 162100: 0.389231
2025-12-13 03:05:18,688 INFO     Training average regularization at step 162200: 0.302079
2025-12-13 03:05:18,689 INFO     Training average positive_sample_loss at step 162200: 0.064833
2025-12-13 03:05:18,689 INFO     Training average negative_sample_loss at step 162200: 0.108279
2025-12-13 03:05:18,689 INFO     Training average loss at step 162200: 0.388635
2025-12-13 03:05:20,839 INFO     Training average regularization at step 162300: 0.302078
2025-12-13 03:05:20,841 INFO     Training average positive_sample_loss at step 162300: 0.065876
2025-12-13 03:05:20,841 INFO     Training average negative_sample_loss at step 162300: 0.109786
2025-12-13 03:05:20,841 INFO     Training average loss at step 162300: 0.389909
2025-12-13 03:05:22,985 INFO     Training average regularization at step 162400: 0.302078
2025-12-13 03:05:22,985 INFO     Training average positive_sample_loss at step 162400: 0.067607
2025-12-13 03:05:22,985 INFO     Training average negative_sample_loss at step 162400: 0.109584
2025-12-13 03:05:22,985 INFO     Training average loss at step 162400: 0.390674
2025-12-13 03:05:25,141 INFO     Training average regularization at step 162500: 0.302078
2025-12-13 03:05:25,142 INFO     Training average positive_sample_loss at step 162500: 0.067117
2025-12-13 03:05:25,142 INFO     Training average negative_sample_loss at step 162500: 0.107065
2025-12-13 03:05:25,142 INFO     Training average loss at step 162500: 0.389169
2025-12-13 03:05:27,281 INFO     Training average regularization at step 162600: 0.302078
2025-12-13 03:05:27,282 INFO     Training average positive_sample_loss at step 162600: 0.068730
2025-12-13 03:05:27,282 INFO     Training average negative_sample_loss at step 162600: 0.111465
2025-12-13 03:05:27,282 INFO     Training average loss at step 162600: 0.392176
2025-12-13 03:05:29,460 INFO     Training average regularization at step 162700: 0.302078
2025-12-13 03:05:29,460 INFO     Training average positive_sample_loss at step 162700: 0.067930
2025-12-13 03:05:29,460 INFO     Training average negative_sample_loss at step 162700: 0.106068
2025-12-13 03:05:29,460 INFO     Training average loss at step 162700: 0.389077
2025-12-13 03:05:31,613 INFO     Training average regularization at step 162800: 0.302078
2025-12-13 03:05:31,613 INFO     Training average positive_sample_loss at step 162800: 0.067181
2025-12-13 03:05:31,613 INFO     Training average negative_sample_loss at step 162800: 0.110458
2025-12-13 03:05:31,613 INFO     Training average loss at step 162800: 0.390897
2025-12-13 03:05:33,786 INFO     Training average regularization at step 162900: 0.302078
2025-12-13 03:05:33,787 INFO     Training average positive_sample_loss at step 162900: 0.065805
2025-12-13 03:05:33,787 INFO     Training average negative_sample_loss at step 162900: 0.108808
2025-12-13 03:05:33,787 INFO     Training average loss at step 162900: 0.389384
2025-12-13 03:05:35,957 INFO     Training average regularization at step 163000: 0.302078
2025-12-13 03:05:35,957 INFO     Training average positive_sample_loss at step 163000: 0.066853
2025-12-13 03:05:35,957 INFO     Training average negative_sample_loss at step 163000: 0.111001
2025-12-13 03:05:35,957 INFO     Training average loss at step 163000: 0.391005
2025-12-13 03:05:38,138 INFO     Training average regularization at step 163100: 0.302078
2025-12-13 03:05:38,138 INFO     Training average positive_sample_loss at step 163100: 0.065806
2025-12-13 03:05:38,138 INFO     Training average negative_sample_loss at step 163100: 0.108319
2025-12-13 03:05:38,138 INFO     Training average loss at step 163100: 0.389140
2025-12-13 03:05:40,360 INFO     Training average regularization at step 163200: 0.302078
2025-12-13 03:05:40,360 INFO     Training average positive_sample_loss at step 163200: 0.068031
2025-12-13 03:05:40,360 INFO     Training average negative_sample_loss at step 163200: 0.111381
2025-12-13 03:05:40,360 INFO     Training average loss at step 163200: 0.391784
2025-12-13 03:05:42,511 INFO     Training average regularization at step 163300: 0.302078
2025-12-13 03:05:42,511 INFO     Training average positive_sample_loss at step 163300: 0.067279
2025-12-13 03:05:42,511 INFO     Training average negative_sample_loss at step 163300: 0.111557
2025-12-13 03:05:42,511 INFO     Training average loss at step 163300: 0.391496
2025-12-13 03:05:44,667 INFO     Training average regularization at step 163400: 0.302078
2025-12-13 03:05:44,668 INFO     Training average positive_sample_loss at step 163400: 0.065746
2025-12-13 03:05:44,668 INFO     Training average negative_sample_loss at step 163400: 0.108755
2025-12-13 03:05:44,668 INFO     Training average loss at step 163400: 0.389328
2025-12-13 03:05:46,838 INFO     Training average regularization at step 163500: 0.302077
2025-12-13 03:05:46,838 INFO     Training average positive_sample_loss at step 163500: 0.067665
2025-12-13 03:05:46,838 INFO     Training average negative_sample_loss at step 163500: 0.109223
2025-12-13 03:05:46,838 INFO     Training average loss at step 163500: 0.390521
2025-12-13 03:05:49,003 INFO     Training average regularization at step 163600: 0.302077
2025-12-13 03:05:49,004 INFO     Training average positive_sample_loss at step 163600: 0.067567
2025-12-13 03:05:49,004 INFO     Training average negative_sample_loss at step 163600: 0.107428
2025-12-13 03:05:49,004 INFO     Training average loss at step 163600: 0.389575
2025-12-13 03:05:51,168 INFO     Training average regularization at step 163700: 0.302077
2025-12-13 03:05:51,169 INFO     Training average positive_sample_loss at step 163700: 0.067279
2025-12-13 03:05:51,169 INFO     Training average negative_sample_loss at step 163700: 0.109302
2025-12-13 03:05:51,169 INFO     Training average loss at step 163700: 0.390368
2025-12-13 03:05:53,306 INFO     Training average regularization at step 163800: 0.302077
2025-12-13 03:05:53,306 INFO     Training average positive_sample_loss at step 163800: 0.066587
2025-12-13 03:05:53,306 INFO     Training average negative_sample_loss at step 163800: 0.109714
2025-12-13 03:05:53,306 INFO     Training average loss at step 163800: 0.390228
2025-12-13 03:05:55,481 INFO     Training average regularization at step 163900: 0.302077
2025-12-13 03:05:55,481 INFO     Training average positive_sample_loss at step 163900: 0.066339
2025-12-13 03:05:55,481 INFO     Training average negative_sample_loss at step 163900: 0.109231
2025-12-13 03:05:55,481 INFO     Training average loss at step 163900: 0.389862
2025-12-13 03:05:57,633 INFO     Training average regularization at step 164000: 0.302077
2025-12-13 03:05:57,633 INFO     Training average positive_sample_loss at step 164000: 0.067822
2025-12-13 03:05:57,633 INFO     Training average negative_sample_loss at step 164000: 0.107946
2025-12-13 03:05:57,633 INFO     Training average loss at step 164000: 0.389961
2025-12-13 03:05:59,801 INFO     Training average regularization at step 164100: 0.302077
2025-12-13 03:05:59,801 INFO     Training average positive_sample_loss at step 164100: 0.066226
2025-12-13 03:05:59,801 INFO     Training average negative_sample_loss at step 164100: 0.110943
2025-12-13 03:05:59,801 INFO     Training average loss at step 164100: 0.390661
2025-12-13 03:06:01,991 INFO     Training average regularization at step 164200: 0.302077
2025-12-13 03:06:01,991 INFO     Training average positive_sample_loss at step 164200: 0.068134
2025-12-13 03:06:01,991 INFO     Training average negative_sample_loss at step 164200: 0.110554
2025-12-13 03:06:01,991 INFO     Training average loss at step 164200: 0.391421
2025-12-13 03:06:05,247 INFO     Training average regularization at step 164300: 0.302077
2025-12-13 03:06:05,247 INFO     Training average positive_sample_loss at step 164300: 0.066657
2025-12-13 03:06:05,247 INFO     Training average negative_sample_loss at step 164300: 0.107737
2025-12-13 03:06:05,247 INFO     Training average loss at step 164300: 0.389274
2025-12-13 03:06:07,395 INFO     Training average regularization at step 164400: 0.302077
2025-12-13 03:06:07,395 INFO     Training average positive_sample_loss at step 164400: 0.066520
2025-12-13 03:06:07,395 INFO     Training average negative_sample_loss at step 164400: 0.109943
2025-12-13 03:06:07,396 INFO     Training average loss at step 164400: 0.390308
2025-12-13 03:06:09,551 INFO     Training average regularization at step 164500: 0.302077
2025-12-13 03:06:09,551 INFO     Training average positive_sample_loss at step 164500: 0.066369
2025-12-13 03:06:09,551 INFO     Training average negative_sample_loss at step 164500: 0.108923
2025-12-13 03:06:09,551 INFO     Training average loss at step 164500: 0.389723
2025-12-13 03:06:11,716 INFO     Training average regularization at step 164600: 0.302077
2025-12-13 03:06:11,716 INFO     Training average positive_sample_loss at step 164600: 0.067382
2025-12-13 03:06:11,716 INFO     Training average negative_sample_loss at step 164600: 0.110667
2025-12-13 03:06:11,716 INFO     Training average loss at step 164600: 0.391101
2025-12-13 03:06:13,906 INFO     Training average regularization at step 164700: 0.302077
2025-12-13 03:06:13,907 INFO     Training average positive_sample_loss at step 164700: 0.067128
2025-12-13 03:06:13,907 INFO     Training average negative_sample_loss at step 164700: 0.108534
2025-12-13 03:06:13,907 INFO     Training average loss at step 164700: 0.389908
2025-12-13 03:06:16,082 INFO     Training average regularization at step 164800: 0.302077
2025-12-13 03:06:16,082 INFO     Training average positive_sample_loss at step 164800: 0.067179
2025-12-13 03:06:16,082 INFO     Training average negative_sample_loss at step 164800: 0.108262
2025-12-13 03:06:16,082 INFO     Training average loss at step 164800: 0.389797
2025-12-13 03:06:18,237 INFO     Training average regularization at step 164900: 0.302076
2025-12-13 03:06:18,237 INFO     Training average positive_sample_loss at step 164900: 0.065939
2025-12-13 03:06:18,237 INFO     Training average negative_sample_loss at step 164900: 0.108799
2025-12-13 03:06:18,237 INFO     Training average loss at step 164900: 0.389446
2025-12-13 03:06:20,402 INFO     Training average regularization at step 165000: 0.302076
2025-12-13 03:06:20,403 INFO     Training average positive_sample_loss at step 165000: 0.066789
2025-12-13 03:06:20,403 INFO     Training average negative_sample_loss at step 165000: 0.107471
2025-12-13 03:06:20,403 INFO     Training average loss at step 165000: 0.389207
2025-12-13 03:06:22,564 INFO     Training average regularization at step 165100: 0.302076
2025-12-13 03:06:22,565 INFO     Training average positive_sample_loss at step 165100: 0.067704
2025-12-13 03:06:22,565 INFO     Training average negative_sample_loss at step 165100: 0.110067
2025-12-13 03:06:22,565 INFO     Training average loss at step 165100: 0.390962
2025-12-13 03:06:24,773 INFO     Training average regularization at step 165200: 0.302076
2025-12-13 03:06:24,774 INFO     Training average positive_sample_loss at step 165200: 0.066823
2025-12-13 03:06:24,774 INFO     Training average negative_sample_loss at step 165200: 0.107443
2025-12-13 03:06:24,774 INFO     Training average loss at step 165200: 0.389209
2025-12-13 03:06:26,944 INFO     Training average regularization at step 165300: 0.302076
2025-12-13 03:06:26,944 INFO     Training average positive_sample_loss at step 165300: 0.067153
2025-12-13 03:06:26,944 INFO     Training average negative_sample_loss at step 165300: 0.108954
2025-12-13 03:06:26,944 INFO     Training average loss at step 165300: 0.390129
2025-12-13 03:06:29,099 INFO     Training average regularization at step 165400: 0.302076
2025-12-13 03:06:29,099 INFO     Training average positive_sample_loss at step 165400: 0.066622
2025-12-13 03:06:29,099 INFO     Training average negative_sample_loss at step 165400: 0.108503
2025-12-13 03:06:29,100 INFO     Training average loss at step 165400: 0.389638
2025-12-13 03:06:31,247 INFO     Training average regularization at step 165500: 0.302076
2025-12-13 03:06:31,247 INFO     Training average positive_sample_loss at step 165500: 0.065990
2025-12-13 03:06:31,247 INFO     Training average negative_sample_loss at step 165500: 0.109004
2025-12-13 03:06:31,247 INFO     Training average loss at step 165500: 0.389573
2025-12-13 03:06:33,384 INFO     Training average regularization at step 165600: 0.302076
2025-12-13 03:06:33,384 INFO     Training average positive_sample_loss at step 165600: 0.067215
2025-12-13 03:06:33,384 INFO     Training average negative_sample_loss at step 165600: 0.106911
2025-12-13 03:06:33,384 INFO     Training average loss at step 165600: 0.389139
2025-12-13 03:06:35,582 INFO     Training average regularization at step 165700: 0.302076
2025-12-13 03:06:35,582 INFO     Training average positive_sample_loss at step 165700: 0.066435
2025-12-13 03:06:35,582 INFO     Training average negative_sample_loss at step 165700: 0.108092
2025-12-13 03:06:35,582 INFO     Training average loss at step 165700: 0.389339
2025-12-13 03:06:37,805 INFO     Training average regularization at step 165800: 0.302076
2025-12-13 03:06:37,806 INFO     Training average positive_sample_loss at step 165800: 0.066738
2025-12-13 03:06:37,806 INFO     Training average negative_sample_loss at step 165800: 0.107494
2025-12-13 03:06:37,806 INFO     Training average loss at step 165800: 0.389192
2025-12-13 03:06:39,968 INFO     Training average regularization at step 165900: 0.302076
2025-12-13 03:06:39,969 INFO     Training average positive_sample_loss at step 165900: 0.067144
2025-12-13 03:06:39,969 INFO     Training average negative_sample_loss at step 165900: 0.109456
2025-12-13 03:06:39,969 INFO     Training average loss at step 165900: 0.390376
2025-12-13 03:06:42,153 INFO     Training average regularization at step 166000: 0.302076
2025-12-13 03:06:42,153 INFO     Training average positive_sample_loss at step 166000: 0.065771
2025-12-13 03:06:42,153 INFO     Training average negative_sample_loss at step 166000: 0.109896
2025-12-13 03:06:42,153 INFO     Training average loss at step 166000: 0.389909
2025-12-13 03:06:44,326 INFO     Training average regularization at step 166100: 0.302076
2025-12-13 03:06:44,326 INFO     Training average positive_sample_loss at step 166100: 0.066478
2025-12-13 03:06:44,326 INFO     Training average negative_sample_loss at step 166100: 0.108504
2025-12-13 03:06:44,326 INFO     Training average loss at step 166100: 0.389566
2025-12-13 03:06:46,509 INFO     Training average regularization at step 166200: 0.302076
2025-12-13 03:06:46,509 INFO     Training average positive_sample_loss at step 166200: 0.067485
2025-12-13 03:06:46,509 INFO     Training average negative_sample_loss at step 166200: 0.108543
2025-12-13 03:06:46,510 INFO     Training average loss at step 166200: 0.390090
2025-12-13 03:06:48,668 INFO     Training average regularization at step 166300: 0.302075
2025-12-13 03:06:48,669 INFO     Training average positive_sample_loss at step 166300: 0.064921
2025-12-13 03:06:48,669 INFO     Training average negative_sample_loss at step 166300: 0.107192
2025-12-13 03:06:48,669 INFO     Training average loss at step 166300: 0.388132
2025-12-13 03:06:50,813 INFO     Training average regularization at step 166400: 0.302075
2025-12-13 03:06:50,814 INFO     Training average positive_sample_loss at step 166400: 0.065193
2025-12-13 03:06:50,814 INFO     Training average negative_sample_loss at step 166400: 0.109306
2025-12-13 03:06:50,814 INFO     Training average loss at step 166400: 0.389325
2025-12-13 03:06:52,978 INFO     Training average regularization at step 166500: 0.302075
2025-12-13 03:06:52,978 INFO     Training average positive_sample_loss at step 166500: 0.066833
2025-12-13 03:06:52,978 INFO     Training average negative_sample_loss at step 166500: 0.108105
2025-12-13 03:06:52,978 INFO     Training average loss at step 166500: 0.389544
2025-12-13 03:06:55,154 INFO     Training average regularization at step 166600: 0.302075
2025-12-13 03:06:55,154 INFO     Training average positive_sample_loss at step 166600: 0.066668
2025-12-13 03:06:55,154 INFO     Training average negative_sample_loss at step 166600: 0.108051
2025-12-13 03:06:55,154 INFO     Training average loss at step 166600: 0.389434
2025-12-13 03:06:57,329 INFO     Training average regularization at step 166700: 0.302075
2025-12-13 03:06:57,333 INFO     Training average positive_sample_loss at step 166700: 0.067137
2025-12-13 03:06:57,333 INFO     Training average negative_sample_loss at step 166700: 0.110270
2025-12-13 03:06:57,333 INFO     Training average loss at step 166700: 0.390779
2025-12-13 03:06:59,464 INFO     Training average regularization at step 166800: 0.302075
2025-12-13 03:06:59,464 INFO     Training average positive_sample_loss at step 166800: 0.067065
2025-12-13 03:06:59,465 INFO     Training average negative_sample_loss at step 166800: 0.111933
2025-12-13 03:06:59,465 INFO     Training average loss at step 166800: 0.391574
2025-12-13 03:07:01,610 INFO     Training average regularization at step 166900: 0.302075
2025-12-13 03:07:01,610 INFO     Training average positive_sample_loss at step 166900: 0.067338
2025-12-13 03:07:01,610 INFO     Training average negative_sample_loss at step 166900: 0.109756
2025-12-13 03:07:01,610 INFO     Training average loss at step 166900: 0.390622
2025-12-13 03:07:03,749 INFO     Training average regularization at step 167000: 0.302075
2025-12-13 03:07:03,749 INFO     Training average positive_sample_loss at step 167000: 0.066639
2025-12-13 03:07:03,749 INFO     Training average negative_sample_loss at step 167000: 0.107304
2025-12-13 03:07:03,749 INFO     Training average loss at step 167000: 0.389047
2025-12-13 03:07:05,895 INFO     Training average regularization at step 167100: 0.302075
2025-12-13 03:07:05,895 INFO     Training average positive_sample_loss at step 167100: 0.067048
2025-12-13 03:07:05,895 INFO     Training average negative_sample_loss at step 167100: 0.110934
2025-12-13 03:07:05,895 INFO     Training average loss at step 167100: 0.391066
2025-12-13 03:07:08,090 INFO     Training average regularization at step 167200: 0.302075
2025-12-13 03:07:08,090 INFO     Training average positive_sample_loss at step 167200: 0.066408
2025-12-13 03:07:08,090 INFO     Training average negative_sample_loss at step 167200: 0.107989
2025-12-13 03:07:08,090 INFO     Training average loss at step 167200: 0.389273
2025-12-13 03:07:10,225 INFO     Training average regularization at step 167300: 0.302075
2025-12-13 03:07:10,226 INFO     Training average positive_sample_loss at step 167300: 0.066412
2025-12-13 03:07:10,226 INFO     Training average negative_sample_loss at step 167300: 0.108222
2025-12-13 03:07:10,226 INFO     Training average loss at step 167300: 0.389392
2025-12-13 03:07:12,491 INFO     Training average regularization at step 167400: 0.302075
2025-12-13 03:07:12,491 INFO     Training average positive_sample_loss at step 167400: 0.067102
2025-12-13 03:07:12,491 INFO     Training average negative_sample_loss at step 167400: 0.109185
2025-12-13 03:07:12,491 INFO     Training average loss at step 167400: 0.390218
2025-12-13 03:07:14,632 INFO     Training average regularization at step 167500: 0.302075
2025-12-13 03:07:14,632 INFO     Training average positive_sample_loss at step 167500: 0.066398
2025-12-13 03:07:14,632 INFO     Training average negative_sample_loss at step 167500: 0.107190
2025-12-13 03:07:14,632 INFO     Training average loss at step 167500: 0.388869
2025-12-13 03:07:16,794 INFO     Training average regularization at step 167600: 0.302075
2025-12-13 03:07:16,795 INFO     Training average positive_sample_loss at step 167600: 0.066615
2025-12-13 03:07:16,795 INFO     Training average negative_sample_loss at step 167600: 0.108610
2025-12-13 03:07:16,795 INFO     Training average loss at step 167600: 0.389687
2025-12-13 03:07:18,957 INFO     Training average regularization at step 167700: 0.302075
2025-12-13 03:07:18,957 INFO     Training average positive_sample_loss at step 167700: 0.065999
2025-12-13 03:07:18,957 INFO     Training average negative_sample_loss at step 167700: 0.107936
2025-12-13 03:07:18,957 INFO     Training average loss at step 167700: 0.389042
2025-12-13 03:07:21,090 INFO     Training average regularization at step 167800: 0.302074
2025-12-13 03:07:21,091 INFO     Training average positive_sample_loss at step 167800: 0.066283
2025-12-13 03:07:21,091 INFO     Training average negative_sample_loss at step 167800: 0.109384
2025-12-13 03:07:21,091 INFO     Training average loss at step 167800: 0.389908
2025-12-13 03:07:23,238 INFO     Training average regularization at step 167900: 0.302074
2025-12-13 03:07:23,239 INFO     Training average positive_sample_loss at step 167900: 0.066476
2025-12-13 03:07:23,239 INFO     Training average negative_sample_loss at step 167900: 0.110051
2025-12-13 03:07:23,239 INFO     Training average loss at step 167900: 0.390338
2025-12-13 03:07:25,383 INFO     Training average regularization at step 168000: 0.302074
2025-12-13 03:07:25,383 INFO     Training average positive_sample_loss at step 168000: 0.066459
2025-12-13 03:07:25,383 INFO     Training average negative_sample_loss at step 168000: 0.107564
2025-12-13 03:07:25,383 INFO     Training average loss at step 168000: 0.389086
2025-12-13 03:07:27,524 INFO     Training average regularization at step 168100: 0.302074
2025-12-13 03:07:27,530 INFO     Training average positive_sample_loss at step 168100: 0.066211
2025-12-13 03:07:27,530 INFO     Training average negative_sample_loss at step 168100: 0.109442
2025-12-13 03:07:27,530 INFO     Training average loss at step 168100: 0.389901
2025-12-13 03:07:29,686 INFO     Training average regularization at step 168200: 0.302074
2025-12-13 03:07:29,686 INFO     Training average positive_sample_loss at step 168200: 0.066602
2025-12-13 03:07:29,686 INFO     Training average negative_sample_loss at step 168200: 0.109770
2025-12-13 03:07:29,686 INFO     Training average loss at step 168200: 0.390260
2025-12-13 03:07:31,844 INFO     Training average regularization at step 168300: 0.302074
2025-12-13 03:07:31,844 INFO     Training average positive_sample_loss at step 168300: 0.067954
2025-12-13 03:07:31,844 INFO     Training average negative_sample_loss at step 168300: 0.108281
2025-12-13 03:07:31,844 INFO     Training average loss at step 168300: 0.390192
2025-12-13 03:07:33,982 INFO     Training average regularization at step 168400: 0.302074
2025-12-13 03:07:33,982 INFO     Training average positive_sample_loss at step 168400: 0.067117
2025-12-13 03:07:33,982 INFO     Training average negative_sample_loss at step 168400: 0.111612
2025-12-13 03:07:33,982 INFO     Training average loss at step 168400: 0.391438
2025-12-13 03:07:36,151 INFO     Training average regularization at step 168500: 0.302074
2025-12-13 03:07:36,151 INFO     Training average positive_sample_loss at step 168500: 0.066691
2025-12-13 03:07:36,151 INFO     Training average negative_sample_loss at step 168500: 0.111715
2025-12-13 03:07:36,151 INFO     Training average loss at step 168500: 0.391277
2025-12-13 03:07:38,302 INFO     Training average regularization at step 168600: 0.302074
2025-12-13 03:07:38,302 INFO     Training average positive_sample_loss at step 168600: 0.066888
2025-12-13 03:07:38,302 INFO     Training average negative_sample_loss at step 168600: 0.110677
2025-12-13 03:07:38,303 INFO     Training average loss at step 168600: 0.390856
2025-12-13 03:07:40,515 INFO     Training average regularization at step 168700: 0.302074
2025-12-13 03:07:40,516 INFO     Training average positive_sample_loss at step 168700: 0.066539
2025-12-13 03:07:40,516 INFO     Training average negative_sample_loss at step 168700: 0.108726
2025-12-13 03:07:40,516 INFO     Training average loss at step 168700: 0.389706
2025-12-13 03:07:42,724 INFO     Training average regularization at step 168800: 0.302074
2025-12-13 03:07:42,724 INFO     Training average positive_sample_loss at step 168800: 0.067547
2025-12-13 03:07:42,724 INFO     Training average negative_sample_loss at step 168800: 0.109629
2025-12-13 03:07:42,724 INFO     Training average loss at step 168800: 0.390662
2025-12-13 03:07:44,898 INFO     Training average regularization at step 168900: 0.302074
2025-12-13 03:07:44,898 INFO     Training average positive_sample_loss at step 168900: 0.067240
2025-12-13 03:07:44,898 INFO     Training average negative_sample_loss at step 168900: 0.107703
2025-12-13 03:07:44,899 INFO     Training average loss at step 168900: 0.389545
2025-12-13 03:07:47,046 INFO     Training average regularization at step 169000: 0.302074
2025-12-13 03:07:47,046 INFO     Training average positive_sample_loss at step 169000: 0.067672
2025-12-13 03:07:47,046 INFO     Training average negative_sample_loss at step 169000: 0.111168
2025-12-13 03:07:47,046 INFO     Training average loss at step 169000: 0.391494
2025-12-13 03:07:49,320 INFO     Training average regularization at step 169100: 0.302074
2025-12-13 03:07:49,320 INFO     Training average positive_sample_loss at step 169100: 0.065652
2025-12-13 03:07:49,320 INFO     Training average negative_sample_loss at step 169100: 0.108366
2025-12-13 03:07:49,320 INFO     Training average loss at step 169100: 0.389083
2025-12-13 03:07:52,342 INFO     Training average regularization at step 169200: 0.302074
2025-12-13 03:07:52,342 INFO     Training average positive_sample_loss at step 169200: 0.067640
2025-12-13 03:07:52,342 INFO     Training average negative_sample_loss at step 169200: 0.108962
2025-12-13 03:07:52,342 INFO     Training average loss at step 169200: 0.390374
2025-12-13 03:07:54,494 INFO     Training average regularization at step 169300: 0.302074
2025-12-13 03:07:54,494 INFO     Training average positive_sample_loss at step 169300: 0.066615
2025-12-13 03:07:54,494 INFO     Training average negative_sample_loss at step 169300: 0.108037
2025-12-13 03:07:54,494 INFO     Training average loss at step 169300: 0.389399
2025-12-13 03:07:56,649 INFO     Training average regularization at step 169400: 0.302073
2025-12-13 03:07:56,649 INFO     Training average positive_sample_loss at step 169400: 0.067377
2025-12-13 03:07:56,649 INFO     Training average negative_sample_loss at step 169400: 0.108810
2025-12-13 03:07:56,649 INFO     Training average loss at step 169400: 0.390167
2025-12-13 03:07:58,805 INFO     Training average regularization at step 169500: 0.302073
2025-12-13 03:07:58,806 INFO     Training average positive_sample_loss at step 169500: 0.066028
2025-12-13 03:07:58,806 INFO     Training average negative_sample_loss at step 169500: 0.106833
2025-12-13 03:07:58,806 INFO     Training average loss at step 169500: 0.388504
2025-12-13 03:08:00,950 INFO     Training average regularization at step 169600: 0.302073
2025-12-13 03:08:00,951 INFO     Training average positive_sample_loss at step 169600: 0.066223
2025-12-13 03:08:00,951 INFO     Training average negative_sample_loss at step 169600: 0.110768
2025-12-13 03:08:00,951 INFO     Training average loss at step 169600: 0.390569
2025-12-13 03:08:03,117 INFO     Training average regularization at step 169700: 0.302073
2025-12-13 03:08:03,118 INFO     Training average positive_sample_loss at step 169700: 0.066912
2025-12-13 03:08:03,118 INFO     Training average negative_sample_loss at step 169700: 0.109281
2025-12-13 03:08:03,118 INFO     Training average loss at step 169700: 0.390170
2025-12-13 03:08:05,253 INFO     Training average regularization at step 169800: 0.302073
2025-12-13 03:08:05,253 INFO     Training average positive_sample_loss at step 169800: 0.066380
2025-12-13 03:08:05,254 INFO     Training average negative_sample_loss at step 169800: 0.108196
2025-12-13 03:08:05,254 INFO     Training average loss at step 169800: 0.389361
2025-12-13 03:08:07,407 INFO     Training average regularization at step 169900: 0.302073
2025-12-13 03:08:07,407 INFO     Training average positive_sample_loss at step 169900: 0.066836
2025-12-13 03:08:07,407 INFO     Training average negative_sample_loss at step 169900: 0.109214
2025-12-13 03:08:07,407 INFO     Training average loss at step 169900: 0.390098
2025-12-13 03:08:09,558 INFO     Training average regularization at step 170000: 0.302073
2025-12-13 03:08:09,558 INFO     Training average positive_sample_loss at step 170000: 0.066459
2025-12-13 03:08:09,558 INFO     Training average negative_sample_loss at step 170000: 0.109556
2025-12-13 03:08:09,558 INFO     Training average loss at step 170000: 0.390080
2025-12-13 03:08:09,559 INFO     Evaluating on Valid Dataset...
2025-12-13 03:08:10,233 INFO     Evaluating the model... (0/50000)
2025-12-13 03:08:13,669 INFO     Evaluating the model... (500/50000)
2025-12-13 03:08:16,272 INFO     Evaluating the model... (1000/50000)
2025-12-13 03:08:18,893 INFO     Evaluating the model... (1500/50000)
2025-12-13 03:08:21,284 INFO     Evaluating the model... (2000/50000)
2025-12-13 03:08:23,727 INFO     Evaluating the model... (2500/50000)
2025-12-13 03:08:27,267 INFO     Evaluating the model... (3000/50000)
2025-12-13 03:08:29,750 INFO     Evaluating the model... (3500/50000)
2025-12-13 03:08:32,318 INFO     Evaluating the model... (4000/50000)
2025-12-13 03:08:34,803 INFO     Evaluating the model... (4500/50000)
2025-12-13 03:08:38,206 INFO     Evaluating the model... (5000/50000)
2025-12-13 03:08:41,023 INFO     Evaluating the model... (5500/50000)
2025-12-13 03:08:43,599 INFO     Evaluating the model... (6000/50000)
2025-12-13 03:08:46,220 INFO     Evaluating the model... (6500/50000)
2025-12-13 03:08:48,683 INFO     Evaluating the model... (7000/50000)
2025-12-13 03:08:51,820 INFO     Evaluating the model... (7500/50000)
2025-12-13 03:08:54,208 INFO     Evaluating the model... (8000/50000)
2025-12-13 03:08:56,647 INFO     Evaluating the model... (8500/50000)
2025-12-13 03:08:59,070 INFO     Evaluating the model... (9000/50000)
2025-12-13 03:09:01,802 INFO     Evaluating the model... (9500/50000)
2025-12-13 03:09:04,897 INFO     Evaluating the model... (10000/50000)
2025-12-13 03:09:07,337 INFO     Evaluating the model... (10500/50000)
2025-12-13 03:09:09,797 INFO     Evaluating the model... (11000/50000)
2025-12-13 03:09:12,430 INFO     Evaluating the model... (11500/50000)
2025-12-13 03:09:14,991 INFO     Evaluating the model... (12000/50000)
2025-12-13 03:09:18,497 INFO     Evaluating the model... (12500/50000)
2025-12-13 03:09:20,969 INFO     Evaluating the model... (13000/50000)
2025-12-13 03:09:23,559 INFO     Evaluating the model... (13500/50000)
2025-12-13 03:09:26,077 INFO     Evaluating the model... (14000/50000)
2025-12-13 03:09:28,423 INFO     Evaluating the model... (14500/50000)
2025-12-13 03:09:31,803 INFO     Evaluating the model... (15000/50000)
2025-12-13 03:09:34,281 INFO     Evaluating the model... (15500/50000)
2025-12-13 03:09:37,009 INFO     Evaluating the model... (16000/50000)
2025-12-13 03:09:39,741 INFO     Evaluating the model... (16500/50000)
2025-12-13 03:09:42,659 INFO     Evaluating the model... (17000/50000)
2025-12-13 03:09:46,825 INFO     Evaluating the model... (17500/50000)
2025-12-13 03:09:49,440 INFO     Evaluating the model... (18000/50000)
2025-12-13 03:09:51,834 INFO     Evaluating the model... (18500/50000)
2025-12-13 03:09:54,282 INFO     Evaluating the model... (19000/50000)
2025-12-13 03:09:56,743 INFO     Evaluating the model... (19500/50000)
2025-12-13 03:10:00,302 INFO     Evaluating the model... (20000/50000)
2025-12-13 03:10:02,734 INFO     Evaluating the model... (20500/50000)
2025-12-13 03:10:05,230 INFO     Evaluating the model... (21000/50000)
2025-12-13 03:10:07,672 INFO     Evaluating the model... (21500/50000)
2025-12-13 03:10:10,410 INFO     Evaluating the model... (22000/50000)
2025-12-13 03:10:14,075 INFO     Evaluating the model... (22500/50000)
2025-12-13 03:10:16,456 INFO     Evaluating the model... (23000/50000)
2025-12-13 03:10:19,031 INFO     Evaluating the model... (23500/50000)
2025-12-13 03:10:21,833 INFO     Evaluating the model... (24000/50000)
2025-12-13 03:10:25,735 INFO     Evaluating the model... (24500/50000)
2025-12-13 03:10:28,585 INFO     Evaluating the model... (25000/50000)
2025-12-13 03:10:31,176 INFO     Evaluating the model... (25500/50000)
2025-12-13 03:10:33,972 INFO     Evaluating the model... (26000/50000)
2025-12-13 03:10:36,635 INFO     Evaluating the model... (26500/50000)
2025-12-13 03:10:39,466 INFO     Evaluating the model... (27000/50000)
2025-12-13 03:10:43,492 INFO     Evaluating the model... (27500/50000)
2025-12-13 03:10:46,336 INFO     Evaluating the model... (28000/50000)
2025-12-13 03:10:48,875 INFO     Evaluating the model... (28500/50000)
2025-12-13 03:10:51,374 INFO     Evaluating the model... (29000/50000)
2025-12-13 03:10:53,787 INFO     Evaluating the model... (29500/50000)
2025-12-13 03:10:57,462 INFO     Evaluating the model... (30000/50000)
2025-12-13 03:10:59,977 INFO     Evaluating the model... (30500/50000)
2025-12-13 03:11:02,489 INFO     Evaluating the model... (31000/50000)
2025-12-13 03:11:05,066 INFO     Evaluating the model... (31500/50000)
2025-12-13 03:11:08,803 INFO     Evaluating the model... (32000/50000)
2025-12-13 03:11:11,528 INFO     Evaluating the model... (32500/50000)
2025-12-13 03:11:13,989 INFO     Evaluating the model... (33000/50000)
2025-12-13 03:11:16,499 INFO     Evaluating the model... (33500/50000)
2025-12-13 03:11:19,353 INFO     Evaluating the model... (34000/50000)
2025-12-13 03:11:22,442 INFO     Evaluating the model... (34500/50000)
2025-12-13 03:11:25,038 INFO     Evaluating the model... (35000/50000)
2025-12-13 03:11:27,554 INFO     Evaluating the model... (35500/50000)
2025-12-13 03:11:30,395 INFO     Evaluating the model... (36000/50000)
2025-12-13 03:11:32,916 INFO     Evaluating the model... (36500/50000)
2025-12-13 03:11:36,120 INFO     Evaluating the model... (37000/50000)
2025-12-13 03:11:38,734 INFO     Evaluating the model... (37500/50000)
2025-12-13 03:11:41,708 INFO     Evaluating the model... (38000/50000)
2025-12-13 03:11:44,464 INFO     Evaluating the model... (38500/50000)
2025-12-13 03:11:47,093 INFO     Evaluating the model... (39000/50000)
2025-12-13 03:11:50,128 INFO     Evaluating the model... (39500/50000)
2025-12-13 03:11:52,686 INFO     Evaluating the model... (40000/50000)
2025-12-13 03:11:55,381 INFO     Evaluating the model... (40500/50000)
2025-12-13 03:11:57,888 INFO     Evaluating the model... (41000/50000)
2025-12-13 03:12:00,483 INFO     Evaluating the model... (41500/50000)
2025-12-13 03:12:03,526 INFO     Evaluating the model... (42000/50000)
2025-12-13 03:12:06,368 INFO     Evaluating the model... (42500/50000)
2025-12-13 03:12:08,917 INFO     Evaluating the model... (43000/50000)
2025-12-13 03:12:11,461 INFO     Evaluating the model... (43500/50000)
2025-12-13 03:12:14,022 INFO     Evaluating the model... (44000/50000)
2025-12-13 03:12:17,978 INFO     Evaluating the model... (44500/50000)
2025-12-13 03:12:20,466 INFO     Evaluating the model... (45000/50000)
2025-12-13 03:12:23,022 INFO     Evaluating the model... (45500/50000)
2025-12-13 03:12:25,594 INFO     Evaluating the model... (46000/50000)
2025-12-13 03:12:28,441 INFO     Evaluating the model... (46500/50000)
2025-12-13 03:12:31,674 INFO     Evaluating the model... (47000/50000)
2025-12-13 03:12:34,086 INFO     Evaluating the model... (47500/50000)
2025-12-13 03:12:36,768 INFO     Evaluating the model... (48000/50000)
2025-12-13 03:12:39,731 INFO     Evaluating the model... (48500/50000)
2025-12-13 03:12:42,481 INFO     Evaluating the model... (49000/50000)
2025-12-13 03:12:45,995 INFO     Evaluating the model... (49500/50000)
2025-12-13 03:12:48,858 INFO     Valid MRR at step 170000: 0.632977
2025-12-13 03:12:48,858 INFO     Valid MR at step 170000: 266.740010
2025-12-13 03:12:48,858 INFO     Valid HITS@1 at step 170000: 0.547210
2025-12-13 03:12:48,858 INFO     Valid HITS@3 at step 170000: 0.685990
2025-12-13 03:12:48,858 INFO     Valid HITS@10 at step 170000: 0.784710
2025-12-13 03:12:50,084 INFO     Evaluating on Test Dataset...
2025-12-13 03:12:50,655 INFO     Evaluating the model... (0/59072)
2025-12-13 03:12:53,376 INFO     Evaluating the model... (500/59072)
2025-12-13 03:12:56,003 INFO     Evaluating the model... (1000/59072)
2025-12-13 03:12:58,426 INFO     Evaluating the model... (1500/59072)
2025-12-13 03:13:01,754 INFO     Evaluating the model... (2000/59072)
2025-12-13 03:13:04,318 INFO     Evaluating the model... (2500/59072)
2025-12-13 03:13:06,896 INFO     Evaluating the model... (3000/59072)
2025-12-13 03:13:09,361 INFO     Evaluating the model... (3500/59072)
2025-12-13 03:13:11,977 INFO     Evaluating the model... (4000/59072)
2025-12-13 03:13:15,257 INFO     Evaluating the model... (4500/59072)
2025-12-13 03:13:17,804 INFO     Evaluating the model... (5000/59072)
2025-12-13 03:13:20,312 INFO     Evaluating the model... (5500/59072)
2025-12-13 03:13:22,774 INFO     Evaluating the model... (6000/59072)
2025-12-13 03:13:25,387 INFO     Evaluating the model... (6500/59072)
2025-12-13 03:13:28,453 INFO     Evaluating the model... (7000/59072)
2025-12-13 03:13:30,944 INFO     Evaluating the model... (7500/59072)
2025-12-13 03:13:33,340 INFO     Evaluating the model... (8000/59072)
2025-12-13 03:13:35,968 INFO     Evaluating the model... (8500/59072)
2025-12-13 03:13:38,925 INFO     Evaluating the model... (9000/59072)
2025-12-13 03:13:42,108 INFO     Evaluating the model... (9500/59072)
2025-12-13 03:13:44,712 INFO     Evaluating the model... (10000/59072)
2025-12-13 03:13:47,140 INFO     Evaluating the model... (10500/59072)
2025-12-13 03:13:49,808 INFO     Evaluating the model... (11000/59072)
2025-12-13 03:13:52,738 INFO     Evaluating the model... (11500/59072)
2025-12-13 03:13:55,146 INFO     Evaluating the model... (12000/59072)
2025-12-13 03:13:57,634 INFO     Evaluating the model... (12500/59072)
2025-12-13 03:14:00,231 INFO     Evaluating the model... (13000/59072)
2025-12-13 03:14:02,777 INFO     Evaluating the model... (13500/59072)
2025-12-13 03:14:05,801 INFO     Evaluating the model... (14000/59072)
2025-12-13 03:14:08,202 INFO     Evaluating the model... (14500/59072)
2025-12-13 03:14:10,835 INFO     Evaluating the model... (15000/59072)
2025-12-13 03:14:13,440 INFO     Evaluating the model... (15500/59072)
2025-12-13 03:14:15,967 INFO     Evaluating the model... (16000/59072)
2025-12-13 03:14:19,143 INFO     Evaluating the model... (16500/59072)
2025-12-13 03:14:21,653 INFO     Evaluating the model... (17000/59072)
2025-12-13 03:14:24,394 INFO     Evaluating the model... (17500/59072)
2025-12-13 03:14:26,982 INFO     Evaluating the model... (18000/59072)
2025-12-13 03:14:29,315 INFO     Evaluating the model... (18500/59072)
2025-12-13 03:14:32,330 INFO     Evaluating the model... (19000/59072)
2025-12-13 03:14:35,022 INFO     Evaluating the model... (19500/59072)
2025-12-13 03:14:37,700 INFO     Evaluating the model... (20000/59072)
2025-12-13 03:14:40,483 INFO     Evaluating the model... (20500/59072)
2025-12-13 03:14:43,102 INFO     Evaluating the model... (21000/59072)
2025-12-13 03:14:46,763 INFO     Evaluating the model... (21500/59072)
2025-12-13 03:14:49,120 INFO     Evaluating the model... (22000/59072)
2025-12-13 03:14:51,516 INFO     Evaluating the model... (22500/59072)
2025-12-13 03:14:54,087 INFO     Evaluating the model... (23000/59072)
2025-12-13 03:14:56,403 INFO     Evaluating the model... (23500/59072)
2025-12-13 03:15:00,002 INFO     Evaluating the model... (24000/59072)
2025-12-13 03:15:02,512 INFO     Evaluating the model... (24500/59072)
2025-12-13 03:15:04,940 INFO     Evaluating the model... (25000/59072)
2025-12-13 03:15:07,461 INFO     Evaluating the model... (25500/59072)
2025-12-13 03:15:10,019 INFO     Evaluating the model... (26000/59072)
2025-12-13 03:15:13,757 INFO     Evaluating the model... (26500/59072)
2025-12-13 03:15:16,201 INFO     Evaluating the model... (27000/59072)
2025-12-13 03:15:18,643 INFO     Evaluating the model... (27500/59072)
2025-12-13 03:15:21,298 INFO     Evaluating the model... (28000/59072)
2025-12-13 03:15:23,864 INFO     Evaluating the model... (28500/59072)
2025-12-13 03:15:27,812 INFO     Evaluating the model... (29000/59072)
2025-12-13 03:15:30,160 INFO     Evaluating the model... (29500/59072)
2025-12-13 03:15:33,266 INFO     Evaluating the model... (30000/59072)
2025-12-13 03:15:35,732 INFO     Evaluating the model... (30500/59072)
2025-12-13 03:15:39,498 INFO     Evaluating the model... (31000/59072)
2025-12-13 03:15:42,167 INFO     Evaluating the model... (31500/59072)
2025-12-13 03:15:45,188 INFO     Evaluating the model... (32000/59072)
2025-12-13 03:15:47,746 INFO     Evaluating the model... (32500/59072)
2025-12-13 03:15:50,207 INFO     Evaluating the model... (33000/59072)
2025-12-13 03:15:53,644 INFO     Evaluating the model... (33500/59072)
2025-12-13 03:15:56,400 INFO     Evaluating the model... (34000/59072)
2025-12-13 03:15:58,899 INFO     Evaluating the model... (34500/59072)
2025-12-13 03:16:01,369 INFO     Evaluating the model... (35000/59072)
2025-12-13 03:16:03,726 INFO     Evaluating the model... (35500/59072)
2025-12-13 03:16:07,386 INFO     Evaluating the model... (36000/59072)
2025-12-13 03:16:09,788 INFO     Evaluating the model... (36500/59072)
2025-12-13 03:16:12,271 INFO     Evaluating the model... (37000/59072)
2025-12-13 03:16:14,880 INFO     Evaluating the model... (37500/59072)
2025-12-13 03:16:17,491 INFO     Evaluating the model... (38000/59072)
2025-12-13 03:16:20,731 INFO     Evaluating the model... (38500/59072)
2025-12-13 03:16:23,164 INFO     Evaluating the model... (39000/59072)
2025-12-13 03:16:25,722 INFO     Evaluating the model... (39500/59072)
2025-12-13 03:16:28,156 INFO     Evaluating the model... (40000/59072)
2025-12-13 03:16:31,817 INFO     Evaluating the model... (40500/59072)
2025-12-13 03:16:34,263 INFO     Evaluating the model... (41000/59072)
2025-12-13 03:16:37,017 INFO     Evaluating the model... (41500/59072)
2025-12-13 03:16:39,822 INFO     Evaluating the model... (42000/59072)
2025-12-13 03:16:42,772 INFO     Evaluating the model... (42500/59072)
2025-12-13 03:16:46,579 INFO     Evaluating the model... (43000/59072)
2025-12-13 03:16:49,007 INFO     Evaluating the model... (43500/59072)
2025-12-13 03:16:51,505 INFO     Evaluating the model... (44000/59072)
2025-12-13 03:16:54,226 INFO     Evaluating the model... (44500/59072)
2025-12-13 03:16:56,866 INFO     Evaluating the model... (45000/59072)
2025-12-13 03:17:00,386 INFO     Evaluating the model... (45500/59072)
2025-12-13 03:17:02,733 INFO     Evaluating the model... (46000/59072)
2025-12-13 03:17:05,373 INFO     Evaluating the model... (46500/59072)
2025-12-13 03:17:07,840 INFO     Evaluating the model... (47000/59072)
2025-12-13 03:17:10,310 INFO     Evaluating the model... (47500/59072)
2025-12-13 03:17:13,688 INFO     Evaluating the model... (48000/59072)
2025-12-13 03:17:16,439 INFO     Evaluating the model... (48500/59072)
2025-12-13 03:17:18,963 INFO     Evaluating the model... (49000/59072)
2025-12-13 03:17:21,437 INFO     Evaluating the model... (49500/59072)
2025-12-13 03:17:23,828 INFO     Evaluating the model... (50000/59072)
2025-12-13 03:17:27,676 INFO     Evaluating the model... (50500/59072)
2025-12-13 03:17:30,144 INFO     Evaluating the model... (51000/59072)
2025-12-13 03:17:32,596 INFO     Evaluating the model... (51500/59072)
2025-12-13 03:17:35,124 INFO     Evaluating the model... (52000/59072)
2025-12-13 03:17:38,051 INFO     Evaluating the model... (52500/59072)
2025-12-13 03:17:42,290 INFO     Evaluating the model... (53000/59072)
2025-12-13 03:17:44,938 INFO     Evaluating the model... (53500/59072)
2025-12-13 03:17:47,682 INFO     Evaluating the model... (54000/59072)
2025-12-13 03:17:50,229 INFO     Evaluating the model... (54500/59072)
2025-12-13 03:17:52,790 INFO     Evaluating the model... (55000/59072)
2025-12-13 03:17:56,563 INFO     Evaluating the model... (55500/59072)
2025-12-13 03:17:59,005 INFO     Evaluating the model... (56000/59072)
2025-12-13 03:18:01,598 INFO     Evaluating the model... (56500/59072)
2025-12-13 03:18:04,228 INFO     Evaluating the model... (57000/59072)
2025-12-13 03:18:06,796 INFO     Evaluating the model... (57500/59072)
2025-12-13 03:18:10,448 INFO     Evaluating the model... (58000/59072)
2025-12-13 03:18:13,109 INFO     Evaluating the model... (58500/59072)
2025-12-13 03:18:15,772 INFO     Evaluating the model... (59000/59072)
2025-12-13 03:18:16,417 INFO     Test MRR at step 170000: 0.629886
2025-12-13 03:18:16,417 INFO     Test MR at step 170000: 268.724611
2025-12-13 03:18:16,417 INFO     Test HITS@1 at step 170000: 0.542779
2025-12-13 03:18:16,417 INFO     Test HITS@3 at step 170000: 0.684329
2025-12-13 03:18:16,417 INFO     Test HITS@10 at step 170000: 0.782948
2025-12-13 03:18:18,575 INFO     Training average regularization at step 170100: 0.302073
2025-12-13 03:18:18,575 INFO     Training average positive_sample_loss at step 170100: 0.065327
2025-12-13 03:18:18,575 INFO     Training average negative_sample_loss at step 170100: 0.107886
2025-12-13 03:18:18,575 INFO     Training average loss at step 170100: 0.388679
2025-12-13 03:18:20,745 INFO     Training average regularization at step 170200: 0.302073
2025-12-13 03:18:20,746 INFO     Training average positive_sample_loss at step 170200: 0.067763
2025-12-13 03:18:20,746 INFO     Training average negative_sample_loss at step 170200: 0.110434
2025-12-13 03:18:20,746 INFO     Training average loss at step 170200: 0.391171
2025-12-13 03:18:22,905 INFO     Training average regularization at step 170300: 0.302073
2025-12-13 03:18:22,905 INFO     Training average positive_sample_loss at step 170300: 0.066968
2025-12-13 03:18:22,905 INFO     Training average negative_sample_loss at step 170300: 0.107109
2025-12-13 03:18:22,905 INFO     Training average loss at step 170300: 0.389111
2025-12-13 03:18:25,100 INFO     Training average regularization at step 170400: 0.302073
2025-12-13 03:18:25,100 INFO     Training average positive_sample_loss at step 170400: 0.067430
2025-12-13 03:18:25,101 INFO     Training average negative_sample_loss at step 170400: 0.108978
2025-12-13 03:18:25,101 INFO     Training average loss at step 170400: 0.390277
2025-12-13 03:18:27,266 INFO     Training average regularization at step 170500: 0.302073
2025-12-13 03:18:27,267 INFO     Training average positive_sample_loss at step 170500: 0.067782
2025-12-13 03:18:27,267 INFO     Training average negative_sample_loss at step 170500: 0.108574
2025-12-13 03:18:27,267 INFO     Training average loss at step 170500: 0.390250
2025-12-13 03:18:29,423 INFO     Training average regularization at step 170600: 0.302073
2025-12-13 03:18:29,424 INFO     Training average positive_sample_loss at step 170600: 0.067340
2025-12-13 03:18:29,424 INFO     Training average negative_sample_loss at step 170600: 0.108280
2025-12-13 03:18:29,424 INFO     Training average loss at step 170600: 0.389883
2025-12-13 03:18:31,595 INFO     Training average regularization at step 170700: 0.302072
2025-12-13 03:18:31,595 INFO     Training average positive_sample_loss at step 170700: 0.065682
2025-12-13 03:18:31,595 INFO     Training average negative_sample_loss at step 170700: 0.110496
2025-12-13 03:18:31,595 INFO     Training average loss at step 170700: 0.390161
2025-12-13 03:18:33,759 INFO     Training average regularization at step 170800: 0.302072
2025-12-13 03:18:33,759 INFO     Training average positive_sample_loss at step 170800: 0.067384
2025-12-13 03:18:33,759 INFO     Training average negative_sample_loss at step 170800: 0.107227
2025-12-13 03:18:33,759 INFO     Training average loss at step 170800: 0.389378
2025-12-13 03:18:35,950 INFO     Training average regularization at step 170900: 0.302072
2025-12-13 03:18:35,951 INFO     Training average positive_sample_loss at step 170900: 0.066483
2025-12-13 03:18:35,951 INFO     Training average negative_sample_loss at step 170900: 0.110416
2025-12-13 03:18:35,951 INFO     Training average loss at step 170900: 0.390522
2025-12-13 03:18:38,120 INFO     Training average regularization at step 171000: 0.302072
2025-12-13 03:18:38,120 INFO     Training average positive_sample_loss at step 171000: 0.065868
2025-12-13 03:18:38,120 INFO     Training average negative_sample_loss at step 171000: 0.108879
2025-12-13 03:18:38,120 INFO     Training average loss at step 171000: 0.389446
2025-12-13 03:18:40,296 INFO     Training average regularization at step 171100: 0.302072
2025-12-13 03:18:40,297 INFO     Training average positive_sample_loss at step 171100: 0.067119
2025-12-13 03:18:40,297 INFO     Training average negative_sample_loss at step 171100: 0.110674
2025-12-13 03:18:40,297 INFO     Training average loss at step 171100: 0.390969
2025-12-13 03:18:42,475 INFO     Training average regularization at step 171200: 0.302072
2025-12-13 03:18:42,476 INFO     Training average positive_sample_loss at step 171200: 0.066255
2025-12-13 03:18:42,476 INFO     Training average negative_sample_loss at step 171200: 0.109288
2025-12-13 03:18:42,476 INFO     Training average loss at step 171200: 0.389844
2025-12-13 03:18:44,672 INFO     Training average regularization at step 171300: 0.302072
2025-12-13 03:18:44,672 INFO     Training average positive_sample_loss at step 171300: 0.067887
2025-12-13 03:18:44,672 INFO     Training average negative_sample_loss at step 171300: 0.110246
2025-12-13 03:18:44,672 INFO     Training average loss at step 171300: 0.391139
2025-12-13 03:18:46,868 INFO     Training average regularization at step 171400: 0.302072
2025-12-13 03:18:46,869 INFO     Training average positive_sample_loss at step 171400: 0.067470
2025-12-13 03:18:46,869 INFO     Training average negative_sample_loss at step 171400: 0.109647
2025-12-13 03:18:46,869 INFO     Training average loss at step 171400: 0.390631
2025-12-13 03:18:49,026 INFO     Training average regularization at step 171500: 0.302072
2025-12-13 03:18:49,027 INFO     Training average positive_sample_loss at step 171500: 0.066645
2025-12-13 03:18:49,027 INFO     Training average negative_sample_loss at step 171500: 0.110426
2025-12-13 03:18:49,027 INFO     Training average loss at step 171500: 0.390607
2025-12-13 03:18:51,188 INFO     Training average regularization at step 171600: 0.302072
2025-12-13 03:18:51,189 INFO     Training average positive_sample_loss at step 171600: 0.064920
2025-12-13 03:18:51,189 INFO     Training average negative_sample_loss at step 171600: 0.109903
2025-12-13 03:18:51,189 INFO     Training average loss at step 171600: 0.389483
2025-12-13 03:18:53,364 INFO     Training average regularization at step 171700: 0.302072
2025-12-13 03:18:53,364 INFO     Training average positive_sample_loss at step 171700: 0.068399
2025-12-13 03:18:53,364 INFO     Training average negative_sample_loss at step 171700: 0.109354
2025-12-13 03:18:53,364 INFO     Training average loss at step 171700: 0.390948
2025-12-13 03:18:55,692 INFO     Training average regularization at step 171800: 0.302072
2025-12-13 03:18:55,693 INFO     Training average positive_sample_loss at step 171800: 0.065897
2025-12-13 03:18:55,693 INFO     Training average negative_sample_loss at step 171800: 0.106170
2025-12-13 03:18:55,693 INFO     Training average loss at step 171800: 0.388105
2025-12-13 03:18:57,857 INFO     Training average regularization at step 171900: 0.302072
2025-12-13 03:18:57,857 INFO     Training average positive_sample_loss at step 171900: 0.066576
2025-12-13 03:18:57,857 INFO     Training average negative_sample_loss at step 171900: 0.109973
2025-12-13 03:18:57,857 INFO     Training average loss at step 171900: 0.390346
2025-12-13 03:19:00,003 INFO     Training average regularization at step 172000: 0.302072
2025-12-13 03:19:00,003 INFO     Training average positive_sample_loss at step 172000: 0.066547
2025-12-13 03:19:00,003 INFO     Training average negative_sample_loss at step 172000: 0.107932
2025-12-13 03:19:00,003 INFO     Training average loss at step 172000: 0.389311
2025-12-13 03:19:02,169 INFO     Training average regularization at step 172100: 0.302072
2025-12-13 03:19:02,169 INFO     Training average positive_sample_loss at step 172100: 0.067219
2025-12-13 03:19:02,169 INFO     Training average negative_sample_loss at step 172100: 0.107901
2025-12-13 03:19:02,169 INFO     Training average loss at step 172100: 0.389631
2025-12-13 03:19:04,309 INFO     Training average regularization at step 172200: 0.302071
2025-12-13 03:19:04,310 INFO     Training average positive_sample_loss at step 172200: 0.066678
2025-12-13 03:19:04,310 INFO     Training average negative_sample_loss at step 172200: 0.107148
2025-12-13 03:19:04,310 INFO     Training average loss at step 172200: 0.388985
2025-12-13 03:19:06,462 INFO     Training average regularization at step 172300: 0.302071
2025-12-13 03:19:06,462 INFO     Training average positive_sample_loss at step 172300: 0.065957
2025-12-13 03:19:06,462 INFO     Training average negative_sample_loss at step 172300: 0.108737
2025-12-13 03:19:06,462 INFO     Training average loss at step 172300: 0.389419
2025-12-13 03:19:08,611 INFO     Training average regularization at step 172400: 0.302071
2025-12-13 03:19:08,611 INFO     Training average positive_sample_loss at step 172400: 0.067390
2025-12-13 03:19:08,612 INFO     Training average negative_sample_loss at step 172400: 0.108313
2025-12-13 03:19:08,612 INFO     Training average loss at step 172400: 0.389923
2025-12-13 03:19:10,748 INFO     Training average regularization at step 172500: 0.302071
2025-12-13 03:19:10,750 INFO     Training average positive_sample_loss at step 172500: 0.066029
2025-12-13 03:19:10,750 INFO     Training average negative_sample_loss at step 172500: 0.111613
2025-12-13 03:19:10,750 INFO     Training average loss at step 172500: 0.390892
2025-12-13 03:19:12,895 INFO     Training average regularization at step 172600: 0.302071
2025-12-13 03:19:12,896 INFO     Training average positive_sample_loss at step 172600: 0.066848
2025-12-13 03:19:12,896 INFO     Training average negative_sample_loss at step 172600: 0.106591
2025-12-13 03:19:12,896 INFO     Training average loss at step 172600: 0.388791
2025-12-13 03:19:15,045 INFO     Training average regularization at step 172700: 0.302071
2025-12-13 03:19:15,045 INFO     Training average positive_sample_loss at step 172700: 0.066201
2025-12-13 03:19:15,045 INFO     Training average negative_sample_loss at step 172700: 0.107731
2025-12-13 03:19:15,045 INFO     Training average loss at step 172700: 0.389037
2025-12-13 03:19:17,154 INFO     Training average regularization at step 172800: 0.302071
2025-12-13 03:19:17,154 INFO     Training average positive_sample_loss at step 172800: 0.066468
2025-12-13 03:19:17,154 INFO     Training average negative_sample_loss at step 172800: 0.107653
2025-12-13 03:19:17,154 INFO     Training average loss at step 172800: 0.389131
2025-12-13 03:19:19,294 INFO     Training average regularization at step 172900: 0.302071
2025-12-13 03:19:19,294 INFO     Training average positive_sample_loss at step 172900: 0.066498
2025-12-13 03:19:19,295 INFO     Training average negative_sample_loss at step 172900: 0.107559
2025-12-13 03:19:19,295 INFO     Training average loss at step 172900: 0.389100
2025-12-13 03:19:21,433 INFO     Training average regularization at step 173000: 0.302071
2025-12-13 03:19:21,434 INFO     Training average positive_sample_loss at step 173000: 0.065673
2025-12-13 03:19:21,434 INFO     Training average negative_sample_loss at step 173000: 0.105836
2025-12-13 03:19:21,434 INFO     Training average loss at step 173000: 0.387825
2025-12-13 03:19:23,569 INFO     Training average regularization at step 173100: 0.302071
2025-12-13 03:19:23,570 INFO     Training average positive_sample_loss at step 173100: 0.067724
2025-12-13 03:19:23,570 INFO     Training average negative_sample_loss at step 173100: 0.107113
2025-12-13 03:19:23,570 INFO     Training average loss at step 173100: 0.389490
2025-12-13 03:19:25,709 INFO     Training average regularization at step 173200: 0.302071
2025-12-13 03:19:25,709 INFO     Training average positive_sample_loss at step 173200: 0.065506
2025-12-13 03:19:25,709 INFO     Training average negative_sample_loss at step 173200: 0.107927
2025-12-13 03:19:25,709 INFO     Training average loss at step 173200: 0.388787
2025-12-13 03:19:27,849 INFO     Training average regularization at step 173300: 0.302071
2025-12-13 03:19:27,854 INFO     Training average positive_sample_loss at step 173300: 0.067797
2025-12-13 03:19:27,854 INFO     Training average negative_sample_loss at step 173300: 0.109914
2025-12-13 03:19:27,854 INFO     Training average loss at step 173300: 0.390926
2025-12-13 03:19:30,013 INFO     Training average regularization at step 173400: 0.302071
2025-12-13 03:19:30,013 INFO     Training average positive_sample_loss at step 173400: 0.065956
2025-12-13 03:19:30,013 INFO     Training average negative_sample_loss at step 173400: 0.108721
2025-12-13 03:19:30,013 INFO     Training average loss at step 173400: 0.389409
2025-12-13 03:19:32,169 INFO     Training average regularization at step 173500: 0.302071
2025-12-13 03:19:32,169 INFO     Training average positive_sample_loss at step 173500: 0.066910
2025-12-13 03:19:32,169 INFO     Training average negative_sample_loss at step 173500: 0.107102
2025-12-13 03:19:32,169 INFO     Training average loss at step 173500: 0.389077
2025-12-13 03:19:34,312 INFO     Training average regularization at step 173600: 0.302071
2025-12-13 03:19:34,312 INFO     Training average positive_sample_loss at step 173600: 0.067268
2025-12-13 03:19:34,312 INFO     Training average negative_sample_loss at step 173600: 0.110780
2025-12-13 03:19:34,312 INFO     Training average loss at step 173600: 0.391094
2025-12-13 03:19:36,485 INFO     Training average regularization at step 173700: 0.302071
2025-12-13 03:19:36,485 INFO     Training average positive_sample_loss at step 173700: 0.067018
2025-12-13 03:19:36,485 INFO     Training average negative_sample_loss at step 173700: 0.108954
2025-12-13 03:19:36,485 INFO     Training average loss at step 173700: 0.390056
2025-12-13 03:19:38,641 INFO     Training average regularization at step 173800: 0.302070
2025-12-13 03:19:38,641 INFO     Training average positive_sample_loss at step 173800: 0.067252
2025-12-13 03:19:38,641 INFO     Training average negative_sample_loss at step 173800: 0.107371
2025-12-13 03:19:38,641 INFO     Training average loss at step 173800: 0.389382
2025-12-13 03:19:40,813 INFO     Training average regularization at step 173900: 0.302070
2025-12-13 03:19:40,814 INFO     Training average positive_sample_loss at step 173900: 0.066820
2025-12-13 03:19:40,814 INFO     Training average negative_sample_loss at step 173900: 0.107484
2025-12-13 03:19:40,814 INFO     Training average loss at step 173900: 0.389223
2025-12-13 03:19:44,221 INFO     Training average regularization at step 174000: 0.302070
2025-12-13 03:19:44,221 INFO     Training average positive_sample_loss at step 174000: 0.066886
2025-12-13 03:19:44,221 INFO     Training average negative_sample_loss at step 174000: 0.108711
2025-12-13 03:19:44,221 INFO     Training average loss at step 174000: 0.389869
2025-12-13 03:19:46,396 INFO     Training average regularization at step 174100: 0.302070
2025-12-13 03:19:46,396 INFO     Training average positive_sample_loss at step 174100: 0.067384
2025-12-13 03:19:46,396 INFO     Training average negative_sample_loss at step 174100: 0.107316
2025-12-13 03:19:46,397 INFO     Training average loss at step 174100: 0.389420
2025-12-13 03:19:48,559 INFO     Training average regularization at step 174200: 0.302070
2025-12-13 03:19:48,559 INFO     Training average positive_sample_loss at step 174200: 0.068682
2025-12-13 03:19:48,559 INFO     Training average negative_sample_loss at step 174200: 0.107415
2025-12-13 03:19:48,559 INFO     Training average loss at step 174200: 0.390119
2025-12-13 03:19:50,718 INFO     Training average regularization at step 174300: 0.302070
2025-12-13 03:19:50,718 INFO     Training average positive_sample_loss at step 174300: 0.066464
2025-12-13 03:19:50,718 INFO     Training average negative_sample_loss at step 174300: 0.108311
2025-12-13 03:19:50,718 INFO     Training average loss at step 174300: 0.389458
2025-12-13 03:19:52,919 INFO     Training average regularization at step 174400: 0.302070
2025-12-13 03:19:52,919 INFO     Training average positive_sample_loss at step 174400: 0.066613
2025-12-13 03:19:52,919 INFO     Training average negative_sample_loss at step 174400: 0.107712
2025-12-13 03:19:52,919 INFO     Training average loss at step 174400: 0.389232
2025-12-13 03:19:55,078 INFO     Training average regularization at step 174500: 0.302070
2025-12-13 03:19:55,078 INFO     Training average positive_sample_loss at step 174500: 0.065960
2025-12-13 03:19:55,078 INFO     Training average negative_sample_loss at step 174500: 0.107570
2025-12-13 03:19:55,078 INFO     Training average loss at step 174500: 0.388835
2025-12-13 03:19:57,225 INFO     Training average regularization at step 174600: 0.302070
2025-12-13 03:19:57,227 INFO     Training average positive_sample_loss at step 174600: 0.064751
2025-12-13 03:19:57,227 INFO     Training average negative_sample_loss at step 174600: 0.109263
2025-12-13 03:19:57,227 INFO     Training average loss at step 174600: 0.389077
2025-12-13 03:19:59,375 INFO     Training average regularization at step 174700: 0.302070
2025-12-13 03:19:59,375 INFO     Training average positive_sample_loss at step 174700: 0.066821
2025-12-13 03:19:59,375 INFO     Training average negative_sample_loss at step 174700: 0.108117
2025-12-13 03:19:59,375 INFO     Training average loss at step 174700: 0.389539
2025-12-13 03:20:01,523 INFO     Training average regularization at step 174800: 0.302070
2025-12-13 03:20:01,523 INFO     Training average positive_sample_loss at step 174800: 0.065618
2025-12-13 03:20:01,523 INFO     Training average negative_sample_loss at step 174800: 0.109291
2025-12-13 03:20:01,523 INFO     Training average loss at step 174800: 0.389524
2025-12-13 03:20:03,698 INFO     Training average regularization at step 174900: 0.302070
2025-12-13 03:20:03,698 INFO     Training average positive_sample_loss at step 174900: 0.066869
2025-12-13 03:20:03,698 INFO     Training average negative_sample_loss at step 174900: 0.109203
2025-12-13 03:20:03,698 INFO     Training average loss at step 174900: 0.390106
2025-12-13 03:20:05,855 INFO     Training average regularization at step 175000: 0.302070
2025-12-13 03:20:05,855 INFO     Training average positive_sample_loss at step 175000: 0.067346
2025-12-13 03:20:05,855 INFO     Training average negative_sample_loss at step 175000: 0.108994
2025-12-13 03:20:05,855 INFO     Training average loss at step 175000: 0.390240
2025-12-13 03:20:08,001 INFO     Training average regularization at step 175100: 0.302070
2025-12-13 03:20:08,001 INFO     Training average positive_sample_loss at step 175100: 0.067515
2025-12-13 03:20:08,001 INFO     Training average negative_sample_loss at step 175100: 0.107739
2025-12-13 03:20:08,001 INFO     Training average loss at step 175100: 0.389697
2025-12-13 03:20:10,156 INFO     Training average regularization at step 175200: 0.302069
2025-12-13 03:20:10,157 INFO     Training average positive_sample_loss at step 175200: 0.066856
2025-12-13 03:20:10,157 INFO     Training average negative_sample_loss at step 175200: 0.108952
2025-12-13 03:20:10,157 INFO     Training average loss at step 175200: 0.389973
2025-12-13 03:20:12,313 INFO     Training average regularization at step 175300: 0.302069
2025-12-13 03:20:12,313 INFO     Training average positive_sample_loss at step 175300: 0.066455
2025-12-13 03:20:12,313 INFO     Training average negative_sample_loss at step 175300: 0.109586
2025-12-13 03:20:12,313 INFO     Training average loss at step 175300: 0.390090
2025-12-13 03:20:14,493 INFO     Training average regularization at step 175400: 0.302069
2025-12-13 03:20:14,493 INFO     Training average positive_sample_loss at step 175400: 0.066068
2025-12-13 03:20:14,494 INFO     Training average negative_sample_loss at step 175400: 0.110167
2025-12-13 03:20:14,494 INFO     Training average loss at step 175400: 0.390187
2025-12-13 03:20:16,676 INFO     Training average regularization at step 175500: 0.302069
2025-12-13 03:20:16,676 INFO     Training average positive_sample_loss at step 175500: 0.066595
2025-12-13 03:20:16,676 INFO     Training average negative_sample_loss at step 175500: 0.108649
2025-12-13 03:20:16,676 INFO     Training average loss at step 175500: 0.389691
2025-12-13 03:20:18,824 INFO     Training average regularization at step 175600: 0.302069
2025-12-13 03:20:18,824 INFO     Training average positive_sample_loss at step 175600: 0.066669
2025-12-13 03:20:18,824 INFO     Training average negative_sample_loss at step 175600: 0.106203
2025-12-13 03:20:18,824 INFO     Training average loss at step 175600: 0.388505
2025-12-13 03:20:20,974 INFO     Training average regularization at step 175700: 0.302069
2025-12-13 03:20:20,975 INFO     Training average positive_sample_loss at step 175700: 0.068767
2025-12-13 03:20:20,975 INFO     Training average negative_sample_loss at step 175700: 0.111695
2025-12-13 03:20:20,975 INFO     Training average loss at step 175700: 0.392300
2025-12-13 03:20:23,127 INFO     Training average regularization at step 175800: 0.302069
2025-12-13 03:20:23,127 INFO     Training average positive_sample_loss at step 175800: 0.066870
2025-12-13 03:20:23,127 INFO     Training average negative_sample_loss at step 175800: 0.109303
2025-12-13 03:20:23,127 INFO     Training average loss at step 175800: 0.390155
2025-12-13 03:20:25,289 INFO     Training average regularization at step 175900: 0.302069
2025-12-13 03:20:25,290 INFO     Training average positive_sample_loss at step 175900: 0.066461
2025-12-13 03:20:25,290 INFO     Training average negative_sample_loss at step 175900: 0.106964
2025-12-13 03:20:25,290 INFO     Training average loss at step 175900: 0.388781
2025-12-13 03:20:27,434 INFO     Training average regularization at step 176000: 0.302069
2025-12-13 03:20:27,435 INFO     Training average positive_sample_loss at step 176000: 0.065971
2025-12-13 03:20:27,435 INFO     Training average negative_sample_loss at step 176000: 0.108188
2025-12-13 03:20:27,435 INFO     Training average loss at step 176000: 0.389149
2025-12-13 03:20:29,572 INFO     Training average regularization at step 176100: 0.302069
2025-12-13 03:20:29,572 INFO     Training average positive_sample_loss at step 176100: 0.066499
2025-12-13 03:20:29,572 INFO     Training average negative_sample_loss at step 176100: 0.106807
2025-12-13 03:20:29,572 INFO     Training average loss at step 176100: 0.388722
2025-12-13 03:20:31,736 INFO     Training average regularization at step 176200: 0.302069
2025-12-13 03:20:31,736 INFO     Training average positive_sample_loss at step 176200: 0.066420
2025-12-13 03:20:31,736 INFO     Training average negative_sample_loss at step 176200: 0.106717
2025-12-13 03:20:31,736 INFO     Training average loss at step 176200: 0.388637
2025-12-13 03:20:33,903 INFO     Training average regularization at step 176300: 0.302069
2025-12-13 03:20:33,903 INFO     Training average positive_sample_loss at step 176300: 0.066278
2025-12-13 03:20:33,903 INFO     Training average negative_sample_loss at step 176300: 0.108634
2025-12-13 03:20:33,903 INFO     Training average loss at step 176300: 0.389525
2025-12-13 03:20:36,079 INFO     Training average regularization at step 176400: 0.302069
2025-12-13 03:20:36,079 INFO     Training average positive_sample_loss at step 176400: 0.066330
2025-12-13 03:20:36,079 INFO     Training average negative_sample_loss at step 176400: 0.107345
2025-12-13 03:20:36,079 INFO     Training average loss at step 176400: 0.388906
2025-12-13 03:20:38,290 INFO     Training average regularization at step 176500: 0.302069
2025-12-13 03:20:38,290 INFO     Training average positive_sample_loss at step 176500: 0.066773
2025-12-13 03:20:38,290 INFO     Training average negative_sample_loss at step 176500: 0.107129
2025-12-13 03:20:38,290 INFO     Training average loss at step 176500: 0.389019
2025-12-13 03:20:40,473 INFO     Training average regularization at step 176600: 0.302069
2025-12-13 03:20:40,474 INFO     Training average positive_sample_loss at step 176600: 0.067046
2025-12-13 03:20:40,474 INFO     Training average negative_sample_loss at step 176600: 0.110352
2025-12-13 03:20:40,474 INFO     Training average loss at step 176600: 0.390768
2025-12-13 03:20:42,654 INFO     Training average regularization at step 176700: 0.302068
2025-12-13 03:20:42,654 INFO     Training average positive_sample_loss at step 176700: 0.066890
2025-12-13 03:20:42,654 INFO     Training average negative_sample_loss at step 176700: 0.105469
2025-12-13 03:20:42,654 INFO     Training average loss at step 176700: 0.388248
2025-12-13 03:20:44,852 INFO     Training average regularization at step 176800: 0.302068
2025-12-13 03:20:44,852 INFO     Training average positive_sample_loss at step 176800: 0.065961
2025-12-13 03:20:44,852 INFO     Training average negative_sample_loss at step 176800: 0.109056
2025-12-13 03:20:44,852 INFO     Training average loss at step 176800: 0.389577
2025-12-13 03:20:47,013 INFO     Training average regularization at step 176900: 0.302068
2025-12-13 03:20:47,013 INFO     Training average positive_sample_loss at step 176900: 0.067447
2025-12-13 03:20:47,013 INFO     Training average negative_sample_loss at step 176900: 0.110323
2025-12-13 03:20:47,013 INFO     Training average loss at step 176900: 0.390953
2025-12-13 03:20:49,180 INFO     Training average regularization at step 177000: 0.302068
2025-12-13 03:20:49,180 INFO     Training average positive_sample_loss at step 177000: 0.067417
2025-12-13 03:20:49,180 INFO     Training average negative_sample_loss at step 177000: 0.106756
2025-12-13 03:20:49,180 INFO     Training average loss at step 177000: 0.389155
2025-12-13 03:20:51,335 INFO     Training average regularization at step 177100: 0.302068
2025-12-13 03:20:51,339 INFO     Training average positive_sample_loss at step 177100: 0.067606
2025-12-13 03:20:51,339 INFO     Training average negative_sample_loss at step 177100: 0.108554
2025-12-13 03:20:51,339 INFO     Training average loss at step 177100: 0.390148
2025-12-13 03:20:53,508 INFO     Training average regularization at step 177200: 0.302068
2025-12-13 03:20:53,509 INFO     Training average positive_sample_loss at step 177200: 0.066664
2025-12-13 03:20:53,509 INFO     Training average negative_sample_loss at step 177200: 0.109478
2025-12-13 03:20:53,509 INFO     Training average loss at step 177200: 0.390139
2025-12-13 03:20:55,680 INFO     Training average regularization at step 177300: 0.302068
2025-12-13 03:20:55,680 INFO     Training average positive_sample_loss at step 177300: 0.068781
2025-12-13 03:20:55,681 INFO     Training average negative_sample_loss at step 177300: 0.109137
2025-12-13 03:20:55,681 INFO     Training average loss at step 177300: 0.391027
2025-12-13 03:20:57,817 INFO     Training average regularization at step 177400: 0.302068
2025-12-13 03:20:57,817 INFO     Training average positive_sample_loss at step 177400: 0.066869
2025-12-13 03:20:57,817 INFO     Training average negative_sample_loss at step 177400: 0.108782
2025-12-13 03:20:57,817 INFO     Training average loss at step 177400: 0.389893
2025-12-13 03:21:00,000 INFO     Training average regularization at step 177500: 0.302068
2025-12-13 03:21:00,000 INFO     Training average positive_sample_loss at step 177500: 0.066671
2025-12-13 03:21:00,000 INFO     Training average negative_sample_loss at step 177500: 0.108436
2025-12-13 03:21:00,000 INFO     Training average loss at step 177500: 0.389622
2025-12-13 03:21:02,160 INFO     Training average regularization at step 177600: 0.302068
2025-12-13 03:21:02,160 INFO     Training average positive_sample_loss at step 177600: 0.067770
2025-12-13 03:21:02,160 INFO     Training average negative_sample_loss at step 177600: 0.112386
2025-12-13 03:21:02,160 INFO     Training average loss at step 177600: 0.392146
2025-12-13 03:21:04,322 INFO     Training average regularization at step 177700: 0.302068
2025-12-13 03:21:04,322 INFO     Training average positive_sample_loss at step 177700: 0.065597
2025-12-13 03:21:04,322 INFO     Training average negative_sample_loss at step 177700: 0.107619
2025-12-13 03:21:04,322 INFO     Training average loss at step 177700: 0.388676
2025-12-13 03:21:06,473 INFO     Training average regularization at step 177800: 0.302068
2025-12-13 03:21:06,473 INFO     Training average positive_sample_loss at step 177800: 0.066924
2025-12-13 03:21:06,474 INFO     Training average negative_sample_loss at step 177800: 0.106967
2025-12-13 03:21:06,474 INFO     Training average loss at step 177800: 0.389014
2025-12-13 03:21:08,640 INFO     Training average regularization at step 177900: 0.302068
2025-12-13 03:21:08,640 INFO     Training average positive_sample_loss at step 177900: 0.066582
2025-12-13 03:21:08,640 INFO     Training average negative_sample_loss at step 177900: 0.109408
2025-12-13 03:21:08,640 INFO     Training average loss at step 177900: 0.390063
2025-12-13 03:21:10,800 INFO     Training average regularization at step 178000: 0.302068
2025-12-13 03:21:10,800 INFO     Training average positive_sample_loss at step 178000: 0.065749
2025-12-13 03:21:10,801 INFO     Training average negative_sample_loss at step 178000: 0.108031
2025-12-13 03:21:10,801 INFO     Training average loss at step 178000: 0.388958
2025-12-13 03:21:12,940 INFO     Training average regularization at step 178100: 0.302068
2025-12-13 03:21:12,940 INFO     Training average positive_sample_loss at step 178100: 0.066743
2025-12-13 03:21:12,940 INFO     Training average negative_sample_loss at step 178100: 0.108931
2025-12-13 03:21:12,940 INFO     Training average loss at step 178100: 0.389904
2025-12-13 03:21:15,109 INFO     Training average regularization at step 178200: 0.302068
2025-12-13 03:21:15,109 INFO     Training average positive_sample_loss at step 178200: 0.066423
2025-12-13 03:21:15,109 INFO     Training average negative_sample_loss at step 178200: 0.107884
2025-12-13 03:21:15,109 INFO     Training average loss at step 178200: 0.389221
2025-12-13 03:21:17,279 INFO     Training average regularization at step 178300: 0.302068
2025-12-13 03:21:17,279 INFO     Training average positive_sample_loss at step 178300: 0.067236
2025-12-13 03:21:17,279 INFO     Training average negative_sample_loss at step 178300: 0.107578
2025-12-13 03:21:17,279 INFO     Training average loss at step 178300: 0.389475
2025-12-13 03:21:19,449 INFO     Training average regularization at step 178400: 0.302067
2025-12-13 03:21:19,449 INFO     Training average positive_sample_loss at step 178400: 0.067024
2025-12-13 03:21:19,449 INFO     Training average negative_sample_loss at step 178400: 0.109265
2025-12-13 03:21:19,449 INFO     Training average loss at step 178400: 0.390212
2025-12-13 03:21:21,610 INFO     Training average regularization at step 178500: 0.302067
2025-12-13 03:21:21,610 INFO     Training average positive_sample_loss at step 178500: 0.066902
2025-12-13 03:21:21,610 INFO     Training average negative_sample_loss at step 178500: 0.109906
2025-12-13 03:21:21,610 INFO     Training average loss at step 178500: 0.390471
2025-12-13 03:21:23,779 INFO     Training average regularization at step 178600: 0.302067
2025-12-13 03:21:23,779 INFO     Training average positive_sample_loss at step 178600: 0.066042
2025-12-13 03:21:23,779 INFO     Training average negative_sample_loss at step 178600: 0.109665
2025-12-13 03:21:23,779 INFO     Training average loss at step 178600: 0.389921
2025-12-13 03:21:25,925 INFO     Training average regularization at step 178700: 0.302067
2025-12-13 03:21:25,926 INFO     Training average positive_sample_loss at step 178700: 0.065989
2025-12-13 03:21:25,926 INFO     Training average negative_sample_loss at step 178700: 0.109602
2025-12-13 03:21:25,926 INFO     Training average loss at step 178700: 0.389863
2025-12-13 03:21:29,069 INFO     Training average regularization at step 178800: 0.302067
2025-12-13 03:21:29,069 INFO     Training average positive_sample_loss at step 178800: 0.066409
2025-12-13 03:21:29,070 INFO     Training average negative_sample_loss at step 178800: 0.108132
2025-12-13 03:21:29,070 INFO     Training average loss at step 178800: 0.389338
2025-12-13 03:21:31,230 INFO     Training average regularization at step 178900: 0.302067
2025-12-13 03:21:31,231 INFO     Training average positive_sample_loss at step 178900: 0.067534
2025-12-13 03:21:31,231 INFO     Training average negative_sample_loss at step 178900: 0.110375
2025-12-13 03:21:31,231 INFO     Training average loss at step 178900: 0.391021
2025-12-13 03:21:33,411 INFO     Training average regularization at step 179000: 0.302067
2025-12-13 03:21:33,411 INFO     Training average positive_sample_loss at step 179000: 0.066188
2025-12-13 03:21:33,411 INFO     Training average negative_sample_loss at step 179000: 0.108271
2025-12-13 03:21:33,411 INFO     Training average loss at step 179000: 0.389297
2025-12-13 03:21:35,587 INFO     Training average regularization at step 179100: 0.302067
2025-12-13 03:21:35,587 INFO     Training average positive_sample_loss at step 179100: 0.068634
2025-12-13 03:21:35,587 INFO     Training average negative_sample_loss at step 179100: 0.108072
2025-12-13 03:21:35,587 INFO     Training average loss at step 179100: 0.390420
2025-12-13 03:21:37,796 INFO     Training average regularization at step 179200: 0.302067
2025-12-13 03:21:37,797 INFO     Training average positive_sample_loss at step 179200: 0.067686
2025-12-13 03:21:37,797 INFO     Training average negative_sample_loss at step 179200: 0.108812
2025-12-13 03:21:37,797 INFO     Training average loss at step 179200: 0.390316
2025-12-13 03:21:39,996 INFO     Training average regularization at step 179300: 0.302067
2025-12-13 03:21:39,996 INFO     Training average positive_sample_loss at step 179300: 0.068363
2025-12-13 03:21:39,996 INFO     Training average negative_sample_loss at step 179300: 0.108154
2025-12-13 03:21:39,996 INFO     Training average loss at step 179300: 0.390326
2025-12-13 03:21:42,174 INFO     Training average regularization at step 179400: 0.302067
2025-12-13 03:21:42,175 INFO     Training average positive_sample_loss at step 179400: 0.066840
2025-12-13 03:21:42,175 INFO     Training average negative_sample_loss at step 179400: 0.107393
2025-12-13 03:21:42,175 INFO     Training average loss at step 179400: 0.389183
2025-12-13 03:21:44,402 INFO     Training average regularization at step 179500: 0.302067
2025-12-13 03:21:44,403 INFO     Training average positive_sample_loss at step 179500: 0.066138
2025-12-13 03:21:44,403 INFO     Training average negative_sample_loss at step 179500: 0.107904
2025-12-13 03:21:44,403 INFO     Training average loss at step 179500: 0.389088
2025-12-13 03:21:46,573 INFO     Training average regularization at step 179600: 0.302067
2025-12-13 03:21:46,574 INFO     Training average positive_sample_loss at step 179600: 0.066347
2025-12-13 03:21:46,574 INFO     Training average negative_sample_loss at step 179600: 0.108884
2025-12-13 03:21:46,574 INFO     Training average loss at step 179600: 0.389682
2025-12-13 03:21:48,745 INFO     Training average regularization at step 179700: 0.302067
2025-12-13 03:21:48,745 INFO     Training average positive_sample_loss at step 179700: 0.066176
2025-12-13 03:21:48,745 INFO     Training average negative_sample_loss at step 179700: 0.107614
2025-12-13 03:21:48,745 INFO     Training average loss at step 179700: 0.388962
2025-12-13 03:21:50,891 INFO     Training average regularization at step 179800: 0.302066
2025-12-13 03:21:50,892 INFO     Training average positive_sample_loss at step 179800: 0.066388
2025-12-13 03:21:50,892 INFO     Training average negative_sample_loss at step 179800: 0.112129
2025-12-13 03:21:50,892 INFO     Training average loss at step 179800: 0.391325
2025-12-13 03:21:53,043 INFO     Training average regularization at step 179900: 0.302066
2025-12-13 03:21:53,043 INFO     Training average positive_sample_loss at step 179900: 0.066324
2025-12-13 03:21:53,043 INFO     Training average negative_sample_loss at step 179900: 0.108899
2025-12-13 03:21:53,043 INFO     Training average loss at step 179900: 0.389678
2025-12-13 03:21:57,539 INFO     Training average regularization at step 180000: 0.302066
2025-12-13 03:21:57,539 INFO     Training average positive_sample_loss at step 180000: 0.067258
2025-12-13 03:21:57,539 INFO     Training average negative_sample_loss at step 180000: 0.109379
2025-12-13 03:21:57,539 INFO     Training average loss at step 180000: 0.390385
2025-12-13 03:21:57,539 INFO     Evaluating on Valid Dataset...
2025-12-13 03:21:58,194 INFO     Evaluating the model... (0/50000)
2025-12-13 03:22:00,809 INFO     Evaluating the model... (500/50000)
2025-12-13 03:22:04,378 INFO     Evaluating the model... (1000/50000)
2025-12-13 03:22:07,004 INFO     Evaluating the model... (1500/50000)
2025-12-13 03:22:09,433 INFO     Evaluating the model... (2000/50000)
2025-12-13 03:22:11,859 INFO     Evaluating the model... (2500/50000)
2025-12-13 03:22:14,277 INFO     Evaluating the model... (3000/50000)
2025-12-13 03:22:17,714 INFO     Evaluating the model... (3500/50000)
2025-12-13 03:22:20,215 INFO     Evaluating the model... (4000/50000)
2025-12-13 03:22:22,579 INFO     Evaluating the model... (4500/50000)
2025-12-13 03:22:25,082 INFO     Evaluating the model... (5000/50000)
2025-12-13 03:22:27,508 INFO     Evaluating the model... (5500/50000)
2025-12-13 03:22:31,050 INFO     Evaluating the model... (6000/50000)
2025-12-13 03:22:33,466 INFO     Evaluating the model... (6500/50000)
2025-12-13 03:22:36,057 INFO     Evaluating the model... (7000/50000)
2025-12-13 03:22:38,715 INFO     Evaluating the model... (7500/50000)
2025-12-13 03:22:42,461 INFO     Evaluating the model... (8000/50000)
2025-12-13 03:22:44,963 INFO     Evaluating the model... (8500/50000)
2025-12-13 03:22:47,400 INFO     Evaluating the model... (9000/50000)
2025-12-13 03:22:49,861 INFO     Evaluating the model... (9500/50000)
2025-12-13 03:22:52,413 INFO     Evaluating the model... (10000/50000)
2025-12-13 03:22:55,818 INFO     Evaluating the model... (10500/50000)
2025-12-13 03:22:58,186 INFO     Evaluating the model... (11000/50000)
2025-12-13 03:23:00,638 INFO     Evaluating the model... (11500/50000)
2025-12-13 03:23:03,240 INFO     Evaluating the model... (12000/50000)
2025-12-13 03:23:05,765 INFO     Evaluating the model... (12500/50000)
2025-12-13 03:23:08,796 INFO     Evaluating the model... (13000/50000)
2025-12-13 03:23:11,346 INFO     Evaluating the model... (13500/50000)
2025-12-13 03:23:13,816 INFO     Evaluating the model... (14000/50000)
2025-12-13 03:23:16,570 INFO     Evaluating the model... (14500/50000)
2025-12-13 03:23:19,018 INFO     Evaluating the model... (15000/50000)
2025-12-13 03:23:22,265 INFO     Evaluating the model... (15500/50000)
2025-12-13 03:23:24,661 INFO     Evaluating the model... (16000/50000)
2025-12-13 03:23:27,325 INFO     Evaluating the model... (16500/50000)
2025-12-13 03:23:29,832 INFO     Evaluating the model... (17000/50000)
2025-12-13 03:23:32,129 INFO     Evaluating the model... (17500/50000)
2025-12-13 03:23:35,584 INFO     Evaluating the model... (18000/50000)
2025-12-13 03:23:38,500 INFO     Evaluating the model... (18500/50000)
2025-12-13 03:23:41,098 INFO     Evaluating the model... (19000/50000)
2025-12-13 03:23:43,747 INFO     Evaluating the model... (19500/50000)
2025-12-13 03:23:46,312 INFO     Evaluating the model... (20000/50000)
2025-12-13 03:23:50,025 INFO     Evaluating the model... (20500/50000)
2025-12-13 03:23:52,392 INFO     Evaluating the model... (21000/50000)
2025-12-13 03:23:54,906 INFO     Evaluating the model... (21500/50000)
2025-12-13 03:23:57,341 INFO     Evaluating the model... (22000/50000)
2025-12-13 03:23:59,788 INFO     Evaluating the model... (22500/50000)
2025-12-13 03:24:03,386 INFO     Evaluating the model... (23000/50000)
2025-12-13 03:24:05,875 INFO     Evaluating the model... (23500/50000)
2025-12-13 03:24:08,240 INFO     Evaluating the model... (24000/50000)
2025-12-13 03:24:10,744 INFO     Evaluating the model... (24500/50000)
2025-12-13 03:24:13,701 INFO     Evaluating the model... (25000/50000)
2025-12-13 03:24:17,389 INFO     Evaluating the model... (25500/50000)
2025-12-13 03:24:19,910 INFO     Evaluating the model... (26000/50000)
2025-12-13 03:24:22,477 INFO     Evaluating the model... (26500/50000)
2025-12-13 03:24:25,255 INFO     Evaluating the model... (27000/50000)
2025-12-13 03:24:27,842 INFO     Evaluating the model... (27500/50000)
2025-12-13 03:24:31,354 INFO     Evaluating the model... (28000/50000)
2025-12-13 03:24:33,878 INFO     Evaluating the model... (28500/50000)
2025-12-13 03:24:36,815 INFO     Evaluating the model... (29000/50000)
2025-12-13 03:24:39,518 INFO     Evaluating the model... (29500/50000)
2025-12-13 03:24:42,184 INFO     Evaluating the model... (30000/50000)
2025-12-13 03:24:45,387 INFO     Evaluating the model... (30500/50000)
2025-12-13 03:24:48,169 INFO     Evaluating the model... (31000/50000)
2025-12-13 03:24:50,683 INFO     Evaluating the model... (31500/50000)
2025-12-13 03:24:53,169 INFO     Evaluating the model... (32000/50000)
2025-12-13 03:24:55,692 INFO     Evaluating the model... (32500/50000)
2025-12-13 03:24:59,140 INFO     Evaluating the model... (33000/50000)
2025-12-13 03:25:01,656 INFO     Evaluating the model... (33500/50000)
2025-12-13 03:25:04,132 INFO     Evaluating the model... (34000/50000)
2025-12-13 03:25:06,696 INFO     Evaluating the model... (34500/50000)
2025-12-13 03:25:10,287 INFO     Evaluating the model... (35000/50000)
2025-12-13 03:25:12,888 INFO     Evaluating the model... (35500/50000)
2025-12-13 03:25:15,529 INFO     Evaluating the model... (36000/50000)
2025-12-13 03:25:18,022 INFO     Evaluating the model... (36500/50000)
2025-12-13 03:25:20,553 INFO     Evaluating the model... (37000/50000)
2025-12-13 03:25:24,048 INFO     Evaluating the model... (37500/50000)
2025-12-13 03:25:26,717 INFO     Evaluating the model... (38000/50000)
2025-12-13 03:25:29,227 INFO     Evaluating the model... (38500/50000)
2025-12-13 03:25:31,597 INFO     Evaluating the model... (39000/50000)
2025-12-13 03:25:34,578 INFO     Evaluating the model... (39500/50000)
2025-12-13 03:25:38,156 INFO     Evaluating the model... (40000/50000)
2025-12-13 03:25:40,976 INFO     Evaluating the model... (40500/50000)
2025-12-13 03:25:43,871 INFO     Evaluating the model... (41000/50000)
2025-12-13 03:25:46,633 INFO     Evaluating the model... (41500/50000)
2025-12-13 03:25:49,194 INFO     Evaluating the model... (42000/50000)
2025-12-13 03:25:52,775 INFO     Evaluating the model... (42500/50000)
2025-12-13 03:25:55,308 INFO     Evaluating the model... (43000/50000)
2025-12-13 03:25:58,039 INFO     Evaluating the model... (43500/50000)
2025-12-13 03:26:00,567 INFO     Evaluating the model... (44000/50000)
2025-12-13 03:26:02,960 INFO     Evaluating the model... (44500/50000)
2025-12-13 03:26:06,406 INFO     Evaluating the model... (45000/50000)
2025-12-13 03:26:09,027 INFO     Evaluating the model... (45500/50000)
2025-12-13 03:26:11,527 INFO     Evaluating the model... (46000/50000)
2025-12-13 03:26:13,968 INFO     Evaluating the model... (46500/50000)
2025-12-13 03:26:16,602 INFO     Evaluating the model... (47000/50000)
2025-12-13 03:26:19,858 INFO     Evaluating the model... (47500/50000)
2025-12-13 03:26:22,356 INFO     Evaluating the model... (48000/50000)
2025-12-13 03:26:24,806 INFO     Evaluating the model... (48500/50000)
2025-12-13 03:26:27,367 INFO     Evaluating the model... (49000/50000)
2025-12-13 03:26:29,973 INFO     Evaluating the model... (49500/50000)
2025-12-13 03:26:33,731 INFO     Valid MRR at step 180000: 0.632990
2025-12-13 03:26:33,731 INFO     Valid MR at step 180000: 266.775580
2025-12-13 03:26:33,731 INFO     Valid HITS@1 at step 180000: 0.547190
2025-12-13 03:26:33,731 INFO     Valid HITS@3 at step 180000: 0.686010
2025-12-13 03:26:33,731 INFO     Valid HITS@10 at step 180000: 0.784720
2025-12-13 03:26:35,012 INFO     Evaluating on Test Dataset...
2025-12-13 03:26:35,602 INFO     Evaluating the model... (0/59072)
2025-12-13 03:26:38,375 INFO     Evaluating the model... (500/59072)
2025-12-13 03:26:40,954 INFO     Evaluating the model... (1000/59072)
2025-12-13 03:26:43,899 INFO     Evaluating the model... (1500/59072)
2025-12-13 03:26:46,547 INFO     Evaluating the model... (2000/59072)
2025-12-13 03:26:49,948 INFO     Evaluating the model... (2500/59072)
2025-12-13 03:26:52,307 INFO     Evaluating the model... (3000/59072)
2025-12-13 03:26:55,002 INFO     Evaluating the model... (3500/59072)
2025-12-13 03:26:57,373 INFO     Evaluating the model... (4000/59072)
2025-12-13 03:26:59,783 INFO     Evaluating the model... (4500/59072)
2025-12-13 03:27:02,862 INFO     Evaluating the model... (5000/59072)
2025-12-13 03:27:05,428 INFO     Evaluating the model... (5500/59072)
2025-12-13 03:27:07,942 INFO     Evaluating the model... (6000/59072)
2025-12-13 03:27:10,402 INFO     Evaluating the model... (6500/59072)
2025-12-13 03:27:12,850 INFO     Evaluating the model... (7000/59072)
2025-12-13 03:27:16,089 INFO     Evaluating the model... (7500/59072)
2025-12-13 03:27:18,657 INFO     Evaluating the model... (8000/59072)
2025-12-13 03:27:21,098 INFO     Evaluating the model... (8500/59072)
2025-12-13 03:27:23,449 INFO     Evaluating the model... (9000/59072)
2025-12-13 03:27:25,894 INFO     Evaluating the model... (9500/59072)
2025-12-13 03:27:29,424 INFO     Evaluating the model... (10000/59072)
2025-12-13 03:27:31,992 INFO     Evaluating the model... (10500/59072)
2025-12-13 03:27:34,324 INFO     Evaluating the model... (11000/59072)
2025-12-13 03:27:36,928 INFO     Evaluating the model... (11500/59072)
2025-12-13 03:27:40,735 INFO     Evaluating the model... (12000/59072)
2025-12-13 03:27:43,278 INFO     Evaluating the model... (12500/59072)
2025-12-13 03:27:45,835 INFO     Evaluating the model... (13000/59072)
2025-12-13 03:27:48,310 INFO     Evaluating the model... (13500/59072)
2025-12-13 03:27:50,808 INFO     Evaluating the model... (14000/59072)
2025-12-13 03:27:54,118 INFO     Evaluating the model... (14500/59072)
2025-12-13 03:27:56,593 INFO     Evaluating the model... (15000/59072)
2025-12-13 03:27:59,013 INFO     Evaluating the model... (15500/59072)
2025-12-13 03:28:01,467 INFO     Evaluating the model... (16000/59072)
2025-12-13 03:28:04,070 INFO     Evaluating the model... (16500/59072)
2025-12-13 03:28:07,698 INFO     Evaluating the model... (17000/59072)
2025-12-13 03:28:10,143 INFO     Evaluating the model... (17500/59072)
2025-12-13 03:28:12,545 INFO     Evaluating the model... (18000/59072)
2025-12-13 03:28:15,168 INFO     Evaluating the model... (18500/59072)
2025-12-13 03:28:17,697 INFO     Evaluating the model... (19000/59072)
2025-12-13 03:28:20,881 INFO     Evaluating the model... (19500/59072)
2025-12-13 03:28:23,284 INFO     Evaluating the model... (20000/59072)
2025-12-13 03:28:26,060 INFO     Evaluating the model... (20500/59072)
2025-12-13 03:28:28,601 INFO     Evaluating the model... (21000/59072)
2025-12-13 03:28:31,035 INFO     Evaluating the model... (21500/59072)
2025-12-13 03:28:34,631 INFO     Evaluating the model... (22000/59072)
2025-12-13 03:28:37,542 INFO     Evaluating the model... (22500/59072)
2025-12-13 03:28:40,094 INFO     Evaluating the model... (23000/59072)
2025-12-13 03:28:42,734 INFO     Evaluating the model... (23500/59072)
2025-12-13 03:28:45,409 INFO     Evaluating the model... (24000/59072)
2025-12-13 03:28:49,271 INFO     Evaluating the model... (24500/59072)
2025-12-13 03:28:51,724 INFO     Evaluating the model... (25000/59072)
2025-12-13 03:28:54,134 INFO     Evaluating the model... (25500/59072)
2025-12-13 03:28:56,677 INFO     Evaluating the model... (26000/59072)
2025-12-13 03:28:59,256 INFO     Evaluating the model... (26500/59072)
2025-12-13 03:29:03,037 INFO     Evaluating the model... (27000/59072)
2025-12-13 03:29:05,491 INFO     Evaluating the model... (27500/59072)
2025-12-13 03:29:07,970 INFO     Evaluating the model... (28000/59072)
2025-12-13 03:29:10,401 INFO     Evaluating the model... (28500/59072)
2025-12-13 03:29:12,923 INFO     Evaluating the model... (29000/59072)
2025-12-13 03:29:16,559 INFO     Evaluating the model... (29500/59072)
2025-12-13 03:29:19,323 INFO     Evaluating the model... (30000/59072)
2025-12-13 03:29:21,827 INFO     Evaluating the model... (30500/59072)
2025-12-13 03:29:24,418 INFO     Evaluating the model... (31000/59072)
2025-12-13 03:29:27,839 INFO     Evaluating the model... (31500/59072)
2025-12-13 03:29:30,341 INFO     Evaluating the model... (32000/59072)
2025-12-13 03:29:32,893 INFO     Evaluating the model... (32500/59072)
2025-12-13 03:29:35,757 INFO     Evaluating the model... (33000/59072)
2025-12-13 03:29:38,419 INFO     Evaluating the model... (33500/59072)
2025-12-13 03:29:41,959 INFO     Evaluating the model... (34000/59072)
2025-12-13 03:29:44,625 INFO     Evaluating the model... (34500/59072)
2025-12-13 03:29:47,590 INFO     Evaluating the model... (35000/59072)
2025-12-13 03:29:50,103 INFO     Evaluating the model... (35500/59072)
2025-12-13 03:29:52,617 INFO     Evaluating the model... (36000/59072)
2025-12-13 03:29:55,780 INFO     Evaluating the model... (36500/59072)
2025-12-13 03:29:58,500 INFO     Evaluating the model... (37000/59072)
2025-12-13 03:30:01,018 INFO     Evaluating the model... (37500/59072)
2025-12-13 03:30:03,572 INFO     Evaluating the model... (38000/59072)
2025-12-13 03:30:06,125 INFO     Evaluating the model... (38500/59072)
2025-12-13 03:30:09,402 INFO     Evaluating the model... (39000/59072)
2025-12-13 03:30:11,999 INFO     Evaluating the model... (39500/59072)
2025-12-13 03:30:14,495 INFO     Evaluating the model... (40000/59072)
2025-12-13 03:30:17,091 INFO     Evaluating the model... (40500/59072)
2025-12-13 03:30:19,697 INFO     Evaluating the model... (41000/59072)
2025-12-13 03:30:22,880 INFO     Evaluating the model... (41500/59072)
2025-12-13 03:30:25,513 INFO     Evaluating the model... (42000/59072)
2025-12-13 03:30:28,086 INFO     Evaluating the model... (42500/59072)
2025-12-13 03:30:30,622 INFO     Evaluating the model... (43000/59072)
2025-12-13 03:30:33,250 INFO     Evaluating the model... (43500/59072)
2025-12-13 03:30:36,747 INFO     Evaluating the model... (44000/59072)
2025-12-13 03:30:39,365 INFO     Evaluating the model... (44500/59072)
2025-12-13 03:30:42,074 INFO     Evaluating the model... (45000/59072)
2025-12-13 03:30:45,056 INFO     Evaluating the model... (45500/59072)
2025-12-13 03:30:48,844 INFO     Evaluating the model... (46000/59072)
2025-12-13 03:30:51,291 INFO     Evaluating the model... (46500/59072)
2025-12-13 03:30:53,848 INFO     Evaluating the model... (47000/59072)
2025-12-13 03:30:56,593 INFO     Evaluating the model... (47500/59072)
2025-12-13 03:30:59,063 INFO     Evaluating the model... (48000/59072)
2025-12-13 03:31:02,395 INFO     Evaluating the model... (48500/59072)
2025-12-13 03:31:04,808 INFO     Evaluating the model... (49000/59072)
2025-12-13 03:31:07,537 INFO     Evaluating the model... (49500/59072)
2025-12-13 03:31:10,080 INFO     Evaluating the model... (50000/59072)
2025-12-13 03:31:12,592 INFO     Evaluating the model... (50500/59072)
2025-12-13 03:31:15,960 INFO     Evaluating the model... (51000/59072)
2025-12-13 03:31:18,680 INFO     Evaluating the model... (51500/59072)
2025-12-13 03:31:21,115 INFO     Evaluating the model... (52000/59072)
2025-12-13 03:31:23,608 INFO     Evaluating the model... (52500/59072)
2025-12-13 03:31:26,223 INFO     Evaluating the model... (53000/59072)
2025-12-13 03:31:30,028 INFO     Evaluating the model... (53500/59072)
2025-12-13 03:31:32,494 INFO     Evaluating the model... (54000/59072)
2025-12-13 03:31:34,892 INFO     Evaluating the model... (54500/59072)
2025-12-13 03:31:37,601 INFO     Evaluating the model... (55000/59072)
2025-12-13 03:31:40,488 INFO     Evaluating the model... (55500/59072)
2025-12-13 03:31:44,629 INFO     Evaluating the model... (56000/59072)
2025-12-13 03:31:47,083 INFO     Evaluating the model... (56500/59072)
2025-12-13 03:31:49,530 INFO     Evaluating the model... (57000/59072)
2025-12-13 03:31:52,209 INFO     Evaluating the model... (57500/59072)
2025-12-13 03:31:54,737 INFO     Evaluating the model... (58000/59072)
2025-12-13 03:31:58,484 INFO     Evaluating the model... (58500/59072)
2025-12-13 03:32:00,892 INFO     Evaluating the model... (59000/59072)
2025-12-13 03:32:01,585 INFO     Test MRR at step 180000: 0.629988
2025-12-13 03:32:01,585 INFO     Test MR at step 180000: 268.753906
2025-12-13 03:32:01,585 INFO     Test HITS@1 at step 180000: 0.542931
2025-12-13 03:32:01,585 INFO     Test HITS@3 at step 180000: 0.684329
2025-12-13 03:32:01,585 INFO     Test HITS@10 at step 180000: 0.782965
2025-12-13 03:32:03,765 INFO     Training average regularization at step 180100: 0.302066
2025-12-13 03:32:03,765 INFO     Training average positive_sample_loss at step 180100: 0.066455
2025-12-13 03:32:03,765 INFO     Training average negative_sample_loss at step 180100: 0.110040
2025-12-13 03:32:03,765 INFO     Training average loss at step 180100: 0.390314
2025-12-13 03:32:05,931 INFO     Training average regularization at step 180200: 0.302066
2025-12-13 03:32:05,931 INFO     Training average positive_sample_loss at step 180200: 0.067207
2025-12-13 03:32:05,931 INFO     Training average negative_sample_loss at step 180200: 0.107239
2025-12-13 03:32:05,931 INFO     Training average loss at step 180200: 0.389289
2025-12-13 03:32:08,085 INFO     Training average regularization at step 180300: 0.302066
2025-12-13 03:32:08,086 INFO     Training average positive_sample_loss at step 180300: 0.066473
2025-12-13 03:32:08,086 INFO     Training average negative_sample_loss at step 180300: 0.110451
2025-12-13 03:32:08,086 INFO     Training average loss at step 180300: 0.390528
2025-12-13 03:32:10,258 INFO     Training average regularization at step 180400: 0.302066
2025-12-13 03:32:10,258 INFO     Training average positive_sample_loss at step 180400: 0.065928
2025-12-13 03:32:10,258 INFO     Training average negative_sample_loss at step 180400: 0.108606
2025-12-13 03:32:10,258 INFO     Training average loss at step 180400: 0.389333
2025-12-13 03:32:12,421 INFO     Training average regularization at step 180500: 0.302066
2025-12-13 03:32:12,421 INFO     Training average positive_sample_loss at step 180500: 0.066524
2025-12-13 03:32:12,421 INFO     Training average negative_sample_loss at step 180500: 0.109758
2025-12-13 03:32:12,422 INFO     Training average loss at step 180500: 0.390207
2025-12-13 03:32:14,586 INFO     Training average regularization at step 180600: 0.302066
2025-12-13 03:32:14,586 INFO     Training average positive_sample_loss at step 180600: 0.066599
2025-12-13 03:32:14,587 INFO     Training average negative_sample_loss at step 180600: 0.109094
2025-12-13 03:32:14,587 INFO     Training average loss at step 180600: 0.389912
2025-12-13 03:32:16,726 INFO     Training average regularization at step 180700: 0.302066
2025-12-13 03:32:16,726 INFO     Training average positive_sample_loss at step 180700: 0.067711
2025-12-13 03:32:16,727 INFO     Training average negative_sample_loss at step 180700: 0.112096
2025-12-13 03:32:16,727 INFO     Training average loss at step 180700: 0.391969
2025-12-13 03:32:18,889 INFO     Training average regularization at step 180800: 0.302066
2025-12-13 03:32:18,889 INFO     Training average positive_sample_loss at step 180800: 0.066068
2025-12-13 03:32:18,889 INFO     Training average negative_sample_loss at step 180800: 0.109025
2025-12-13 03:32:18,889 INFO     Training average loss at step 180800: 0.389612
2025-12-13 03:32:21,066 INFO     Training average regularization at step 180900: 0.302066
2025-12-13 03:32:21,066 INFO     Training average positive_sample_loss at step 180900: 0.065505
2025-12-13 03:32:21,066 INFO     Training average negative_sample_loss at step 180900: 0.108989
2025-12-13 03:32:21,066 INFO     Training average loss at step 180900: 0.389313
2025-12-13 03:32:23,217 INFO     Training average regularization at step 181000: 0.302066
2025-12-13 03:32:23,217 INFO     Training average positive_sample_loss at step 181000: 0.067110
2025-12-13 03:32:23,218 INFO     Training average negative_sample_loss at step 181000: 0.109873
2025-12-13 03:32:23,218 INFO     Training average loss at step 181000: 0.390557
2025-12-13 03:32:25,380 INFO     Training average regularization at step 181100: 0.302065
2025-12-13 03:32:25,381 INFO     Training average positive_sample_loss at step 181100: 0.065871
2025-12-13 03:32:25,381 INFO     Training average negative_sample_loss at step 181100: 0.111132
2025-12-13 03:32:25,381 INFO     Training average loss at step 181100: 0.390567
2025-12-13 03:32:27,535 INFO     Training average regularization at step 181200: 0.302065
2025-12-13 03:32:27,542 INFO     Training average positive_sample_loss at step 181200: 0.068292
2025-12-13 03:32:27,542 INFO     Training average negative_sample_loss at step 181200: 0.109674
2025-12-13 03:32:27,542 INFO     Training average loss at step 181200: 0.391049
2025-12-13 03:32:29,692 INFO     Training average regularization at step 181300: 0.302065
2025-12-13 03:32:29,692 INFO     Training average positive_sample_loss at step 181300: 0.067266
2025-12-13 03:32:29,692 INFO     Training average negative_sample_loss at step 181300: 0.106921
2025-12-13 03:32:29,692 INFO     Training average loss at step 181300: 0.389159
2025-12-13 03:32:31,838 INFO     Training average regularization at step 181400: 0.302065
2025-12-13 03:32:31,838 INFO     Training average positive_sample_loss at step 181400: 0.067102
2025-12-13 03:32:31,838 INFO     Training average negative_sample_loss at step 181400: 0.107648
2025-12-13 03:32:31,838 INFO     Training average loss at step 181400: 0.389440
2025-12-13 03:32:33,993 INFO     Training average regularization at step 181500: 0.302065
2025-12-13 03:32:33,993 INFO     Training average positive_sample_loss at step 181500: 0.066909
2025-12-13 03:32:33,993 INFO     Training average negative_sample_loss at step 181500: 0.107680
2025-12-13 03:32:33,993 INFO     Training average loss at step 181500: 0.389360
2025-12-13 03:32:36,156 INFO     Training average regularization at step 181600: 0.302065
2025-12-13 03:32:36,156 INFO     Training average positive_sample_loss at step 181600: 0.066530
2025-12-13 03:32:36,156 INFO     Training average negative_sample_loss at step 181600: 0.109109
2025-12-13 03:32:36,156 INFO     Training average loss at step 181600: 0.389885
2025-12-13 03:32:38,353 INFO     Training average regularization at step 181700: 0.302065
2025-12-13 03:32:38,353 INFO     Training average positive_sample_loss at step 181700: 0.066906
2025-12-13 03:32:38,353 INFO     Training average negative_sample_loss at step 181700: 0.107656
2025-12-13 03:32:38,353 INFO     Training average loss at step 181700: 0.389346
2025-12-13 03:32:40,512 INFO     Training average regularization at step 181800: 0.302065
2025-12-13 03:32:40,513 INFO     Training average positive_sample_loss at step 181800: 0.067682
2025-12-13 03:32:40,513 INFO     Training average negative_sample_loss at step 181800: 0.108853
2025-12-13 03:32:40,513 INFO     Training average loss at step 181800: 0.390332
2025-12-13 03:32:42,668 INFO     Training average regularization at step 181900: 0.302065
2025-12-13 03:32:42,668 INFO     Training average positive_sample_loss at step 181900: 0.066428
2025-12-13 03:32:42,668 INFO     Training average negative_sample_loss at step 181900: 0.110411
2025-12-13 03:32:42,668 INFO     Training average loss at step 181900: 0.390485
2025-12-13 03:32:44,863 INFO     Training average regularization at step 182000: 0.302065
2025-12-13 03:32:44,863 INFO     Training average positive_sample_loss at step 182000: 0.067033
2025-12-13 03:32:44,863 INFO     Training average negative_sample_loss at step 182000: 0.111806
2025-12-13 03:32:44,863 INFO     Training average loss at step 182000: 0.391485
2025-12-13 03:32:47,020 INFO     Training average regularization at step 182100: 0.302065
2025-12-13 03:32:47,020 INFO     Training average positive_sample_loss at step 182100: 0.066594
2025-12-13 03:32:47,020 INFO     Training average negative_sample_loss at step 182100: 0.108446
2025-12-13 03:32:47,020 INFO     Training average loss at step 182100: 0.389585
2025-12-13 03:32:49,196 INFO     Training average regularization at step 182200: 0.302065
2025-12-13 03:32:49,196 INFO     Training average positive_sample_loss at step 182200: 0.064242
2025-12-13 03:32:49,196 INFO     Training average negative_sample_loss at step 182200: 0.109755
2025-12-13 03:32:49,196 INFO     Training average loss at step 182200: 0.389064
2025-12-13 03:32:51,364 INFO     Training average regularization at step 182300: 0.302065
2025-12-13 03:32:51,364 INFO     Training average positive_sample_loss at step 182300: 0.066333
2025-12-13 03:32:51,364 INFO     Training average negative_sample_loss at step 182300: 0.108484
2025-12-13 03:32:51,364 INFO     Training average loss at step 182300: 0.389473
2025-12-13 03:32:53,523 INFO     Training average regularization at step 182400: 0.302065
2025-12-13 03:32:53,523 INFO     Training average positive_sample_loss at step 182400: 0.066227
2025-12-13 03:32:53,523 INFO     Training average negative_sample_loss at step 182400: 0.110233
2025-12-13 03:32:53,523 INFO     Training average loss at step 182400: 0.390294
2025-12-13 03:32:55,680 INFO     Training average regularization at step 182500: 0.302065
2025-12-13 03:32:55,680 INFO     Training average positive_sample_loss at step 182500: 0.066189
2025-12-13 03:32:55,680 INFO     Training average negative_sample_loss at step 182500: 0.111275
2025-12-13 03:32:55,680 INFO     Training average loss at step 182500: 0.390796
2025-12-13 03:32:57,823 INFO     Training average regularization at step 182600: 0.302065
2025-12-13 03:32:57,826 INFO     Training average positive_sample_loss at step 182600: 0.066823
2025-12-13 03:32:57,826 INFO     Training average negative_sample_loss at step 182600: 0.109315
2025-12-13 03:32:57,826 INFO     Training average loss at step 182600: 0.390133
2025-12-13 03:32:59,992 INFO     Training average regularization at step 182700: 0.302065
2025-12-13 03:32:59,992 INFO     Training average positive_sample_loss at step 182700: 0.067791
2025-12-13 03:32:59,992 INFO     Training average negative_sample_loss at step 182700: 0.108473
2025-12-13 03:32:59,992 INFO     Training average loss at step 182700: 0.390196
2025-12-13 03:33:02,147 INFO     Training average regularization at step 182800: 0.302064
2025-12-13 03:33:02,147 INFO     Training average positive_sample_loss at step 182800: 0.065624
2025-12-13 03:33:02,147 INFO     Training average negative_sample_loss at step 182800: 0.109232
2025-12-13 03:33:02,147 INFO     Training average loss at step 182800: 0.389493
2025-12-13 03:33:04,300 INFO     Training average regularization at step 182900: 0.302064
2025-12-13 03:33:04,300 INFO     Training average positive_sample_loss at step 182900: 0.066608
2025-12-13 03:33:04,300 INFO     Training average negative_sample_loss at step 182900: 0.109441
2025-12-13 03:33:04,300 INFO     Training average loss at step 182900: 0.390089
2025-12-13 03:33:06,446 INFO     Training average regularization at step 183000: 0.302064
2025-12-13 03:33:06,446 INFO     Training average positive_sample_loss at step 183000: 0.066416
2025-12-13 03:33:06,446 INFO     Training average negative_sample_loss at step 183000: 0.109779
2025-12-13 03:33:06,446 INFO     Training average loss at step 183000: 0.390162
2025-12-13 03:33:08,596 INFO     Training average regularization at step 183100: 0.302064
2025-12-13 03:33:08,596 INFO     Training average positive_sample_loss at step 183100: 0.066754
2025-12-13 03:33:08,596 INFO     Training average negative_sample_loss at step 183100: 0.109104
2025-12-13 03:33:08,596 INFO     Training average loss at step 183100: 0.389993
2025-12-13 03:33:10,773 INFO     Training average regularization at step 183200: 0.302064
2025-12-13 03:33:10,773 INFO     Training average positive_sample_loss at step 183200: 0.065349
2025-12-13 03:33:10,773 INFO     Training average negative_sample_loss at step 183200: 0.107719
2025-12-13 03:33:10,773 INFO     Training average loss at step 183200: 0.388598
2025-12-13 03:33:12,949 INFO     Training average regularization at step 183300: 0.302064
2025-12-13 03:33:12,949 INFO     Training average positive_sample_loss at step 183300: 0.066690
2025-12-13 03:33:12,949 INFO     Training average negative_sample_loss at step 183300: 0.108989
2025-12-13 03:33:12,949 INFO     Training average loss at step 183300: 0.389904
2025-12-13 03:33:15,116 INFO     Training average regularization at step 183400: 0.302064
2025-12-13 03:33:15,117 INFO     Training average positive_sample_loss at step 183400: 0.066940
2025-12-13 03:33:15,117 INFO     Training average negative_sample_loss at step 183400: 0.108277
2025-12-13 03:33:15,117 INFO     Training average loss at step 183400: 0.389673
2025-12-13 03:33:17,295 INFO     Training average regularization at step 183500: 0.302064
2025-12-13 03:33:17,296 INFO     Training average positive_sample_loss at step 183500: 0.067750
2025-12-13 03:33:17,296 INFO     Training average negative_sample_loss at step 183500: 0.106978
2025-12-13 03:33:17,296 INFO     Training average loss at step 183500: 0.389428
2025-12-13 03:33:19,592 INFO     Training average regularization at step 183600: 0.302064
2025-12-13 03:33:19,592 INFO     Training average positive_sample_loss at step 183600: 0.066833
2025-12-13 03:33:19,592 INFO     Training average negative_sample_loss at step 183600: 0.109930
2025-12-13 03:33:19,592 INFO     Training average loss at step 183600: 0.390445
2025-12-13 03:33:22,988 INFO     Training average regularization at step 183700: 0.302064
2025-12-13 03:33:22,988 INFO     Training average positive_sample_loss at step 183700: 0.066657
2025-12-13 03:33:22,988 INFO     Training average negative_sample_loss at step 183700: 0.108082
2025-12-13 03:33:22,989 INFO     Training average loss at step 183700: 0.389433
2025-12-13 03:33:25,145 INFO     Training average regularization at step 183800: 0.302064
2025-12-13 03:33:25,146 INFO     Training average positive_sample_loss at step 183800: 0.068595
2025-12-13 03:33:25,146 INFO     Training average negative_sample_loss at step 183800: 0.107754
2025-12-13 03:33:25,146 INFO     Training average loss at step 183800: 0.390238
2025-12-13 03:33:27,316 INFO     Training average regularization at step 183900: 0.302064
2025-12-13 03:33:27,316 INFO     Training average positive_sample_loss at step 183900: 0.067405
2025-12-13 03:33:27,316 INFO     Training average negative_sample_loss at step 183900: 0.109592
2025-12-13 03:33:27,316 INFO     Training average loss at step 183900: 0.390562
2025-12-13 03:33:29,481 INFO     Training average regularization at step 184000: 0.302064
2025-12-13 03:33:29,481 INFO     Training average positive_sample_loss at step 184000: 0.066832
2025-12-13 03:33:29,481 INFO     Training average negative_sample_loss at step 184000: 0.108035
2025-12-13 03:33:29,481 INFO     Training average loss at step 184000: 0.389497
2025-12-13 03:33:31,672 INFO     Training average regularization at step 184100: 0.302064
2025-12-13 03:33:31,674 INFO     Training average positive_sample_loss at step 184100: 0.067531
2025-12-13 03:33:31,674 INFO     Training average negative_sample_loss at step 184100: 0.111009
2025-12-13 03:33:31,674 INFO     Training average loss at step 184100: 0.391334
2025-12-13 03:33:33,828 INFO     Training average regularization at step 184200: 0.302064
2025-12-13 03:33:33,828 INFO     Training average positive_sample_loss at step 184200: 0.067183
2025-12-13 03:33:33,828 INFO     Training average negative_sample_loss at step 184200: 0.110580
2025-12-13 03:33:33,828 INFO     Training average loss at step 184200: 0.390945
2025-12-13 03:33:36,017 INFO     Training average regularization at step 184300: 0.302063
2025-12-13 03:33:36,017 INFO     Training average positive_sample_loss at step 184300: 0.067689
2025-12-13 03:33:36,017 INFO     Training average negative_sample_loss at step 184300: 0.108130
2025-12-13 03:33:36,017 INFO     Training average loss at step 184300: 0.389973
2025-12-13 03:33:38,202 INFO     Training average regularization at step 184400: 0.302063
2025-12-13 03:33:38,202 INFO     Training average positive_sample_loss at step 184400: 0.067565
2025-12-13 03:33:38,202 INFO     Training average negative_sample_loss at step 184400: 0.111628
2025-12-13 03:33:38,202 INFO     Training average loss at step 184400: 0.391660
2025-12-13 03:33:40,394 INFO     Training average regularization at step 184500: 0.302063
2025-12-13 03:33:40,394 INFO     Training average positive_sample_loss at step 184500: 0.066832
2025-12-13 03:33:40,395 INFO     Training average negative_sample_loss at step 184500: 0.109275
2025-12-13 03:33:40,395 INFO     Training average loss at step 184500: 0.390117
2025-12-13 03:33:42,593 INFO     Training average regularization at step 184600: 0.302063
2025-12-13 03:33:42,593 INFO     Training average positive_sample_loss at step 184600: 0.067206
2025-12-13 03:33:42,593 INFO     Training average negative_sample_loss at step 184600: 0.109106
2025-12-13 03:33:42,593 INFO     Training average loss at step 184600: 0.390219
2025-12-13 03:33:44,814 INFO     Training average regularization at step 184700: 0.302063
2025-12-13 03:33:44,815 INFO     Training average positive_sample_loss at step 184700: 0.067604
2025-12-13 03:33:44,815 INFO     Training average negative_sample_loss at step 184700: 0.108044
2025-12-13 03:33:44,815 INFO     Training average loss at step 184700: 0.389887
2025-12-13 03:33:46,989 INFO     Training average regularization at step 184800: 0.302063
2025-12-13 03:33:46,989 INFO     Training average positive_sample_loss at step 184800: 0.066173
2025-12-13 03:33:46,989 INFO     Training average negative_sample_loss at step 184800: 0.110703
2025-12-13 03:33:46,990 INFO     Training average loss at step 184800: 0.390501
2025-12-13 03:33:49,139 INFO     Training average regularization at step 184900: 0.302063
2025-12-13 03:33:49,139 INFO     Training average positive_sample_loss at step 184900: 0.065322
2025-12-13 03:33:49,139 INFO     Training average negative_sample_loss at step 184900: 0.107028
2025-12-13 03:33:49,139 INFO     Training average loss at step 184900: 0.388238
2025-12-13 03:33:51,294 INFO     Training average regularization at step 185000: 0.302063
2025-12-13 03:33:51,295 INFO     Training average positive_sample_loss at step 185000: 0.066770
2025-12-13 03:33:51,295 INFO     Training average negative_sample_loss at step 185000: 0.112488
2025-12-13 03:33:51,295 INFO     Training average loss at step 185000: 0.391692
2025-12-13 03:33:53,458 INFO     Training average regularization at step 185100: 0.302063
2025-12-13 03:33:53,458 INFO     Training average positive_sample_loss at step 185100: 0.066016
2025-12-13 03:33:53,458 INFO     Training average negative_sample_loss at step 185100: 0.107872
2025-12-13 03:33:53,459 INFO     Training average loss at step 185100: 0.389007
2025-12-13 03:33:55,612 INFO     Training average regularization at step 185200: 0.302063
2025-12-13 03:33:55,612 INFO     Training average positive_sample_loss at step 185200: 0.067906
2025-12-13 03:33:55,612 INFO     Training average negative_sample_loss at step 185200: 0.108036
2025-12-13 03:33:55,612 INFO     Training average loss at step 185200: 0.390034
2025-12-13 03:33:57,767 INFO     Training average regularization at step 185300: 0.302063
2025-12-13 03:33:57,768 INFO     Training average positive_sample_loss at step 185300: 0.067084
2025-12-13 03:33:57,768 INFO     Training average negative_sample_loss at step 185300: 0.110832
2025-12-13 03:33:57,768 INFO     Training average loss at step 185300: 0.391021
2025-12-13 03:33:59,935 INFO     Training average regularization at step 185400: 0.302063
2025-12-13 03:33:59,935 INFO     Training average positive_sample_loss at step 185400: 0.066740
2025-12-13 03:33:59,935 INFO     Training average negative_sample_loss at step 185400: 0.111265
2025-12-13 03:33:59,935 INFO     Training average loss at step 185400: 0.391065
2025-12-13 03:34:02,087 INFO     Training average regularization at step 185500: 0.302063
2025-12-13 03:34:02,087 INFO     Training average positive_sample_loss at step 185500: 0.065791
2025-12-13 03:34:02,087 INFO     Training average negative_sample_loss at step 185500: 0.110399
2025-12-13 03:34:02,087 INFO     Training average loss at step 185500: 0.390158
2025-12-13 03:34:04,273 INFO     Training average regularization at step 185600: 0.302063
2025-12-13 03:34:04,274 INFO     Training average positive_sample_loss at step 185600: 0.065624
2025-12-13 03:34:04,274 INFO     Training average negative_sample_loss at step 185600: 0.108327
2025-12-13 03:34:04,274 INFO     Training average loss at step 185600: 0.389038
2025-12-13 03:34:06,460 INFO     Training average regularization at step 185700: 0.302062
2025-12-13 03:34:06,460 INFO     Training average positive_sample_loss at step 185700: 0.065285
2025-12-13 03:34:06,460 INFO     Training average negative_sample_loss at step 185700: 0.110329
2025-12-13 03:34:06,460 INFO     Training average loss at step 185700: 0.389870
2025-12-13 03:34:08,626 INFO     Training average regularization at step 185800: 0.302062
2025-12-13 03:34:08,628 INFO     Training average positive_sample_loss at step 185800: 0.066205
2025-12-13 03:34:08,628 INFO     Training average negative_sample_loss at step 185800: 0.108463
2025-12-13 03:34:08,628 INFO     Training average loss at step 185800: 0.389396
2025-12-13 03:34:10,830 INFO     Training average regularization at step 185900: 0.302062
2025-12-13 03:34:10,830 INFO     Training average positive_sample_loss at step 185900: 0.065815
2025-12-13 03:34:10,830 INFO     Training average negative_sample_loss at step 185900: 0.107150
2025-12-13 03:34:10,830 INFO     Training average loss at step 185900: 0.388544
2025-12-13 03:34:13,007 INFO     Training average regularization at step 186000: 0.302062
2025-12-13 03:34:13,007 INFO     Training average positive_sample_loss at step 186000: 0.066178
2025-12-13 03:34:13,007 INFO     Training average negative_sample_loss at step 186000: 0.107084
2025-12-13 03:34:13,008 INFO     Training average loss at step 186000: 0.388693
2025-12-13 03:34:15,187 INFO     Training average regularization at step 186100: 0.302062
2025-12-13 03:34:15,188 INFO     Training average positive_sample_loss at step 186100: 0.066892
2025-12-13 03:34:15,188 INFO     Training average negative_sample_loss at step 186100: 0.108632
2025-12-13 03:34:15,188 INFO     Training average loss at step 186100: 0.389824
2025-12-13 03:34:17,337 INFO     Training average regularization at step 186200: 0.302062
2025-12-13 03:34:17,337 INFO     Training average positive_sample_loss at step 186200: 0.066138
2025-12-13 03:34:17,337 INFO     Training average negative_sample_loss at step 186200: 0.108254
2025-12-13 03:34:17,337 INFO     Training average loss at step 186200: 0.389258
2025-12-13 03:34:19,489 INFO     Training average regularization at step 186300: 0.302062
2025-12-13 03:34:19,490 INFO     Training average positive_sample_loss at step 186300: 0.067468
2025-12-13 03:34:19,490 INFO     Training average negative_sample_loss at step 186300: 0.110418
2025-12-13 03:34:19,490 INFO     Training average loss at step 186300: 0.391005
2025-12-13 03:34:21,649 INFO     Training average regularization at step 186400: 0.302062
2025-12-13 03:34:21,649 INFO     Training average positive_sample_loss at step 186400: 0.067701
2025-12-13 03:34:21,649 INFO     Training average negative_sample_loss at step 186400: 0.110041
2025-12-13 03:34:21,649 INFO     Training average loss at step 186400: 0.390933
2025-12-13 03:34:23,806 INFO     Training average regularization at step 186500: 0.302062
2025-12-13 03:34:23,806 INFO     Training average positive_sample_loss at step 186500: 0.065626
2025-12-13 03:34:23,806 INFO     Training average negative_sample_loss at step 186500: 0.109857
2025-12-13 03:34:23,806 INFO     Training average loss at step 186500: 0.389804
2025-12-13 03:34:25,964 INFO     Training average regularization at step 186600: 0.302062
2025-12-13 03:34:25,964 INFO     Training average positive_sample_loss at step 186600: 0.067121
2025-12-13 03:34:25,964 INFO     Training average negative_sample_loss at step 186600: 0.109906
2025-12-13 03:34:25,964 INFO     Training average loss at step 186600: 0.390575
2025-12-13 03:34:28,151 INFO     Training average regularization at step 186700: 0.302062
2025-12-13 03:34:28,152 INFO     Training average positive_sample_loss at step 186700: 0.066091
2025-12-13 03:34:28,152 INFO     Training average negative_sample_loss at step 186700: 0.107866
2025-12-13 03:34:28,152 INFO     Training average loss at step 186700: 0.389040
2025-12-13 03:34:30,309 INFO     Training average regularization at step 186800: 0.302062
2025-12-13 03:34:30,309 INFO     Training average positive_sample_loss at step 186800: 0.066139
2025-12-13 03:34:30,309 INFO     Training average negative_sample_loss at step 186800: 0.106100
2025-12-13 03:34:30,309 INFO     Training average loss at step 186800: 0.388182
2025-12-13 03:34:32,462 INFO     Training average regularization at step 186900: 0.302062
2025-12-13 03:34:32,463 INFO     Training average positive_sample_loss at step 186900: 0.065782
2025-12-13 03:34:32,463 INFO     Training average negative_sample_loss at step 186900: 0.108387
2025-12-13 03:34:32,463 INFO     Training average loss at step 186900: 0.389146
2025-12-13 03:34:34,613 INFO     Training average regularization at step 187000: 0.302062
2025-12-13 03:34:34,613 INFO     Training average positive_sample_loss at step 187000: 0.067750
2025-12-13 03:34:34,613 INFO     Training average negative_sample_loss at step 187000: 0.110037
2025-12-13 03:34:34,613 INFO     Training average loss at step 187000: 0.390955
2025-12-13 03:34:36,784 INFO     Training average regularization at step 187100: 0.302062
2025-12-13 03:34:36,784 INFO     Training average positive_sample_loss at step 187100: 0.066992
2025-12-13 03:34:36,784 INFO     Training average negative_sample_loss at step 187100: 0.109434
2025-12-13 03:34:36,784 INFO     Training average loss at step 187100: 0.390275
2025-12-13 03:34:39,016 INFO     Training average regularization at step 187200: 0.302061
2025-12-13 03:34:39,016 INFO     Training average positive_sample_loss at step 187200: 0.066664
2025-12-13 03:34:39,016 INFO     Training average negative_sample_loss at step 187200: 0.111205
2025-12-13 03:34:39,016 INFO     Training average loss at step 187200: 0.390996
2025-12-13 03:34:41,195 INFO     Training average regularization at step 187300: 0.302061
2025-12-13 03:34:41,195 INFO     Training average positive_sample_loss at step 187300: 0.066081
2025-12-13 03:34:41,195 INFO     Training average negative_sample_loss at step 187300: 0.108749
2025-12-13 03:34:41,195 INFO     Training average loss at step 187300: 0.389477
2025-12-13 03:34:43,405 INFO     Training average regularization at step 187400: 0.302061
2025-12-13 03:34:43,405 INFO     Training average positive_sample_loss at step 187400: 0.067210
2025-12-13 03:34:43,405 INFO     Training average negative_sample_loss at step 187400: 0.108690
2025-12-13 03:34:43,405 INFO     Training average loss at step 187400: 0.390011
2025-12-13 03:34:45,601 INFO     Training average regularization at step 187500: 0.302061
2025-12-13 03:34:45,601 INFO     Training average positive_sample_loss at step 187500: 0.066866
2025-12-13 03:34:45,601 INFO     Training average negative_sample_loss at step 187500: 0.110402
2025-12-13 03:34:45,601 INFO     Training average loss at step 187500: 0.390695
2025-12-13 03:34:47,755 INFO     Training average regularization at step 187600: 0.302061
2025-12-13 03:34:47,755 INFO     Training average positive_sample_loss at step 187600: 0.067460
2025-12-13 03:34:47,755 INFO     Training average negative_sample_loss at step 187600: 0.109766
2025-12-13 03:34:47,755 INFO     Training average loss at step 187600: 0.390674
2025-12-13 03:34:49,935 INFO     Training average regularization at step 187700: 0.302061
2025-12-13 03:34:49,935 INFO     Training average positive_sample_loss at step 187700: 0.066818
2025-12-13 03:34:49,935 INFO     Training average negative_sample_loss at step 187700: 0.108286
2025-12-13 03:34:49,935 INFO     Training average loss at step 187700: 0.389613
2025-12-13 03:34:52,088 INFO     Training average regularization at step 187800: 0.302061
2025-12-13 03:34:52,088 INFO     Training average positive_sample_loss at step 187800: 0.066999
2025-12-13 03:34:52,088 INFO     Training average negative_sample_loss at step 187800: 0.107740
2025-12-13 03:34:52,088 INFO     Training average loss at step 187800: 0.389430
2025-12-13 03:34:54,249 INFO     Training average regularization at step 187900: 0.302061
2025-12-13 03:34:54,249 INFO     Training average positive_sample_loss at step 187900: 0.066457
2025-12-13 03:34:54,249 INFO     Training average negative_sample_loss at step 187900: 0.109468
2025-12-13 03:34:54,249 INFO     Training average loss at step 187900: 0.390023
2025-12-13 03:34:56,385 INFO     Training average regularization at step 188000: 0.302061
2025-12-13 03:34:56,385 INFO     Training average positive_sample_loss at step 188000: 0.065882
2025-12-13 03:34:56,385 INFO     Training average negative_sample_loss at step 188000: 0.110371
2025-12-13 03:34:56,385 INFO     Training average loss at step 188000: 0.390188
2025-12-13 03:34:58,518 INFO     Training average regularization at step 188100: 0.302061
2025-12-13 03:34:58,518 INFO     Training average positive_sample_loss at step 188100: 0.064915
2025-12-13 03:34:58,519 INFO     Training average negative_sample_loss at step 188100: 0.109045
2025-12-13 03:34:58,519 INFO     Training average loss at step 188100: 0.389041
2025-12-13 03:35:00,708 INFO     Training average regularization at step 188200: 0.302061
2025-12-13 03:35:00,708 INFO     Training average positive_sample_loss at step 188200: 0.067834
2025-12-13 03:35:00,708 INFO     Training average negative_sample_loss at step 188200: 0.107763
2025-12-13 03:35:00,708 INFO     Training average loss at step 188200: 0.389859
2025-12-13 03:35:02,867 INFO     Training average regularization at step 188300: 0.302061
2025-12-13 03:35:02,867 INFO     Training average positive_sample_loss at step 188300: 0.066760
2025-12-13 03:35:02,867 INFO     Training average negative_sample_loss at step 188300: 0.109009
2025-12-13 03:35:02,867 INFO     Training average loss at step 188300: 0.389945
2025-12-13 03:35:05,028 INFO     Training average regularization at step 188400: 0.302061
2025-12-13 03:35:05,028 INFO     Training average positive_sample_loss at step 188400: 0.067158
2025-12-13 03:35:05,028 INFO     Training average negative_sample_loss at step 188400: 0.108494
2025-12-13 03:35:05,028 INFO     Training average loss at step 188400: 0.389886
2025-12-13 03:35:08,160 INFO     Training average regularization at step 188500: 0.302061
2025-12-13 03:35:08,161 INFO     Training average positive_sample_loss at step 188500: 0.066418
2025-12-13 03:35:08,161 INFO     Training average negative_sample_loss at step 188500: 0.108371
2025-12-13 03:35:08,161 INFO     Training average loss at step 188500: 0.389456
2025-12-13 03:35:10,309 INFO     Training average regularization at step 188600: 0.302061
2025-12-13 03:35:10,309 INFO     Training average positive_sample_loss at step 188600: 0.066389
2025-12-13 03:35:10,309 INFO     Training average negative_sample_loss at step 188600: 0.110721
2025-12-13 03:35:10,309 INFO     Training average loss at step 188600: 0.390615
2025-12-13 03:35:12,468 INFO     Training average regularization at step 188700: 0.302061
2025-12-13 03:35:12,468 INFO     Training average positive_sample_loss at step 188700: 0.066726
2025-12-13 03:35:12,468 INFO     Training average negative_sample_loss at step 188700: 0.110090
2025-12-13 03:35:12,468 INFO     Training average loss at step 188700: 0.390469
2025-12-13 03:35:14,622 INFO     Training average regularization at step 188800: 0.302060
2025-12-13 03:35:14,622 INFO     Training average positive_sample_loss at step 188800: 0.067156
2025-12-13 03:35:14,622 INFO     Training average negative_sample_loss at step 188800: 0.104814
2025-12-13 03:35:14,622 INFO     Training average loss at step 188800: 0.388046
2025-12-13 03:35:16,774 INFO     Training average regularization at step 188900: 0.302060
2025-12-13 03:35:16,775 INFO     Training average positive_sample_loss at step 188900: 0.067250
2025-12-13 03:35:16,775 INFO     Training average negative_sample_loss at step 188900: 0.106571
2025-12-13 03:35:16,775 INFO     Training average loss at step 188900: 0.388971
2025-12-13 03:35:18,937 INFO     Training average regularization at step 189000: 0.302060
2025-12-13 03:35:18,937 INFO     Training average positive_sample_loss at step 189000: 0.065656
2025-12-13 03:35:18,937 INFO     Training average negative_sample_loss at step 189000: 0.108521
2025-12-13 03:35:18,937 INFO     Training average loss at step 189000: 0.389149
2025-12-13 03:35:21,085 INFO     Training average regularization at step 189100: 0.302060
2025-12-13 03:35:21,086 INFO     Training average positive_sample_loss at step 189100: 0.067101
2025-12-13 03:35:21,086 INFO     Training average negative_sample_loss at step 189100: 0.108337
2025-12-13 03:35:21,086 INFO     Training average loss at step 189100: 0.389779
2025-12-13 03:35:23,239 INFO     Training average regularization at step 189200: 0.302060
2025-12-13 03:35:23,239 INFO     Training average positive_sample_loss at step 189200: 0.066950
2025-12-13 03:35:23,239 INFO     Training average negative_sample_loss at step 189200: 0.108231
2025-12-13 03:35:23,239 INFO     Training average loss at step 189200: 0.389651
2025-12-13 03:35:25,398 INFO     Training average regularization at step 189300: 0.302060
2025-12-13 03:35:25,398 INFO     Training average positive_sample_loss at step 189300: 0.067462
2025-12-13 03:35:25,398 INFO     Training average negative_sample_loss at step 189300: 0.108431
2025-12-13 03:35:25,398 INFO     Training average loss at step 189300: 0.390007
2025-12-13 03:35:27,549 INFO     Training average regularization at step 189400: 0.302060
2025-12-13 03:35:27,549 INFO     Training average positive_sample_loss at step 189400: 0.066454
2025-12-13 03:35:27,549 INFO     Training average negative_sample_loss at step 189400: 0.107266
2025-12-13 03:35:27,549 INFO     Training average loss at step 189400: 0.388920
2025-12-13 03:35:29,694 INFO     Training average regularization at step 189500: 0.302060
2025-12-13 03:35:29,694 INFO     Training average positive_sample_loss at step 189500: 0.066356
2025-12-13 03:35:29,694 INFO     Training average negative_sample_loss at step 189500: 0.110146
2025-12-13 03:35:29,694 INFO     Training average loss at step 189500: 0.390311
2025-12-13 03:35:31,842 INFO     Training average regularization at step 189600: 0.302060
2025-12-13 03:35:31,842 INFO     Training average positive_sample_loss at step 189600: 0.067340
2025-12-13 03:35:31,842 INFO     Training average negative_sample_loss at step 189600: 0.110489
2025-12-13 03:35:31,842 INFO     Training average loss at step 189600: 0.390974
2025-12-13 03:35:34,008 INFO     Training average regularization at step 189700: 0.302060
2025-12-13 03:35:34,008 INFO     Training average positive_sample_loss at step 189700: 0.065579
2025-12-13 03:35:34,008 INFO     Training average negative_sample_loss at step 189700: 0.110021
2025-12-13 03:35:34,008 INFO     Training average loss at step 189700: 0.389860
2025-12-13 03:35:36,170 INFO     Training average regularization at step 189800: 0.302060
2025-12-13 03:35:36,170 INFO     Training average positive_sample_loss at step 189800: 0.067304
2025-12-13 03:35:36,170 INFO     Training average negative_sample_loss at step 189800: 0.109808
2025-12-13 03:35:36,170 INFO     Training average loss at step 189800: 0.390616
2025-12-13 03:35:38,387 INFO     Training average regularization at step 189900: 0.302060
2025-12-13 03:35:38,388 INFO     Training average positive_sample_loss at step 189900: 0.066323
2025-12-13 03:35:38,388 INFO     Training average negative_sample_loss at step 189900: 0.108001
2025-12-13 03:35:38,388 INFO     Training average loss at step 189900: 0.389222
2025-12-13 03:35:40,616 INFO     Training average regularization at step 190000: 0.302060
2025-12-13 03:35:40,616 INFO     Training average positive_sample_loss at step 190000: 0.065868
2025-12-13 03:35:40,616 INFO     Training average negative_sample_loss at step 190000: 0.108158
2025-12-13 03:35:40,616 INFO     Training average loss at step 190000: 0.389073
2025-12-13 03:35:40,616 INFO     Evaluating on Valid Dataset...
2025-12-13 03:35:41,358 INFO     Evaluating the model... (0/50000)
2025-12-13 03:35:43,924 INFO     Evaluating the model... (500/50000)
2025-12-13 03:35:46,758 INFO     Evaluating the model... (1000/50000)
2025-12-13 03:35:50,339 INFO     Evaluating the model... (1500/50000)
2025-12-13 03:35:52,817 INFO     Evaluating the model... (2000/50000)
2025-12-13 03:35:55,246 INFO     Evaluating the model... (2500/50000)
2025-12-13 03:35:57,844 INFO     Evaluating the model... (3000/50000)
2025-12-13 03:36:00,231 INFO     Evaluating the model... (3500/50000)
2025-12-13 03:36:03,261 INFO     Evaluating the model... (4000/50000)
2025-12-13 03:36:05,628 INFO     Evaluating the model... (4500/50000)
2025-12-13 03:36:08,208 INFO     Evaluating the model... (5000/50000)
2025-12-13 03:36:10,627 INFO     Evaluating the model... (5500/50000)
2025-12-13 03:36:13,036 INFO     Evaluating the model... (6000/50000)
2025-12-13 03:36:16,021 INFO     Evaluating the model... (6500/50000)
2025-12-13 03:36:18,372 INFO     Evaluating the model... (7000/50000)
2025-12-13 03:36:21,090 INFO     Evaluating the model... (7500/50000)
2025-12-13 03:36:23,536 INFO     Evaluating the model... (8000/50000)
2025-12-13 03:36:25,976 INFO     Evaluating the model... (8500/50000)
2025-12-13 03:36:28,703 INFO     Evaluating the model... (9000/50000)
2025-12-13 03:36:31,373 INFO     Evaluating the model... (9500/50000)
2025-12-13 03:36:33,743 INFO     Evaluating the model... (10000/50000)
2025-12-13 03:36:36,301 INFO     Evaluating the model... (10500/50000)
2025-12-13 03:36:39,317 INFO     Evaluating the model... (11000/50000)
2025-12-13 03:36:42,006 INFO     Evaluating the model... (11500/50000)
2025-12-13 03:36:44,641 INFO     Evaluating the model... (12000/50000)
2025-12-13 03:36:47,159 INFO     Evaluating the model... (12500/50000)
2025-12-13 03:36:49,611 INFO     Evaluating the model... (13000/50000)
2025-12-13 03:36:52,641 INFO     Evaluating the model... (13500/50000)
2025-12-13 03:36:55,290 INFO     Evaluating the model... (14000/50000)
2025-12-13 03:36:57,709 INFO     Evaluating the model... (14500/50000)
2025-12-13 03:37:00,095 INFO     Evaluating the model... (15000/50000)
2025-12-13 03:37:02,581 INFO     Evaluating the model... (15500/50000)
2025-12-13 03:37:06,154 INFO     Evaluating the model... (16000/50000)
2025-12-13 03:37:08,617 INFO     Evaluating the model... (16500/50000)
2025-12-13 03:37:11,087 INFO     Evaluating the model... (17000/50000)
2025-12-13 03:37:13,463 INFO     Evaluating the model... (17500/50000)
2025-12-13 03:37:16,063 INFO     Evaluating the model... (18000/50000)
2025-12-13 03:37:19,732 INFO     Evaluating the model... (18500/50000)
2025-12-13 03:37:22,147 INFO     Evaluating the model... (19000/50000)
2025-12-13 03:37:24,556 INFO     Evaluating the model... (19500/50000)
2025-12-13 03:37:27,049 INFO     Evaluating the model... (20000/50000)
2025-12-13 03:37:29,552 INFO     Evaluating the model... (20500/50000)
2025-12-13 03:37:33,146 INFO     Evaluating the model... (21000/50000)
2025-12-13 03:37:35,635 INFO     Evaluating the model... (21500/50000)
2025-12-13 03:37:38,262 INFO     Evaluating the model... (22000/50000)
2025-12-13 03:37:41,147 INFO     Evaluating the model... (22500/50000)
2025-12-13 03:37:43,681 INFO     Evaluating the model... (23000/50000)
2025-12-13 03:37:47,084 INFO     Evaluating the model... (23500/50000)
2025-12-13 03:37:49,466 INFO     Evaluating the model... (24000/50000)
2025-12-13 03:37:51,999 INFO     Evaluating the model... (24500/50000)
2025-12-13 03:37:54,770 INFO     Evaluating the model... (25000/50000)
2025-12-13 03:37:57,373 INFO     Evaluating the model... (25500/50000)
2025-12-13 03:38:01,071 INFO     Evaluating the model... (26000/50000)
2025-12-13 03:38:03,683 INFO     Evaluating the model... (26500/50000)
2025-12-13 03:38:06,376 INFO     Evaluating the model... (27000/50000)
2025-12-13 03:38:08,905 INFO     Evaluating the model... (27500/50000)
2025-12-13 03:38:11,417 INFO     Evaluating the model... (28000/50000)
2025-12-13 03:38:14,880 INFO     Evaluating the model... (28500/50000)
2025-12-13 03:38:17,366 INFO     Evaluating the model... (29000/50000)
2025-12-13 03:38:19,830 INFO     Evaluating the model... (29500/50000)
2025-12-13 03:38:22,359 INFO     Evaluating the model... (30000/50000)
2025-12-13 03:38:25,025 INFO     Evaluating the model... (30500/50000)
2025-12-13 03:38:28,503 INFO     Evaluating the model... (31000/50000)
2025-12-13 03:38:30,930 INFO     Evaluating the model... (31500/50000)
2025-12-13 03:38:33,357 INFO     Evaluating the model... (32000/50000)
2025-12-13 03:38:36,135 INFO     Evaluating the model... (32500/50000)
2025-12-13 03:38:39,023 INFO     Evaluating the model... (33000/50000)
2025-12-13 03:38:42,579 INFO     Evaluating the model... (33500/50000)
2025-12-13 03:38:45,223 INFO     Evaluating the model... (34000/50000)
2025-12-13 03:38:47,903 INFO     Evaluating the model... (34500/50000)
2025-12-13 03:38:50,475 INFO     Evaluating the model... (35000/50000)
2025-12-13 03:38:52,947 INFO     Evaluating the model... (35500/50000)
2025-12-13 03:38:56,212 INFO     Evaluating the model... (36000/50000)
2025-12-13 03:38:58,729 INFO     Evaluating the model... (36500/50000)
2025-12-13 03:39:01,316 INFO     Evaluating the model... (37000/50000)
2025-12-13 03:39:03,928 INFO     Evaluating the model... (37500/50000)
2025-12-13 03:39:07,006 INFO     Evaluating the model... (38000/50000)
2025-12-13 03:39:09,534 INFO     Evaluating the model... (38500/50000)
2025-12-13 03:39:12,168 INFO     Evaluating the model... (39000/50000)
2025-12-13 03:39:14,664 INFO     Evaluating the model... (39500/50000)
2025-12-13 03:39:17,240 INFO     Evaluating the model... (40000/50000)
2025-12-13 03:39:20,578 INFO     Evaluating the model... (40500/50000)
2025-12-13 03:39:23,165 INFO     Evaluating the model... (41000/50000)
2025-12-13 03:39:25,719 INFO     Evaluating the model... (41500/50000)
2025-12-13 03:39:28,315 INFO     Evaluating the model... (42000/50000)
2025-12-13 03:39:30,819 INFO     Evaluating the model... (42500/50000)
2025-12-13 03:39:34,503 INFO     Evaluating the model... (43000/50000)
2025-12-13 03:39:37,238 INFO     Evaluating the model... (43500/50000)
2025-12-13 03:39:39,904 INFO     Evaluating the model... (44000/50000)
2025-12-13 03:39:42,498 INFO     Evaluating the model... (44500/50000)
2025-12-13 03:39:45,213 INFO     Evaluating the model... (45000/50000)
2025-12-13 03:39:48,585 INFO     Evaluating the model... (45500/50000)
2025-12-13 03:39:51,004 INFO     Evaluating the model... (46000/50000)
2025-12-13 03:39:53,536 INFO     Evaluating the model... (46500/50000)
2025-12-13 03:39:56,171 INFO     Evaluating the model... (47000/50000)
2025-12-13 03:39:58,876 INFO     Evaluating the model... (47500/50000)
2025-12-13 03:40:02,404 INFO     Evaluating the model... (48000/50000)
2025-12-13 03:40:04,896 INFO     Evaluating the model... (48500/50000)
2025-12-13 03:40:07,400 INFO     Evaluating the model... (49000/50000)
2025-12-13 03:40:10,180 INFO     Evaluating the model... (49500/50000)
2025-12-13 03:40:12,919 INFO     Valid MRR at step 190000: 0.633113
2025-12-13 03:40:12,919 INFO     Valid MR at step 190000: 266.826420
2025-12-13 03:40:12,919 INFO     Valid HITS@1 at step 190000: 0.547440
2025-12-13 03:40:12,919 INFO     Valid HITS@3 at step 190000: 0.685990
2025-12-13 03:40:12,919 INFO     Valid HITS@10 at step 190000: 0.784660
2025-12-13 03:40:14,260 INFO     Evaluating on Test Dataset...
2025-12-13 03:40:14,820 INFO     Evaluating the model... (0/59072)
2025-12-13 03:40:18,451 INFO     Evaluating the model... (500/59072)
2025-12-13 03:40:21,197 INFO     Evaluating the model... (1000/59072)
2025-12-13 03:40:23,922 INFO     Evaluating the model... (1500/59072)
2025-12-13 03:40:26,443 INFO     Evaluating the model... (2000/59072)
2025-12-13 03:40:28,908 INFO     Evaluating the model... (2500/59072)
2025-12-13 03:40:32,313 INFO     Evaluating the model... (3000/59072)
2025-12-13 03:40:34,715 INFO     Evaluating the model... (3500/59072)
2025-12-13 03:40:37,378 INFO     Evaluating the model... (4000/59072)
2025-12-13 03:40:40,065 INFO     Evaluating the model... (4500/59072)
2025-12-13 03:40:42,896 INFO     Evaluating the model... (5000/59072)
2025-12-13 03:40:46,112 INFO     Evaluating the model... (5500/59072)
2025-12-13 03:40:48,522 INFO     Evaluating the model... (6000/59072)
2025-12-13 03:40:50,963 INFO     Evaluating the model... (6500/59072)
2025-12-13 03:40:53,433 INFO     Evaluating the model... (7000/59072)
2025-12-13 03:40:56,203 INFO     Evaluating the model... (7500/59072)
2025-12-13 03:40:59,065 INFO     Evaluating the model... (8000/59072)
2025-12-13 03:41:01,500 INFO     Evaluating the model... (8500/59072)
2025-12-13 03:41:03,942 INFO     Evaluating the model... (9000/59072)
2025-12-13 03:41:06,653 INFO     Evaluating the model... (9500/59072)
2025-12-13 03:41:09,050 INFO     Evaluating the model... (10000/59072)
2025-12-13 03:41:11,946 INFO     Evaluating the model... (10500/59072)
2025-12-13 03:41:14,323 INFO     Evaluating the model... (11000/59072)
2025-12-13 03:41:16,826 INFO     Evaluating the model... (11500/59072)
2025-12-13 03:41:19,464 INFO     Evaluating the model... (12000/59072)
2025-12-13 03:41:21,869 INFO     Evaluating the model... (12500/59072)
2025-12-13 03:41:25,101 INFO     Evaluating the model... (13000/59072)
2025-12-13 03:41:27,476 INFO     Evaluating the model... (13500/59072)
2025-12-13 03:41:30,154 INFO     Evaluating the model... (14000/59072)
2025-12-13 03:41:32,609 INFO     Evaluating the model... (14500/59072)
2025-12-13 03:41:35,945 INFO     Evaluating the model... (15000/59072)
2025-12-13 03:41:38,632 INFO     Evaluating the model... (15500/59072)
2025-12-13 03:41:41,636 INFO     Evaluating the model... (16000/59072)
2025-12-13 03:41:44,274 INFO     Evaluating the model... (16500/59072)
2025-12-13 03:41:46,839 INFO     Evaluating the model... (17000/59072)
2025-12-13 03:41:50,112 INFO     Evaluating the model... (17500/59072)
2025-12-13 03:41:52,763 INFO     Evaluating the model... (18000/59072)
2025-12-13 03:41:55,286 INFO     Evaluating the model... (18500/59072)
2025-12-13 03:41:57,697 INFO     Evaluating the model... (19000/59072)
2025-12-13 03:42:00,139 INFO     Evaluating the model... (19500/59072)
2025-12-13 03:42:03,629 INFO     Evaluating the model... (20000/59072)
2025-12-13 03:42:06,099 INFO     Evaluating the model... (20500/59072)
2025-12-13 03:42:08,489 INFO     Evaluating the model... (21000/59072)
2025-12-13 03:42:10,918 INFO     Evaluating the model... (21500/59072)
2025-12-13 03:42:13,385 INFO     Evaluating the model... (22000/59072)
2025-12-13 03:42:16,687 INFO     Evaluating the model... (22500/59072)
2025-12-13 03:42:19,208 INFO     Evaluating the model... (23000/59072)
2025-12-13 03:42:21,627 INFO     Evaluating the model... (23500/59072)
2025-12-13 03:42:24,048 INFO     Evaluating the model... (24000/59072)
2025-12-13 03:42:26,781 INFO     Evaluating the model... (24500/59072)
2025-12-13 03:42:30,652 INFO     Evaluating the model... (25000/59072)
2025-12-13 03:42:33,352 INFO     Evaluating the model... (25500/59072)
2025-12-13 03:42:35,982 INFO     Evaluating the model... (26000/59072)
2025-12-13 03:42:38,862 INFO     Evaluating the model... (26500/59072)
2025-12-13 03:42:41,501 INFO     Evaluating the model... (27000/59072)
2025-12-13 03:42:45,344 INFO     Evaluating the model... (27500/59072)
2025-12-13 03:42:47,773 INFO     Evaluating the model... (28000/59072)
2025-12-13 03:42:50,425 INFO     Evaluating the model... (28500/59072)
2025-12-13 03:42:52,918 INFO     Evaluating the model... (29000/59072)
2025-12-13 03:42:55,362 INFO     Evaluating the model... (29500/59072)
2025-12-13 03:42:58,295 INFO     Evaluating the model... (30000/59072)
2025-12-13 03:43:01,164 INFO     Evaluating the model... (30500/59072)
2025-12-13 03:43:03,735 INFO     Evaluating the model... (31000/59072)
2025-12-13 03:43:06,416 INFO     Evaluating the model... (31500/59072)
2025-12-13 03:43:09,689 INFO     Evaluating the model... (32000/59072)
2025-12-13 03:43:12,324 INFO     Evaluating the model... (32500/59072)
2025-12-13 03:43:15,000 INFO     Evaluating the model... (33000/59072)
2025-12-13 03:43:17,613 INFO     Evaluating the model... (33500/59072)
2025-12-13 03:43:20,087 INFO     Evaluating the model... (34000/59072)
2025-12-13 03:43:23,514 INFO     Evaluating the model... (34500/59072)
2025-12-13 03:43:26,256 INFO     Evaluating the model... (35000/59072)
2025-12-13 03:43:28,804 INFO     Evaluating the model... (35500/59072)
2025-12-13 03:43:31,430 INFO     Evaluating the model... (36000/59072)
2025-12-13 03:43:33,889 INFO     Evaluating the model... (36500/59072)
2025-12-13 03:43:37,605 INFO     Evaluating the model... (37000/59072)
2025-12-13 03:43:40,177 INFO     Evaluating the model... (37500/59072)
2025-12-13 03:43:42,735 INFO     Evaluating the model... (38000/59072)
2025-12-13 03:43:45,282 INFO     Evaluating the model... (38500/59072)
2025-12-13 03:43:47,972 INFO     Evaluating the model... (39000/59072)
2025-12-13 03:43:51,004 INFO     Evaluating the model... (39500/59072)
2025-12-13 03:43:53,389 INFO     Evaluating the model... (40000/59072)
2025-12-13 03:43:56,007 INFO     Evaluating the model... (40500/59072)
2025-12-13 03:43:58,669 INFO     Evaluating the model... (41000/59072)
2025-12-13 03:44:01,306 INFO     Evaluating the model... (41500/59072)
2025-12-13 03:44:04,226 INFO     Evaluating the model... (42000/59072)
2025-12-13 03:44:06,712 INFO     Evaluating the model... (42500/59072)
2025-12-13 03:44:09,109 INFO     Evaluating the model... (43000/59072)
2025-12-13 03:44:11,921 INFO     Evaluating the model... (43500/59072)
2025-12-13 03:44:14,427 INFO     Evaluating the model... (44000/59072)
2025-12-13 03:44:17,628 INFO     Evaluating the model... (44500/59072)
2025-12-13 03:44:20,206 INFO     Evaluating the model... (45000/59072)
2025-12-13 03:44:22,935 INFO     Evaluating the model... (45500/59072)
2025-12-13 03:44:25,490 INFO     Evaluating the model... (46000/59072)
2025-12-13 03:44:27,886 INFO     Evaluating the model... (46500/59072)
2025-12-13 03:44:31,428 INFO     Evaluating the model... (47000/59072)
2025-12-13 03:44:34,030 INFO     Evaluating the model... (47500/59072)
2025-12-13 03:44:36,646 INFO     Evaluating the model... (48000/59072)
2025-12-13 03:44:39,384 INFO     Evaluating the model... (48500/59072)
2025-12-13 03:44:43,090 INFO     Evaluating the model... (49000/59072)
2025-12-13 03:44:45,896 INFO     Evaluating the model... (49500/59072)
2025-12-13 03:44:48,376 INFO     Evaluating the model... (50000/59072)
2025-12-13 03:44:50,819 INFO     Evaluating the model... (50500/59072)
2025-12-13 03:44:53,154 INFO     Evaluating the model... (51000/59072)
2025-12-13 03:44:56,927 INFO     Evaluating the model... (51500/59072)
2025-12-13 03:44:59,424 INFO     Evaluating the model... (52000/59072)
2025-12-13 03:45:02,075 INFO     Evaluating the model... (52500/59072)
2025-12-13 03:45:04,565 INFO     Evaluating the model... (53000/59072)
2025-12-13 03:45:07,180 INFO     Evaluating the model... (53500/59072)
2025-12-13 03:45:11,188 INFO     Evaluating the model... (54000/59072)
2025-12-13 03:45:13,648 INFO     Evaluating the model... (54500/59072)
2025-12-13 03:45:16,103 INFO     Evaluating the model... (55000/59072)
2025-12-13 03:45:18,683 INFO     Evaluating the model... (55500/59072)
2025-12-13 03:45:21,456 INFO     Evaluating the model... (56000/59072)
2025-12-13 03:45:25,489 INFO     Evaluating the model... (56500/59072)
2025-12-13 03:45:27,898 INFO     Evaluating the model... (57000/59072)
2025-12-13 03:45:30,377 INFO     Evaluating the model... (57500/59072)
2025-12-13 03:45:33,043 INFO     Evaluating the model... (58000/59072)
2025-12-13 03:45:35,632 INFO     Evaluating the model... (58500/59072)
2025-12-13 03:45:39,771 INFO     Evaluating the model... (59000/59072)
2025-12-13 03:45:40,429 INFO     Test MRR at step 190000: 0.629977
2025-12-13 03:45:40,430 INFO     Test MR at step 190000: 268.803711
2025-12-13 03:45:40,430 INFO     Test HITS@1 at step 190000: 0.542881
2025-12-13 03:45:40,430 INFO     Test HITS@3 at step 190000: 0.684363
2025-12-13 03:45:40,430 INFO     Test HITS@10 at step 190000: 0.782981
2025-12-13 03:45:42,650 INFO     Training average regularization at step 190100: 0.302059
2025-12-13 03:45:42,650 INFO     Training average positive_sample_loss at step 190100: 0.067207
2025-12-13 03:45:42,650 INFO     Training average negative_sample_loss at step 190100: 0.109555
2025-12-13 03:45:42,650 INFO     Training average loss at step 190100: 0.390441
2025-12-13 03:45:44,883 INFO     Training average regularization at step 190200: 0.302059
2025-12-13 03:45:44,884 INFO     Training average positive_sample_loss at step 190200: 0.066814
2025-12-13 03:45:44,884 INFO     Training average negative_sample_loss at step 190200: 0.109299
2025-12-13 03:45:44,884 INFO     Training average loss at step 190200: 0.390116
2025-12-13 03:45:47,061 INFO     Training average regularization at step 190300: 0.302059
2025-12-13 03:45:47,062 INFO     Training average positive_sample_loss at step 190300: 0.064512
2025-12-13 03:45:47,062 INFO     Training average negative_sample_loss at step 190300: 0.106870
2025-12-13 03:45:47,062 INFO     Training average loss at step 190300: 0.387750
2025-12-13 03:45:49,207 INFO     Training average regularization at step 190400: 0.302059
2025-12-13 03:45:49,208 INFO     Training average positive_sample_loss at step 190400: 0.066979
2025-12-13 03:45:49,208 INFO     Training average negative_sample_loss at step 190400: 0.108795
2025-12-13 03:45:49,208 INFO     Training average loss at step 190400: 0.389946
2025-12-13 03:45:51,385 INFO     Training average regularization at step 190500: 0.302059
2025-12-13 03:45:51,386 INFO     Training average positive_sample_loss at step 190500: 0.067270
2025-12-13 03:45:51,386 INFO     Training average negative_sample_loss at step 190500: 0.108550
2025-12-13 03:45:51,386 INFO     Training average loss at step 190500: 0.389969
2025-12-13 03:45:53,567 INFO     Training average regularization at step 190600: 0.302059
2025-12-13 03:45:53,567 INFO     Training average positive_sample_loss at step 190600: 0.066752
2025-12-13 03:45:53,567 INFO     Training average negative_sample_loss at step 190600: 0.109417
2025-12-13 03:45:53,567 INFO     Training average loss at step 190600: 0.390144
2025-12-13 03:45:55,705 INFO     Training average regularization at step 190700: 0.302059
2025-12-13 03:45:55,705 INFO     Training average positive_sample_loss at step 190700: 0.067784
2025-12-13 03:45:55,705 INFO     Training average negative_sample_loss at step 190700: 0.109717
2025-12-13 03:45:55,705 INFO     Training average loss at step 190700: 0.390809
2025-12-13 03:45:57,885 INFO     Training average regularization at step 190800: 0.302059
2025-12-13 03:45:57,885 INFO     Training average positive_sample_loss at step 190800: 0.067654
2025-12-13 03:45:57,885 INFO     Training average negative_sample_loss at step 190800: 0.109016
2025-12-13 03:45:57,885 INFO     Training average loss at step 190800: 0.390394
2025-12-13 03:46:00,058 INFO     Training average regularization at step 190900: 0.302059
2025-12-13 03:46:00,058 INFO     Training average positive_sample_loss at step 190900: 0.067449
2025-12-13 03:46:00,058 INFO     Training average negative_sample_loss at step 190900: 0.112864
2025-12-13 03:46:00,058 INFO     Training average loss at step 190900: 0.392215
2025-12-13 03:46:02,206 INFO     Training average regularization at step 191000: 0.302059
2025-12-13 03:46:02,206 INFO     Training average positive_sample_loss at step 191000: 0.066782
2025-12-13 03:46:02,207 INFO     Training average negative_sample_loss at step 191000: 0.107767
2025-12-13 03:46:02,207 INFO     Training average loss at step 191000: 0.389333
2025-12-13 03:46:04,361 INFO     Training average regularization at step 191100: 0.302059
2025-12-13 03:46:04,362 INFO     Training average positive_sample_loss at step 191100: 0.068709
2025-12-13 03:46:04,362 INFO     Training average negative_sample_loss at step 191100: 0.112439
2025-12-13 03:46:04,362 INFO     Training average loss at step 191100: 0.392633
2025-12-13 03:46:06,533 INFO     Training average regularization at step 191200: 0.302059
2025-12-13 03:46:06,533 INFO     Training average positive_sample_loss at step 191200: 0.066404
2025-12-13 03:46:06,533 INFO     Training average negative_sample_loss at step 191200: 0.108999
2025-12-13 03:46:06,533 INFO     Training average loss at step 191200: 0.389760
2025-12-13 03:46:08,690 INFO     Training average regularization at step 191300: 0.302059
2025-12-13 03:46:08,691 INFO     Training average positive_sample_loss at step 191300: 0.065177
2025-12-13 03:46:08,691 INFO     Training average negative_sample_loss at step 191300: 0.108415
2025-12-13 03:46:08,691 INFO     Training average loss at step 191300: 0.388855
2025-12-13 03:46:10,837 INFO     Training average regularization at step 191400: 0.302059
2025-12-13 03:46:10,838 INFO     Training average positive_sample_loss at step 191400: 0.067407
2025-12-13 03:46:10,838 INFO     Training average negative_sample_loss at step 191400: 0.111415
2025-12-13 03:46:10,838 INFO     Training average loss at step 191400: 0.391469
2025-12-13 03:46:12,982 INFO     Training average regularization at step 191500: 0.302059
2025-12-13 03:46:12,982 INFO     Training average positive_sample_loss at step 191500: 0.065635
2025-12-13 03:46:12,982 INFO     Training average negative_sample_loss at step 191500: 0.108786
2025-12-13 03:46:12,982 INFO     Training average loss at step 191500: 0.389269
2025-12-13 03:46:15,125 INFO     Training average regularization at step 191600: 0.302058
2025-12-13 03:46:15,126 INFO     Training average positive_sample_loss at step 191600: 0.066194
2025-12-13 03:46:15,126 INFO     Training average negative_sample_loss at step 191600: 0.111715
2025-12-13 03:46:15,126 INFO     Training average loss at step 191600: 0.391013
2025-12-13 03:46:17,278 INFO     Training average regularization at step 191700: 0.302058
2025-12-13 03:46:17,278 INFO     Training average positive_sample_loss at step 191700: 0.067321
2025-12-13 03:46:17,278 INFO     Training average negative_sample_loss at step 191700: 0.110824
2025-12-13 03:46:17,278 INFO     Training average loss at step 191700: 0.391131
2025-12-13 03:46:19,413 INFO     Training average regularization at step 191800: 0.302058
2025-12-13 03:46:19,413 INFO     Training average positive_sample_loss at step 191800: 0.066682
2025-12-13 03:46:19,413 INFO     Training average negative_sample_loss at step 191800: 0.107859
2025-12-13 03:46:19,413 INFO     Training average loss at step 191800: 0.389329
2025-12-13 03:46:21,548 INFO     Training average regularization at step 191900: 0.302058
2025-12-13 03:46:21,548 INFO     Training average positive_sample_loss at step 191900: 0.067603
2025-12-13 03:46:21,548 INFO     Training average negative_sample_loss at step 191900: 0.109135
2025-12-13 03:46:21,548 INFO     Training average loss at step 191900: 0.390428
2025-12-13 03:46:23,672 INFO     Training average regularization at step 192000: 0.302058
2025-12-13 03:46:23,672 INFO     Training average positive_sample_loss at step 192000: 0.066750
2025-12-13 03:46:23,672 INFO     Training average negative_sample_loss at step 192000: 0.107743
2025-12-13 03:46:23,673 INFO     Training average loss at step 192000: 0.389305
2025-12-13 03:46:25,808 INFO     Training average regularization at step 192100: 0.302058
2025-12-13 03:46:25,808 INFO     Training average positive_sample_loss at step 192100: 0.066144
2025-12-13 03:46:25,808 INFO     Training average negative_sample_loss at step 192100: 0.110364
2025-12-13 03:46:25,808 INFO     Training average loss at step 192100: 0.390312
2025-12-13 03:46:27,963 INFO     Training average regularization at step 192200: 0.302058
2025-12-13 03:46:27,964 INFO     Training average positive_sample_loss at step 192200: 0.067469
2025-12-13 03:46:27,964 INFO     Training average negative_sample_loss at step 192200: 0.110144
2025-12-13 03:46:27,964 INFO     Training average loss at step 192200: 0.390865
2025-12-13 03:46:30,112 INFO     Training average regularization at step 192300: 0.302058
2025-12-13 03:46:30,113 INFO     Training average positive_sample_loss at step 192300: 0.066246
2025-12-13 03:46:30,113 INFO     Training average negative_sample_loss at step 192300: 0.108574
2025-12-13 03:46:30,113 INFO     Training average loss at step 192300: 0.389468
2025-12-13 03:46:32,237 INFO     Training average regularization at step 192400: 0.302058
2025-12-13 03:46:32,238 INFO     Training average positive_sample_loss at step 192400: 0.066339
2025-12-13 03:46:32,238 INFO     Training average negative_sample_loss at step 192400: 0.110116
2025-12-13 03:46:32,238 INFO     Training average loss at step 192400: 0.390286
2025-12-13 03:46:34,378 INFO     Training average regularization at step 192500: 0.302058
2025-12-13 03:46:34,379 INFO     Training average positive_sample_loss at step 192500: 0.065649
2025-12-13 03:46:34,379 INFO     Training average negative_sample_loss at step 192500: 0.106462
2025-12-13 03:46:34,379 INFO     Training average loss at step 192500: 0.388113
2025-12-13 03:46:36,547 INFO     Training average regularization at step 192600: 0.302058
2025-12-13 03:46:36,547 INFO     Training average positive_sample_loss at step 192600: 0.066788
2025-12-13 03:46:36,547 INFO     Training average negative_sample_loss at step 192600: 0.109743
2025-12-13 03:46:36,547 INFO     Training average loss at step 192600: 0.390323
2025-12-13 03:46:38,714 INFO     Training average regularization at step 192700: 0.302058
2025-12-13 03:46:38,714 INFO     Training average positive_sample_loss at step 192700: 0.066814
2025-12-13 03:46:38,714 INFO     Training average negative_sample_loss at step 192700: 0.109093
2025-12-13 03:46:38,714 INFO     Training average loss at step 192700: 0.390012
2025-12-13 03:46:40,864 INFO     Training average regularization at step 192800: 0.302058
2025-12-13 03:46:40,865 INFO     Training average positive_sample_loss at step 192800: 0.065963
2025-12-13 03:46:40,865 INFO     Training average negative_sample_loss at step 192800: 0.107140
2025-12-13 03:46:40,865 INFO     Training average loss at step 192800: 0.388609
2025-12-13 03:46:43,027 INFO     Training average regularization at step 192900: 0.302058
2025-12-13 03:46:43,027 INFO     Training average positive_sample_loss at step 192900: 0.066953
2025-12-13 03:46:43,027 INFO     Training average negative_sample_loss at step 192900: 0.109300
2025-12-13 03:46:43,027 INFO     Training average loss at step 192900: 0.390184
2025-12-13 03:46:45,185 INFO     Training average regularization at step 193000: 0.302058
2025-12-13 03:46:45,186 INFO     Training average positive_sample_loss at step 193000: 0.067606
2025-12-13 03:46:45,186 INFO     Training average negative_sample_loss at step 193000: 0.108275
2025-12-13 03:46:45,186 INFO     Training average loss at step 193000: 0.389998
2025-12-13 03:46:47,349 INFO     Training average regularization at step 193100: 0.302058
2025-12-13 03:46:47,349 INFO     Training average positive_sample_loss at step 193100: 0.066406
2025-12-13 03:46:47,349 INFO     Training average negative_sample_loss at step 193100: 0.110694
2025-12-13 03:46:47,349 INFO     Training average loss at step 193100: 0.390608
2025-12-13 03:46:49,500 INFO     Training average regularization at step 193200: 0.302058
2025-12-13 03:46:49,500 INFO     Training average positive_sample_loss at step 193200: 0.066546
2025-12-13 03:46:49,500 INFO     Training average negative_sample_loss at step 193200: 0.107113
2025-12-13 03:46:49,501 INFO     Training average loss at step 193200: 0.388887
2025-12-13 03:46:52,605 INFO     Training average regularization at step 193300: 0.302057
2025-12-13 03:46:52,606 INFO     Training average positive_sample_loss at step 193300: 0.067617
2025-12-13 03:46:52,606 INFO     Training average negative_sample_loss at step 193300: 0.111034
2025-12-13 03:46:52,606 INFO     Training average loss at step 193300: 0.391383
2025-12-13 03:46:54,753 INFO     Training average regularization at step 193400: 0.302057
2025-12-13 03:46:54,754 INFO     Training average positive_sample_loss at step 193400: 0.067744
2025-12-13 03:46:54,754 INFO     Training average negative_sample_loss at step 193400: 0.110396
2025-12-13 03:46:54,754 INFO     Training average loss at step 193400: 0.391128
2025-12-13 03:46:56,920 INFO     Training average regularization at step 193500: 0.302057
2025-12-13 03:46:56,920 INFO     Training average positive_sample_loss at step 193500: 0.068476
2025-12-13 03:46:56,920 INFO     Training average negative_sample_loss at step 193500: 0.106476
2025-12-13 03:46:56,920 INFO     Training average loss at step 193500: 0.389533
2025-12-13 03:46:59,088 INFO     Training average regularization at step 193600: 0.302057
2025-12-13 03:46:59,088 INFO     Training average positive_sample_loss at step 193600: 0.067513
2025-12-13 03:46:59,088 INFO     Training average negative_sample_loss at step 193600: 0.107985
2025-12-13 03:46:59,088 INFO     Training average loss at step 193600: 0.389806
2025-12-13 03:47:01,223 INFO     Training average regularization at step 193700: 0.302057
2025-12-13 03:47:01,225 INFO     Training average positive_sample_loss at step 193700: 0.065520
2025-12-13 03:47:01,225 INFO     Training average negative_sample_loss at step 193700: 0.108823
2025-12-13 03:47:01,225 INFO     Training average loss at step 193700: 0.389229
2025-12-13 03:47:03,342 INFO     Training average regularization at step 193800: 0.302057
2025-12-13 03:47:03,343 INFO     Training average positive_sample_loss at step 193800: 0.066948
2025-12-13 03:47:03,343 INFO     Training average negative_sample_loss at step 193800: 0.109805
2025-12-13 03:47:03,343 INFO     Training average loss at step 193800: 0.390433
2025-12-13 03:47:05,459 INFO     Training average regularization at step 193900: 0.302057
2025-12-13 03:47:05,460 INFO     Training average positive_sample_loss at step 193900: 0.067154
2025-12-13 03:47:05,460 INFO     Training average negative_sample_loss at step 193900: 0.109508
2025-12-13 03:47:05,460 INFO     Training average loss at step 193900: 0.390388
2025-12-13 03:47:07,607 INFO     Training average regularization at step 194000: 0.302057
2025-12-13 03:47:07,607 INFO     Training average positive_sample_loss at step 194000: 0.066409
2025-12-13 03:47:07,607 INFO     Training average negative_sample_loss at step 194000: 0.108788
2025-12-13 03:47:07,607 INFO     Training average loss at step 194000: 0.389656
2025-12-13 03:47:09,732 INFO     Training average regularization at step 194100: 0.302057
2025-12-13 03:47:09,732 INFO     Training average positive_sample_loss at step 194100: 0.066260
2025-12-13 03:47:09,732 INFO     Training average negative_sample_loss at step 194100: 0.111063
2025-12-13 03:47:09,732 INFO     Training average loss at step 194100: 0.390718
2025-12-13 03:47:11,866 INFO     Training average regularization at step 194200: 0.302057
2025-12-13 03:47:11,867 INFO     Training average positive_sample_loss at step 194200: 0.066351
2025-12-13 03:47:11,867 INFO     Training average negative_sample_loss at step 194200: 0.110450
2025-12-13 03:47:11,867 INFO     Training average loss at step 194200: 0.390457
2025-12-13 03:47:13,962 INFO     Training average regularization at step 194300: 0.302057
2025-12-13 03:47:13,962 INFO     Training average positive_sample_loss at step 194300: 0.066498
2025-12-13 03:47:13,962 INFO     Training average negative_sample_loss at step 194300: 0.110352
2025-12-13 03:47:13,962 INFO     Training average loss at step 194300: 0.390482
2025-12-13 03:47:16,084 INFO     Training average regularization at step 194400: 0.302057
2025-12-13 03:47:16,084 INFO     Training average positive_sample_loss at step 194400: 0.066223
2025-12-13 03:47:16,084 INFO     Training average negative_sample_loss at step 194400: 0.110977
2025-12-13 03:47:16,084 INFO     Training average loss at step 194400: 0.390657
2025-12-13 03:47:18,170 INFO     Training average regularization at step 194500: 0.302057
2025-12-13 03:47:18,170 INFO     Training average positive_sample_loss at step 194500: 0.067013
2025-12-13 03:47:18,171 INFO     Training average negative_sample_loss at step 194500: 0.111032
2025-12-13 03:47:18,171 INFO     Training average loss at step 194500: 0.391079
2025-12-13 03:47:20,259 INFO     Training average regularization at step 194600: 0.302057
2025-12-13 03:47:20,259 INFO     Training average positive_sample_loss at step 194600: 0.065876
2025-12-13 03:47:20,260 INFO     Training average negative_sample_loss at step 194600: 0.106995
2025-12-13 03:47:20,260 INFO     Training average loss at step 194600: 0.388492
2025-12-13 03:47:22,385 INFO     Training average regularization at step 194700: 0.302056
2025-12-13 03:47:22,385 INFO     Training average positive_sample_loss at step 194700: 0.067589
2025-12-13 03:47:22,385 INFO     Training average negative_sample_loss at step 194700: 0.110538
2025-12-13 03:47:22,385 INFO     Training average loss at step 194700: 0.391120
2025-12-13 03:47:24,479 INFO     Training average regularization at step 194800: 0.302056
2025-12-13 03:47:24,479 INFO     Training average positive_sample_loss at step 194800: 0.066840
2025-12-13 03:47:24,479 INFO     Training average negative_sample_loss at step 194800: 0.114347
2025-12-13 03:47:24,479 INFO     Training average loss at step 194800: 0.392650
2025-12-13 03:47:26,606 INFO     Training average regularization at step 194900: 0.302056
2025-12-13 03:47:26,606 INFO     Training average positive_sample_loss at step 194900: 0.066395
2025-12-13 03:47:26,606 INFO     Training average negative_sample_loss at step 194900: 0.108559
2025-12-13 03:47:26,606 INFO     Training average loss at step 194900: 0.389533
2025-12-13 03:47:28,693 INFO     Training average regularization at step 195000: 0.302056
2025-12-13 03:47:28,694 INFO     Training average positive_sample_loss at step 195000: 0.065873
2025-12-13 03:47:28,694 INFO     Training average negative_sample_loss at step 195000: 0.109887
2025-12-13 03:47:28,694 INFO     Training average loss at step 195000: 0.389936
2025-12-13 03:47:30,799 INFO     Training average regularization at step 195100: 0.302056
2025-12-13 03:47:30,799 INFO     Training average positive_sample_loss at step 195100: 0.067200
2025-12-13 03:47:30,799 INFO     Training average negative_sample_loss at step 195100: 0.109343
2025-12-13 03:47:30,799 INFO     Training average loss at step 195100: 0.390328
2025-12-13 03:47:32,905 INFO     Training average regularization at step 195200: 0.302056
2025-12-13 03:47:32,905 INFO     Training average positive_sample_loss at step 195200: 0.065778
2025-12-13 03:47:32,905 INFO     Training average negative_sample_loss at step 195200: 0.108903
2025-12-13 03:47:32,905 INFO     Training average loss at step 195200: 0.389397
2025-12-13 03:47:35,024 INFO     Training average regularization at step 195300: 0.302056
2025-12-13 03:47:35,024 INFO     Training average positive_sample_loss at step 195300: 0.066095
2025-12-13 03:47:35,025 INFO     Training average negative_sample_loss at step 195300: 0.109300
2025-12-13 03:47:35,025 INFO     Training average loss at step 195300: 0.389753
2025-12-13 03:47:37,191 INFO     Training average regularization at step 195400: 0.302056
2025-12-13 03:47:37,191 INFO     Training average positive_sample_loss at step 195400: 0.066728
2025-12-13 03:47:37,191 INFO     Training average negative_sample_loss at step 195400: 0.111486
2025-12-13 03:47:37,191 INFO     Training average loss at step 195400: 0.391163
2025-12-13 03:47:39,328 INFO     Training average regularization at step 195500: 0.302056
2025-12-13 03:47:39,329 INFO     Training average positive_sample_loss at step 195500: 0.065698
2025-12-13 03:47:39,329 INFO     Training average negative_sample_loss at step 195500: 0.108250
2025-12-13 03:47:39,329 INFO     Training average loss at step 195500: 0.389030
2025-12-13 03:47:41,470 INFO     Training average regularization at step 195600: 0.302056
2025-12-13 03:47:41,470 INFO     Training average positive_sample_loss at step 195600: 0.066136
2025-12-13 03:47:41,470 INFO     Training average negative_sample_loss at step 195600: 0.107275
2025-12-13 03:47:41,470 INFO     Training average loss at step 195600: 0.388761
2025-12-13 03:47:43,603 INFO     Training average regularization at step 195700: 0.302056
2025-12-13 03:47:43,603 INFO     Training average positive_sample_loss at step 195700: 0.066007
2025-12-13 03:47:43,603 INFO     Training average negative_sample_loss at step 195700: 0.109896
2025-12-13 03:47:43,603 INFO     Training average loss at step 195700: 0.390007
2025-12-13 03:47:45,715 INFO     Training average regularization at step 195800: 0.302056
2025-12-13 03:47:45,716 INFO     Training average positive_sample_loss at step 195800: 0.065999
2025-12-13 03:47:45,716 INFO     Training average negative_sample_loss at step 195800: 0.106566
2025-12-13 03:47:45,716 INFO     Training average loss at step 195800: 0.388338
2025-12-13 03:47:47,843 INFO     Training average regularization at step 195900: 0.302056
2025-12-13 03:47:47,843 INFO     Training average positive_sample_loss at step 195900: 0.068448
2025-12-13 03:47:47,843 INFO     Training average negative_sample_loss at step 195900: 0.111475
2025-12-13 03:47:47,843 INFO     Training average loss at step 195900: 0.392017
2025-12-13 03:47:49,926 INFO     Training average regularization at step 196000: 0.302056
2025-12-13 03:47:49,926 INFO     Training average positive_sample_loss at step 196000: 0.066559
2025-12-13 03:47:49,926 INFO     Training average negative_sample_loss at step 196000: 0.107984
2025-12-13 03:47:49,926 INFO     Training average loss at step 196000: 0.389327
2025-12-13 03:47:52,047 INFO     Training average regularization at step 196100: 0.302055
2025-12-13 03:47:52,047 INFO     Training average positive_sample_loss at step 196100: 0.067192
2025-12-13 03:47:52,047 INFO     Training average negative_sample_loss at step 196100: 0.111602
2025-12-13 03:47:52,047 INFO     Training average loss at step 196100: 0.391453
2025-12-13 03:47:54,198 INFO     Training average regularization at step 196200: 0.302055
2025-12-13 03:47:54,198 INFO     Training average positive_sample_loss at step 196200: 0.066687
2025-12-13 03:47:54,198 INFO     Training average negative_sample_loss at step 196200: 0.110762
2025-12-13 03:47:54,198 INFO     Training average loss at step 196200: 0.390780
2025-12-13 03:47:56,357 INFO     Training average regularization at step 196300: 0.302055
2025-12-13 03:47:56,358 INFO     Training average positive_sample_loss at step 196300: 0.067340
2025-12-13 03:47:56,358 INFO     Training average negative_sample_loss at step 196300: 0.107709
2025-12-13 03:47:56,358 INFO     Training average loss at step 196300: 0.389580
2025-12-13 03:47:58,482 INFO     Training average regularization at step 196400: 0.302055
2025-12-13 03:47:58,482 INFO     Training average positive_sample_loss at step 196400: 0.066097
2025-12-13 03:47:58,483 INFO     Training average negative_sample_loss at step 196400: 0.108229
2025-12-13 03:47:58,483 INFO     Training average loss at step 196400: 0.389218
2025-12-13 03:48:00,571 INFO     Training average regularization at step 196500: 0.302055
2025-12-13 03:48:00,571 INFO     Training average positive_sample_loss at step 196500: 0.066775
2025-12-13 03:48:00,571 INFO     Training average negative_sample_loss at step 196500: 0.111915
2025-12-13 03:48:00,571 INFO     Training average loss at step 196500: 0.391401
2025-12-13 03:48:02,661 INFO     Training average regularization at step 196600: 0.302055
2025-12-13 03:48:02,661 INFO     Training average positive_sample_loss at step 196600: 0.067685
2025-12-13 03:48:02,661 INFO     Training average negative_sample_loss at step 196600: 0.108039
2025-12-13 03:48:02,661 INFO     Training average loss at step 196600: 0.389917
2025-12-13 03:48:04,748 INFO     Training average regularization at step 196700: 0.302055
2025-12-13 03:48:04,748 INFO     Training average positive_sample_loss at step 196700: 0.065809
2025-12-13 03:48:04,748 INFO     Training average negative_sample_loss at step 196700: 0.110197
2025-12-13 03:48:04,748 INFO     Training average loss at step 196700: 0.390058
2025-12-13 03:48:06,848 INFO     Training average regularization at step 196800: 0.302055
2025-12-13 03:48:06,848 INFO     Training average positive_sample_loss at step 196800: 0.067201
2025-12-13 03:48:06,848 INFO     Training average negative_sample_loss at step 196800: 0.109687
2025-12-13 03:48:06,848 INFO     Training average loss at step 196800: 0.390499
2025-12-13 03:48:08,932 INFO     Training average regularization at step 196900: 0.302055
2025-12-13 03:48:08,933 INFO     Training average positive_sample_loss at step 196900: 0.065576
2025-12-13 03:48:08,933 INFO     Training average negative_sample_loss at step 196900: 0.107891
2025-12-13 03:48:08,933 INFO     Training average loss at step 196900: 0.388788
2025-12-13 03:48:11,062 INFO     Training average regularization at step 197000: 0.302055
2025-12-13 03:48:11,063 INFO     Training average positive_sample_loss at step 197000: 0.066459
2025-12-13 03:48:11,063 INFO     Training average negative_sample_loss at step 197000: 0.107366
2025-12-13 03:48:11,063 INFO     Training average loss at step 197000: 0.388967
2025-12-13 03:48:13,173 INFO     Training average regularization at step 197100: 0.302055
2025-12-13 03:48:13,173 INFO     Training average positive_sample_loss at step 197100: 0.067668
2025-12-13 03:48:13,173 INFO     Training average negative_sample_loss at step 197100: 0.109174
2025-12-13 03:48:13,173 INFO     Training average loss at step 197100: 0.390476
2025-12-13 03:48:15,267 INFO     Training average regularization at step 197200: 0.302055
2025-12-13 03:48:15,267 INFO     Training average positive_sample_loss at step 197200: 0.066547
2025-12-13 03:48:15,267 INFO     Training average negative_sample_loss at step 197200: 0.109736
2025-12-13 03:48:15,267 INFO     Training average loss at step 197200: 0.390196
2025-12-13 03:48:17,485 INFO     Training average regularization at step 197300: 0.302055
2025-12-13 03:48:17,485 INFO     Training average positive_sample_loss at step 197300: 0.067221
2025-12-13 03:48:17,485 INFO     Training average negative_sample_loss at step 197300: 0.109995
2025-12-13 03:48:17,486 INFO     Training average loss at step 197300: 0.390663
2025-12-13 03:48:19,583 INFO     Training average regularization at step 197400: 0.302055
2025-12-13 03:48:19,583 INFO     Training average positive_sample_loss at step 197400: 0.066491
2025-12-13 03:48:19,584 INFO     Training average negative_sample_loss at step 197400: 0.108258
2025-12-13 03:48:19,584 INFO     Training average loss at step 197400: 0.389429
2025-12-13 03:48:21,684 INFO     Training average regularization at step 197500: 0.302055
2025-12-13 03:48:21,684 INFO     Training average positive_sample_loss at step 197500: 0.066765
2025-12-13 03:48:21,684 INFO     Training average negative_sample_loss at step 197500: 0.110492
2025-12-13 03:48:21,684 INFO     Training average loss at step 197500: 0.390683
2025-12-13 03:48:23,770 INFO     Training average regularization at step 197600: 0.302054
2025-12-13 03:48:23,770 INFO     Training average positive_sample_loss at step 197600: 0.065593
2025-12-13 03:48:23,770 INFO     Training average negative_sample_loss at step 197600: 0.106879
2025-12-13 03:48:23,770 INFO     Training average loss at step 197600: 0.388290
2025-12-13 03:48:25,893 INFO     Training average regularization at step 197700: 0.302054
2025-12-13 03:48:25,894 INFO     Training average positive_sample_loss at step 197700: 0.066439
2025-12-13 03:48:25,894 INFO     Training average negative_sample_loss at step 197700: 0.106725
2025-12-13 03:48:25,894 INFO     Training average loss at step 197700: 0.388636
2025-12-13 03:48:28,050 INFO     Training average regularization at step 197800: 0.302054
2025-12-13 03:48:28,050 INFO     Training average positive_sample_loss at step 197800: 0.066786
2025-12-13 03:48:28,050 INFO     Training average negative_sample_loss at step 197800: 0.106838
2025-12-13 03:48:28,050 INFO     Training average loss at step 197800: 0.388866
2025-12-13 03:48:30,173 INFO     Training average regularization at step 197900: 0.302054
2025-12-13 03:48:30,173 INFO     Training average positive_sample_loss at step 197900: 0.066863
2025-12-13 03:48:30,173 INFO     Training average negative_sample_loss at step 197900: 0.111080
2025-12-13 03:48:30,173 INFO     Training average loss at step 197900: 0.391026
2025-12-13 03:48:32,296 INFO     Training average regularization at step 198000: 0.302054
2025-12-13 03:48:32,296 INFO     Training average positive_sample_loss at step 198000: 0.067522
2025-12-13 03:48:32,296 INFO     Training average negative_sample_loss at step 198000: 0.108036
2025-12-13 03:48:32,296 INFO     Training average loss at step 198000: 0.389833
2025-12-13 03:48:34,535 INFO     Training average regularization at step 198100: 0.302054
2025-12-13 03:48:34,535 INFO     Training average positive_sample_loss at step 198100: 0.068441
2025-12-13 03:48:34,536 INFO     Training average negative_sample_loss at step 198100: 0.110734
2025-12-13 03:48:34,536 INFO     Training average loss at step 198100: 0.391642
2025-12-13 03:48:37,781 INFO     Training average regularization at step 198200: 0.302054
2025-12-13 03:48:37,782 INFO     Training average positive_sample_loss at step 198200: 0.066400
2025-12-13 03:48:37,782 INFO     Training average negative_sample_loss at step 198200: 0.108637
2025-12-13 03:48:37,782 INFO     Training average loss at step 198200: 0.389573
2025-12-13 03:48:39,989 INFO     Training average regularization at step 198300: 0.302054
2025-12-13 03:48:39,991 INFO     Training average positive_sample_loss at step 198300: 0.066699
2025-12-13 03:48:39,991 INFO     Training average negative_sample_loss at step 198300: 0.108307
2025-12-13 03:48:39,991 INFO     Training average loss at step 198300: 0.389557
2025-12-13 03:48:42,237 INFO     Training average regularization at step 198400: 0.302054
2025-12-13 03:48:42,238 INFO     Training average positive_sample_loss at step 198400: 0.066942
2025-12-13 03:48:42,238 INFO     Training average negative_sample_loss at step 198400: 0.108074
2025-12-13 03:48:42,238 INFO     Training average loss at step 198400: 0.389562
2025-12-13 03:48:44,436 INFO     Training average regularization at step 198500: 0.302054
2025-12-13 03:48:44,436 INFO     Training average positive_sample_loss at step 198500: 0.066256
2025-12-13 03:48:44,436 INFO     Training average negative_sample_loss at step 198500: 0.109722
2025-12-13 03:48:44,436 INFO     Training average loss at step 198500: 0.390043
2025-12-13 03:48:46,600 INFO     Training average regularization at step 198600: 0.302054
2025-12-13 03:48:46,600 INFO     Training average positive_sample_loss at step 198600: 0.067687
2025-12-13 03:48:46,600 INFO     Training average negative_sample_loss at step 198600: 0.117870
2025-12-13 03:48:46,600 INFO     Training average loss at step 198600: 0.394833
2025-12-13 03:48:48,790 INFO     Training average regularization at step 198700: 0.302054
2025-12-13 03:48:48,790 INFO     Training average positive_sample_loss at step 198700: 0.066485
2025-12-13 03:48:48,790 INFO     Training average negative_sample_loss at step 198700: 0.110067
2025-12-13 03:48:48,790 INFO     Training average loss at step 198700: 0.390330
2025-12-13 03:48:50,961 INFO     Training average regularization at step 198800: 0.302054
2025-12-13 03:48:50,961 INFO     Training average positive_sample_loss at step 198800: 0.067314
2025-12-13 03:48:50,961 INFO     Training average negative_sample_loss at step 198800: 0.109593
2025-12-13 03:48:50,961 INFO     Training average loss at step 198800: 0.390507
2025-12-13 03:48:53,107 INFO     Training average regularization at step 198900: 0.302054
2025-12-13 03:48:53,107 INFO     Training average positive_sample_loss at step 198900: 0.066590
2025-12-13 03:48:53,108 INFO     Training average negative_sample_loss at step 198900: 0.108456
2025-12-13 03:48:53,108 INFO     Training average loss at step 198900: 0.389577
2025-12-13 03:48:55,256 INFO     Training average regularization at step 199000: 0.302054
2025-12-13 03:48:55,256 INFO     Training average positive_sample_loss at step 199000: 0.065918
2025-12-13 03:48:55,256 INFO     Training average negative_sample_loss at step 199000: 0.109210
2025-12-13 03:48:55,256 INFO     Training average loss at step 199000: 0.389618
2025-12-13 03:48:57,437 INFO     Training average regularization at step 199100: 0.302053
2025-12-13 03:48:57,437 INFO     Training average positive_sample_loss at step 199100: 0.067335
2025-12-13 03:48:57,437 INFO     Training average negative_sample_loss at step 199100: 0.108985
2025-12-13 03:48:57,437 INFO     Training average loss at step 199100: 0.390213
2025-12-13 03:48:59,608 INFO     Training average regularization at step 199200: 0.302053
2025-12-13 03:48:59,609 INFO     Training average positive_sample_loss at step 199200: 0.068465
2025-12-13 03:48:59,609 INFO     Training average negative_sample_loss at step 199200: 0.109518
2025-12-13 03:48:59,609 INFO     Training average loss at step 199200: 0.391044
2025-12-13 03:49:01,775 INFO     Training average regularization at step 199300: 0.302053
2025-12-13 03:49:01,776 INFO     Training average positive_sample_loss at step 199300: 0.066812
2025-12-13 03:49:01,776 INFO     Training average negative_sample_loss at step 199300: 0.110051
2025-12-13 03:49:01,776 INFO     Training average loss at step 199300: 0.390485
2025-12-13 03:49:03,926 INFO     Training average regularization at step 199400: 0.302053
2025-12-13 03:49:03,926 INFO     Training average positive_sample_loss at step 199400: 0.067709
2025-12-13 03:49:03,926 INFO     Training average negative_sample_loss at step 199400: 0.107369
2025-12-13 03:49:03,926 INFO     Training average loss at step 199400: 0.389592
2025-12-13 03:49:06,056 INFO     Training average regularization at step 199500: 0.302053
2025-12-13 03:49:06,056 INFO     Training average positive_sample_loss at step 199500: 0.066687
2025-12-13 03:49:06,056 INFO     Training average negative_sample_loss at step 199500: 0.108527
2025-12-13 03:49:06,056 INFO     Training average loss at step 199500: 0.389660
2025-12-13 03:49:08,179 INFO     Training average regularization at step 199600: 0.302053
2025-12-13 03:49:08,180 INFO     Training average positive_sample_loss at step 199600: 0.066590
2025-12-13 03:49:08,180 INFO     Training average negative_sample_loss at step 199600: 0.106138
2025-12-13 03:49:08,180 INFO     Training average loss at step 199600: 0.388418
2025-12-13 03:49:10,303 INFO     Training average regularization at step 199700: 0.302053
2025-12-13 03:49:10,303 INFO     Training average positive_sample_loss at step 199700: 0.065818
2025-12-13 03:49:10,303 INFO     Training average negative_sample_loss at step 199700: 0.109442
2025-12-13 03:49:10,303 INFO     Training average loss at step 199700: 0.389683
2025-12-13 03:49:12,472 INFO     Training average regularization at step 199800: 0.302053
2025-12-13 03:49:12,472 INFO     Training average positive_sample_loss at step 199800: 0.066228
2025-12-13 03:49:12,472 INFO     Training average negative_sample_loss at step 199800: 0.109903
2025-12-13 03:49:12,472 INFO     Training average loss at step 199800: 0.390119
2025-12-13 03:49:14,612 INFO     Training average regularization at step 199900: 0.302053
2025-12-13 03:49:14,613 INFO     Training average positive_sample_loss at step 199900: 0.066511
2025-12-13 03:49:14,613 INFO     Training average negative_sample_loss at step 199900: 0.109307
2025-12-13 03:49:14,613 INFO     Training average loss at step 199900: 0.389962
2025-12-13 03:49:18,507 INFO     Training average regularization at step 200000: 0.302053
2025-12-13 03:49:18,507 INFO     Training average positive_sample_loss at step 200000: 0.066303
2025-12-13 03:49:18,508 INFO     Training average negative_sample_loss at step 200000: 0.108387
2025-12-13 03:49:18,508 INFO     Training average loss at step 200000: 0.389398
2025-12-13 03:49:18,508 INFO     Evaluating on Valid Dataset...
2025-12-13 03:49:19,066 INFO     Evaluating the model... (0/50000)
2025-12-13 03:49:21,632 INFO     Evaluating the model... (500/50000)
2025-12-13 03:49:24,326 INFO     Evaluating the model... (1000/50000)
2025-12-13 03:49:26,884 INFO     Evaluating the model... (1500/50000)
2025-12-13 03:49:30,500 INFO     Evaluating the model... (2000/50000)
2025-12-13 03:49:32,964 INFO     Evaluating the model... (2500/50000)
2025-12-13 03:49:35,740 INFO     Evaluating the model... (3000/50000)
2025-12-13 03:49:38,504 INFO     Evaluating the model... (3500/50000)
2025-12-13 03:49:41,145 INFO     Evaluating the model... (4000/50000)
2025-12-13 03:49:44,652 INFO     Evaluating the model... (4500/50000)
2025-12-13 03:49:47,466 INFO     Evaluating the model... (5000/50000)
2025-12-13 03:49:49,912 INFO     Evaluating the model... (5500/50000)
2025-12-13 03:49:52,400 INFO     Evaluating the model... (6000/50000)
2025-12-13 03:49:55,015 INFO     Evaluating the model... (6500/50000)
2025-12-13 03:49:58,245 INFO     Evaluating the model... (7000/50000)
2025-12-13 03:50:00,714 INFO     Evaluating the model... (7500/50000)
2025-12-13 03:50:03,200 INFO     Evaluating the model... (8000/50000)
2025-12-13 03:50:05,738 INFO     Evaluating the model... (8500/50000)
2025-12-13 03:50:08,254 INFO     Evaluating the model... (9000/50000)
2025-12-13 03:50:11,438 INFO     Evaluating the model... (9500/50000)
2025-12-13 03:50:13,881 INFO     Evaluating the model... (10000/50000)
2025-12-13 03:50:16,345 INFO     Evaluating the model... (10500/50000)
2025-12-13 03:50:18,731 INFO     Evaluating the model... (11000/50000)
2025-12-13 03:50:21,328 INFO     Evaluating the model... (11500/50000)
2025-12-13 03:50:24,521 INFO     Evaluating the model... (12000/50000)
2025-12-13 03:50:27,028 INFO     Evaluating the model... (12500/50000)
2025-12-13 03:50:29,448 INFO     Evaluating the model... (13000/50000)
2025-12-13 03:50:31,969 INFO     Evaluating the model... (13500/50000)
2025-12-13 03:50:35,386 INFO     Evaluating the model... (14000/50000)
2025-12-13 03:50:37,894 INFO     Evaluating the model... (14500/50000)
2025-12-13 03:50:40,474 INFO     Evaluating the model... (15000/50000)
2025-12-13 03:50:43,273 INFO     Evaluating the model... (15500/50000)
2025-12-13 03:50:45,901 INFO     Evaluating the model... (16000/50000)
2025-12-13 03:50:49,125 INFO     Evaluating the model... (16500/50000)
2025-12-13 03:50:51,486 INFO     Evaluating the model... (17000/50000)
2025-12-13 03:50:53,869 INFO     Evaluating the model... (17500/50000)
2025-12-13 03:50:56,482 INFO     Evaluating the model... (18000/50000)
2025-12-13 03:50:58,948 INFO     Evaluating the model... (18500/50000)
2025-12-13 03:51:02,239 INFO     Evaluating the model... (19000/50000)
2025-12-13 03:51:04,713 INFO     Evaluating the model... (19500/50000)
2025-12-13 03:51:07,393 INFO     Evaluating the model... (20000/50000)
2025-12-13 03:51:09,786 INFO     Evaluating the model... (20500/50000)
2025-12-13 03:51:12,151 INFO     Evaluating the model... (21000/50000)
2025-12-13 03:51:15,639 INFO     Evaluating the model... (21500/50000)
2025-12-13 03:51:18,159 INFO     Evaluating the model... (22000/50000)
2025-12-13 03:51:20,625 INFO     Evaluating the model... (22500/50000)
2025-12-13 03:51:23,251 INFO     Evaluating the model... (23000/50000)
2025-12-13 03:51:25,787 INFO     Evaluating the model... (23500/50000)
2025-12-13 03:51:29,413 INFO     Evaluating the model... (24000/50000)
2025-12-13 03:51:31,838 INFO     Evaluating the model... (24500/50000)
2025-12-13 03:51:34,574 INFO     Evaluating the model... (25000/50000)
2025-12-13 03:51:37,221 INFO     Evaluating the model... (25500/50000)
2025-12-13 03:51:40,120 INFO     Evaluating the model... (26000/50000)
2025-12-13 03:51:44,181 INFO     Evaluating the model... (26500/50000)
2025-12-13 03:51:46,830 INFO     Evaluating the model... (27000/50000)
2025-12-13 03:51:49,324 INFO     Evaluating the model... (27500/50000)
2025-12-13 03:51:51,980 INFO     Evaluating the model... (28000/50000)
2025-12-13 03:51:54,747 INFO     Evaluating the model... (28500/50000)
2025-12-13 03:51:57,851 INFO     Evaluating the model... (29000/50000)
2025-12-13 03:52:00,276 INFO     Evaluating the model... (29500/50000)
2025-12-13 03:52:02,741 INFO     Evaluating the model... (30000/50000)
2025-12-13 03:52:05,457 INFO     Evaluating the model... (30500/50000)
2025-12-13 03:52:08,009 INFO     Evaluating the model... (31000/50000)
2025-12-13 03:52:11,062 INFO     Evaluating the model... (31500/50000)
2025-12-13 03:52:13,564 INFO     Evaluating the model... (32000/50000)
2025-12-13 03:52:16,217 INFO     Evaluating the model... (32500/50000)
2025-12-13 03:52:18,677 INFO     Evaluating the model... (33000/50000)
2025-12-13 03:52:21,098 INFO     Evaluating the model... (33500/50000)
2025-12-13 03:52:24,242 INFO     Evaluating the model... (34000/50000)
2025-12-13 03:52:26,916 INFO     Evaluating the model... (34500/50000)
2025-12-13 03:52:29,585 INFO     Evaluating the model... (35000/50000)
2025-12-13 03:52:32,150 INFO     Evaluating the model... (35500/50000)
2025-12-13 03:52:34,715 INFO     Evaluating the model... (36000/50000)
2025-12-13 03:52:38,121 INFO     Evaluating the model... (36500/50000)
2025-12-13 03:52:40,971 INFO     Evaluating the model... (37000/50000)
2025-12-13 03:52:43,623 INFO     Evaluating the model... (37500/50000)
2025-12-13 03:52:46,245 INFO     Evaluating the model... (38000/50000)
2025-12-13 03:52:48,700 INFO     Evaluating the model... (38500/50000)
2025-12-13 03:52:52,170 INFO     Evaluating the model... (39000/50000)
2025-12-13 03:52:54,694 INFO     Evaluating the model... (39500/50000)
2025-12-13 03:52:57,241 INFO     Evaluating the model... (40000/50000)
2025-12-13 03:52:59,708 INFO     Evaluating the model... (40500/50000)
2025-12-13 03:53:03,480 INFO     Evaluating the model... (41000/50000)
2025-12-13 03:53:05,922 INFO     Evaluating the model... (41500/50000)
2025-12-13 03:53:08,458 INFO     Evaluating the model... (42000/50000)
2025-12-13 03:53:11,014 INFO     Evaluating the model... (42500/50000)
2025-12-13 03:53:13,801 INFO     Evaluating the model... (43000/50000)
2025-12-13 03:53:17,177 INFO     Evaluating the model... (43500/50000)
2025-12-13 03:53:19,585 INFO     Evaluating the model... (44000/50000)
2025-12-13 03:53:22,106 INFO     Evaluating the model... (44500/50000)
2025-12-13 03:53:24,822 INFO     Evaluating the model... (45000/50000)
2025-12-13 03:53:27,411 INFO     Evaluating the model... (45500/50000)
2025-12-13 03:53:31,117 INFO     Evaluating the model... (46000/50000)
2025-12-13 03:53:33,756 INFO     Evaluating the model... (46500/50000)
2025-12-13 03:53:36,722 INFO     Evaluating the model... (47000/50000)
2025-12-13 03:53:39,430 INFO     Evaluating the model... (47500/50000)
2025-12-13 03:53:42,128 INFO     Evaluating the model... (48000/50000)
2025-12-13 03:53:45,773 INFO     Evaluating the model... (48500/50000)
2025-12-13 03:53:48,542 INFO     Evaluating the model... (49000/50000)
2025-12-13 03:53:51,044 INFO     Evaluating the model... (49500/50000)
2025-12-13 03:53:54,171 INFO     Valid MRR at step 200000: 0.633157
2025-12-13 03:53:54,171 INFO     Valid MR at step 200000: 266.828920
2025-12-13 03:53:54,171 INFO     Valid HITS@1 at step 200000: 0.547490
2025-12-13 03:53:54,172 INFO     Valid HITS@3 at step 200000: 0.686070
2025-12-13 03:53:54,172 INFO     Valid HITS@10 at step 200000: 0.784770
2025-12-13 03:53:55,682 INFO     Evaluating on Test Dataset...
2025-12-13 03:53:56,212 INFO     Evaluating the model... (0/59072)
2025-12-13 03:53:58,852 INFO     Evaluating the model... (500/59072)
2025-12-13 03:54:02,378 INFO     Evaluating the model... (1000/59072)
2025-12-13 03:54:04,920 INFO     Evaluating the model... (1500/59072)
2025-12-13 03:54:07,580 INFO     Evaluating the model... (2000/59072)
2025-12-13 03:54:10,143 INFO     Evaluating the model... (2500/59072)
2025-12-13 03:54:12,702 INFO     Evaluating the model... (3000/59072)
2025-12-13 03:54:16,068 INFO     Evaluating the model... (3500/59072)
2025-12-13 03:54:18,445 INFO     Evaluating the model... (4000/59072)
2025-12-13 03:54:20,976 INFO     Evaluating the model... (4500/59072)
2025-12-13 03:54:23,543 INFO     Evaluating the model... (5000/59072)
2025-12-13 03:54:26,111 INFO     Evaluating the model... (5500/59072)
2025-12-13 03:54:29,392 INFO     Evaluating the model... (6000/59072)
2025-12-13 03:54:31,859 INFO     Evaluating the model... (6500/59072)
2025-12-13 03:54:34,360 INFO     Evaluating the model... (7000/59072)
2025-12-13 03:54:37,155 INFO     Evaluating the model... (7500/59072)
2025-12-13 03:54:39,857 INFO     Evaluating the model... (8000/59072)
2025-12-13 03:54:43,145 INFO     Evaluating the model... (8500/59072)
2025-12-13 03:54:45,839 INFO     Evaluating the model... (9000/59072)
2025-12-13 03:54:48,332 INFO     Evaluating the model... (9500/59072)
2025-12-13 03:54:50,854 INFO     Evaluating the model... (10000/59072)
2025-12-13 03:54:53,326 INFO     Evaluating the model... (10500/59072)
2025-12-13 03:54:56,413 INFO     Evaluating the model... (11000/59072)
2025-12-13 03:54:58,904 INFO     Evaluating the model... (11500/59072)
2025-12-13 03:55:01,358 INFO     Evaluating the model... (12000/59072)
2025-12-13 03:55:03,756 INFO     Evaluating the model... (12500/59072)
2025-12-13 03:55:06,225 INFO     Evaluating the model... (13000/59072)
2025-12-13 03:55:09,430 INFO     Evaluating the model... (13500/59072)
2025-12-13 03:55:11,861 INFO     Evaluating the model... (14000/59072)
2025-12-13 03:55:14,361 INFO     Evaluating the model... (14500/59072)
2025-12-13 03:55:16,894 INFO     Evaluating the model... (15000/59072)
2025-12-13 03:55:19,306 INFO     Evaluating the model... (15500/59072)
2025-12-13 03:55:22,773 INFO     Evaluating the model... (16000/59072)
2025-12-13 03:55:25,236 INFO     Evaluating the model... (16500/59072)
2025-12-13 03:55:27,602 INFO     Evaluating the model... (17000/59072)
2025-12-13 03:55:30,011 INFO     Evaluating the model... (17500/59072)
2025-12-13 03:55:33,556 INFO     Evaluating the model... (18000/59072)
2025-12-13 03:55:36,232 INFO     Evaluating the model... (18500/59072)
2025-12-13 03:55:38,864 INFO     Evaluating the model... (19000/59072)
2025-12-13 03:55:41,481 INFO     Evaluating the model... (19500/59072)
2025-12-13 03:55:44,395 INFO     Evaluating the model... (20000/59072)
2025-12-13 03:55:47,730 INFO     Evaluating the model... (20500/59072)
2025-12-13 03:55:50,145 INFO     Evaluating the model... (21000/59072)
2025-12-13 03:55:52,520 INFO     Evaluating the model... (21500/59072)
2025-12-13 03:55:55,136 INFO     Evaluating the model... (22000/59072)
2025-12-13 03:55:57,623 INFO     Evaluating the model... (22500/59072)
2025-12-13 03:56:01,281 INFO     Evaluating the model... (23000/59072)
2025-12-13 03:56:03,758 INFO     Evaluating the model... (23500/59072)
2025-12-13 03:56:06,377 INFO     Evaluating the model... (24000/59072)
2025-12-13 03:56:08,769 INFO     Evaluating the model... (24500/59072)
2025-12-13 03:56:11,245 INFO     Evaluating the model... (25000/59072)
2025-12-13 03:56:14,832 INFO     Evaluating the model... (25500/59072)
2025-12-13 03:56:17,523 INFO     Evaluating the model... (26000/59072)
2025-12-13 03:56:19,949 INFO     Evaluating the model... (26500/59072)
2025-12-13 03:56:22,319 INFO     Evaluating the model... (27000/59072)
2025-12-13 03:56:24,723 INFO     Evaluating the model... (27500/59072)
2025-12-13 03:56:28,544 INFO     Evaluating the model... (28000/59072)
2025-12-13 03:56:31,132 INFO     Evaluating the model... (28500/59072)
2025-12-13 03:56:33,476 INFO     Evaluating the model... (29000/59072)
2025-12-13 03:56:35,992 INFO     Evaluating the model... (29500/59072)
2025-12-13 03:56:40,053 INFO     Evaluating the model... (30000/59072)
2025-12-13 03:56:42,866 INFO     Evaluating the model... (30500/59072)
2025-12-13 03:56:45,597 INFO     Evaluating the model... (31000/59072)
2025-12-13 03:56:48,135 INFO     Evaluating the model... (31500/59072)
2025-12-13 03:56:50,640 INFO     Evaluating the model... (32000/59072)
2025-12-13 03:56:54,074 INFO     Evaluating the model... (32500/59072)
2025-12-13 03:56:56,627 INFO     Evaluating the model... (33000/59072)
2025-12-13 03:56:59,075 INFO     Evaluating the model... (33500/59072)
2025-12-13 03:57:01,590 INFO     Evaluating the model... (34000/59072)
2025-12-13 03:57:04,284 INFO     Evaluating the model... (34500/59072)
2025-12-13 03:57:07,301 INFO     Evaluating the model... (35000/59072)
2025-12-13 03:57:09,785 INFO     Evaluating the model... (35500/59072)
2025-12-13 03:57:12,253 INFO     Evaluating the model... (36000/59072)
2025-12-13 03:57:14,762 INFO     Evaluating the model... (36500/59072)
2025-12-13 03:57:17,433 INFO     Evaluating the model... (37000/59072)
2025-12-13 03:57:20,525 INFO     Evaluating the model... (37500/59072)
2025-12-13 03:57:22,949 INFO     Evaluating the model... (38000/59072)
2025-12-13 03:57:25,405 INFO     Evaluating the model... (38500/59072)
2025-12-13 03:57:28,180 INFO     Evaluating the model... (39000/59072)
2025-12-13 03:57:30,636 INFO     Evaluating the model... (39500/59072)
2025-12-13 03:57:33,798 INFO     Evaluating the model... (40000/59072)
2025-12-13 03:57:36,506 INFO     Evaluating the model... (40500/59072)
2025-12-13 03:57:39,543 INFO     Evaluating the model... (41000/59072)
2025-12-13 03:57:42,213 INFO     Evaluating the model... (41500/59072)
2025-12-13 03:57:44,866 INFO     Evaluating the model... (42000/59072)
2025-12-13 03:57:48,368 INFO     Evaluating the model... (42500/59072)
2025-12-13 03:57:51,109 INFO     Evaluating the model... (43000/59072)
2025-12-13 03:57:53,608 INFO     Evaluating the model... (43500/59072)
2025-12-13 03:57:56,182 INFO     Evaluating the model... (44000/59072)
2025-12-13 03:57:58,708 INFO     Evaluating the model... (44500/59072)
2025-12-13 03:58:02,258 INFO     Evaluating the model... (45000/59072)
2025-12-13 03:58:04,749 INFO     Evaluating the model... (45500/59072)
2025-12-13 03:58:07,406 INFO     Evaluating the model... (46000/59072)
2025-12-13 03:58:09,876 INFO     Evaluating the model... (46500/59072)
2025-12-13 03:58:12,519 INFO     Evaluating the model... (47000/59072)
2025-12-13 03:58:16,103 INFO     Evaluating the model... (47500/59072)
2025-12-13 03:58:18,609 INFO     Evaluating the model... (48000/59072)
2025-12-13 03:58:21,048 INFO     Evaluating the model... (48500/59072)
2025-12-13 03:58:23,616 INFO     Evaluating the model... (49000/59072)
2025-12-13 03:58:27,025 INFO     Evaluating the model... (49500/59072)
2025-12-13 03:58:29,514 INFO     Evaluating the model... (50000/59072)
2025-12-13 03:58:32,050 INFO     Evaluating the model... (50500/59072)
2025-12-13 03:58:34,531 INFO     Evaluating the model... (51000/59072)
2025-12-13 03:58:37,500 INFO     Evaluating the model... (51500/59072)
2025-12-13 03:58:41,123 INFO     Evaluating the model... (52000/59072)
2025-12-13 03:58:43,752 INFO     Evaluating the model... (52500/59072)
2025-12-13 03:58:46,481 INFO     Evaluating the model... (53000/59072)
2025-12-13 03:58:49,136 INFO     Evaluating the model... (53500/59072)
2025-12-13 03:58:51,696 INFO     Evaluating the model... (54000/59072)
2025-12-13 03:58:55,108 INFO     Evaluating the model... (54500/59072)
2025-12-13 03:58:57,533 INFO     Evaluating the model... (55000/59072)
2025-12-13 03:59:00,150 INFO     Evaluating the model... (55500/59072)
2025-12-13 03:59:02,684 INFO     Evaluating the model... (56000/59072)
2025-12-13 03:59:05,190 INFO     Evaluating the model... (56500/59072)
2025-12-13 03:59:08,632 INFO     Evaluating the model... (57000/59072)
2025-12-13 03:59:11,414 INFO     Evaluating the model... (57500/59072)
2025-12-13 03:59:13,920 INFO     Evaluating the model... (58000/59072)
2025-12-13 03:59:16,471 INFO     Evaluating the model... (58500/59072)
2025-12-13 03:59:18,886 INFO     Evaluating the model... (59000/59072)
2025-12-13 03:59:19,518 INFO     Test MRR at step 200000: 0.630045
2025-12-13 03:59:19,518 INFO     Test MR at step 200000: 268.799733
2025-12-13 03:59:19,518 INFO     Test HITS@1 at step 200000: 0.542974
2025-12-13 03:59:19,518 INFO     Test HITS@3 at step 200000: 0.684397
2025-12-13 03:59:19,518 INFO     Test HITS@10 at step 200000: 0.782948
2025-12-13 03:59:21,678 INFO     Training average regularization at step 200100: 0.302053
2025-12-13 03:59:21,678 INFO     Training average positive_sample_loss at step 200100: 0.067455
2025-12-13 03:59:21,678 INFO     Training average negative_sample_loss at step 200100: 0.109180
2025-12-13 03:59:21,678 INFO     Training average loss at step 200100: 0.390370
2025-12-13 03:59:23,786 INFO     Training average regularization at step 200200: 0.302053
2025-12-13 03:59:23,787 INFO     Training average positive_sample_loss at step 200200: 0.067163
2025-12-13 03:59:23,787 INFO     Training average negative_sample_loss at step 200200: 0.110298
2025-12-13 03:59:23,787 INFO     Training average loss at step 200200: 0.390783
2025-12-13 03:59:25,919 INFO     Training average regularization at step 200300: 0.302053
2025-12-13 03:59:25,920 INFO     Training average positive_sample_loss at step 200300: 0.067091
2025-12-13 03:59:25,920 INFO     Training average negative_sample_loss at step 200300: 0.108926
2025-12-13 03:59:25,920 INFO     Training average loss at step 200300: 0.390061
2025-12-13 03:59:28,044 INFO     Training average regularization at step 200400: 0.302053
2025-12-13 03:59:28,044 INFO     Training average positive_sample_loss at step 200400: 0.066376
2025-12-13 03:59:28,044 INFO     Training average negative_sample_loss at step 200400: 0.109713
2025-12-13 03:59:28,044 INFO     Training average loss at step 200400: 0.390097
2025-12-13 03:59:30,166 INFO     Training average regularization at step 200500: 0.302053
2025-12-13 03:59:30,167 INFO     Training average positive_sample_loss at step 200500: 0.066664
2025-12-13 03:59:30,167 INFO     Training average negative_sample_loss at step 200500: 0.109162
2025-12-13 03:59:30,167 INFO     Training average loss at step 200500: 0.389966
2025-12-13 03:59:32,355 INFO     Training average regularization at step 200600: 0.302052
2025-12-13 03:59:32,355 INFO     Training average positive_sample_loss at step 200600: 0.064988
2025-12-13 03:59:32,355 INFO     Training average negative_sample_loss at step 200600: 0.108327
2025-12-13 03:59:32,355 INFO     Training average loss at step 200600: 0.388710
2025-12-13 03:59:34,513 INFO     Training average regularization at step 200700: 0.302052
2025-12-13 03:59:34,513 INFO     Training average positive_sample_loss at step 200700: 0.065775
2025-12-13 03:59:34,513 INFO     Training average negative_sample_loss at step 200700: 0.108225
2025-12-13 03:59:34,513 INFO     Training average loss at step 200700: 0.389052
2025-12-13 03:59:36,684 INFO     Training average regularization at step 200800: 0.302052
2025-12-13 03:59:36,684 INFO     Training average positive_sample_loss at step 200800: 0.067015
2025-12-13 03:59:36,684 INFO     Training average negative_sample_loss at step 200800: 0.108218
2025-12-13 03:59:36,684 INFO     Training average loss at step 200800: 0.389669
2025-12-13 03:59:38,873 INFO     Training average regularization at step 200900: 0.302052
2025-12-13 03:59:38,874 INFO     Training average positive_sample_loss at step 200900: 0.066357
2025-12-13 03:59:38,874 INFO     Training average negative_sample_loss at step 200900: 0.108843
2025-12-13 03:59:38,874 INFO     Training average loss at step 200900: 0.389652
2025-12-13 03:59:41,051 INFO     Training average regularization at step 201000: 0.302052
2025-12-13 03:59:41,051 INFO     Training average positive_sample_loss at step 201000: 0.066786
2025-12-13 03:59:41,051 INFO     Training average negative_sample_loss at step 201000: 0.107632
2025-12-13 03:59:41,052 INFO     Training average loss at step 201000: 0.389261
2025-12-13 03:59:43,264 INFO     Training average regularization at step 201100: 0.302052
2025-12-13 03:59:43,265 INFO     Training average positive_sample_loss at step 201100: 0.066426
2025-12-13 03:59:43,265 INFO     Training average negative_sample_loss at step 201100: 0.106996
2025-12-13 03:59:43,265 INFO     Training average loss at step 201100: 0.388763
2025-12-13 03:59:45,469 INFO     Training average regularization at step 201200: 0.302052
2025-12-13 03:59:45,469 INFO     Training average positive_sample_loss at step 201200: 0.065910
2025-12-13 03:59:45,469 INFO     Training average negative_sample_loss at step 201200: 0.109010
2025-12-13 03:59:45,469 INFO     Training average loss at step 201200: 0.389512
2025-12-13 03:59:47,648 INFO     Training average regularization at step 201300: 0.302052
2025-12-13 03:59:47,649 INFO     Training average positive_sample_loss at step 201300: 0.066872
2025-12-13 03:59:47,649 INFO     Training average negative_sample_loss at step 201300: 0.111126
2025-12-13 03:59:47,649 INFO     Training average loss at step 201300: 0.391051
2025-12-13 03:59:49,776 INFO     Training average regularization at step 201400: 0.302052
2025-12-13 03:59:49,780 INFO     Training average positive_sample_loss at step 201400: 0.065870
2025-12-13 03:59:49,780 INFO     Training average negative_sample_loss at step 201400: 0.111482
2025-12-13 03:59:49,780 INFO     Training average loss at step 201400: 0.390728
2025-12-13 03:59:51,888 INFO     Training average regularization at step 201500: 0.302052
2025-12-13 03:59:51,888 INFO     Training average positive_sample_loss at step 201500: 0.066911
2025-12-13 03:59:51,888 INFO     Training average negative_sample_loss at step 201500: 0.107690
2025-12-13 03:59:51,889 INFO     Training average loss at step 201500: 0.389352
2025-12-13 03:59:54,013 INFO     Training average regularization at step 201600: 0.302052
2025-12-13 03:59:54,014 INFO     Training average positive_sample_loss at step 201600: 0.065881
2025-12-13 03:59:54,014 INFO     Training average negative_sample_loss at step 201600: 0.110374
2025-12-13 03:59:54,014 INFO     Training average loss at step 201600: 0.390180
2025-12-13 03:59:56,176 INFO     Training average regularization at step 201700: 0.302052
2025-12-13 03:59:56,177 INFO     Training average positive_sample_loss at step 201700: 0.067675
2025-12-13 03:59:56,177 INFO     Training average negative_sample_loss at step 201700: 0.108921
2025-12-13 03:59:56,177 INFO     Training average loss at step 201700: 0.390350
2025-12-13 03:59:58,322 INFO     Training average regularization at step 201800: 0.302052
2025-12-13 03:59:58,323 INFO     Training average positive_sample_loss at step 201800: 0.066324
2025-12-13 03:59:58,323 INFO     Training average negative_sample_loss at step 201800: 0.107838
2025-12-13 03:59:58,323 INFO     Training average loss at step 201800: 0.389132
2025-12-13 04:00:00,442 INFO     Training average regularization at step 201900: 0.302052
2025-12-13 04:00:00,442 INFO     Training average positive_sample_loss at step 201900: 0.066152
2025-12-13 04:00:00,442 INFO     Training average negative_sample_loss at step 201900: 0.107662
2025-12-13 04:00:00,442 INFO     Training average loss at step 201900: 0.388958
2025-12-13 04:00:02,584 INFO     Training average regularization at step 202000: 0.302051
2025-12-13 04:00:02,585 INFO     Training average positive_sample_loss at step 202000: 0.066634
2025-12-13 04:00:02,585 INFO     Training average negative_sample_loss at step 202000: 0.107780
2025-12-13 04:00:02,585 INFO     Training average loss at step 202000: 0.389259
2025-12-13 04:00:04,720 INFO     Training average regularization at step 202100: 0.302051
2025-12-13 04:00:04,720 INFO     Training average positive_sample_loss at step 202100: 0.066560
2025-12-13 04:00:04,720 INFO     Training average negative_sample_loss at step 202100: 0.110455
2025-12-13 04:00:04,720 INFO     Training average loss at step 202100: 0.390559
2025-12-13 04:00:06,834 INFO     Training average regularization at step 202200: 0.302051
2025-12-13 04:00:06,834 INFO     Training average positive_sample_loss at step 202200: 0.066412
2025-12-13 04:00:06,834 INFO     Training average negative_sample_loss at step 202200: 0.111502
2025-12-13 04:00:06,834 INFO     Training average loss at step 202200: 0.391008
2025-12-13 04:00:08,983 INFO     Training average regularization at step 202300: 0.302051
2025-12-13 04:00:08,983 INFO     Training average positive_sample_loss at step 202300: 0.066968
2025-12-13 04:00:08,983 INFO     Training average negative_sample_loss at step 202300: 0.111014
2025-12-13 04:00:08,983 INFO     Training average loss at step 202300: 0.391042
2025-12-13 04:00:11,108 INFO     Training average regularization at step 202400: 0.302051
2025-12-13 04:00:11,109 INFO     Training average positive_sample_loss at step 202400: 0.067728
2025-12-13 04:00:11,109 INFO     Training average negative_sample_loss at step 202400: 0.109074
2025-12-13 04:00:11,109 INFO     Training average loss at step 202400: 0.390452
2025-12-13 04:00:13,244 INFO     Training average regularization at step 202500: 0.302051
2025-12-13 04:00:13,244 INFO     Training average positive_sample_loss at step 202500: 0.066698
2025-12-13 04:00:13,244 INFO     Training average negative_sample_loss at step 202500: 0.108076
2025-12-13 04:00:13,244 INFO     Training average loss at step 202500: 0.389438
2025-12-13 04:00:15,362 INFO     Training average regularization at step 202600: 0.302051
2025-12-13 04:00:15,362 INFO     Training average positive_sample_loss at step 202600: 0.066630
2025-12-13 04:00:15,362 INFO     Training average negative_sample_loss at step 202600: 0.107531
2025-12-13 04:00:15,362 INFO     Training average loss at step 202600: 0.389132
2025-12-13 04:00:17,504 INFO     Training average regularization at step 202700: 0.302051
2025-12-13 04:00:17,504 INFO     Training average positive_sample_loss at step 202700: 0.068197
2025-12-13 04:00:17,504 INFO     Training average negative_sample_loss at step 202700: 0.108041
2025-12-13 04:00:17,505 INFO     Training average loss at step 202700: 0.390170
2025-12-13 04:00:19,623 INFO     Training average regularization at step 202800: 0.302051
2025-12-13 04:00:19,623 INFO     Training average positive_sample_loss at step 202800: 0.067410
2025-12-13 04:00:19,623 INFO     Training average negative_sample_loss at step 202800: 0.109924
2025-12-13 04:00:19,623 INFO     Training average loss at step 202800: 0.390718
2025-12-13 04:00:21,741 INFO     Training average regularization at step 202900: 0.302051
2025-12-13 04:00:21,741 INFO     Training average positive_sample_loss at step 202900: 0.066295
2025-12-13 04:00:21,741 INFO     Training average negative_sample_loss at step 202900: 0.108414
2025-12-13 04:00:21,741 INFO     Training average loss at step 202900: 0.389406
2025-12-13 04:00:25,306 INFO     Training average regularization at step 203000: 0.302051
2025-12-13 04:00:25,306 INFO     Training average positive_sample_loss at step 203000: 0.068309
2025-12-13 04:00:25,307 INFO     Training average negative_sample_loss at step 203000: 0.107928
2025-12-13 04:00:25,307 INFO     Training average loss at step 203000: 0.390169
2025-12-13 04:00:27,492 INFO     Training average regularization at step 203100: 0.302051
2025-12-13 04:00:27,493 INFO     Training average positive_sample_loss at step 203100: 0.069051
2025-12-13 04:00:27,493 INFO     Training average negative_sample_loss at step 203100: 0.111445
2025-12-13 04:00:27,493 INFO     Training average loss at step 203100: 0.392299
2025-12-13 04:00:29,663 INFO     Training average regularization at step 203200: 0.302051
2025-12-13 04:00:29,663 INFO     Training average positive_sample_loss at step 203200: 0.067022
2025-12-13 04:00:29,663 INFO     Training average negative_sample_loss at step 203200: 0.107448
2025-12-13 04:00:29,663 INFO     Training average loss at step 203200: 0.389286
2025-12-13 04:00:31,810 INFO     Training average regularization at step 203300: 0.302051
2025-12-13 04:00:31,810 INFO     Training average positive_sample_loss at step 203300: 0.066538
2025-12-13 04:00:31,810 INFO     Training average negative_sample_loss at step 203300: 0.108754
2025-12-13 04:00:31,810 INFO     Training average loss at step 203300: 0.389697
2025-12-13 04:00:33,906 INFO     Training average regularization at step 203400: 0.302051
2025-12-13 04:00:33,907 INFO     Training average positive_sample_loss at step 203400: 0.066341
2025-12-13 04:00:33,907 INFO     Training average negative_sample_loss at step 203400: 0.109081
2025-12-13 04:00:33,907 INFO     Training average loss at step 203400: 0.389762
2025-12-13 04:00:36,095 INFO     Training average regularization at step 203500: 0.302051
2025-12-13 04:00:36,095 INFO     Training average positive_sample_loss at step 203500: 0.066066
2025-12-13 04:00:36,095 INFO     Training average negative_sample_loss at step 203500: 0.110156
2025-12-13 04:00:36,095 INFO     Training average loss at step 203500: 0.390162
2025-12-13 04:00:38,335 INFO     Training average regularization at step 203600: 0.302050
2025-12-13 04:00:38,335 INFO     Training average positive_sample_loss at step 203600: 0.066777
2025-12-13 04:00:38,335 INFO     Training average negative_sample_loss at step 203600: 0.107170
2025-12-13 04:00:38,335 INFO     Training average loss at step 203600: 0.389024
2025-12-13 04:00:40,499 INFO     Training average regularization at step 203700: 0.302050
2025-12-13 04:00:40,499 INFO     Training average positive_sample_loss at step 203700: 0.067097
2025-12-13 04:00:40,499 INFO     Training average negative_sample_loss at step 203700: 0.110127
2025-12-13 04:00:40,499 INFO     Training average loss at step 203700: 0.390663
2025-12-13 04:00:42,686 INFO     Training average regularization at step 203800: 0.302050
2025-12-13 04:00:42,686 INFO     Training average positive_sample_loss at step 203800: 0.067258
2025-12-13 04:00:42,686 INFO     Training average negative_sample_loss at step 203800: 0.111547
2025-12-13 04:00:42,686 INFO     Training average loss at step 203800: 0.391453
2025-12-13 04:00:44,881 INFO     Training average regularization at step 203900: 0.302050
2025-12-13 04:00:44,881 INFO     Training average positive_sample_loss at step 203900: 0.066454
2025-12-13 04:00:44,881 INFO     Training average negative_sample_loss at step 203900: 0.107293
2025-12-13 04:00:44,881 INFO     Training average loss at step 203900: 0.388924
2025-12-13 04:00:47,038 INFO     Training average regularization at step 204000: 0.302050
2025-12-13 04:00:47,052 INFO     Training average positive_sample_loss at step 204000: 0.067313
2025-12-13 04:00:47,053 INFO     Training average negative_sample_loss at step 204000: 0.110171
2025-12-13 04:00:47,053 INFO     Training average loss at step 204000: 0.390792
2025-12-13 04:00:49,146 INFO     Training average regularization at step 204100: 0.302050
2025-12-13 04:00:49,146 INFO     Training average positive_sample_loss at step 204100: 0.067174
2025-12-13 04:00:49,146 INFO     Training average negative_sample_loss at step 204100: 0.107972
2025-12-13 04:00:49,146 INFO     Training average loss at step 204100: 0.389623
2025-12-13 04:00:51,284 INFO     Training average regularization at step 204200: 0.302050
2025-12-13 04:00:51,284 INFO     Training average positive_sample_loss at step 204200: 0.066987
2025-12-13 04:00:51,284 INFO     Training average negative_sample_loss at step 204200: 0.109140
2025-12-13 04:00:51,284 INFO     Training average loss at step 204200: 0.390113
2025-12-13 04:00:53,397 INFO     Training average regularization at step 204300: 0.302050
2025-12-13 04:00:53,397 INFO     Training average positive_sample_loss at step 204300: 0.066180
2025-12-13 04:00:53,397 INFO     Training average negative_sample_loss at step 204300: 0.107947
2025-12-13 04:00:53,397 INFO     Training average loss at step 204300: 0.389113
2025-12-13 04:00:55,521 INFO     Training average regularization at step 204400: 0.302050
2025-12-13 04:00:55,521 INFO     Training average positive_sample_loss at step 204400: 0.066627
2025-12-13 04:00:55,521 INFO     Training average negative_sample_loss at step 204400: 0.110348
2025-12-13 04:00:55,521 INFO     Training average loss at step 204400: 0.390537
2025-12-13 04:00:57,676 INFO     Training average regularization at step 204500: 0.302050
2025-12-13 04:00:57,676 INFO     Training average positive_sample_loss at step 204500: 0.067038
2025-12-13 04:00:57,676 INFO     Training average negative_sample_loss at step 204500: 0.109146
2025-12-13 04:00:57,676 INFO     Training average loss at step 204500: 0.390142
2025-12-13 04:00:59,837 INFO     Training average regularization at step 204600: 0.302050
2025-12-13 04:00:59,837 INFO     Training average positive_sample_loss at step 204600: 0.066624
2025-12-13 04:00:59,837 INFO     Training average negative_sample_loss at step 204600: 0.107069
2025-12-13 04:00:59,837 INFO     Training average loss at step 204600: 0.388897
2025-12-13 04:01:01,977 INFO     Training average regularization at step 204700: 0.302050
2025-12-13 04:01:01,977 INFO     Training average positive_sample_loss at step 204700: 0.065638
2025-12-13 04:01:01,977 INFO     Training average negative_sample_loss at step 204700: 0.109400
2025-12-13 04:01:01,977 INFO     Training average loss at step 204700: 0.389568
2025-12-13 04:01:04,087 INFO     Training average regularization at step 204800: 0.302050
2025-12-13 04:01:04,087 INFO     Training average positive_sample_loss at step 204800: 0.065946
2025-12-13 04:01:04,087 INFO     Training average negative_sample_loss at step 204800: 0.110626
2025-12-13 04:01:04,087 INFO     Training average loss at step 204800: 0.390336
2025-12-13 04:01:06,244 INFO     Training average regularization at step 204900: 0.302050
2025-12-13 04:01:06,244 INFO     Training average positive_sample_loss at step 204900: 0.066975
2025-12-13 04:01:06,244 INFO     Training average negative_sample_loss at step 204900: 0.108756
2025-12-13 04:01:06,244 INFO     Training average loss at step 204900: 0.389915
2025-12-13 04:01:08,366 INFO     Training average regularization at step 205000: 0.302049
2025-12-13 04:01:08,367 INFO     Training average positive_sample_loss at step 205000: 0.065963
2025-12-13 04:01:08,367 INFO     Training average negative_sample_loss at step 205000: 0.109432
2025-12-13 04:01:08,367 INFO     Training average loss at step 205000: 0.389747
2025-12-13 04:01:10,471 INFO     Training average regularization at step 205100: 0.302049
2025-12-13 04:01:10,471 INFO     Training average positive_sample_loss at step 205100: 0.065887
2025-12-13 04:01:10,471 INFO     Training average negative_sample_loss at step 205100: 0.107177
2025-12-13 04:01:10,471 INFO     Training average loss at step 205100: 0.388581
2025-12-13 04:01:12,623 INFO     Training average regularization at step 205200: 0.302049
2025-12-13 04:01:12,623 INFO     Training average positive_sample_loss at step 205200: 0.066409
2025-12-13 04:01:12,623 INFO     Training average negative_sample_loss at step 205200: 0.108156
2025-12-13 04:01:12,623 INFO     Training average loss at step 205200: 0.389332
2025-12-13 04:01:14,740 INFO     Training average regularization at step 205300: 0.302049
2025-12-13 04:01:14,741 INFO     Training average positive_sample_loss at step 205300: 0.066621
2025-12-13 04:01:14,741 INFO     Training average negative_sample_loss at step 205300: 0.108999
2025-12-13 04:01:14,741 INFO     Training average loss at step 205300: 0.389859
2025-12-13 04:01:16,895 INFO     Training average regularization at step 205400: 0.302049
2025-12-13 04:01:16,895 INFO     Training average positive_sample_loss at step 205400: 0.067790
2025-12-13 04:01:16,895 INFO     Training average negative_sample_loss at step 205400: 0.108912
2025-12-13 04:01:16,895 INFO     Training average loss at step 205400: 0.390400
2025-12-13 04:01:19,032 INFO     Training average regularization at step 205500: 0.302049
2025-12-13 04:01:19,032 INFO     Training average positive_sample_loss at step 205500: 0.066257
2025-12-13 04:01:19,033 INFO     Training average negative_sample_loss at step 205500: 0.105992
2025-12-13 04:01:19,033 INFO     Training average loss at step 205500: 0.388174
2025-12-13 04:01:21,154 INFO     Training average regularization at step 205600: 0.302049
2025-12-13 04:01:21,154 INFO     Training average positive_sample_loss at step 205600: 0.066634
2025-12-13 04:01:21,154 INFO     Training average negative_sample_loss at step 205600: 0.107665
2025-12-13 04:01:21,154 INFO     Training average loss at step 205600: 0.389199
2025-12-13 04:01:23,292 INFO     Training average regularization at step 205700: 0.302049
2025-12-13 04:01:23,292 INFO     Training average positive_sample_loss at step 205700: 0.066211
2025-12-13 04:01:23,292 INFO     Training average negative_sample_loss at step 205700: 0.107954
2025-12-13 04:01:23,292 INFO     Training average loss at step 205700: 0.389132
2025-12-13 04:01:25,468 INFO     Training average regularization at step 205800: 0.302049
2025-12-13 04:01:25,469 INFO     Training average positive_sample_loss at step 205800: 0.066924
2025-12-13 04:01:25,469 INFO     Training average negative_sample_loss at step 205800: 0.108841
2025-12-13 04:01:25,469 INFO     Training average loss at step 205800: 0.389931
2025-12-13 04:01:27,651 INFO     Training average regularization at step 205900: 0.302049
2025-12-13 04:01:27,651 INFO     Training average positive_sample_loss at step 205900: 0.066690
2025-12-13 04:01:27,651 INFO     Training average negative_sample_loss at step 205900: 0.109321
2025-12-13 04:01:27,651 INFO     Training average loss at step 205900: 0.390054
2025-12-13 04:01:29,756 INFO     Training average regularization at step 206000: 0.302049
2025-12-13 04:01:29,756 INFO     Training average positive_sample_loss at step 206000: 0.066648
2025-12-13 04:01:29,756 INFO     Training average negative_sample_loss at step 206000: 0.107927
2025-12-13 04:01:29,756 INFO     Training average loss at step 206000: 0.389336
2025-12-13 04:01:31,888 INFO     Training average regularization at step 206100: 0.302049
2025-12-13 04:01:31,888 INFO     Training average positive_sample_loss at step 206100: 0.066120
2025-12-13 04:01:31,888 INFO     Training average negative_sample_loss at step 206100: 0.107897
2025-12-13 04:01:31,888 INFO     Training average loss at step 206100: 0.389058
2025-12-13 04:01:34,075 INFO     Training average regularization at step 206200: 0.302049
2025-12-13 04:01:34,075 INFO     Training average positive_sample_loss at step 206200: 0.065560
2025-12-13 04:01:34,075 INFO     Training average negative_sample_loss at step 206200: 0.108985
2025-12-13 04:01:34,075 INFO     Training average loss at step 206200: 0.389321
2025-12-13 04:01:36,254 INFO     Training average regularization at step 206300: 0.302049
2025-12-13 04:01:36,254 INFO     Training average positive_sample_loss at step 206300: 0.066672
2025-12-13 04:01:36,254 INFO     Training average negative_sample_loss at step 206300: 0.106065
2025-12-13 04:01:36,254 INFO     Training average loss at step 206300: 0.388417
2025-12-13 04:01:38,457 INFO     Training average regularization at step 206400: 0.302049
2025-12-13 04:01:38,457 INFO     Training average positive_sample_loss at step 206400: 0.067422
2025-12-13 04:01:38,458 INFO     Training average negative_sample_loss at step 206400: 0.109065
2025-12-13 04:01:38,458 INFO     Training average loss at step 206400: 0.390292
2025-12-13 04:01:40,609 INFO     Training average regularization at step 206500: 0.302048
2025-12-13 04:01:40,610 INFO     Training average positive_sample_loss at step 206500: 0.067294
2025-12-13 04:01:40,610 INFO     Training average negative_sample_loss at step 206500: 0.110687
2025-12-13 04:01:40,610 INFO     Training average loss at step 206500: 0.391039
2025-12-13 04:01:42,771 INFO     Training average regularization at step 206600: 0.302048
2025-12-13 04:01:42,771 INFO     Training average positive_sample_loss at step 206600: 0.066994
2025-12-13 04:01:42,771 INFO     Training average negative_sample_loss at step 206600: 0.109537
2025-12-13 04:01:42,771 INFO     Training average loss at step 206600: 0.390314
2025-12-13 04:01:45,001 INFO     Training average regularization at step 206700: 0.302048
2025-12-13 04:01:45,001 INFO     Training average positive_sample_loss at step 206700: 0.067363
2025-12-13 04:01:45,001 INFO     Training average negative_sample_loss at step 206700: 0.108087
2025-12-13 04:01:45,001 INFO     Training average loss at step 206700: 0.389773
2025-12-13 04:01:47,203 INFO     Training average regularization at step 206800: 0.302048
2025-12-13 04:01:47,203 INFO     Training average positive_sample_loss at step 206800: 0.066866
2025-12-13 04:01:47,203 INFO     Training average negative_sample_loss at step 206800: 0.109560
2025-12-13 04:01:47,203 INFO     Training average loss at step 206800: 0.390262
2025-12-13 04:01:49,318 INFO     Training average regularization at step 206900: 0.302048
2025-12-13 04:01:49,319 INFO     Training average positive_sample_loss at step 206900: 0.067271
2025-12-13 04:01:49,319 INFO     Training average negative_sample_loss at step 206900: 0.109783
2025-12-13 04:01:49,319 INFO     Training average loss at step 206900: 0.390575
2025-12-13 04:01:51,448 INFO     Training average regularization at step 207000: 0.302048
2025-12-13 04:01:51,451 INFO     Training average positive_sample_loss at step 207000: 0.066471
2025-12-13 04:01:51,451 INFO     Training average negative_sample_loss at step 207000: 0.109736
2025-12-13 04:01:51,451 INFO     Training average loss at step 207000: 0.390152
2025-12-13 04:01:53,560 INFO     Training average regularization at step 207100: 0.302048
2025-12-13 04:01:53,560 INFO     Training average positive_sample_loss at step 207100: 0.066213
2025-12-13 04:01:53,560 INFO     Training average negative_sample_loss at step 207100: 0.108338
2025-12-13 04:01:53,560 INFO     Training average loss at step 207100: 0.389324
2025-12-13 04:01:55,686 INFO     Training average regularization at step 207200: 0.302048
2025-12-13 04:01:55,686 INFO     Training average positive_sample_loss at step 207200: 0.065854
2025-12-13 04:01:55,687 INFO     Training average negative_sample_loss at step 207200: 0.110058
2025-12-13 04:01:55,687 INFO     Training average loss at step 207200: 0.390004
2025-12-13 04:01:57,814 INFO     Training average regularization at step 207300: 0.302048
2025-12-13 04:01:57,814 INFO     Training average positive_sample_loss at step 207300: 0.066451
2025-12-13 04:01:57,814 INFO     Training average negative_sample_loss at step 207300: 0.111248
2025-12-13 04:01:57,814 INFO     Training average loss at step 207300: 0.390898
2025-12-13 04:01:59,932 INFO     Training average regularization at step 207400: 0.302048
2025-12-13 04:01:59,932 INFO     Training average positive_sample_loss at step 207400: 0.066906
2025-12-13 04:01:59,933 INFO     Training average negative_sample_loss at step 207400: 0.109503
2025-12-13 04:01:59,933 INFO     Training average loss at step 207400: 0.390253
2025-12-13 04:02:02,041 INFO     Training average regularization at step 207500: 0.302048
2025-12-13 04:02:02,041 INFO     Training average positive_sample_loss at step 207500: 0.066416
2025-12-13 04:02:02,041 INFO     Training average negative_sample_loss at step 207500: 0.109785
2025-12-13 04:02:02,041 INFO     Training average loss at step 207500: 0.390148
2025-12-13 04:02:04,155 INFO     Training average regularization at step 207600: 0.302048
2025-12-13 04:02:04,155 INFO     Training average positive_sample_loss at step 207600: 0.066671
2025-12-13 04:02:04,155 INFO     Training average negative_sample_loss at step 207600: 0.108881
2025-12-13 04:02:04,155 INFO     Training average loss at step 207600: 0.389824
2025-12-13 04:02:06,284 INFO     Training average regularization at step 207700: 0.302048
2025-12-13 04:02:06,284 INFO     Training average positive_sample_loss at step 207700: 0.067255
2025-12-13 04:02:06,285 INFO     Training average negative_sample_loss at step 207700: 0.109014
2025-12-13 04:02:06,285 INFO     Training average loss at step 207700: 0.390182
2025-12-13 04:02:09,899 INFO     Training average regularization at step 207800: 0.302048
2025-12-13 04:02:09,899 INFO     Training average positive_sample_loss at step 207800: 0.066394
2025-12-13 04:02:09,899 INFO     Training average negative_sample_loss at step 207800: 0.108367
2025-12-13 04:02:09,900 INFO     Training average loss at step 207800: 0.389428
2025-12-13 04:02:12,009 INFO     Training average regularization at step 207900: 0.302048
2025-12-13 04:02:12,010 INFO     Training average positive_sample_loss at step 207900: 0.065721
2025-12-13 04:02:12,010 INFO     Training average negative_sample_loss at step 207900: 0.109437
2025-12-13 04:02:12,010 INFO     Training average loss at step 207900: 0.389626
2025-12-13 04:02:14,183 INFO     Training average regularization at step 208000: 0.302048
2025-12-13 04:02:14,184 INFO     Training average positive_sample_loss at step 208000: 0.066989
2025-12-13 04:02:14,184 INFO     Training average negative_sample_loss at step 208000: 0.106522
2025-12-13 04:02:14,184 INFO     Training average loss at step 208000: 0.388803
2025-12-13 04:02:16,314 INFO     Training average regularization at step 208100: 0.302047
2025-12-13 04:02:16,314 INFO     Training average positive_sample_loss at step 208100: 0.065403
2025-12-13 04:02:16,315 INFO     Training average negative_sample_loss at step 208100: 0.106562
2025-12-13 04:02:16,315 INFO     Training average loss at step 208100: 0.388030
2025-12-13 04:02:18,490 INFO     Training average regularization at step 208200: 0.302047
2025-12-13 04:02:18,490 INFO     Training average positive_sample_loss at step 208200: 0.067439
2025-12-13 04:02:18,490 INFO     Training average negative_sample_loss at step 208200: 0.107716
2025-12-13 04:02:18,490 INFO     Training average loss at step 208200: 0.389625
2025-12-13 04:02:20,665 INFO     Training average regularization at step 208300: 0.302047
2025-12-13 04:02:20,665 INFO     Training average positive_sample_loss at step 208300: 0.066601
2025-12-13 04:02:20,665 INFO     Training average negative_sample_loss at step 208300: 0.109328
2025-12-13 04:02:20,665 INFO     Training average loss at step 208300: 0.390012
2025-12-13 04:02:22,762 INFO     Training average regularization at step 208400: 0.302047
2025-12-13 04:02:22,762 INFO     Training average positive_sample_loss at step 208400: 0.066466
2025-12-13 04:02:22,762 INFO     Training average negative_sample_loss at step 208400: 0.115224
2025-12-13 04:02:22,762 INFO     Training average loss at step 208400: 0.392892
2025-12-13 04:02:24,901 INFO     Training average regularization at step 208500: 0.302047
2025-12-13 04:02:24,901 INFO     Training average positive_sample_loss at step 208500: 0.067285
2025-12-13 04:02:24,901 INFO     Training average negative_sample_loss at step 208500: 0.112509
2025-12-13 04:02:24,901 INFO     Training average loss at step 208500: 0.391944
2025-12-13 04:02:27,077 INFO     Training average regularization at step 208600: 0.302047
2025-12-13 04:02:27,077 INFO     Training average positive_sample_loss at step 208600: 0.066803
2025-12-13 04:02:27,077 INFO     Training average negative_sample_loss at step 208600: 0.107521
2025-12-13 04:02:27,077 INFO     Training average loss at step 208600: 0.389209
2025-12-13 04:02:29,230 INFO     Training average regularization at step 208700: 0.302047
2025-12-13 04:02:29,230 INFO     Training average positive_sample_loss at step 208700: 0.066895
2025-12-13 04:02:29,230 INFO     Training average negative_sample_loss at step 208700: 0.109236
2025-12-13 04:02:29,230 INFO     Training average loss at step 208700: 0.390112
2025-12-13 04:02:31,400 INFO     Training average regularization at step 208800: 0.302047
2025-12-13 04:02:31,400 INFO     Training average positive_sample_loss at step 208800: 0.065954
2025-12-13 04:02:31,400 INFO     Training average negative_sample_loss at step 208800: 0.107666
2025-12-13 04:02:31,400 INFO     Training average loss at step 208800: 0.388857
2025-12-13 04:02:33,558 INFO     Training average regularization at step 208900: 0.302047
2025-12-13 04:02:33,559 INFO     Training average positive_sample_loss at step 208900: 0.065853
2025-12-13 04:02:33,559 INFO     Training average negative_sample_loss at step 208900: 0.106951
2025-12-13 04:02:33,559 INFO     Training average loss at step 208900: 0.388449
2025-12-13 04:02:35,731 INFO     Training average regularization at step 209000: 0.302047
2025-12-13 04:02:35,731 INFO     Training average positive_sample_loss at step 209000: 0.066143
2025-12-13 04:02:35,732 INFO     Training average negative_sample_loss at step 209000: 0.106726
2025-12-13 04:02:35,732 INFO     Training average loss at step 209000: 0.388481
2025-12-13 04:02:37,924 INFO     Training average regularization at step 209100: 0.302047
2025-12-13 04:02:37,925 INFO     Training average positive_sample_loss at step 209100: 0.067830
2025-12-13 04:02:37,925 INFO     Training average negative_sample_loss at step 209100: 0.108024
2025-12-13 04:02:37,925 INFO     Training average loss at step 209100: 0.389973
2025-12-13 04:02:40,148 INFO     Training average regularization at step 209200: 0.302047
2025-12-13 04:02:40,148 INFO     Training average positive_sample_loss at step 209200: 0.066674
2025-12-13 04:02:40,148 INFO     Training average negative_sample_loss at step 209200: 0.108619
2025-12-13 04:02:40,148 INFO     Training average loss at step 209200: 0.389693
2025-12-13 04:02:42,372 INFO     Training average regularization at step 209300: 0.302047
2025-12-13 04:02:42,372 INFO     Training average positive_sample_loss at step 209300: 0.067488
2025-12-13 04:02:42,372 INFO     Training average negative_sample_loss at step 209300: 0.108632
2025-12-13 04:02:42,372 INFO     Training average loss at step 209300: 0.390107
2025-12-13 04:02:44,550 INFO     Training average regularization at step 209400: 0.302046
2025-12-13 04:02:44,551 INFO     Training average positive_sample_loss at step 209400: 0.066177
2025-12-13 04:02:44,551 INFO     Training average negative_sample_loss at step 209400: 0.106871
2025-12-13 04:02:44,551 INFO     Training average loss at step 209400: 0.388571
2025-12-13 04:02:46,729 INFO     Training average regularization at step 209500: 0.302046
2025-12-13 04:02:46,729 INFO     Training average positive_sample_loss at step 209500: 0.067012
2025-12-13 04:02:46,729 INFO     Training average negative_sample_loss at step 209500: 0.108553
2025-12-13 04:02:46,729 INFO     Training average loss at step 209500: 0.389829
2025-12-13 04:02:48,902 INFO     Training average regularization at step 209600: 0.302046
2025-12-13 04:02:48,903 INFO     Training average positive_sample_loss at step 209600: 0.067546
2025-12-13 04:02:48,903 INFO     Training average negative_sample_loss at step 209600: 0.111129
2025-12-13 04:02:48,903 INFO     Training average loss at step 209600: 0.391384
2025-12-13 04:02:51,080 INFO     Training average regularization at step 209700: 0.302046
2025-12-13 04:02:51,080 INFO     Training average positive_sample_loss at step 209700: 0.067089
2025-12-13 04:02:51,080 INFO     Training average negative_sample_loss at step 209700: 0.108171
2025-12-13 04:02:51,080 INFO     Training average loss at step 209700: 0.389677
2025-12-13 04:02:53,239 INFO     Training average regularization at step 209800: 0.302046
2025-12-13 04:02:53,239 INFO     Training average positive_sample_loss at step 209800: 0.066050
2025-12-13 04:02:53,239 INFO     Training average negative_sample_loss at step 209800: 0.107293
2025-12-13 04:02:53,239 INFO     Training average loss at step 209800: 0.388718
2025-12-13 04:02:55,399 INFO     Training average regularization at step 209900: 0.302046
2025-12-13 04:02:55,400 INFO     Training average positive_sample_loss at step 209900: 0.066847
2025-12-13 04:02:55,400 INFO     Training average negative_sample_loss at step 209900: 0.109181
2025-12-13 04:02:55,400 INFO     Training average loss at step 209900: 0.390060
2025-12-13 04:02:57,559 INFO     Training average regularization at step 210000: 0.302046
2025-12-13 04:02:57,560 INFO     Training average positive_sample_loss at step 210000: 0.066583
2025-12-13 04:02:57,560 INFO     Training average negative_sample_loss at step 210000: 0.108467
2025-12-13 04:02:57,560 INFO     Training average loss at step 210000: 0.389571
2025-12-13 04:02:57,560 INFO     Evaluating on Valid Dataset...
2025-12-13 04:02:58,333 INFO     Evaluating the model... (0/50000)
2025-12-13 04:03:01,136 INFO     Evaluating the model... (500/50000)
2025-12-13 04:03:03,786 INFO     Evaluating the model... (1000/50000)
2025-12-13 04:03:06,441 INFO     Evaluating the model... (1500/50000)
2025-12-13 04:03:08,974 INFO     Evaluating the model... (2000/50000)
2025-12-13 04:03:12,027 INFO     Evaluating the model... (2500/50000)
2025-12-13 04:03:14,552 INFO     Evaluating the model... (3000/50000)
2025-12-13 04:03:17,098 INFO     Evaluating the model... (3500/50000)
2025-12-13 04:03:19,469 INFO     Evaluating the model... (4000/50000)
2025-12-13 04:03:21,930 INFO     Evaluating the model... (4500/50000)
2025-12-13 04:03:25,105 INFO     Evaluating the model... (5000/50000)
2025-12-13 04:03:27,531 INFO     Evaluating the model... (5500/50000)
2025-12-13 04:03:29,875 INFO     Evaluating the model... (6000/50000)
2025-12-13 04:03:32,267 INFO     Evaluating the model... (6500/50000)
2025-12-13 04:03:34,637 INFO     Evaluating the model... (7000/50000)
2025-12-13 04:03:38,306 INFO     Evaluating the model... (7500/50000)
2025-12-13 04:03:40,957 INFO     Evaluating the model... (8000/50000)
2025-12-13 04:03:43,535 INFO     Evaluating the model... (8500/50000)
2025-12-13 04:03:46,103 INFO     Evaluating the model... (9000/50000)
2025-12-13 04:03:48,745 INFO     Evaluating the model... (9500/50000)
2025-12-13 04:03:52,323 INFO     Evaluating the model... (10000/50000)
2025-12-13 04:03:54,742 INFO     Evaluating the model... (10500/50000)
2025-12-13 04:03:57,302 INFO     Evaluating the model... (11000/50000)
2025-12-13 04:03:59,923 INFO     Evaluating the model... (11500/50000)
2025-12-13 04:04:02,366 INFO     Evaluating the model... (12000/50000)
2025-12-13 04:04:05,874 INFO     Evaluating the model... (12500/50000)
2025-12-13 04:04:08,410 INFO     Evaluating the model... (13000/50000)
2025-12-13 04:04:11,047 INFO     Evaluating the model... (13500/50000)
2025-12-13 04:04:13,448 INFO     Evaluating the model... (14000/50000)
2025-12-13 04:04:15,975 INFO     Evaluating the model... (14500/50000)
2025-12-13 04:04:19,764 INFO     Evaluating the model... (15000/50000)
2025-12-13 04:04:22,372 INFO     Evaluating the model... (15500/50000)
2025-12-13 04:04:24,900 INFO     Evaluating the model... (16000/50000)
2025-12-13 04:04:27,314 INFO     Evaluating the model... (16500/50000)
2025-12-13 04:04:29,704 INFO     Evaluating the model... (17000/50000)
2025-12-13 04:04:33,668 INFO     Evaluating the model... (17500/50000)
2025-12-13 04:04:36,386 INFO     Evaluating the model... (18000/50000)
2025-12-13 04:04:39,079 INFO     Evaluating the model... (18500/50000)
2025-12-13 04:04:41,723 INFO     Evaluating the model... (19000/50000)
2025-12-13 04:04:45,252 INFO     Evaluating the model... (19500/50000)
2025-12-13 04:04:48,345 INFO     Evaluating the model... (20000/50000)
2025-12-13 04:04:50,740 INFO     Evaluating the model... (20500/50000)
2025-12-13 04:04:53,160 INFO     Evaluating the model... (21000/50000)
2025-12-13 04:04:55,507 INFO     Evaluating the model... (21500/50000)
2025-12-13 04:04:59,588 INFO     Evaluating the model... (22000/50000)
2025-12-13 04:05:01,958 INFO     Evaluating the model... (22500/50000)
2025-12-13 04:05:04,239 INFO     Evaluating the model... (23000/50000)
2025-12-13 04:05:06,740 INFO     Evaluating the model... (23500/50000)
2025-12-13 04:05:09,455 INFO     Evaluating the model... (24000/50000)
2025-12-13 04:05:13,090 INFO     Evaluating the model... (24500/50000)
2025-12-13 04:05:15,886 INFO     Evaluating the model... (25000/50000)
2025-12-13 04:05:18,344 INFO     Evaluating the model... (25500/50000)
2025-12-13 04:05:21,085 INFO     Evaluating the model... (26000/50000)
2025-12-13 04:05:23,731 INFO     Evaluating the model... (26500/50000)
2025-12-13 04:05:26,649 INFO     Evaluating the model... (27000/50000)
2025-12-13 04:05:29,862 INFO     Evaluating the model... (27500/50000)
2025-12-13 04:05:32,577 INFO     Evaluating the model... (28000/50000)
2025-12-13 04:05:35,189 INFO     Evaluating the model... (28500/50000)
2025-12-13 04:05:37,962 INFO     Evaluating the model... (29000/50000)
2025-12-13 04:05:41,287 INFO     Evaluating the model... (29500/50000)
2025-12-13 04:05:44,243 INFO     Evaluating the model... (30000/50000)
2025-12-13 04:05:46,917 INFO     Evaluating the model... (30500/50000)
2025-12-13 04:05:49,423 INFO     Evaluating the model... (31000/50000)
2025-12-13 04:05:52,035 INFO     Evaluating the model... (31500/50000)
2025-12-13 04:05:55,157 INFO     Evaluating the model... (32000/50000)
2025-12-13 04:05:57,686 INFO     Evaluating the model... (32500/50000)
2025-12-13 04:06:00,182 INFO     Evaluating the model... (33000/50000)
2025-12-13 04:06:02,620 INFO     Evaluating the model... (33500/50000)
2025-12-13 04:06:05,202 INFO     Evaluating the model... (34000/50000)
2025-12-13 04:06:08,710 INFO     Evaluating the model... (34500/50000)
2025-12-13 04:06:11,135 INFO     Evaluating the model... (35000/50000)
2025-12-13 04:06:13,637 INFO     Evaluating the model... (35500/50000)
2025-12-13 04:06:16,165 INFO     Evaluating the model... (36000/50000)
2025-12-13 04:06:18,793 INFO     Evaluating the model... (36500/50000)
2025-12-13 04:06:22,000 INFO     Evaluating the model... (37000/50000)
2025-12-13 04:06:24,426 INFO     Evaluating the model... (37500/50000)
2025-12-13 04:06:26,971 INFO     Evaluating the model... (38000/50000)
2025-12-13 04:06:29,707 INFO     Evaluating the model... (38500/50000)
2025-12-13 04:06:32,203 INFO     Evaluating the model... (39000/50000)
2025-12-13 04:06:35,485 INFO     Evaluating the model... (39500/50000)
2025-12-13 04:06:38,307 INFO     Evaluating the model... (40000/50000)
2025-12-13 04:06:41,268 INFO     Evaluating the model... (40500/50000)
2025-12-13 04:06:44,049 INFO     Evaluating the model... (41000/50000)
2025-12-13 04:06:46,712 INFO     Evaluating the model... (41500/50000)
2025-12-13 04:06:50,033 INFO     Evaluating the model... (42000/50000)
2025-12-13 04:06:52,737 INFO     Evaluating the model... (42500/50000)
2025-12-13 04:06:55,306 INFO     Evaluating the model... (43000/50000)
2025-12-13 04:06:57,837 INFO     Evaluating the model... (43500/50000)
2025-12-13 04:07:00,318 INFO     Evaluating the model... (44000/50000)
2025-12-13 04:07:03,861 INFO     Evaluating the model... (44500/50000)
2025-12-13 04:07:06,460 INFO     Evaluating the model... (45000/50000)
2025-12-13 04:07:08,977 INFO     Evaluating the model... (45500/50000)
2025-12-13 04:07:11,433 INFO     Evaluating the model... (46000/50000)
2025-12-13 04:07:13,965 INFO     Evaluating the model... (46500/50000)
2025-12-13 04:07:17,485 INFO     Evaluating the model... (47000/50000)
2025-12-13 04:07:20,051 INFO     Evaluating the model... (47500/50000)
2025-12-13 04:07:22,607 INFO     Evaluating the model... (48000/50000)
2025-12-13 04:07:25,158 INFO     Evaluating the model... (48500/50000)
2025-12-13 04:07:28,790 INFO     Evaluating the model... (49000/50000)
2025-12-13 04:07:31,376 INFO     Evaluating the model... (49500/50000)
2025-12-13 04:07:34,207 INFO     Valid MRR at step 210000: 0.633273
2025-12-13 04:07:34,207 INFO     Valid MR at step 210000: 266.843490
2025-12-13 04:07:34,207 INFO     Valid HITS@1 at step 210000: 0.547710
2025-12-13 04:07:34,207 INFO     Valid HITS@3 at step 210000: 0.686000
2025-12-13 04:07:34,207 INFO     Valid HITS@10 at step 210000: 0.784780
2025-12-13 04:07:35,486 INFO     Evaluating on Test Dataset...
2025-12-13 04:07:36,042 INFO     Evaluating the model... (0/59072)
2025-12-13 04:07:38,987 INFO     Evaluating the model... (500/59072)
2025-12-13 04:07:41,590 INFO     Evaluating the model... (1000/59072)
2025-12-13 04:07:44,382 INFO     Evaluating the model... (1500/59072)
2025-12-13 04:07:47,762 INFO     Evaluating the model... (2000/59072)
2025-12-13 04:07:50,425 INFO     Evaluating the model... (2500/59072)
2025-12-13 04:07:52,938 INFO     Evaluating the model... (3000/59072)
2025-12-13 04:07:55,408 INFO     Evaluating the model... (3500/59072)
2025-12-13 04:07:57,825 INFO     Evaluating the model... (4000/59072)
2025-12-13 04:08:01,089 INFO     Evaluating the model... (4500/59072)
2025-12-13 04:08:03,567 INFO     Evaluating the model... (5000/59072)
2025-12-13 04:08:06,042 INFO     Evaluating the model... (5500/59072)
2025-12-13 04:08:08,488 INFO     Evaluating the model... (6000/59072)
2025-12-13 04:08:11,715 INFO     Evaluating the model... (6500/59072)
2025-12-13 04:08:14,333 INFO     Evaluating the model... (7000/59072)
2025-12-13 04:08:16,694 INFO     Evaluating the model... (7500/59072)
2025-12-13 04:08:19,212 INFO     Evaluating the model... (8000/59072)
2025-12-13 04:08:21,678 INFO     Evaluating the model... (8500/59072)
2025-12-13 04:08:24,872 INFO     Evaluating the model... (9000/59072)
2025-12-13 04:08:27,366 INFO     Evaluating the model... (9500/59072)
2025-12-13 04:08:29,796 INFO     Evaluating the model... (10000/59072)
2025-12-13 04:08:32,251 INFO     Evaluating the model... (10500/59072)
2025-12-13 04:08:34,722 INFO     Evaluating the model... (11000/59072)
2025-12-13 04:08:38,314 INFO     Evaluating the model... (11500/59072)
2025-12-13 04:08:40,833 INFO     Evaluating the model... (12000/59072)
2025-12-13 04:08:43,464 INFO     Evaluating the model... (12500/59072)
2025-12-13 04:08:46,074 INFO     Evaluating the model... (13000/59072)
2025-12-13 04:08:48,757 INFO     Evaluating the model... (13500/59072)
2025-12-13 04:08:51,946 INFO     Evaluating the model... (14000/59072)
2025-12-13 04:08:54,323 INFO     Evaluating the model... (14500/59072)
2025-12-13 04:08:56,876 INFO     Evaluating the model... (15000/59072)
2025-12-13 04:08:59,729 INFO     Evaluating the model... (15500/59072)
2025-12-13 04:09:02,162 INFO     Evaluating the model... (16000/59072)
2025-12-13 04:09:05,623 INFO     Evaluating the model... (16500/59072)
2025-12-13 04:09:08,089 INFO     Evaluating the model... (17000/59072)
2025-12-13 04:09:10,750 INFO     Evaluating the model... (17500/59072)
2025-12-13 04:09:13,263 INFO     Evaluating the model... (18000/59072)
2025-12-13 04:09:15,728 INFO     Evaluating the model... (18500/59072)
2025-12-13 04:09:19,270 INFO     Evaluating the model... (19000/59072)
2025-12-13 04:09:21,881 INFO     Evaluating the model... (19500/59072)
2025-12-13 04:09:24,275 INFO     Evaluating the model... (20000/59072)
2025-12-13 04:09:26,767 INFO     Evaluating the model... (20500/59072)
2025-12-13 04:09:29,183 INFO     Evaluating the model... (21000/59072)
2025-12-13 04:09:32,623 INFO     Evaluating the model... (21500/59072)
2025-12-13 04:09:35,253 INFO     Evaluating the model... (22000/59072)
2025-12-13 04:09:37,930 INFO     Evaluating the model... (22500/59072)
2025-12-13 04:09:40,701 INFO     Evaluating the model... (23000/59072)
2025-12-13 04:09:43,308 INFO     Evaluating the model... (23500/59072)
2025-12-13 04:09:46,995 INFO     Evaluating the model... (24000/59072)
2025-12-13 04:09:49,526 INFO     Evaluating the model... (24500/59072)
2025-12-13 04:09:51,990 INFO     Evaluating the model... (25000/59072)
2025-12-13 04:09:54,497 INFO     Evaluating the model... (25500/59072)
2025-12-13 04:09:57,960 INFO     Evaluating the model... (26000/59072)
2025-12-13 04:10:00,781 INFO     Evaluating the model... (26500/59072)
2025-12-13 04:10:03,362 INFO     Evaluating the model... (27000/59072)
2025-12-13 04:10:05,884 INFO     Evaluating the model... (27500/59072)
2025-12-13 04:10:08,552 INFO     Evaluating the model... (28000/59072)
2025-12-13 04:10:12,155 INFO     Evaluating the model... (28500/59072)
2025-12-13 04:10:14,623 INFO     Evaluating the model... (29000/59072)
2025-12-13 04:10:17,021 INFO     Evaluating the model... (29500/59072)
2025-12-13 04:10:20,129 INFO     Evaluating the model... (30000/59072)
2025-12-13 04:10:22,578 INFO     Evaluating the model... (30500/59072)
2025-12-13 04:10:26,148 INFO     Evaluating the model... (31000/59072)
2025-12-13 04:10:28,676 INFO     Evaluating the model... (31500/59072)
2025-12-13 04:10:31,402 INFO     Evaluating the model... (32000/59072)
2025-12-13 04:10:33,890 INFO     Evaluating the model... (32500/59072)
2025-12-13 04:10:36,503 INFO     Evaluating the model... (33000/59072)
2025-12-13 04:10:39,971 INFO     Evaluating the model... (33500/59072)
2025-12-13 04:10:42,845 INFO     Evaluating the model... (34000/59072)
2025-12-13 04:10:45,541 INFO     Evaluating the model... (34500/59072)
2025-12-13 04:10:48,014 INFO     Evaluating the model... (35000/59072)
2025-12-13 04:10:50,617 INFO     Evaluating the model... (35500/59072)
2025-12-13 04:10:53,802 INFO     Evaluating the model... (36000/59072)
2025-12-13 04:10:56,331 INFO     Evaluating the model... (36500/59072)
2025-12-13 04:10:58,795 INFO     Evaluating the model... (37000/59072)
2025-12-13 04:11:01,246 INFO     Evaluating the model... (37500/59072)
2025-12-13 04:11:04,552 INFO     Evaluating the model... (38000/59072)
2025-12-13 04:11:07,213 INFO     Evaluating the model... (38500/59072)
2025-12-13 04:11:09,723 INFO     Evaluating the model... (39000/59072)
2025-12-13 04:11:12,194 INFO     Evaluating the model... (39500/59072)
2025-12-13 04:11:14,691 INFO     Evaluating the model... (40000/59072)
2025-12-13 04:11:18,030 INFO     Evaluating the model... (40500/59072)
2025-12-13 04:11:20,417 INFO     Evaluating the model... (41000/59072)
2025-12-13 04:11:22,834 INFO     Evaluating the model... (41500/59072)
2025-12-13 04:11:25,393 INFO     Evaluating the model... (42000/59072)
2025-12-13 04:11:27,958 INFO     Evaluating the model... (42500/59072)
2025-12-13 04:11:31,419 INFO     Evaluating the model... (43000/59072)
2025-12-13 04:11:33,933 INFO     Evaluating the model... (43500/59072)
2025-12-13 04:11:36,492 INFO     Evaluating the model... (44000/59072)
2025-12-13 04:11:39,379 INFO     Evaluating the model... (44500/59072)
2025-12-13 04:11:42,328 INFO     Evaluating the model... (45000/59072)
2025-12-13 04:11:45,760 INFO     Evaluating the model... (45500/59072)
2025-12-13 04:11:48,243 INFO     Evaluating the model... (46000/59072)
2025-12-13 04:11:50,714 INFO     Evaluating the model... (46500/59072)
2025-12-13 04:11:53,423 INFO     Evaluating the model... (47000/59072)
2025-12-13 04:11:55,977 INFO     Evaluating the model... (47500/59072)
2025-12-13 04:11:59,300 INFO     Evaluating the model... (48000/59072)
2025-12-13 04:12:01,862 INFO     Evaluating the model... (48500/59072)
2025-12-13 04:12:04,512 INFO     Evaluating the model... (49000/59072)
2025-12-13 04:12:07,116 INFO     Evaluating the model... (49500/59072)
2025-12-13 04:12:09,629 INFO     Evaluating the model... (50000/59072)
2025-12-13 04:12:12,959 INFO     Evaluating the model... (50500/59072)
2025-12-13 04:12:15,591 INFO     Evaluating the model... (51000/59072)
2025-12-13 04:12:18,097 INFO     Evaluating the model... (51500/59072)
2025-12-13 04:12:20,711 INFO     Evaluating the model... (52000/59072)
2025-12-13 04:12:23,171 INFO     Evaluating the model... (52500/59072)
2025-12-13 04:12:26,875 INFO     Evaluating the model... (53000/59072)
2025-12-13 04:12:29,388 INFO     Evaluating the model... (53500/59072)
2025-12-13 04:12:31,954 INFO     Evaluating the model... (54000/59072)
2025-12-13 04:12:34,401 INFO     Evaluating the model... (54500/59072)
2025-12-13 04:12:37,337 INFO     Evaluating the model... (55000/59072)
2025-12-13 04:12:41,361 INFO     Evaluating the model... (55500/59072)
2025-12-13 04:12:44,129 INFO     Evaluating the model... (56000/59072)
2025-12-13 04:12:46,837 INFO     Evaluating the model... (56500/59072)
2025-12-13 04:12:49,541 INFO     Evaluating the model... (57000/59072)
2025-12-13 04:12:53,218 INFO     Evaluating the model... (57500/59072)
2025-12-13 04:12:55,814 INFO     Evaluating the model... (58000/59072)
2025-12-13 04:12:58,420 INFO     Evaluating the model... (58500/59072)
2025-12-13 04:13:01,189 INFO     Evaluating the model... (59000/59072)
2025-12-13 04:13:01,843 INFO     Test MRR at step 210000: 0.630123
2025-12-13 04:13:01,844 INFO     Test MR at step 210000: 268.813445
2025-12-13 04:13:01,844 INFO     Test HITS@1 at step 210000: 0.543118
2025-12-13 04:13:01,844 INFO     Test HITS@3 at step 210000: 0.684287
2025-12-13 04:13:01,844 INFO     Test HITS@10 at step 210000: 0.782922
2025-12-13 04:13:04,024 INFO     Training average regularization at step 210100: 0.302046
2025-12-13 04:13:04,024 INFO     Training average positive_sample_loss at step 210100: 0.066299
2025-12-13 04:13:04,024 INFO     Training average negative_sample_loss at step 210100: 0.108690
2025-12-13 04:13:04,025 INFO     Training average loss at step 210100: 0.389541
2025-12-13 04:13:06,218 INFO     Training average regularization at step 210200: 0.302046
2025-12-13 04:13:06,218 INFO     Training average positive_sample_loss at step 210200: 0.066971
2025-12-13 04:13:06,218 INFO     Training average negative_sample_loss at step 210200: 0.110603
2025-12-13 04:13:06,218 INFO     Training average loss at step 210200: 0.390833
2025-12-13 04:13:08,395 INFO     Training average regularization at step 210300: 0.302046
2025-12-13 04:13:08,395 INFO     Training average positive_sample_loss at step 210300: 0.067994
2025-12-13 04:13:08,395 INFO     Training average negative_sample_loss at step 210300: 0.108615
2025-12-13 04:13:08,395 INFO     Training average loss at step 210300: 0.390350
2025-12-13 04:13:10,535 INFO     Training average regularization at step 210400: 0.302046
2025-12-13 04:13:10,535 INFO     Training average positive_sample_loss at step 210400: 0.066389
2025-12-13 04:13:10,535 INFO     Training average negative_sample_loss at step 210400: 0.108285
2025-12-13 04:13:10,535 INFO     Training average loss at step 210400: 0.389383
2025-12-13 04:13:12,720 INFO     Training average regularization at step 210500: 0.302046
2025-12-13 04:13:12,720 INFO     Training average positive_sample_loss at step 210500: 0.066849
2025-12-13 04:13:12,720 INFO     Training average negative_sample_loss at step 210500: 0.106845
2025-12-13 04:13:12,720 INFO     Training average loss at step 210500: 0.388893
2025-12-13 04:13:14,904 INFO     Training average regularization at step 210600: 0.302046
2025-12-13 04:13:14,904 INFO     Training average positive_sample_loss at step 210600: 0.066200
2025-12-13 04:13:14,904 INFO     Training average negative_sample_loss at step 210600: 0.109901
2025-12-13 04:13:14,904 INFO     Training average loss at step 210600: 0.390096
2025-12-13 04:13:17,070 INFO     Training average regularization at step 210700: 0.302046
2025-12-13 04:13:17,071 INFO     Training average positive_sample_loss at step 210700: 0.067396
2025-12-13 04:13:17,071 INFO     Training average negative_sample_loss at step 210700: 0.109236
2025-12-13 04:13:17,071 INFO     Training average loss at step 210700: 0.390362
2025-12-13 04:13:19,246 INFO     Training average regularization at step 210800: 0.302046
2025-12-13 04:13:19,247 INFO     Training average positive_sample_loss at step 210800: 0.066377
2025-12-13 04:13:19,247 INFO     Training average negative_sample_loss at step 210800: 0.108632
2025-12-13 04:13:19,247 INFO     Training average loss at step 210800: 0.389550
2025-12-13 04:13:21,416 INFO     Training average regularization at step 210900: 0.302046
2025-12-13 04:13:21,416 INFO     Training average positive_sample_loss at step 210900: 0.066686
2025-12-13 04:13:21,416 INFO     Training average negative_sample_loss at step 210900: 0.109465
2025-12-13 04:13:21,416 INFO     Training average loss at step 210900: 0.390121
2025-12-13 04:13:23,628 INFO     Training average regularization at step 211000: 0.302045
2025-12-13 04:13:23,628 INFO     Training average positive_sample_loss at step 211000: 0.065776
2025-12-13 04:13:23,628 INFO     Training average negative_sample_loss at step 211000: 0.109822
2025-12-13 04:13:23,628 INFO     Training average loss at step 211000: 0.389844
2025-12-13 04:13:25,818 INFO     Training average regularization at step 211100: 0.302045
2025-12-13 04:13:25,819 INFO     Training average positive_sample_loss at step 211100: 0.068216
2025-12-13 04:13:25,819 INFO     Training average negative_sample_loss at step 211100: 0.108173
2025-12-13 04:13:25,819 INFO     Training average loss at step 211100: 0.390240
2025-12-13 04:13:27,991 INFO     Training average regularization at step 211200: 0.302045
2025-12-13 04:13:27,992 INFO     Training average positive_sample_loss at step 211200: 0.066171
2025-12-13 04:13:27,992 INFO     Training average negative_sample_loss at step 211200: 0.108730
2025-12-13 04:13:27,992 INFO     Training average loss at step 211200: 0.389496
2025-12-13 04:13:30,171 INFO     Training average regularization at step 211300: 0.302045
2025-12-13 04:13:30,171 INFO     Training average positive_sample_loss at step 211300: 0.067330
2025-12-13 04:13:30,171 INFO     Training average negative_sample_loss at step 211300: 0.108524
2025-12-13 04:13:30,171 INFO     Training average loss at step 211300: 0.389972
2025-12-13 04:13:32,296 INFO     Training average regularization at step 211400: 0.302045
2025-12-13 04:13:32,297 INFO     Training average positive_sample_loss at step 211400: 0.067487
2025-12-13 04:13:32,297 INFO     Training average negative_sample_loss at step 211400: 0.112951
2025-12-13 04:13:32,297 INFO     Training average loss at step 211400: 0.392264
2025-12-13 04:13:34,463 INFO     Training average regularization at step 211500: 0.302045
2025-12-13 04:13:34,463 INFO     Training average positive_sample_loss at step 211500: 0.066047
2025-12-13 04:13:34,463 INFO     Training average negative_sample_loss at step 211500: 0.111021
2025-12-13 04:13:34,463 INFO     Training average loss at step 211500: 0.390579
2025-12-13 04:13:36,677 INFO     Training average regularization at step 211600: 0.302045
2025-12-13 04:13:36,677 INFO     Training average positive_sample_loss at step 211600: 0.066881
2025-12-13 04:13:36,677 INFO     Training average negative_sample_loss at step 211600: 0.110911
2025-12-13 04:13:36,677 INFO     Training average loss at step 211600: 0.390941
2025-12-13 04:13:38,867 INFO     Training average regularization at step 211700: 0.302045
2025-12-13 04:13:38,867 INFO     Training average positive_sample_loss at step 211700: 0.067466
2025-12-13 04:13:38,867 INFO     Training average negative_sample_loss at step 211700: 0.110789
2025-12-13 04:13:38,867 INFO     Training average loss at step 211700: 0.391173
2025-12-13 04:13:41,041 INFO     Training average regularization at step 211800: 0.302045
2025-12-13 04:13:41,045 INFO     Training average positive_sample_loss at step 211800: 0.066631
2025-12-13 04:13:41,045 INFO     Training average negative_sample_loss at step 211800: 0.108804
2025-12-13 04:13:41,045 INFO     Training average loss at step 211800: 0.389762
2025-12-13 04:13:43,267 INFO     Training average regularization at step 211900: 0.302045
2025-12-13 04:13:43,267 INFO     Training average positive_sample_loss at step 211900: 0.065882
2025-12-13 04:13:43,267 INFO     Training average negative_sample_loss at step 211900: 0.109595
2025-12-13 04:13:43,267 INFO     Training average loss at step 211900: 0.389783
2025-12-13 04:13:45,459 INFO     Training average regularization at step 212000: 0.302045
2025-12-13 04:13:45,459 INFO     Training average positive_sample_loss at step 212000: 0.066047
2025-12-13 04:13:45,459 INFO     Training average negative_sample_loss at step 212000: 0.108249
2025-12-13 04:13:45,459 INFO     Training average loss at step 212000: 0.389193
2025-12-13 04:13:47,611 INFO     Training average regularization at step 212100: 0.302045
2025-12-13 04:13:47,623 INFO     Training average positive_sample_loss at step 212100: 0.067336
2025-12-13 04:13:47,624 INFO     Training average negative_sample_loss at step 212100: 0.108561
2025-12-13 04:13:47,624 INFO     Training average loss at step 212100: 0.389994
2025-12-13 04:13:49,766 INFO     Training average regularization at step 212200: 0.302045
2025-12-13 04:13:49,766 INFO     Training average positive_sample_loss at step 212200: 0.067450
2025-12-13 04:13:49,766 INFO     Training average negative_sample_loss at step 212200: 0.116132
2025-12-13 04:13:49,766 INFO     Training average loss at step 212200: 0.393835
2025-12-13 04:13:51,896 INFO     Training average regularization at step 212300: 0.302045
2025-12-13 04:13:51,896 INFO     Training average positive_sample_loss at step 212300: 0.066938
2025-12-13 04:13:51,896 INFO     Training average negative_sample_loss at step 212300: 0.109709
2025-12-13 04:13:51,896 INFO     Training average loss at step 212300: 0.390369
2025-12-13 04:13:54,016 INFO     Training average regularization at step 212400: 0.302045
2025-12-13 04:13:54,016 INFO     Training average positive_sample_loss at step 212400: 0.066029
2025-12-13 04:13:54,016 INFO     Training average negative_sample_loss at step 212400: 0.107790
2025-12-13 04:13:54,016 INFO     Training average loss at step 212400: 0.388954
2025-12-13 04:13:56,215 INFO     Training average regularization at step 212500: 0.302044
2025-12-13 04:13:56,215 INFO     Training average positive_sample_loss at step 212500: 0.067257
2025-12-13 04:13:56,215 INFO     Training average negative_sample_loss at step 212500: 0.107707
2025-12-13 04:13:56,215 INFO     Training average loss at step 212500: 0.389526
2025-12-13 04:13:58,522 INFO     Training average regularization at step 212600: 0.302044
2025-12-13 04:13:58,522 INFO     Training average positive_sample_loss at step 212600: 0.065598
2025-12-13 04:13:58,522 INFO     Training average negative_sample_loss at step 212600: 0.110624
2025-12-13 04:13:58,523 INFO     Training average loss at step 212600: 0.390155
2025-12-13 04:14:01,585 INFO     Training average regularization at step 212700: 0.302044
2025-12-13 04:14:01,585 INFO     Training average positive_sample_loss at step 212700: 0.066184
2025-12-13 04:14:01,585 INFO     Training average negative_sample_loss at step 212700: 0.108765
2025-12-13 04:14:01,585 INFO     Training average loss at step 212700: 0.389519
2025-12-13 04:14:03,761 INFO     Training average regularization at step 212800: 0.302044
2025-12-13 04:14:03,761 INFO     Training average positive_sample_loss at step 212800: 0.067334
2025-12-13 04:14:03,761 INFO     Training average negative_sample_loss at step 212800: 0.108829
2025-12-13 04:14:03,761 INFO     Training average loss at step 212800: 0.390126
2025-12-13 04:14:05,931 INFO     Training average regularization at step 212900: 0.302044
2025-12-13 04:14:05,931 INFO     Training average positive_sample_loss at step 212900: 0.067570
2025-12-13 04:14:05,931 INFO     Training average negative_sample_loss at step 212900: 0.107629
2025-12-13 04:14:05,931 INFO     Training average loss at step 212900: 0.389644
2025-12-13 04:14:08,142 INFO     Training average regularization at step 213000: 0.302044
2025-12-13 04:14:08,143 INFO     Training average positive_sample_loss at step 213000: 0.066442
2025-12-13 04:14:08,143 INFO     Training average negative_sample_loss at step 213000: 0.108739
2025-12-13 04:14:08,143 INFO     Training average loss at step 213000: 0.389635
2025-12-13 04:14:10,279 INFO     Training average regularization at step 213100: 0.302044
2025-12-13 04:14:10,279 INFO     Training average positive_sample_loss at step 213100: 0.065722
2025-12-13 04:14:10,279 INFO     Training average negative_sample_loss at step 213100: 0.113721
2025-12-13 04:14:10,279 INFO     Training average loss at step 213100: 0.391765
2025-12-13 04:14:12,406 INFO     Training average regularization at step 213200: 0.302044
2025-12-13 04:14:12,406 INFO     Training average positive_sample_loss at step 213200: 0.066833
2025-12-13 04:14:12,406 INFO     Training average negative_sample_loss at step 213200: 0.109773
2025-12-13 04:14:12,406 INFO     Training average loss at step 213200: 0.390347
2025-12-13 04:14:14,528 INFO     Training average regularization at step 213300: 0.302044
2025-12-13 04:14:14,528 INFO     Training average positive_sample_loss at step 213300: 0.066879
2025-12-13 04:14:14,528 INFO     Training average negative_sample_loss at step 213300: 0.109665
2025-12-13 04:14:14,528 INFO     Training average loss at step 213300: 0.390316
2025-12-13 04:14:16,660 INFO     Training average regularization at step 213400: 0.302044
2025-12-13 04:14:16,661 INFO     Training average positive_sample_loss at step 213400: 0.066496
2025-12-13 04:14:16,661 INFO     Training average negative_sample_loss at step 213400: 0.109017
2025-12-13 04:14:16,661 INFO     Training average loss at step 213400: 0.389800
2025-12-13 04:14:18,806 INFO     Training average regularization at step 213500: 0.302044
2025-12-13 04:14:18,806 INFO     Training average positive_sample_loss at step 213500: 0.066676
2025-12-13 04:14:18,806 INFO     Training average negative_sample_loss at step 213500: 0.110044
2025-12-13 04:14:18,806 INFO     Training average loss at step 213500: 0.390404
2025-12-13 04:14:20,921 INFO     Training average regularization at step 213600: 0.302044
2025-12-13 04:14:20,921 INFO     Training average positive_sample_loss at step 213600: 0.065727
2025-12-13 04:14:20,921 INFO     Training average negative_sample_loss at step 213600: 0.110316
2025-12-13 04:14:20,921 INFO     Training average loss at step 213600: 0.390065
2025-12-13 04:14:23,038 INFO     Training average regularization at step 213700: 0.302044
2025-12-13 04:14:23,038 INFO     Training average positive_sample_loss at step 213700: 0.065746
2025-12-13 04:14:23,038 INFO     Training average negative_sample_loss at step 213700: 0.108496
2025-12-13 04:14:23,038 INFO     Training average loss at step 213700: 0.389165
2025-12-13 04:14:25,173 INFO     Training average regularization at step 213800: 0.302044
2025-12-13 04:14:25,174 INFO     Training average positive_sample_loss at step 213800: 0.066777
2025-12-13 04:14:25,174 INFO     Training average negative_sample_loss at step 213800: 0.110182
2025-12-13 04:14:25,174 INFO     Training average loss at step 213800: 0.390523
2025-12-13 04:14:27,286 INFO     Training average regularization at step 213900: 0.302043
2025-12-13 04:14:27,286 INFO     Training average positive_sample_loss at step 213900: 0.066380
2025-12-13 04:14:27,286 INFO     Training average negative_sample_loss at step 213900: 0.106673
2025-12-13 04:14:27,286 INFO     Training average loss at step 213900: 0.388570
2025-12-13 04:14:29,434 INFO     Training average regularization at step 214000: 0.302043
2025-12-13 04:14:29,434 INFO     Training average positive_sample_loss at step 214000: 0.067490
2025-12-13 04:14:29,434 INFO     Training average negative_sample_loss at step 214000: 0.109912
2025-12-13 04:14:29,434 INFO     Training average loss at step 214000: 0.390745
2025-12-13 04:14:31,538 INFO     Training average regularization at step 214100: 0.302043
2025-12-13 04:14:31,539 INFO     Training average positive_sample_loss at step 214100: 0.066199
2025-12-13 04:14:31,539 INFO     Training average negative_sample_loss at step 214100: 0.108417
2025-12-13 04:14:31,539 INFO     Training average loss at step 214100: 0.389351
2025-12-13 04:14:33,644 INFO     Training average regularization at step 214200: 0.302043
2025-12-13 04:14:33,645 INFO     Training average positive_sample_loss at step 214200: 0.067058
2025-12-13 04:14:33,645 INFO     Training average negative_sample_loss at step 214200: 0.109361
2025-12-13 04:14:33,645 INFO     Training average loss at step 214200: 0.390252
2025-12-13 04:14:35,817 INFO     Training average regularization at step 214300: 0.302043
2025-12-13 04:14:35,817 INFO     Training average positive_sample_loss at step 214300: 0.065988
2025-12-13 04:14:35,817 INFO     Training average negative_sample_loss at step 214300: 0.107960
2025-12-13 04:14:35,817 INFO     Training average loss at step 214300: 0.389017
2025-12-13 04:14:37,942 INFO     Training average regularization at step 214400: 0.302043
2025-12-13 04:14:37,942 INFO     Training average positive_sample_loss at step 214400: 0.067219
2025-12-13 04:14:37,942 INFO     Training average negative_sample_loss at step 214400: 0.109396
2025-12-13 04:14:37,942 INFO     Training average loss at step 214400: 0.390351
2025-12-13 04:14:40,112 INFO     Training average regularization at step 214500: 0.302043
2025-12-13 04:14:40,112 INFO     Training average positive_sample_loss at step 214500: 0.066994
2025-12-13 04:14:40,112 INFO     Training average negative_sample_loss at step 214500: 0.108384
2025-12-13 04:14:40,112 INFO     Training average loss at step 214500: 0.389732
2025-12-13 04:14:42,256 INFO     Training average regularization at step 214600: 0.302043
2025-12-13 04:14:42,256 INFO     Training average positive_sample_loss at step 214600: 0.065881
2025-12-13 04:14:42,257 INFO     Training average negative_sample_loss at step 214600: 0.108597
2025-12-13 04:14:42,257 INFO     Training average loss at step 214600: 0.389282
2025-12-13 04:14:44,429 INFO     Training average regularization at step 214700: 0.302043
2025-12-13 04:14:44,429 INFO     Training average positive_sample_loss at step 214700: 0.067350
2025-12-13 04:14:44,429 INFO     Training average negative_sample_loss at step 214700: 0.109188
2025-12-13 04:14:44,429 INFO     Training average loss at step 214700: 0.390312
2025-12-13 04:14:46,595 INFO     Training average regularization at step 214800: 0.302043
2025-12-13 04:14:46,595 INFO     Training average positive_sample_loss at step 214800: 0.066580
2025-12-13 04:14:46,596 INFO     Training average negative_sample_loss at step 214800: 0.108135
2025-12-13 04:14:46,596 INFO     Training average loss at step 214800: 0.389400
2025-12-13 04:14:48,708 INFO     Training average regularization at step 214900: 0.302043
2025-12-13 04:14:48,708 INFO     Training average positive_sample_loss at step 214900: 0.067275
2025-12-13 04:14:48,708 INFO     Training average negative_sample_loss at step 214900: 0.110628
2025-12-13 04:14:48,708 INFO     Training average loss at step 214900: 0.390994
2025-12-13 04:14:50,875 INFO     Training average regularization at step 215000: 0.302043
2025-12-13 04:14:50,875 INFO     Training average positive_sample_loss at step 215000: 0.066587
2025-12-13 04:14:50,875 INFO     Training average negative_sample_loss at step 215000: 0.108082
2025-12-13 04:14:50,875 INFO     Training average loss at step 215000: 0.389377
2025-12-13 04:14:52,979 INFO     Training average regularization at step 215100: 0.302043
2025-12-13 04:14:52,979 INFO     Training average positive_sample_loss at step 215100: 0.067373
2025-12-13 04:14:52,979 INFO     Training average negative_sample_loss at step 215100: 0.108085
2025-12-13 04:14:52,979 INFO     Training average loss at step 215100: 0.389771
2025-12-13 04:14:55,097 INFO     Training average regularization at step 215200: 0.302043
2025-12-13 04:14:55,097 INFO     Training average positive_sample_loss at step 215200: 0.065375
2025-12-13 04:14:55,097 INFO     Training average negative_sample_loss at step 215200: 0.109372
2025-12-13 04:14:55,097 INFO     Training average loss at step 215200: 0.389416
2025-12-13 04:14:57,206 INFO     Training average regularization at step 215300: 0.302043
2025-12-13 04:14:57,206 INFO     Training average positive_sample_loss at step 215300: 0.065532
2025-12-13 04:14:57,206 INFO     Training average negative_sample_loss at step 215300: 0.109216
2025-12-13 04:14:57,206 INFO     Training average loss at step 215300: 0.389417
2025-12-13 04:14:59,349 INFO     Training average regularization at step 215400: 0.302042
2025-12-13 04:14:59,349 INFO     Training average positive_sample_loss at step 215400: 0.066398
2025-12-13 04:14:59,349 INFO     Training average negative_sample_loss at step 215400: 0.109139
2025-12-13 04:14:59,349 INFO     Training average loss at step 215400: 0.389811
2025-12-13 04:15:01,494 INFO     Training average regularization at step 215500: 0.302042
2025-12-13 04:15:01,495 INFO     Training average positive_sample_loss at step 215500: 0.065269
2025-12-13 04:15:01,495 INFO     Training average negative_sample_loss at step 215500: 0.108327
2025-12-13 04:15:01,495 INFO     Training average loss at step 215500: 0.388841
2025-12-13 04:15:03,613 INFO     Training average regularization at step 215600: 0.302042
2025-12-13 04:15:03,613 INFO     Training average positive_sample_loss at step 215600: 0.065456
2025-12-13 04:15:03,613 INFO     Training average negative_sample_loss at step 215600: 0.106886
2025-12-13 04:15:03,613 INFO     Training average loss at step 215600: 0.388213
2025-12-13 04:15:05,698 INFO     Training average regularization at step 215700: 0.302042
2025-12-13 04:15:05,698 INFO     Training average positive_sample_loss at step 215700: 0.066849
2025-12-13 04:15:05,698 INFO     Training average negative_sample_loss at step 215700: 0.108154
2025-12-13 04:15:05,698 INFO     Training average loss at step 215700: 0.389544
2025-12-13 04:15:07,818 INFO     Training average regularization at step 215800: 0.302042
2025-12-13 04:15:07,818 INFO     Training average positive_sample_loss at step 215800: 0.067005
2025-12-13 04:15:07,818 INFO     Training average negative_sample_loss at step 215800: 0.107689
2025-12-13 04:15:07,818 INFO     Training average loss at step 215800: 0.389389
2025-12-13 04:15:09,903 INFO     Training average regularization at step 215900: 0.302042
2025-12-13 04:15:09,903 INFO     Training average positive_sample_loss at step 215900: 0.067821
2025-12-13 04:15:09,903 INFO     Training average negative_sample_loss at step 215900: 0.109646
2025-12-13 04:15:09,903 INFO     Training average loss at step 215900: 0.390776
2025-12-13 04:15:12,008 INFO     Training average regularization at step 216000: 0.302042
2025-12-13 04:15:12,009 INFO     Training average positive_sample_loss at step 216000: 0.066304
2025-12-13 04:15:12,009 INFO     Training average negative_sample_loss at step 216000: 0.109086
2025-12-13 04:15:12,009 INFO     Training average loss at step 216000: 0.389737
2025-12-13 04:15:14,124 INFO     Training average regularization at step 216100: 0.302042
2025-12-13 04:15:14,124 INFO     Training average positive_sample_loss at step 216100: 0.066623
2025-12-13 04:15:14,124 INFO     Training average negative_sample_loss at step 216100: 0.110681
2025-12-13 04:15:14,124 INFO     Training average loss at step 216100: 0.390694
2025-12-13 04:15:16,253 INFO     Training average regularization at step 216200: 0.302042
2025-12-13 04:15:16,253 INFO     Training average positive_sample_loss at step 216200: 0.067286
2025-12-13 04:15:16,254 INFO     Training average negative_sample_loss at step 216200: 0.106633
2025-12-13 04:15:16,254 INFO     Training average loss at step 216200: 0.389001
2025-12-13 04:15:18,397 INFO     Training average regularization at step 216300: 0.302042
2025-12-13 04:15:18,398 INFO     Training average positive_sample_loss at step 216300: 0.066960
2025-12-13 04:15:18,398 INFO     Training average negative_sample_loss at step 216300: 0.108449
2025-12-13 04:15:18,398 INFO     Training average loss at step 216300: 0.389747
2025-12-13 04:15:20,522 INFO     Training average regularization at step 216400: 0.302042
2025-12-13 04:15:20,523 INFO     Training average positive_sample_loss at step 216400: 0.068952
2025-12-13 04:15:20,523 INFO     Training average negative_sample_loss at step 216400: 0.107183
2025-12-13 04:15:20,523 INFO     Training average loss at step 216400: 0.390109
2025-12-13 04:15:22,626 INFO     Training average regularization at step 216500: 0.302042
2025-12-13 04:15:22,626 INFO     Training average positive_sample_loss at step 216500: 0.067889
2025-12-13 04:15:22,626 INFO     Training average negative_sample_loss at step 216500: 0.110707
2025-12-13 04:15:22,626 INFO     Training average loss at step 216500: 0.391340
2025-12-13 04:15:24,763 INFO     Training average regularization at step 216600: 0.302042
2025-12-13 04:15:24,764 INFO     Training average positive_sample_loss at step 216600: 0.066500
2025-12-13 04:15:24,764 INFO     Training average negative_sample_loss at step 216600: 0.109230
2025-12-13 04:15:24,764 INFO     Training average loss at step 216600: 0.389907
2025-12-13 04:15:26,880 INFO     Training average regularization at step 216700: 0.302042
2025-12-13 04:15:26,881 INFO     Training average positive_sample_loss at step 216700: 0.066556
2025-12-13 04:15:26,881 INFO     Training average negative_sample_loss at step 216700: 0.108218
2025-12-13 04:15:26,881 INFO     Training average loss at step 216700: 0.389429
2025-12-13 04:15:28,985 INFO     Training average regularization at step 216800: 0.302042
2025-12-13 04:15:28,985 INFO     Training average positive_sample_loss at step 216800: 0.066724
2025-12-13 04:15:28,985 INFO     Training average negative_sample_loss at step 216800: 0.107857
2025-12-13 04:15:28,985 INFO     Training average loss at step 216800: 0.389332
2025-12-13 04:15:31,096 INFO     Training average regularization at step 216900: 0.302042
2025-12-13 04:15:31,096 INFO     Training average positive_sample_loss at step 216900: 0.066833
2025-12-13 04:15:31,096 INFO     Training average negative_sample_loss at step 216900: 0.109725
2025-12-13 04:15:31,096 INFO     Training average loss at step 216900: 0.390321
2025-12-13 04:15:33,192 INFO     Training average regularization at step 217000: 0.302041
2025-12-13 04:15:33,192 INFO     Training average positive_sample_loss at step 217000: 0.065944
2025-12-13 04:15:33,192 INFO     Training average negative_sample_loss at step 217000: 0.110845
2025-12-13 04:15:33,192 INFO     Training average loss at step 217000: 0.390436
2025-12-13 04:15:35,345 INFO     Training average regularization at step 217100: 0.302041
2025-12-13 04:15:35,345 INFO     Training average positive_sample_loss at step 217100: 0.066537
2025-12-13 04:15:35,345 INFO     Training average negative_sample_loss at step 217100: 0.111055
2025-12-13 04:15:35,345 INFO     Training average loss at step 217100: 0.390837
2025-12-13 04:15:37,493 INFO     Training average regularization at step 217200: 0.302041
2025-12-13 04:15:37,493 INFO     Training average positive_sample_loss at step 217200: 0.065988
2025-12-13 04:15:37,493 INFO     Training average negative_sample_loss at step 217200: 0.110907
2025-12-13 04:15:37,493 INFO     Training average loss at step 217200: 0.390489
2025-12-13 04:15:39,624 INFO     Training average regularization at step 217300: 0.302041
2025-12-13 04:15:39,624 INFO     Training average positive_sample_loss at step 217300: 0.067440
2025-12-13 04:15:39,624 INFO     Training average negative_sample_loss at step 217300: 0.110747
2025-12-13 04:15:39,625 INFO     Training average loss at step 217300: 0.391135
2025-12-13 04:15:41,757 INFO     Training average regularization at step 217400: 0.302041
2025-12-13 04:15:41,757 INFO     Training average positive_sample_loss at step 217400: 0.068056
2025-12-13 04:15:41,757 INFO     Training average negative_sample_loss at step 217400: 0.109590
2025-12-13 04:15:41,757 INFO     Training average loss at step 217400: 0.390864
2025-12-13 04:15:45,116 INFO     Training average regularization at step 217500: 0.302041
2025-12-13 04:15:45,116 INFO     Training average positive_sample_loss at step 217500: 0.067199
2025-12-13 04:15:45,116 INFO     Training average negative_sample_loss at step 217500: 0.108137
2025-12-13 04:15:45,116 INFO     Training average loss at step 217500: 0.389709
2025-12-13 04:15:47,278 INFO     Training average regularization at step 217600: 0.302041
2025-12-13 04:15:47,279 INFO     Training average positive_sample_loss at step 217600: 0.067552
2025-12-13 04:15:47,279 INFO     Training average negative_sample_loss at step 217600: 0.108691
2025-12-13 04:15:47,279 INFO     Training average loss at step 217600: 0.390162
2025-12-13 04:15:49,393 INFO     Training average regularization at step 217700: 0.302041
2025-12-13 04:15:49,394 INFO     Training average positive_sample_loss at step 217700: 0.067417
2025-12-13 04:15:49,394 INFO     Training average negative_sample_loss at step 217700: 0.108289
2025-12-13 04:15:49,394 INFO     Training average loss at step 217700: 0.389894
2025-12-13 04:15:51,510 INFO     Training average regularization at step 217800: 0.302041
2025-12-13 04:15:51,510 INFO     Training average positive_sample_loss at step 217800: 0.067185
2025-12-13 04:15:51,510 INFO     Training average negative_sample_loss at step 217800: 0.106320
2025-12-13 04:15:51,510 INFO     Training average loss at step 217800: 0.388794
2025-12-13 04:15:53,651 INFO     Training average regularization at step 217900: 0.302041
2025-12-13 04:15:53,652 INFO     Training average positive_sample_loss at step 217900: 0.066350
2025-12-13 04:15:53,652 INFO     Training average negative_sample_loss at step 217900: 0.106930
2025-12-13 04:15:53,652 INFO     Training average loss at step 217900: 0.388681
2025-12-13 04:15:55,804 INFO     Training average regularization at step 218000: 0.302041
2025-12-13 04:15:55,804 INFO     Training average positive_sample_loss at step 218000: 0.066004
2025-12-13 04:15:55,804 INFO     Training average negative_sample_loss at step 218000: 0.108249
2025-12-13 04:15:55,804 INFO     Training average loss at step 218000: 0.389167
2025-12-13 04:15:57,973 INFO     Training average regularization at step 218100: 0.302041
2025-12-13 04:15:57,973 INFO     Training average positive_sample_loss at step 218100: 0.065855
2025-12-13 04:15:57,973 INFO     Training average negative_sample_loss at step 218100: 0.109804
2025-12-13 04:15:57,973 INFO     Training average loss at step 218100: 0.389870
2025-12-13 04:16:00,107 INFO     Training average regularization at step 218200: 0.302041
2025-12-13 04:16:00,108 INFO     Training average positive_sample_loss at step 218200: 0.067053
2025-12-13 04:16:00,108 INFO     Training average negative_sample_loss at step 218200: 0.107451
2025-12-13 04:16:00,108 INFO     Training average loss at step 218200: 0.389292
2025-12-13 04:16:02,207 INFO     Training average regularization at step 218300: 0.302041
2025-12-13 04:16:02,207 INFO     Training average positive_sample_loss at step 218300: 0.067369
2025-12-13 04:16:02,207 INFO     Training average negative_sample_loss at step 218300: 0.110621
2025-12-13 04:16:02,207 INFO     Training average loss at step 218300: 0.391036
2025-12-13 04:16:04,365 INFO     Training average regularization at step 218400: 0.302041
2025-12-13 04:16:04,366 INFO     Training average positive_sample_loss at step 218400: 0.067109
2025-12-13 04:16:04,366 INFO     Training average negative_sample_loss at step 218400: 0.109478
2025-12-13 04:16:04,366 INFO     Training average loss at step 218400: 0.390334
2025-12-13 04:16:06,466 INFO     Training average regularization at step 218500: 0.302040
2025-12-13 04:16:06,467 INFO     Training average positive_sample_loss at step 218500: 0.067012
2025-12-13 04:16:06,467 INFO     Training average negative_sample_loss at step 218500: 0.108254
2025-12-13 04:16:06,467 INFO     Training average loss at step 218500: 0.389674
2025-12-13 04:16:08,626 INFO     Training average regularization at step 218600: 0.302040
2025-12-13 04:16:08,627 INFO     Training average positive_sample_loss at step 218600: 0.068213
2025-12-13 04:16:08,627 INFO     Training average negative_sample_loss at step 218600: 0.108439
2025-12-13 04:16:08,627 INFO     Training average loss at step 218600: 0.390366
2025-12-13 04:16:10,726 INFO     Training average regularization at step 218700: 0.302040
2025-12-13 04:16:10,726 INFO     Training average positive_sample_loss at step 218700: 0.066297
2025-12-13 04:16:10,726 INFO     Training average negative_sample_loss at step 218700: 0.108322
2025-12-13 04:16:10,726 INFO     Training average loss at step 218700: 0.389350
2025-12-13 04:16:12,820 INFO     Training average regularization at step 218800: 0.302040
2025-12-13 04:16:12,828 INFO     Training average positive_sample_loss at step 218800: 0.066740
2025-12-13 04:16:12,840 INFO     Training average negative_sample_loss at step 218800: 0.110596
2025-12-13 04:16:12,840 INFO     Training average loss at step 218800: 0.390709
2025-12-13 04:16:14,942 INFO     Training average regularization at step 218900: 0.302040
2025-12-13 04:16:14,942 INFO     Training average positive_sample_loss at step 218900: 0.066892
2025-12-13 04:16:14,942 INFO     Training average negative_sample_loss at step 218900: 0.112199
2025-12-13 04:16:14,942 INFO     Training average loss at step 218900: 0.391586
2025-12-13 04:16:17,051 INFO     Training average regularization at step 219000: 0.302040
2025-12-13 04:16:17,051 INFO     Training average positive_sample_loss at step 219000: 0.065874
2025-12-13 04:16:17,051 INFO     Training average negative_sample_loss at step 219000: 0.110177
2025-12-13 04:16:17,051 INFO     Training average loss at step 219000: 0.390066
2025-12-13 04:16:19,151 INFO     Training average regularization at step 219100: 0.302040
2025-12-13 04:16:19,152 INFO     Training average positive_sample_loss at step 219100: 0.066560
2025-12-13 04:16:19,152 INFO     Training average negative_sample_loss at step 219100: 0.108261
2025-12-13 04:16:19,152 INFO     Training average loss at step 219100: 0.389450
2025-12-13 04:16:21,241 INFO     Training average regularization at step 219200: 0.302040
2025-12-13 04:16:21,241 INFO     Training average positive_sample_loss at step 219200: 0.067878
2025-12-13 04:16:21,241 INFO     Training average negative_sample_loss at step 219200: 0.111236
2025-12-13 04:16:21,241 INFO     Training average loss at step 219200: 0.391597
2025-12-13 04:16:23,319 INFO     Training average regularization at step 219300: 0.302040
2025-12-13 04:16:23,319 INFO     Training average positive_sample_loss at step 219300: 0.066851
2025-12-13 04:16:23,319 INFO     Training average negative_sample_loss at step 219300: 0.107946
2025-12-13 04:16:23,319 INFO     Training average loss at step 219300: 0.389438
2025-12-13 04:16:25,425 INFO     Training average regularization at step 219400: 0.302040
2025-12-13 04:16:25,425 INFO     Training average positive_sample_loss at step 219400: 0.065885
2025-12-13 04:16:25,425 INFO     Training average negative_sample_loss at step 219400: 0.108352
2025-12-13 04:16:25,425 INFO     Training average loss at step 219400: 0.389159
2025-12-13 04:16:27,530 INFO     Training average regularization at step 219500: 0.302040
2025-12-13 04:16:27,530 INFO     Training average positive_sample_loss at step 219500: 0.067215
2025-12-13 04:16:27,530 INFO     Training average negative_sample_loss at step 219500: 0.106733
2025-12-13 04:16:27,530 INFO     Training average loss at step 219500: 0.389014
2025-12-13 04:16:29,652 INFO     Training average regularization at step 219600: 0.302040
2025-12-13 04:16:29,652 INFO     Training average positive_sample_loss at step 219600: 0.067109
2025-12-13 04:16:29,652 INFO     Training average negative_sample_loss at step 219600: 0.109341
2025-12-13 04:16:29,652 INFO     Training average loss at step 219600: 0.390265
2025-12-13 04:16:31,752 INFO     Training average regularization at step 219700: 0.302040
2025-12-13 04:16:31,753 INFO     Training average positive_sample_loss at step 219700: 0.067390
2025-12-13 04:16:31,753 INFO     Training average negative_sample_loss at step 219700: 0.109497
2025-12-13 04:16:31,753 INFO     Training average loss at step 219700: 0.390483
2025-12-13 04:16:33,892 INFO     Training average regularization at step 219800: 0.302040
2025-12-13 04:16:33,892 INFO     Training average positive_sample_loss at step 219800: 0.067041
2025-12-13 04:16:33,892 INFO     Training average negative_sample_loss at step 219800: 0.107252
2025-12-13 04:16:33,892 INFO     Training average loss at step 219800: 0.389186
2025-12-13 04:16:36,090 INFO     Training average regularization at step 219900: 0.302040
2025-12-13 04:16:36,090 INFO     Training average positive_sample_loss at step 219900: 0.067191
2025-12-13 04:16:36,090 INFO     Training average negative_sample_loss at step 219900: 0.106816
2025-12-13 04:16:36,090 INFO     Training average loss at step 219900: 0.389043
2025-12-13 04:16:39,595 INFO     Training average regularization at step 220000: 0.302039
2025-12-13 04:16:39,595 INFO     Training average positive_sample_loss at step 220000: 0.066944
2025-12-13 04:16:39,595 INFO     Training average negative_sample_loss at step 220000: 0.108795
2025-12-13 04:16:39,596 INFO     Training average loss at step 220000: 0.389909
2025-12-13 04:16:39,596 INFO     Evaluating on Valid Dataset...
2025-12-13 04:16:40,270 INFO     Evaluating the model... (0/50000)
2025-12-13 04:16:43,127 INFO     Evaluating the model... (500/50000)
2025-12-13 04:16:46,896 INFO     Evaluating the model... (1000/50000)
2025-12-13 04:16:49,355 INFO     Evaluating the model... (1500/50000)
2025-12-13 04:16:52,028 INFO     Evaluating the model... (2000/50000)
2025-12-13 04:16:54,687 INFO     Evaluating the model... (2500/50000)
2025-12-13 04:16:57,988 INFO     Evaluating the model... (3000/50000)
2025-12-13 04:17:00,347 INFO     Evaluating the model... (3500/50000)
2025-12-13 04:17:02,793 INFO     Evaluating the model... (4000/50000)
2025-12-13 04:17:05,440 INFO     Evaluating the model... (4500/50000)
2025-12-13 04:17:07,921 INFO     Evaluating the model... (5000/50000)
2025-12-13 04:17:11,270 INFO     Evaluating the model... (5500/50000)
2025-12-13 04:17:13,650 INFO     Evaluating the model... (6000/50000)
2025-12-13 04:17:16,401 INFO     Evaluating the model... (6500/50000)
2025-12-13 04:17:18,900 INFO     Evaluating the model... (7000/50000)
2025-12-13 04:17:21,401 INFO     Evaluating the model... (7500/50000)
2025-12-13 04:17:24,396 INFO     Evaluating the model... (8000/50000)
2025-12-13 04:17:26,870 INFO     Evaluating the model... (8500/50000)
2025-12-13 04:17:29,417 INFO     Evaluating the model... (9000/50000)
2025-12-13 04:17:31,797 INFO     Evaluating the model... (9500/50000)
2025-12-13 04:17:34,164 INFO     Evaluating the model... (10000/50000)
2025-12-13 04:17:37,720 INFO     Evaluating the model... (10500/50000)
2025-12-13 04:17:40,565 INFO     Evaluating the model... (11000/50000)
2025-12-13 04:17:43,407 INFO     Evaluating the model... (11500/50000)
2025-12-13 04:17:46,040 INFO     Evaluating the model... (12000/50000)
2025-12-13 04:17:48,517 INFO     Evaluating the model... (12500/50000)
2025-12-13 04:17:51,811 INFO     Evaluating the model... (13000/50000)
2025-12-13 04:17:54,163 INFO     Evaluating the model... (13500/50000)
2025-12-13 04:17:56,791 INFO     Evaluating the model... (14000/50000)
2025-12-13 04:17:59,230 INFO     Evaluating the model... (14500/50000)
2025-12-13 04:18:01,859 INFO     Evaluating the model... (15000/50000)
2025-12-13 04:18:05,189 INFO     Evaluating the model... (15500/50000)
2025-12-13 04:18:07,587 INFO     Evaluating the model... (16000/50000)
2025-12-13 04:18:09,978 INFO     Evaluating the model... (16500/50000)
2025-12-13 04:18:12,324 INFO     Evaluating the model... (17000/50000)
2025-12-13 04:18:14,899 INFO     Evaluating the model... (17500/50000)
2025-12-13 04:18:18,222 INFO     Evaluating the model... (18000/50000)
2025-12-13 04:18:20,700 INFO     Evaluating the model... (18500/50000)
2025-12-13 04:18:23,124 INFO     Evaluating the model... (19000/50000)
2025-12-13 04:18:25,812 INFO     Evaluating the model... (19500/50000)
2025-12-13 04:18:28,346 INFO     Evaluating the model... (20000/50000)
2025-12-13 04:18:31,919 INFO     Evaluating the model... (20500/50000)
2025-12-13 04:18:34,233 INFO     Evaluating the model... (21000/50000)
2025-12-13 04:18:37,191 INFO     Evaluating the model... (21500/50000)
2025-12-13 04:18:39,792 INFO     Evaluating the model... (22000/50000)
2025-12-13 04:18:43,698 INFO     Evaluating the model... (22500/50000)
2025-12-13 04:18:46,205 INFO     Evaluating the model... (23000/50000)
2025-12-13 04:18:48,824 INFO     Evaluating the model... (23500/50000)
2025-12-13 04:18:51,341 INFO     Evaluating the model... (24000/50000)
2025-12-13 04:18:53,791 INFO     Evaluating the model... (24500/50000)
2025-12-13 04:18:57,836 INFO     Evaluating the model... (25000/50000)
2025-12-13 04:19:01,367 INFO     Evaluating the model... (25500/50000)
2025-12-13 04:19:03,857 INFO     Evaluating the model... (26000/50000)
2025-12-13 04:19:06,434 INFO     Evaluating the model... (26500/50000)
2025-12-13 04:19:08,937 INFO     Evaluating the model... (27000/50000)
2025-12-13 04:19:11,621 INFO     Evaluating the model... (27500/50000)
2025-12-13 04:19:14,892 INFO     Evaluating the model... (28000/50000)
2025-12-13 04:19:17,447 INFO     Evaluating the model... (28500/50000)
2025-12-13 04:19:19,936 INFO     Evaluating the model... (29000/50000)
2025-12-13 04:19:22,610 INFO     Evaluating the model... (29500/50000)
2025-12-13 04:19:25,452 INFO     Evaluating the model... (30000/50000)
2025-12-13 04:19:28,381 INFO     Evaluating the model... (30500/50000)
2025-12-13 04:19:30,788 INFO     Evaluating the model... (31000/50000)
2025-12-13 04:19:33,370 INFO     Evaluating the model... (31500/50000)
2025-12-13 04:19:36,059 INFO     Evaluating the model... (32000/50000)
2025-12-13 04:19:39,629 INFO     Evaluating the model... (32500/50000)
2025-12-13 04:19:42,348 INFO     Evaluating the model... (33000/50000)
2025-12-13 04:19:45,390 INFO     Evaluating the model... (33500/50000)
2025-12-13 04:19:48,237 INFO     Evaluating the model... (34000/50000)
2025-12-13 04:19:50,753 INFO     Evaluating the model... (34500/50000)
2025-12-13 04:19:54,179 INFO     Evaluating the model... (35000/50000)
2025-12-13 04:19:56,857 INFO     Evaluating the model... (35500/50000)
2025-12-13 04:19:59,450 INFO     Evaluating the model... (36000/50000)
2025-12-13 04:20:01,918 INFO     Evaluating the model... (36500/50000)
2025-12-13 04:20:04,450 INFO     Evaluating the model... (37000/50000)
2025-12-13 04:20:08,103 INFO     Evaluating the model... (37500/50000)
2025-12-13 04:20:10,842 INFO     Evaluating the model... (38000/50000)
2025-12-13 04:20:13,277 INFO     Evaluating the model... (38500/50000)
2025-12-13 04:20:15,816 INFO     Evaluating the model... (39000/50000)
2025-12-13 04:20:18,375 INFO     Evaluating the model... (39500/50000)
2025-12-13 04:20:22,202 INFO     Evaluating the model... (40000/50000)
2025-12-13 04:20:24,703 INFO     Evaluating the model... (40500/50000)
2025-12-13 04:20:27,341 INFO     Evaluating the model... (41000/50000)
2025-12-13 04:20:29,775 INFO     Evaluating the model... (41500/50000)
2025-12-13 04:20:32,501 INFO     Evaluating the model... (42000/50000)
2025-12-13 04:20:36,025 INFO     Evaluating the model... (42500/50000)
2025-12-13 04:20:38,709 INFO     Evaluating the model... (43000/50000)
2025-12-13 04:20:41,451 INFO     Evaluating the model... (43500/50000)
2025-12-13 04:20:44,437 INFO     Evaluating the model... (44000/50000)
2025-12-13 04:20:47,084 INFO     Evaluating the model... (44500/50000)
2025-12-13 04:20:50,501 INFO     Evaluating the model... (45000/50000)
2025-12-13 04:20:53,060 INFO     Evaluating the model... (45500/50000)
2025-12-13 04:20:55,832 INFO     Evaluating the model... (46000/50000)
2025-12-13 04:20:58,412 INFO     Evaluating the model... (46500/50000)
2025-12-13 04:21:00,977 INFO     Evaluating the model... (47000/50000)
2025-12-13 04:21:04,415 INFO     Evaluating the model... (47500/50000)
2025-12-13 04:21:07,195 INFO     Evaluating the model... (48000/50000)
2025-12-13 04:21:09,729 INFO     Evaluating the model... (48500/50000)
2025-12-13 04:21:12,183 INFO     Evaluating the model... (49000/50000)
2025-12-13 04:21:15,084 INFO     Evaluating the model... (49500/50000)
2025-12-13 04:21:18,382 INFO     Valid MRR at step 220000: 0.633292
2025-12-13 04:21:18,382 INFO     Valid MR at step 220000: 266.854610
2025-12-13 04:21:18,382 INFO     Valid HITS@1 at step 220000: 0.547700
2025-12-13 04:21:18,382 INFO     Valid HITS@3 at step 220000: 0.686080
2025-12-13 04:21:18,382 INFO     Valid HITS@10 at step 220000: 0.784830
2025-12-13 04:21:19,704 INFO     Evaluating on Test Dataset...
2025-12-13 04:21:20,223 INFO     Evaluating the model... (0/59072)
2025-12-13 04:21:22,791 INFO     Evaluating the model... (500/59072)
2025-12-13 04:21:25,277 INFO     Evaluating the model... (1000/59072)
2025-12-13 04:21:27,831 INFO     Evaluating the model... (1500/59072)
2025-12-13 04:21:30,540 INFO     Evaluating the model... (2000/59072)
2025-12-13 04:21:34,036 INFO     Evaluating the model... (2500/59072)
2025-12-13 04:21:36,810 INFO     Evaluating the model... (3000/59072)
2025-12-13 04:21:39,434 INFO     Evaluating the model... (3500/59072)
2025-12-13 04:21:42,426 INFO     Evaluating the model... (4000/59072)
2025-12-13 04:21:45,194 INFO     Evaluating the model... (4500/59072)
2025-12-13 04:21:48,849 INFO     Evaluating the model... (5000/59072)
2025-12-13 04:21:51,181 INFO     Evaluating the model... (5500/59072)
2025-12-13 04:21:53,921 INFO     Evaluating the model... (6000/59072)
2025-12-13 04:21:56,500 INFO     Evaluating the model... (6500/59072)
2025-12-13 04:21:58,953 INFO     Evaluating the model... (7000/59072)
2025-12-13 04:22:02,074 INFO     Evaluating the model... (7500/59072)
2025-12-13 04:22:04,808 INFO     Evaluating the model... (8000/59072)
2025-12-13 04:22:07,331 INFO     Evaluating the model... (8500/59072)
2025-12-13 04:22:09,776 INFO     Evaluating the model... (9000/59072)
2025-12-13 04:22:12,970 INFO     Evaluating the model... (9500/59072)
2025-12-13 04:22:15,502 INFO     Evaluating the model... (10000/59072)
2025-12-13 04:22:18,126 INFO     Evaluating the model... (10500/59072)
2025-12-13 04:22:20,525 INFO     Evaluating the model... (11000/59072)
2025-12-13 04:22:22,933 INFO     Evaluating the model... (11500/59072)
2025-12-13 04:22:26,108 INFO     Evaluating the model... (12000/59072)
2025-12-13 04:22:28,752 INFO     Evaluating the model... (12500/59072)
2025-12-13 04:22:31,243 INFO     Evaluating the model... (13000/59072)
2025-12-13 04:22:33,654 INFO     Evaluating the model... (13500/59072)
2025-12-13 04:22:36,377 INFO     Evaluating the model... (14000/59072)
2025-12-13 04:22:39,915 INFO     Evaluating the model... (14500/59072)
2025-12-13 04:22:42,647 INFO     Evaluating the model... (15000/59072)
2025-12-13 04:22:45,297 INFO     Evaluating the model... (15500/59072)
2025-12-13 04:22:47,743 INFO     Evaluating the model... (16000/59072)
2025-12-13 04:22:50,232 INFO     Evaluating the model... (16500/59072)
2025-12-13 04:22:53,696 INFO     Evaluating the model... (17000/59072)
2025-12-13 04:22:56,191 INFO     Evaluating the model... (17500/59072)
2025-12-13 04:22:58,581 INFO     Evaluating the model... (18000/59072)
2025-12-13 04:23:01,201 INFO     Evaluating the model... (18500/59072)
2025-12-13 04:23:03,630 INFO     Evaluating the model... (19000/59072)
2025-12-13 04:23:06,958 INFO     Evaluating the model... (19500/59072)
2025-12-13 04:23:09,353 INFO     Evaluating the model... (20000/59072)
2025-12-13 04:23:11,920 INFO     Evaluating the model... (20500/59072)
2025-12-13 04:23:14,534 INFO     Evaluating the model... (21000/59072)
2025-12-13 04:23:17,092 INFO     Evaluating the model... (21500/59072)
2025-12-13 04:23:20,070 INFO     Evaluating the model... (22000/59072)
2025-12-13 04:23:22,573 INFO     Evaluating the model... (22500/59072)
2025-12-13 04:23:25,176 INFO     Evaluating the model... (23000/59072)
2025-12-13 04:23:27,676 INFO     Evaluating the model... (23500/59072)
2025-12-13 04:23:30,052 INFO     Evaluating the model... (24000/59072)
2025-12-13 04:23:33,100 INFO     Evaluating the model... (24500/59072)
2025-12-13 04:23:35,625 INFO     Evaluating the model... (25000/59072)
2025-12-13 04:23:38,503 INFO     Evaluating the model... (25500/59072)
2025-12-13 04:23:41,197 INFO     Evaluating the model... (26000/59072)
2025-12-13 04:23:43,832 INFO     Evaluating the model... (26500/59072)
2025-12-13 04:23:47,595 INFO     Evaluating the model... (27000/59072)
2025-12-13 04:23:50,058 INFO     Evaluating the model... (27500/59072)
2025-12-13 04:23:52,481 INFO     Evaluating the model... (28000/59072)
2025-12-13 04:23:54,960 INFO     Evaluating the model... (28500/59072)
2025-12-13 04:23:58,362 INFO     Evaluating the model... (29000/59072)
2025-12-13 04:24:00,859 INFO     Evaluating the model... (29500/59072)
2025-12-13 04:24:03,749 INFO     Evaluating the model... (30000/59072)
2025-12-13 04:24:06,347 INFO     Evaluating the model... (30500/59072)
2025-12-13 04:24:08,834 INFO     Evaluating the model... (31000/59072)
2025-12-13 04:24:12,362 INFO     Evaluating the model... (31500/59072)
2025-12-13 04:24:14,806 INFO     Evaluating the model... (32000/59072)
2025-12-13 04:24:17,358 INFO     Evaluating the model... (32500/59072)
2025-12-13 04:24:19,854 INFO     Evaluating the model... (33000/59072)
2025-12-13 04:24:22,387 INFO     Evaluating the model... (33500/59072)
2025-12-13 04:24:25,944 INFO     Evaluating the model... (34000/59072)
2025-12-13 04:24:28,460 INFO     Evaluating the model... (34500/59072)
2025-12-13 04:24:30,849 INFO     Evaluating the model... (35000/59072)
2025-12-13 04:24:33,402 INFO     Evaluating the model... (35500/59072)
2025-12-13 04:24:36,190 INFO     Evaluating the model... (36000/59072)
2025-12-13 04:24:39,453 INFO     Evaluating the model... (36500/59072)
2025-12-13 04:24:42,211 INFO     Evaluating the model... (37000/59072)
2025-12-13 04:24:45,075 INFO     Evaluating the model... (37500/59072)
2025-12-13 04:24:47,670 INFO     Evaluating the model... (38000/59072)
2025-12-13 04:24:50,116 INFO     Evaluating the model... (38500/59072)
2025-12-13 04:24:53,141 INFO     Evaluating the model... (39000/59072)
2025-12-13 04:24:55,713 INFO     Evaluating the model... (39500/59072)
2025-12-13 04:24:58,305 INFO     Evaluating the model... (40000/59072)
2025-12-13 04:25:00,817 INFO     Evaluating the model... (40500/59072)
2025-12-13 04:25:03,982 INFO     Evaluating the model... (41000/59072)
2025-12-13 04:25:06,475 INFO     Evaluating the model... (41500/59072)
2025-12-13 04:25:09,233 INFO     Evaluating the model... (42000/59072)
2025-12-13 04:25:11,724 INFO     Evaluating the model... (42500/59072)
2025-12-13 04:25:14,168 INFO     Evaluating the model... (43000/59072)
2025-12-13 04:25:17,339 INFO     Evaluating the model... (43500/59072)
2025-12-13 04:25:20,029 INFO     Evaluating the model... (44000/59072)
2025-12-13 04:25:22,637 INFO     Evaluating the model... (44500/59072)
2025-12-13 04:25:25,082 INFO     Evaluating the model... (45000/59072)
2025-12-13 04:25:27,628 INFO     Evaluating the model... (45500/59072)
2025-12-13 04:25:31,049 INFO     Evaluating the model... (46000/59072)
2025-12-13 04:25:33,572 INFO     Evaluating the model... (46500/59072)
2025-12-13 04:25:36,240 INFO     Evaluating the model... (47000/59072)
2025-12-13 04:25:38,859 INFO     Evaluating the model... (47500/59072)
2025-12-13 04:25:41,481 INFO     Evaluating the model... (48000/59072)
2025-12-13 04:25:45,054 INFO     Evaluating the model... (48500/59072)
2025-12-13 04:25:47,590 INFO     Evaluating the model... (49000/59072)
2025-12-13 04:25:50,128 INFO     Evaluating the model... (49500/59072)
2025-12-13 04:25:52,817 INFO     Evaluating the model... (50000/59072)
2025-12-13 04:25:55,659 INFO     Evaluating the model... (50500/59072)
2025-12-13 04:25:58,944 INFO     Evaluating the model... (51000/59072)
2025-12-13 04:26:01,475 INFO     Evaluating the model... (51500/59072)
2025-12-13 04:26:03,938 INFO     Evaluating the model... (52000/59072)
2025-12-13 04:26:06,676 INFO     Evaluating the model... (52500/59072)
2025-12-13 04:26:09,173 INFO     Evaluating the model... (53000/59072)
2025-12-13 04:26:12,137 INFO     Evaluating the model... (53500/59072)
2025-12-13 04:26:14,587 INFO     Evaluating the model... (54000/59072)
2025-12-13 04:26:17,344 INFO     Evaluating the model... (54500/59072)
2025-12-13 04:26:19,862 INFO     Evaluating the model... (55000/59072)
2025-12-13 04:26:22,297 INFO     Evaluating the model... (55500/59072)
2025-12-13 04:26:25,713 INFO     Evaluating the model... (56000/59072)
2025-12-13 04:26:28,210 INFO     Evaluating the model... (56500/59072)
2025-12-13 04:26:30,789 INFO     Evaluating the model... (57000/59072)
2025-12-13 04:26:33,361 INFO     Evaluating the model... (57500/59072)
2025-12-13 04:26:35,880 INFO     Evaluating the model... (58000/59072)
2025-12-13 04:26:39,742 INFO     Evaluating the model... (58500/59072)
2025-12-13 04:26:42,537 INFO     Evaluating the model... (59000/59072)
2025-12-13 04:26:43,245 INFO     Test MRR at step 220000: 0.630186
2025-12-13 04:26:43,245 INFO     Test MR at step 220000: 268.829239
2025-12-13 04:26:43,245 INFO     Test HITS@1 at step 220000: 0.543194
2025-12-13 04:26:43,245 INFO     Test HITS@3 at step 220000: 0.684473
2025-12-13 04:26:43,245 INFO     Test HITS@10 at step 220000: 0.782965
2025-12-13 04:26:45,452 INFO     Training average regularization at step 220100: 0.302039
2025-12-13 04:26:45,452 INFO     Training average positive_sample_loss at step 220100: 0.066405
2025-12-13 04:26:45,452 INFO     Training average negative_sample_loss at step 220100: 0.108445
2025-12-13 04:26:45,453 INFO     Training average loss at step 220100: 0.389464
2025-12-13 04:26:47,617 INFO     Training average regularization at step 220200: 0.302039
2025-12-13 04:26:47,617 INFO     Training average positive_sample_loss at step 220200: 0.067085
2025-12-13 04:26:47,617 INFO     Training average negative_sample_loss at step 220200: 0.110873
2025-12-13 04:26:47,617 INFO     Training average loss at step 220200: 0.391018
2025-12-13 04:26:49,801 INFO     Training average regularization at step 220300: 0.302039
2025-12-13 04:26:49,801 INFO     Training average positive_sample_loss at step 220300: 0.066610
2025-12-13 04:26:49,801 INFO     Training average negative_sample_loss at step 220300: 0.108800
2025-12-13 04:26:49,801 INFO     Training average loss at step 220300: 0.389744
2025-12-13 04:26:51,986 INFO     Training average regularization at step 220400: 0.302039
2025-12-13 04:26:51,986 INFO     Training average positive_sample_loss at step 220400: 0.066832
2025-12-13 04:26:51,986 INFO     Training average negative_sample_loss at step 220400: 0.109136
2025-12-13 04:26:51,986 INFO     Training average loss at step 220400: 0.390023
2025-12-13 04:26:54,158 INFO     Training average regularization at step 220500: 0.302039
2025-12-13 04:26:54,159 INFO     Training average positive_sample_loss at step 220500: 0.066256
2025-12-13 04:26:54,159 INFO     Training average negative_sample_loss at step 220500: 0.107692
2025-12-13 04:26:54,159 INFO     Training average loss at step 220500: 0.389013
2025-12-13 04:26:56,335 INFO     Training average regularization at step 220600: 0.302039
2025-12-13 04:26:56,336 INFO     Training average positive_sample_loss at step 220600: 0.067277
2025-12-13 04:26:56,336 INFO     Training average negative_sample_loss at step 220600: 0.109587
2025-12-13 04:26:56,336 INFO     Training average loss at step 220600: 0.390471
2025-12-13 04:26:58,496 INFO     Training average regularization at step 220700: 0.302039
2025-12-13 04:26:58,496 INFO     Training average positive_sample_loss at step 220700: 0.065606
2025-12-13 04:26:58,496 INFO     Training average negative_sample_loss at step 220700: 0.106499
2025-12-13 04:26:58,496 INFO     Training average loss at step 220700: 0.388092
2025-12-13 04:27:00,659 INFO     Training average regularization at step 220800: 0.302039
2025-12-13 04:27:00,659 INFO     Training average positive_sample_loss at step 220800: 0.065791
2025-12-13 04:27:00,659 INFO     Training average negative_sample_loss at step 220800: 0.108261
2025-12-13 04:27:00,659 INFO     Training average loss at step 220800: 0.389065
2025-12-13 04:27:02,847 INFO     Training average regularization at step 220900: 0.302039
2025-12-13 04:27:02,847 INFO     Training average positive_sample_loss at step 220900: 0.065523
2025-12-13 04:27:02,847 INFO     Training average negative_sample_loss at step 220900: 0.107764
2025-12-13 04:27:02,847 INFO     Training average loss at step 220900: 0.388682
2025-12-13 04:27:05,014 INFO     Training average regularization at step 221000: 0.302039
2025-12-13 04:27:05,014 INFO     Training average positive_sample_loss at step 221000: 0.066776
2025-12-13 04:27:05,014 INFO     Training average negative_sample_loss at step 221000: 0.106834
2025-12-13 04:27:05,014 INFO     Training average loss at step 221000: 0.388844
2025-12-13 04:27:07,165 INFO     Training average regularization at step 221100: 0.302039
2025-12-13 04:27:07,165 INFO     Training average positive_sample_loss at step 221100: 0.066790
2025-12-13 04:27:07,165 INFO     Training average negative_sample_loss at step 221100: 0.108996
2025-12-13 04:27:07,165 INFO     Training average loss at step 221100: 0.389932
2025-12-13 04:27:09,313 INFO     Training average regularization at step 221200: 0.302039
2025-12-13 04:27:09,313 INFO     Training average positive_sample_loss at step 221200: 0.066388
2025-12-13 04:27:09,313 INFO     Training average negative_sample_loss at step 221200: 0.108332
2025-12-13 04:27:09,313 INFO     Training average loss at step 221200: 0.389399
2025-12-13 04:27:11,482 INFO     Training average regularization at step 221300: 0.302039
2025-12-13 04:27:11,482 INFO     Training average positive_sample_loss at step 221300: 0.066621
2025-12-13 04:27:11,482 INFO     Training average negative_sample_loss at step 221300: 0.107393
2025-12-13 04:27:11,482 INFO     Training average loss at step 221300: 0.389046
2025-12-13 04:27:13,671 INFO     Training average regularization at step 221400: 0.302039
2025-12-13 04:27:13,672 INFO     Training average positive_sample_loss at step 221400: 0.065465
2025-12-13 04:27:13,672 INFO     Training average negative_sample_loss at step 221400: 0.109743
2025-12-13 04:27:13,672 INFO     Training average loss at step 221400: 0.389642
2025-12-13 04:27:15,825 INFO     Training average regularization at step 221500: 0.302039
2025-12-13 04:27:15,825 INFO     Training average positive_sample_loss at step 221500: 0.065322
2025-12-13 04:27:15,825 INFO     Training average negative_sample_loss at step 221500: 0.108838
2025-12-13 04:27:15,825 INFO     Training average loss at step 221500: 0.389119
2025-12-13 04:27:17,979 INFO     Training average regularization at step 221600: 0.302038
2025-12-13 04:27:17,979 INFO     Training average positive_sample_loss at step 221600: 0.065939
2025-12-13 04:27:17,979 INFO     Training average negative_sample_loss at step 221600: 0.110932
2025-12-13 04:27:17,979 INFO     Training average loss at step 221600: 0.390474
2025-12-13 04:27:20,146 INFO     Training average regularization at step 221700: 0.302038
2025-12-13 04:27:20,147 INFO     Training average positive_sample_loss at step 221700: 0.065312
2025-12-13 04:27:20,147 INFO     Training average negative_sample_loss at step 221700: 0.110166
2025-12-13 04:27:20,147 INFO     Training average loss at step 221700: 0.389777
2025-12-13 04:27:22,309 INFO     Training average regularization at step 221800: 0.302038
2025-12-13 04:27:22,309 INFO     Training average positive_sample_loss at step 221800: 0.066357
2025-12-13 04:27:22,309 INFO     Training average negative_sample_loss at step 221800: 0.108964
2025-12-13 04:27:22,309 INFO     Training average loss at step 221800: 0.389699
2025-12-13 04:27:24,488 INFO     Training average regularization at step 221900: 0.302038
2025-12-13 04:27:24,489 INFO     Training average positive_sample_loss at step 221900: 0.067346
2025-12-13 04:27:24,489 INFO     Training average negative_sample_loss at step 221900: 0.108937
2025-12-13 04:27:24,489 INFO     Training average loss at step 221900: 0.390180
2025-12-13 04:27:26,649 INFO     Training average regularization at step 222000: 0.302038
2025-12-13 04:27:26,650 INFO     Training average positive_sample_loss at step 222000: 0.067594
2025-12-13 04:27:26,650 INFO     Training average negative_sample_loss at step 222000: 0.108463
2025-12-13 04:27:26,650 INFO     Training average loss at step 222000: 0.390067
2025-12-13 04:27:28,805 INFO     Training average regularization at step 222100: 0.302038
2025-12-13 04:27:28,806 INFO     Training average positive_sample_loss at step 222100: 0.067066
2025-12-13 04:27:28,806 INFO     Training average negative_sample_loss at step 222100: 0.106137
2025-12-13 04:27:28,806 INFO     Training average loss at step 222100: 0.388639
2025-12-13 04:27:30,950 INFO     Training average regularization at step 222200: 0.302038
2025-12-13 04:27:30,950 INFO     Training average positive_sample_loss at step 222200: 0.068203
2025-12-13 04:27:30,950 INFO     Training average negative_sample_loss at step 222200: 0.110312
2025-12-13 04:27:30,950 INFO     Training average loss at step 222200: 0.391296
2025-12-13 04:27:34,148 INFO     Training average regularization at step 222300: 0.302038
2025-12-13 04:27:34,149 INFO     Training average positive_sample_loss at step 222300: 0.066948
2025-12-13 04:27:34,149 INFO     Training average negative_sample_loss at step 222300: 0.109390
2025-12-13 04:27:34,149 INFO     Training average loss at step 222300: 0.390207
2025-12-13 04:27:36,336 INFO     Training average regularization at step 222400: 0.302038
2025-12-13 04:27:36,343 INFO     Training average positive_sample_loss at step 222400: 0.066993
2025-12-13 04:27:36,343 INFO     Training average negative_sample_loss at step 222400: 0.109776
2025-12-13 04:27:36,343 INFO     Training average loss at step 222400: 0.390422
2025-12-13 04:27:38,536 INFO     Training average regularization at step 222500: 0.302038
2025-12-13 04:27:38,536 INFO     Training average positive_sample_loss at step 222500: 0.066425
2025-12-13 04:27:38,536 INFO     Training average negative_sample_loss at step 222500: 0.108336
2025-12-13 04:27:38,536 INFO     Training average loss at step 222500: 0.389418
2025-12-13 04:27:40,718 INFO     Training average regularization at step 222600: 0.302038
2025-12-13 04:27:40,718 INFO     Training average positive_sample_loss at step 222600: 0.066264
2025-12-13 04:27:40,718 INFO     Training average negative_sample_loss at step 222600: 0.107575
2025-12-13 04:27:40,718 INFO     Training average loss at step 222600: 0.388957
2025-12-13 04:27:42,914 INFO     Training average regularization at step 222700: 0.302038
2025-12-13 04:27:42,915 INFO     Training average positive_sample_loss at step 222700: 0.067339
2025-12-13 04:27:42,915 INFO     Training average negative_sample_loss at step 222700: 0.108050
2025-12-13 04:27:42,915 INFO     Training average loss at step 222700: 0.389732
2025-12-13 04:27:45,105 INFO     Training average regularization at step 222800: 0.302038
2025-12-13 04:27:45,106 INFO     Training average positive_sample_loss at step 222800: 0.068110
2025-12-13 04:27:45,106 INFO     Training average negative_sample_loss at step 222800: 0.110265
2025-12-13 04:27:45,106 INFO     Training average loss at step 222800: 0.391225
2025-12-13 04:27:47,269 INFO     Training average regularization at step 222900: 0.302038
2025-12-13 04:27:47,269 INFO     Training average positive_sample_loss at step 222900: 0.065673
2025-12-13 04:27:47,269 INFO     Training average negative_sample_loss at step 222900: 0.108232
2025-12-13 04:27:47,269 INFO     Training average loss at step 222900: 0.388990
2025-12-13 04:27:49,415 INFO     Training average regularization at step 223000: 0.302037
2025-12-13 04:27:49,416 INFO     Training average positive_sample_loss at step 223000: 0.066140
2025-12-13 04:27:49,416 INFO     Training average negative_sample_loss at step 223000: 0.107429
2025-12-13 04:27:49,416 INFO     Training average loss at step 223000: 0.388822
2025-12-13 04:27:51,553 INFO     Training average regularization at step 223100: 0.302037
2025-12-13 04:27:51,553 INFO     Training average positive_sample_loss at step 223100: 0.065467
2025-12-13 04:27:51,553 INFO     Training average negative_sample_loss at step 223100: 0.109485
2025-12-13 04:27:51,553 INFO     Training average loss at step 223100: 0.389513
2025-12-13 04:27:53,670 INFO     Training average regularization at step 223200: 0.302037
2025-12-13 04:27:53,671 INFO     Training average positive_sample_loss at step 223200: 0.066566
2025-12-13 04:27:53,671 INFO     Training average negative_sample_loss at step 223200: 0.108472
2025-12-13 04:27:53,671 INFO     Training average loss at step 223200: 0.389556
2025-12-13 04:27:55,801 INFO     Training average regularization at step 223300: 0.302037
2025-12-13 04:27:55,801 INFO     Training average positive_sample_loss at step 223300: 0.066774
2025-12-13 04:27:55,801 INFO     Training average negative_sample_loss at step 223300: 0.109124
2025-12-13 04:27:55,801 INFO     Training average loss at step 223300: 0.389986
2025-12-13 04:27:57,961 INFO     Training average regularization at step 223400: 0.302037
2025-12-13 04:27:57,961 INFO     Training average positive_sample_loss at step 223400: 0.067880
2025-12-13 04:27:57,961 INFO     Training average negative_sample_loss at step 223400: 0.111261
2025-12-13 04:27:57,961 INFO     Training average loss at step 223400: 0.391607
2025-12-13 04:28:00,103 INFO     Training average regularization at step 223500: 0.302037
2025-12-13 04:28:00,103 INFO     Training average positive_sample_loss at step 223500: 0.066867
2025-12-13 04:28:00,103 INFO     Training average negative_sample_loss at step 223500: 0.111006
2025-12-13 04:28:00,103 INFO     Training average loss at step 223500: 0.390973
2025-12-13 04:28:02,218 INFO     Training average regularization at step 223600: 0.302037
2025-12-13 04:28:02,220 INFO     Training average positive_sample_loss at step 223600: 0.066340
2025-12-13 04:28:02,220 INFO     Training average negative_sample_loss at step 223600: 0.108924
2025-12-13 04:28:02,220 INFO     Training average loss at step 223600: 0.389669
2025-12-13 04:28:04,376 INFO     Training average regularization at step 223700: 0.302037
2025-12-13 04:28:04,376 INFO     Training average positive_sample_loss at step 223700: 0.066838
2025-12-13 04:28:04,376 INFO     Training average negative_sample_loss at step 223700: 0.109315
2025-12-13 04:28:04,376 INFO     Training average loss at step 223700: 0.390113
2025-12-13 04:28:06,524 INFO     Training average regularization at step 223800: 0.302037
2025-12-13 04:28:06,524 INFO     Training average positive_sample_loss at step 223800: 0.066702
2025-12-13 04:28:06,524 INFO     Training average negative_sample_loss at step 223800: 0.105818
2025-12-13 04:28:06,524 INFO     Training average loss at step 223800: 0.388297
2025-12-13 04:28:08,656 INFO     Training average regularization at step 223900: 0.302037
2025-12-13 04:28:08,656 INFO     Training average positive_sample_loss at step 223900: 0.067149
2025-12-13 04:28:08,656 INFO     Training average negative_sample_loss at step 223900: 0.109709
2025-12-13 04:28:08,656 INFO     Training average loss at step 223900: 0.390466
2025-12-13 04:28:10,796 INFO     Training average regularization at step 224000: 0.302037
2025-12-13 04:28:10,796 INFO     Training average positive_sample_loss at step 224000: 0.067440
2025-12-13 04:28:10,796 INFO     Training average negative_sample_loss at step 224000: 0.109060
2025-12-13 04:28:10,796 INFO     Training average loss at step 224000: 0.390286
2025-12-13 04:28:12,942 INFO     Training average regularization at step 224100: 0.302037
2025-12-13 04:28:12,942 INFO     Training average positive_sample_loss at step 224100: 0.067271
2025-12-13 04:28:12,942 INFO     Training average negative_sample_loss at step 224100: 0.109248
2025-12-13 04:28:12,942 INFO     Training average loss at step 224100: 0.390296
2025-12-13 04:28:15,094 INFO     Training average regularization at step 224200: 0.302037
2025-12-13 04:28:15,094 INFO     Training average positive_sample_loss at step 224200: 0.067276
2025-12-13 04:28:15,094 INFO     Training average negative_sample_loss at step 224200: 0.108193
2025-12-13 04:28:15,094 INFO     Training average loss at step 224200: 0.389771
2025-12-13 04:28:17,222 INFO     Training average regularization at step 224300: 0.302037
2025-12-13 04:28:17,222 INFO     Training average positive_sample_loss at step 224300: 0.065794
2025-12-13 04:28:17,223 INFO     Training average negative_sample_loss at step 224300: 0.110085
2025-12-13 04:28:17,223 INFO     Training average loss at step 224300: 0.389976
2025-12-13 04:28:19,381 INFO     Training average regularization at step 224400: 0.302036
2025-12-13 04:28:19,381 INFO     Training average positive_sample_loss at step 224400: 0.067522
2025-12-13 04:28:19,381 INFO     Training average negative_sample_loss at step 224400: 0.109384
2025-12-13 04:28:19,381 INFO     Training average loss at step 224400: 0.390490
2025-12-13 04:28:21,513 INFO     Training average regularization at step 224500: 0.302036
2025-12-13 04:28:21,513 INFO     Training average positive_sample_loss at step 224500: 0.067835
2025-12-13 04:28:21,513 INFO     Training average negative_sample_loss at step 224500: 0.108386
2025-12-13 04:28:21,513 INFO     Training average loss at step 224500: 0.390147
2025-12-13 04:28:23,633 INFO     Training average regularization at step 224600: 0.302036
2025-12-13 04:28:23,633 INFO     Training average positive_sample_loss at step 224600: 0.066462
2025-12-13 04:28:23,633 INFO     Training average negative_sample_loss at step 224600: 0.109543
2025-12-13 04:28:23,633 INFO     Training average loss at step 224600: 0.390039
2025-12-13 04:28:25,795 INFO     Training average regularization at step 224700: 0.302036
2025-12-13 04:28:25,795 INFO     Training average positive_sample_loss at step 224700: 0.066857
2025-12-13 04:28:25,795 INFO     Training average negative_sample_loss at step 224700: 0.110300
2025-12-13 04:28:25,795 INFO     Training average loss at step 224700: 0.390615
2025-12-13 04:28:27,931 INFO     Training average regularization at step 224800: 0.302036
2025-12-13 04:28:27,931 INFO     Training average positive_sample_loss at step 224800: 0.066998
2025-12-13 04:28:27,931 INFO     Training average negative_sample_loss at step 224800: 0.108988
2025-12-13 04:28:27,931 INFO     Training average loss at step 224800: 0.390029
2025-12-13 04:28:30,069 INFO     Training average regularization at step 224900: 0.302036
2025-12-13 04:28:30,069 INFO     Training average positive_sample_loss at step 224900: 0.066110
2025-12-13 04:28:30,069 INFO     Training average negative_sample_loss at step 224900: 0.108287
2025-12-13 04:28:30,069 INFO     Training average loss at step 224900: 0.389235
2025-12-13 04:28:32,213 INFO     Training average regularization at step 225000: 0.302036
2025-12-13 04:28:32,214 INFO     Training average positive_sample_loss at step 225000: 0.066201
2025-12-13 04:28:32,214 INFO     Training average negative_sample_loss at step 225000: 0.106823
2025-12-13 04:28:32,214 INFO     Training average loss at step 225000: 0.388548
2025-12-13 04:28:34,366 INFO     Training average regularization at step 225100: 0.302036
2025-12-13 04:28:34,366 INFO     Training average positive_sample_loss at step 225100: 0.066525
2025-12-13 04:28:34,366 INFO     Training average negative_sample_loss at step 225100: 0.109121
2025-12-13 04:28:34,366 INFO     Training average loss at step 225100: 0.389859
2025-12-13 04:28:36,501 INFO     Training average regularization at step 225200: 0.302036
2025-12-13 04:28:36,502 INFO     Training average positive_sample_loss at step 225200: 0.066201
2025-12-13 04:28:36,502 INFO     Training average negative_sample_loss at step 225200: 0.109416
2025-12-13 04:28:36,502 INFO     Training average loss at step 225200: 0.389844
2025-12-13 04:28:38,641 INFO     Training average regularization at step 225300: 0.302036
2025-12-13 04:28:38,641 INFO     Training average positive_sample_loss at step 225300: 0.066637
2025-12-13 04:28:38,641 INFO     Training average negative_sample_loss at step 225300: 0.108761
2025-12-13 04:28:38,641 INFO     Training average loss at step 225300: 0.389735
2025-12-13 04:28:40,775 INFO     Training average regularization at step 225400: 0.302036
2025-12-13 04:28:40,775 INFO     Training average positive_sample_loss at step 225400: 0.067921
2025-12-13 04:28:40,775 INFO     Training average negative_sample_loss at step 225400: 0.109154
2025-12-13 04:28:40,775 INFO     Training average loss at step 225400: 0.390574
2025-12-13 04:28:43,001 INFO     Training average regularization at step 225500: 0.302036
2025-12-13 04:28:43,002 INFO     Training average positive_sample_loss at step 225500: 0.065864
2025-12-13 04:28:43,002 INFO     Training average negative_sample_loss at step 225500: 0.109186
2025-12-13 04:28:43,002 INFO     Training average loss at step 225500: 0.389561
2025-12-13 04:28:45,158 INFO     Training average regularization at step 225600: 0.302036
2025-12-13 04:28:45,158 INFO     Training average positive_sample_loss at step 225600: 0.066115
2025-12-13 04:28:45,158 INFO     Training average negative_sample_loss at step 225600: 0.110185
2025-12-13 04:28:45,158 INFO     Training average loss at step 225600: 0.390186
2025-12-13 04:28:47,289 INFO     Training average regularization at step 225700: 0.302036
2025-12-13 04:28:47,289 INFO     Training average positive_sample_loss at step 225700: 0.065711
2025-12-13 04:28:47,289 INFO     Training average negative_sample_loss at step 225700: 0.109305
2025-12-13 04:28:47,289 INFO     Training average loss at step 225700: 0.389544
2025-12-13 04:28:49,427 INFO     Training average regularization at step 225800: 0.302036
2025-12-13 04:28:49,427 INFO     Training average positive_sample_loss at step 225800: 0.066668
2025-12-13 04:28:49,427 INFO     Training average negative_sample_loss at step 225800: 0.107443
2025-12-13 04:28:49,427 INFO     Training average loss at step 225800: 0.389091
2025-12-13 04:28:51,569 INFO     Training average regularization at step 225900: 0.302036
2025-12-13 04:28:51,569 INFO     Training average positive_sample_loss at step 225900: 0.066749
2025-12-13 04:28:51,569 INFO     Training average negative_sample_loss at step 225900: 0.109418
2025-12-13 04:28:51,570 INFO     Training average loss at step 225900: 0.390119
2025-12-13 04:28:53,735 INFO     Training average regularization at step 226000: 0.302035
2025-12-13 04:28:53,735 INFO     Training average positive_sample_loss at step 226000: 0.066579
2025-12-13 04:28:53,735 INFO     Training average negative_sample_loss at step 226000: 0.110666
2025-12-13 04:28:53,735 INFO     Training average loss at step 226000: 0.390658
2025-12-13 04:28:55,894 INFO     Training average regularization at step 226100: 0.302035
2025-12-13 04:28:55,894 INFO     Training average positive_sample_loss at step 226100: 0.068371
2025-12-13 04:28:55,894 INFO     Training average negative_sample_loss at step 226100: 0.111325
2025-12-13 04:28:55,894 INFO     Training average loss at step 226100: 0.391883
2025-12-13 04:28:58,019 INFO     Training average regularization at step 226200: 0.302035
2025-12-13 04:28:58,019 INFO     Training average positive_sample_loss at step 226200: 0.067326
2025-12-13 04:28:58,019 INFO     Training average negative_sample_loss at step 226200: 0.111863
2025-12-13 04:28:58,019 INFO     Training average loss at step 226200: 0.391630
2025-12-13 04:29:00,151 INFO     Training average regularization at step 226300: 0.302035
2025-12-13 04:29:00,151 INFO     Training average positive_sample_loss at step 226300: 0.065430
2025-12-13 04:29:00,151 INFO     Training average negative_sample_loss at step 226300: 0.109319
2025-12-13 04:29:00,151 INFO     Training average loss at step 226300: 0.389410
2025-12-13 04:29:02,275 INFO     Training average regularization at step 226400: 0.302035
2025-12-13 04:29:02,275 INFO     Training average positive_sample_loss at step 226400: 0.066629
2025-12-13 04:29:02,275 INFO     Training average negative_sample_loss at step 226400: 0.110156
2025-12-13 04:29:02,275 INFO     Training average loss at step 226400: 0.390428
2025-12-13 04:29:04,412 INFO     Training average regularization at step 226500: 0.302035
2025-12-13 04:29:04,413 INFO     Training average positive_sample_loss at step 226500: 0.066760
2025-12-13 04:29:04,413 INFO     Training average negative_sample_loss at step 226500: 0.109644
2025-12-13 04:29:04,413 INFO     Training average loss at step 226500: 0.390237
2025-12-13 04:29:06,564 INFO     Training average regularization at step 226600: 0.302035
2025-12-13 04:29:06,564 INFO     Training average positive_sample_loss at step 226600: 0.066614
2025-12-13 04:29:06,564 INFO     Training average negative_sample_loss at step 226600: 0.111344
2025-12-13 04:29:06,564 INFO     Training average loss at step 226600: 0.391014
2025-12-13 04:29:08,685 INFO     Training average regularization at step 226700: 0.302035
2025-12-13 04:29:08,685 INFO     Training average positive_sample_loss at step 226700: 0.066698
2025-12-13 04:29:08,685 INFO     Training average negative_sample_loss at step 226700: 0.106961
2025-12-13 04:29:08,685 INFO     Training average loss at step 226700: 0.388864
2025-12-13 04:29:10,839 INFO     Training average regularization at step 226800: 0.302035
2025-12-13 04:29:10,839 INFO     Training average positive_sample_loss at step 226800: 0.066613
2025-12-13 04:29:10,839 INFO     Training average negative_sample_loss at step 226800: 0.109232
2025-12-13 04:29:10,839 INFO     Training average loss at step 226800: 0.389957
2025-12-13 04:29:12,985 INFO     Training average regularization at step 226900: 0.302035
2025-12-13 04:29:12,986 INFO     Training average positive_sample_loss at step 226900: 0.066823
2025-12-13 04:29:12,986 INFO     Training average negative_sample_loss at step 226900: 0.106709
2025-12-13 04:29:12,986 INFO     Training average loss at step 226900: 0.388801
2025-12-13 04:29:15,145 INFO     Training average regularization at step 227000: 0.302035
2025-12-13 04:29:15,145 INFO     Training average positive_sample_loss at step 227000: 0.065830
2025-12-13 04:29:15,145 INFO     Training average negative_sample_loss at step 227000: 0.111084
2025-12-13 04:29:15,145 INFO     Training average loss at step 227000: 0.390492
2025-12-13 04:29:17,400 INFO     Training average regularization at step 227100: 0.302035
2025-12-13 04:29:17,400 INFO     Training average positive_sample_loss at step 227100: 0.066796
2025-12-13 04:29:17,400 INFO     Training average negative_sample_loss at step 227100: 0.109507
2025-12-13 04:29:17,400 INFO     Training average loss at step 227100: 0.390187
2025-12-13 04:29:20,437 INFO     Training average regularization at step 227200: 0.302035
2025-12-13 04:29:20,437 INFO     Training average positive_sample_loss at step 227200: 0.066571
2025-12-13 04:29:20,437 INFO     Training average negative_sample_loss at step 227200: 0.110645
2025-12-13 04:29:20,438 INFO     Training average loss at step 227200: 0.390643
2025-12-13 04:29:22,583 INFO     Training average regularization at step 227300: 0.302035
2025-12-13 04:29:22,583 INFO     Training average positive_sample_loss at step 227300: 0.066319
2025-12-13 04:29:22,583 INFO     Training average negative_sample_loss at step 227300: 0.111430
2025-12-13 04:29:22,583 INFO     Training average loss at step 227300: 0.390909
2025-12-13 04:29:24,731 INFO     Training average regularization at step 227400: 0.302035
2025-12-13 04:29:24,732 INFO     Training average positive_sample_loss at step 227400: 0.066317
2025-12-13 04:29:24,732 INFO     Training average negative_sample_loss at step 227400: 0.108071
2025-12-13 04:29:24,732 INFO     Training average loss at step 227400: 0.389229
2025-12-13 04:29:26,895 INFO     Training average regularization at step 227500: 0.302035
2025-12-13 04:29:26,895 INFO     Training average positive_sample_loss at step 227500: 0.066502
2025-12-13 04:29:26,895 INFO     Training average negative_sample_loss at step 227500: 0.107030
2025-12-13 04:29:26,895 INFO     Training average loss at step 227500: 0.388800
2025-12-13 04:29:29,046 INFO     Training average regularization at step 227600: 0.302034
2025-12-13 04:29:29,046 INFO     Training average positive_sample_loss at step 227600: 0.066067
2025-12-13 04:29:29,046 INFO     Training average negative_sample_loss at step 227600: 0.107182
2025-12-13 04:29:29,046 INFO     Training average loss at step 227600: 0.388659
2025-12-13 04:29:31,201 INFO     Training average regularization at step 227700: 0.302034
2025-12-13 04:29:31,202 INFO     Training average positive_sample_loss at step 227700: 0.066275
2025-12-13 04:29:31,202 INFO     Training average negative_sample_loss at step 227700: 0.110921
2025-12-13 04:29:31,202 INFO     Training average loss at step 227700: 0.390633
2025-12-13 04:29:33,353 INFO     Training average regularization at step 227800: 0.302034
2025-12-13 04:29:33,353 INFO     Training average positive_sample_loss at step 227800: 0.066845
2025-12-13 04:29:33,353 INFO     Training average negative_sample_loss at step 227800: 0.111097
2025-12-13 04:29:33,353 INFO     Training average loss at step 227800: 0.391006
2025-12-13 04:29:35,516 INFO     Training average regularization at step 227900: 0.302034
2025-12-13 04:29:35,517 INFO     Training average positive_sample_loss at step 227900: 0.067868
2025-12-13 04:29:35,517 INFO     Training average negative_sample_loss at step 227900: 0.109045
2025-12-13 04:29:35,517 INFO     Training average loss at step 227900: 0.390491
2025-12-13 04:29:37,740 INFO     Training average regularization at step 228000: 0.302034
2025-12-13 04:29:37,740 INFO     Training average positive_sample_loss at step 228000: 0.065674
2025-12-13 04:29:37,741 INFO     Training average negative_sample_loss at step 228000: 0.108757
2025-12-13 04:29:37,741 INFO     Training average loss at step 228000: 0.389250
2025-12-13 04:29:39,916 INFO     Training average regularization at step 228100: 0.302034
2025-12-13 04:29:39,916 INFO     Training average positive_sample_loss at step 228100: 0.066985
2025-12-13 04:29:39,916 INFO     Training average negative_sample_loss at step 228100: 0.109566
2025-12-13 04:29:39,916 INFO     Training average loss at step 228100: 0.390309
2025-12-13 04:29:42,092 INFO     Training average regularization at step 228200: 0.302034
2025-12-13 04:29:42,092 INFO     Training average positive_sample_loss at step 228200: 0.066805
2025-12-13 04:29:42,093 INFO     Training average negative_sample_loss at step 228200: 0.109992
2025-12-13 04:29:42,093 INFO     Training average loss at step 228200: 0.390433
2025-12-13 04:29:44,280 INFO     Training average regularization at step 228300: 0.302034
2025-12-13 04:29:44,280 INFO     Training average positive_sample_loss at step 228300: 0.065406
2025-12-13 04:29:44,280 INFO     Training average negative_sample_loss at step 228300: 0.110117
2025-12-13 04:29:44,280 INFO     Training average loss at step 228300: 0.389795
2025-12-13 04:29:46,431 INFO     Training average regularization at step 228400: 0.302034
2025-12-13 04:29:46,432 INFO     Training average positive_sample_loss at step 228400: 0.066713
2025-12-13 04:29:46,432 INFO     Training average negative_sample_loss at step 228400: 0.109709
2025-12-13 04:29:46,432 INFO     Training average loss at step 228400: 0.390245
2025-12-13 04:29:48,616 INFO     Training average regularization at step 228500: 0.302034
2025-12-13 04:29:48,616 INFO     Training average positive_sample_loss at step 228500: 0.065620
2025-12-13 04:29:48,616 INFO     Training average negative_sample_loss at step 228500: 0.107317
2025-12-13 04:29:48,616 INFO     Training average loss at step 228500: 0.388502
2025-12-13 04:29:50,772 INFO     Training average regularization at step 228600: 0.302034
2025-12-13 04:29:50,772 INFO     Training average positive_sample_loss at step 228600: 0.066220
2025-12-13 04:29:50,772 INFO     Training average negative_sample_loss at step 228600: 0.105091
2025-12-13 04:29:50,772 INFO     Training average loss at step 228600: 0.387689
2025-12-13 04:29:52,926 INFO     Training average regularization at step 228700: 0.302034
2025-12-13 04:29:52,926 INFO     Training average positive_sample_loss at step 228700: 0.066233
2025-12-13 04:29:52,926 INFO     Training average negative_sample_loss at step 228700: 0.107229
2025-12-13 04:29:52,926 INFO     Training average loss at step 228700: 0.388765
2025-12-13 04:29:55,071 INFO     Training average regularization at step 228800: 0.302034
2025-12-13 04:29:55,071 INFO     Training average positive_sample_loss at step 228800: 0.067174
2025-12-13 04:29:55,071 INFO     Training average negative_sample_loss at step 228800: 0.109742
2025-12-13 04:29:55,071 INFO     Training average loss at step 228800: 0.390492
2025-12-13 04:29:57,251 INFO     Training average regularization at step 228900: 0.302033
2025-12-13 04:29:57,251 INFO     Training average positive_sample_loss at step 228900: 0.066288
2025-12-13 04:29:57,251 INFO     Training average negative_sample_loss at step 228900: 0.108598
2025-12-13 04:29:57,251 INFO     Training average loss at step 228900: 0.389476
2025-12-13 04:29:59,435 INFO     Training average regularization at step 229000: 0.302033
2025-12-13 04:29:59,435 INFO     Training average positive_sample_loss at step 229000: 0.067063
2025-12-13 04:29:59,435 INFO     Training average negative_sample_loss at step 229000: 0.108645
2025-12-13 04:29:59,435 INFO     Training average loss at step 229000: 0.389887
2025-12-13 04:30:01,591 INFO     Training average regularization at step 229100: 0.302033
2025-12-13 04:30:01,591 INFO     Training average positive_sample_loss at step 229100: 0.067977
2025-12-13 04:30:01,591 INFO     Training average negative_sample_loss at step 229100: 0.111031
2025-12-13 04:30:01,591 INFO     Training average loss at step 229100: 0.391537
2025-12-13 04:30:03,740 INFO     Training average regularization at step 229200: 0.302033
2025-12-13 04:30:03,740 INFO     Training average positive_sample_loss at step 229200: 0.066032
2025-12-13 04:30:03,740 INFO     Training average negative_sample_loss at step 229200: 0.109276
2025-12-13 04:30:03,740 INFO     Training average loss at step 229200: 0.389687
2025-12-13 04:30:05,907 INFO     Training average regularization at step 229300: 0.302033
2025-12-13 04:30:05,907 INFO     Training average positive_sample_loss at step 229300: 0.068070
2025-12-13 04:30:05,907 INFO     Training average negative_sample_loss at step 229300: 0.110371
2025-12-13 04:30:05,907 INFO     Training average loss at step 229300: 0.391254
2025-12-13 04:30:08,064 INFO     Training average regularization at step 229400: 0.302033
2025-12-13 04:30:08,064 INFO     Training average positive_sample_loss at step 229400: 0.066158
2025-12-13 04:30:08,064 INFO     Training average negative_sample_loss at step 229400: 0.104525
2025-12-13 04:30:08,064 INFO     Training average loss at step 229400: 0.387375
2025-12-13 04:30:10,257 INFO     Training average regularization at step 229500: 0.302033
2025-12-13 04:30:10,257 INFO     Training average positive_sample_loss at step 229500: 0.066425
2025-12-13 04:30:10,257 INFO     Training average negative_sample_loss at step 229500: 0.109392
2025-12-13 04:30:10,257 INFO     Training average loss at step 229500: 0.389942
2025-12-13 04:30:12,407 INFO     Training average regularization at step 229600: 0.302033
2025-12-13 04:30:12,408 INFO     Training average positive_sample_loss at step 229600: 0.066898
2025-12-13 04:30:12,408 INFO     Training average negative_sample_loss at step 229600: 0.105895
2025-12-13 04:30:12,408 INFO     Training average loss at step 229600: 0.388430
2025-12-13 04:30:14,564 INFO     Training average regularization at step 229700: 0.302033
2025-12-13 04:30:14,564 INFO     Training average positive_sample_loss at step 229700: 0.066555
2025-12-13 04:30:14,564 INFO     Training average negative_sample_loss at step 229700: 0.109808
2025-12-13 04:30:14,564 INFO     Training average loss at step 229700: 0.390214
2025-12-13 04:30:16,722 INFO     Training average regularization at step 229800: 0.302033
2025-12-13 04:30:16,722 INFO     Training average positive_sample_loss at step 229800: 0.067083
2025-12-13 04:30:16,722 INFO     Training average negative_sample_loss at step 229800: 0.108994
2025-12-13 04:30:16,722 INFO     Training average loss at step 229800: 0.390072
2025-12-13 04:30:18,879 INFO     Training average regularization at step 229900: 0.302033
2025-12-13 04:30:18,879 INFO     Training average positive_sample_loss at step 229900: 0.068445
2025-12-13 04:30:18,879 INFO     Training average negative_sample_loss at step 229900: 0.108594
2025-12-13 04:30:18,879 INFO     Training average loss at step 229900: 0.390552
2025-12-13 04:30:21,053 INFO     Training average regularization at step 230000: 0.302033
2025-12-13 04:30:21,053 INFO     Training average positive_sample_loss at step 230000: 0.068032
2025-12-13 04:30:21,053 INFO     Training average negative_sample_loss at step 230000: 0.108763
2025-12-13 04:30:21,053 INFO     Training average loss at step 230000: 0.390430
2025-12-13 04:30:21,053 INFO     Evaluating on Valid Dataset...
2025-12-13 04:30:21,775 INFO     Evaluating the model... (0/50000)
2025-12-13 04:30:24,302 INFO     Evaluating the model... (500/50000)
2025-12-13 04:30:26,855 INFO     Evaluating the model... (1000/50000)
2025-12-13 04:30:30,509 INFO     Evaluating the model... (1500/50000)
2025-12-13 04:30:33,092 INFO     Evaluating the model... (2000/50000)
2025-12-13 04:30:35,617 INFO     Evaluating the model... (2500/50000)
2025-12-13 04:30:38,147 INFO     Evaluating the model... (3000/50000)
2025-12-13 04:30:40,762 INFO     Evaluating the model... (3500/50000)
2025-12-13 04:30:44,749 INFO     Evaluating the model... (4000/50000)
2025-12-13 04:30:47,181 INFO     Evaluating the model... (4500/50000)
2025-12-13 04:30:49,675 INFO     Evaluating the model... (5000/50000)
2025-12-13 04:30:52,063 INFO     Evaluating the model... (5500/50000)
2025-12-13 04:30:55,325 INFO     Evaluating the model... (6000/50000)
2025-12-13 04:30:57,902 INFO     Evaluating the model... (6500/50000)
2025-12-13 04:31:00,271 INFO     Evaluating the model... (7000/50000)
2025-12-13 04:31:02,629 INFO     Evaluating the model... (7500/50000)
2025-12-13 04:31:05,149 INFO     Evaluating the model... (8000/50000)
2025-12-13 04:31:08,591 INFO     Evaluating the model... (8500/50000)
2025-12-13 04:31:10,912 INFO     Evaluating the model... (9000/50000)
2025-12-13 04:31:13,345 INFO     Evaluating the model... (9500/50000)
2025-12-13 04:31:15,784 INFO     Evaluating the model... (10000/50000)
2025-12-13 04:31:18,352 INFO     Evaluating the model... (10500/50000)
2025-12-13 04:31:21,451 INFO     Evaluating the model... (11000/50000)
2025-12-13 04:31:23,813 INFO     Evaluating the model... (11500/50000)
2025-12-13 04:31:26,212 INFO     Evaluating the model... (12000/50000)
2025-12-13 04:31:28,659 INFO     Evaluating the model... (12500/50000)
2025-12-13 04:31:31,319 INFO     Evaluating the model... (13000/50000)
2025-12-13 04:31:34,113 INFO     Evaluating the model... (13500/50000)
2025-12-13 04:31:36,650 INFO     Evaluating the model... (14000/50000)
2025-12-13 04:31:39,267 INFO     Evaluating the model... (14500/50000)
2025-12-13 04:31:42,173 INFO     Evaluating the model... (15000/50000)
2025-12-13 04:31:44,799 INFO     Evaluating the model... (15500/50000)
2025-12-13 04:31:47,809 INFO     Evaluating the model... (16000/50000)
2025-12-13 04:31:50,385 INFO     Evaluating the model... (16500/50000)
2025-12-13 04:31:52,877 INFO     Evaluating the model... (17000/50000)
2025-12-13 04:31:55,401 INFO     Evaluating the model... (17500/50000)
2025-12-13 04:31:57,836 INFO     Evaluating the model... (18000/50000)
2025-12-13 04:32:01,052 INFO     Evaluating the model... (18500/50000)
2025-12-13 04:32:03,521 INFO     Evaluating the model... (19000/50000)
2025-12-13 04:32:06,202 INFO     Evaluating the model... (19500/50000)
2025-12-13 04:32:08,645 INFO     Evaluating the model... (20000/50000)
2025-12-13 04:32:11,110 INFO     Evaluating the model... (20500/50000)
2025-12-13 04:32:14,553 INFO     Evaluating the model... (21000/50000)
2025-12-13 04:32:17,295 INFO     Evaluating the model... (21500/50000)
2025-12-13 04:32:19,738 INFO     Evaluating the model... (22000/50000)
2025-12-13 04:32:22,096 INFO     Evaluating the model... (22500/50000)
2025-12-13 04:32:24,500 INFO     Evaluating the model... (23000/50000)
2025-12-13 04:32:27,955 INFO     Evaluating the model... (23500/50000)
2025-12-13 04:32:30,407 INFO     Evaluating the model... (24000/50000)
2025-12-13 04:32:32,787 INFO     Evaluating the model... (24500/50000)
2025-12-13 04:32:35,936 INFO     Evaluating the model... (25000/50000)
2025-12-13 04:32:38,750 INFO     Evaluating the model... (25500/50000)
2025-12-13 04:32:42,839 INFO     Evaluating the model... (26000/50000)
2025-12-13 04:32:45,616 INFO     Evaluating the model... (26500/50000)
2025-12-13 04:32:48,132 INFO     Evaluating the model... (27000/50000)
2025-12-13 04:32:50,695 INFO     Evaluating the model... (27500/50000)
2025-12-13 04:32:53,285 INFO     Evaluating the model... (28000/50000)
2025-12-13 04:32:56,496 INFO     Evaluating the model... (28500/50000)
2025-12-13 04:32:59,054 INFO     Evaluating the model... (29000/50000)
2025-12-13 04:33:01,813 INFO     Evaluating the model... (29500/50000)
2025-12-13 04:33:04,407 INFO     Evaluating the model... (30000/50000)
2025-12-13 04:33:07,018 INFO     Evaluating the model... (30500/50000)
2025-12-13 04:33:10,298 INFO     Evaluating the model... (31000/50000)
2025-12-13 04:33:12,951 INFO     Evaluating the model... (31500/50000)
2025-12-13 04:33:15,732 INFO     Evaluating the model... (32000/50000)
2025-12-13 04:33:18,370 INFO     Evaluating the model... (32500/50000)
2025-12-13 04:33:21,813 INFO     Evaluating the model... (33000/50000)
2025-12-13 04:33:24,329 INFO     Evaluating the model... (33500/50000)
2025-12-13 04:33:27,020 INFO     Evaluating the model... (34000/50000)
2025-12-13 04:33:29,601 INFO     Evaluating the model... (34500/50000)
2025-12-13 04:33:32,219 INFO     Evaluating the model... (35000/50000)
2025-12-13 04:33:35,866 INFO     Evaluating the model... (35500/50000)
2025-12-13 04:33:38,886 INFO     Evaluating the model... (36000/50000)
2025-12-13 04:33:41,527 INFO     Evaluating the model... (36500/50000)
2025-12-13 04:33:44,202 INFO     Evaluating the model... (37000/50000)
2025-12-13 04:33:46,869 INFO     Evaluating the model... (37500/50000)
2025-12-13 04:33:50,473 INFO     Evaluating the model... (38000/50000)
2025-12-13 04:33:52,954 INFO     Evaluating the model... (38500/50000)
2025-12-13 04:33:55,461 INFO     Evaluating the model... (39000/50000)
2025-12-13 04:33:58,000 INFO     Evaluating the model... (39500/50000)
2025-12-13 04:34:00,766 INFO     Evaluating the model... (40000/50000)
2025-12-13 04:34:03,797 INFO     Evaluating the model... (40500/50000)
2025-12-13 04:34:06,377 INFO     Evaluating the model... (41000/50000)
2025-12-13 04:34:08,872 INFO     Evaluating the model... (41500/50000)
2025-12-13 04:34:11,643 INFO     Evaluating the model... (42000/50000)
2025-12-13 04:34:14,183 INFO     Evaluating the model... (42500/50000)
2025-12-13 04:34:17,327 INFO     Evaluating the model... (43000/50000)
2025-12-13 04:34:19,835 INFO     Evaluating the model... (43500/50000)
2025-12-13 04:34:22,532 INFO     Evaluating the model... (44000/50000)
2025-12-13 04:34:25,081 INFO     Evaluating the model... (44500/50000)
2025-12-13 04:34:27,549 INFO     Evaluating the model... (45000/50000)
2025-12-13 04:34:31,117 INFO     Evaluating the model... (45500/50000)
2025-12-13 04:34:33,632 INFO     Evaluating the model... (46000/50000)
2025-12-13 04:34:36,418 INFO     Evaluating the model... (46500/50000)
2025-12-13 04:34:39,232 INFO     Evaluating the model... (47000/50000)
2025-12-13 04:34:42,048 INFO     Evaluating the model... (47500/50000)
2025-12-13 04:34:45,930 INFO     Evaluating the model... (48000/50000)
2025-12-13 04:34:48,447 INFO     Evaluating the model... (48500/50000)
2025-12-13 04:34:50,882 INFO     Evaluating the model... (49000/50000)
2025-12-13 04:34:53,467 INFO     Evaluating the model... (49500/50000)
2025-12-13 04:34:56,404 INFO     Valid MRR at step 230000: 0.633401
2025-12-13 04:34:56,404 INFO     Valid MR at step 230000: 266.909710
2025-12-13 04:34:56,404 INFO     Valid HITS@1 at step 230000: 0.547880
2025-12-13 04:34:56,404 INFO     Valid HITS@3 at step 230000: 0.686140
2025-12-13 04:34:56,404 INFO     Valid HITS@10 at step 230000: 0.784850
2025-12-13 04:34:58,085 INFO     Evaluating on Test Dataset...
2025-12-13 04:34:58,639 INFO     Evaluating the model... (0/59072)
2025-12-13 04:35:02,233 INFO     Evaluating the model... (500/59072)
2025-12-13 04:35:04,835 INFO     Evaluating the model... (1000/59072)
2025-12-13 04:35:07,465 INFO     Evaluating the model... (1500/59072)
2025-12-13 04:35:10,081 INFO     Evaluating the model... (2000/59072)
2025-12-13 04:35:12,576 INFO     Evaluating the model... (2500/59072)
2025-12-13 04:35:15,572 INFO     Evaluating the model... (3000/59072)
2025-12-13 04:35:18,053 INFO     Evaluating the model... (3500/59072)
2025-12-13 04:35:20,816 INFO     Evaluating the model... (4000/59072)
2025-12-13 04:35:23,299 INFO     Evaluating the model... (4500/59072)
2025-12-13 04:35:25,688 INFO     Evaluating the model... (5000/59072)
2025-12-13 04:35:28,699 INFO     Evaluating the model... (5500/59072)
2025-12-13 04:35:31,301 INFO     Evaluating the model... (6000/59072)
2025-12-13 04:35:33,833 INFO     Evaluating the model... (6500/59072)
2025-12-13 04:35:36,351 INFO     Evaluating the model... (7000/59072)
2025-12-13 04:35:38,960 INFO     Evaluating the model... (7500/59072)
2025-12-13 04:35:42,204 INFO     Evaluating the model... (8000/59072)
2025-12-13 04:35:44,920 INFO     Evaluating the model... (8500/59072)
2025-12-13 04:35:47,340 INFO     Evaluating the model... (9000/59072)
2025-12-13 04:35:49,735 INFO     Evaluating the model... (9500/59072)
2025-12-13 04:35:52,742 INFO     Evaluating the model... (10000/59072)
2025-12-13 04:35:55,684 INFO     Evaluating the model... (10500/59072)
2025-12-13 04:35:58,115 INFO     Evaluating the model... (11000/59072)
2025-12-13 04:36:00,505 INFO     Evaluating the model... (11500/59072)
2025-12-13 04:36:02,813 INFO     Evaluating the model... (12000/59072)
2025-12-13 04:36:06,185 INFO     Evaluating the model... (12500/59072)
2025-12-13 04:36:08,525 INFO     Evaluating the model... (13000/59072)
2025-12-13 04:36:10,939 INFO     Evaluating the model... (13500/59072)
2025-12-13 04:36:13,342 INFO     Evaluating the model... (14000/59072)
2025-12-13 04:36:15,797 INFO     Evaluating the model... (14500/59072)
2025-12-13 04:36:19,784 INFO     Evaluating the model... (15000/59072)
2025-12-13 04:36:22,337 INFO     Evaluating the model... (15500/59072)
2025-12-13 04:36:24,801 INFO     Evaluating the model... (16000/59072)
2025-12-13 04:36:27,299 INFO     Evaluating the model... (16500/59072)
2025-12-13 04:36:30,032 INFO     Evaluating the model... (17000/59072)
2025-12-13 04:36:33,590 INFO     Evaluating the model... (17500/59072)
2025-12-13 04:36:36,569 INFO     Evaluating the model... (18000/59072)
2025-12-13 04:36:39,064 INFO     Evaluating the model... (18500/59072)
2025-12-13 04:36:41,919 INFO     Evaluating the model... (19000/59072)
2025-12-13 04:36:44,606 INFO     Evaluating the model... (19500/59072)
2025-12-13 04:36:48,231 INFO     Evaluating the model... (20000/59072)
2025-12-13 04:36:50,641 INFO     Evaluating the model... (20500/59072)
2025-12-13 04:36:53,294 INFO     Evaluating the model... (21000/59072)
2025-12-13 04:36:55,805 INFO     Evaluating the model... (21500/59072)
2025-12-13 04:36:58,125 INFO     Evaluating the model... (22000/59072)
2025-12-13 04:37:01,842 INFO     Evaluating the model... (22500/59072)
2025-12-13 04:37:04,406 INFO     Evaluating the model... (23000/59072)
2025-12-13 04:37:06,793 INFO     Evaluating the model... (23500/59072)
2025-12-13 04:37:09,274 INFO     Evaluating the model... (24000/59072)
2025-12-13 04:37:11,679 INFO     Evaluating the model... (24500/59072)
2025-12-13 04:37:15,717 INFO     Evaluating the model... (25000/59072)
2025-12-13 04:37:18,154 INFO     Evaluating the model... (25500/59072)
2025-12-13 04:37:20,602 INFO     Evaluating the model... (26000/59072)
2025-12-13 04:37:23,116 INFO     Evaluating the model... (26500/59072)
2025-12-13 04:37:25,590 INFO     Evaluating the model... (27000/59072)
2025-12-13 04:37:29,602 INFO     Evaluating the model... (27500/59072)
2025-12-13 04:37:31,952 INFO     Evaluating the model... (28000/59072)
2025-12-13 04:37:34,210 INFO     Evaluating the model... (28500/59072)
2025-12-13 04:37:36,860 INFO     Evaluating the model... (29000/59072)
2025-12-13 04:37:40,585 INFO     Evaluating the model... (29500/59072)
2025-12-13 04:37:44,305 INFO     Evaluating the model... (30000/59072)
2025-12-13 04:37:46,927 INFO     Evaluating the model... (30500/59072)
2025-12-13 04:37:49,522 INFO     Evaluating the model... (31000/59072)
2025-12-13 04:37:52,137 INFO     Evaluating the model... (31500/59072)
2025-12-13 04:37:55,719 INFO     Evaluating the model... (32000/59072)
2025-12-13 04:37:58,246 INFO     Evaluating the model... (32500/59072)
2025-12-13 04:38:00,861 INFO     Evaluating the model... (33000/59072)
2025-12-13 04:38:03,475 INFO     Evaluating the model... (33500/59072)
2025-12-13 04:38:06,004 INFO     Evaluating the model... (34000/59072)
2025-12-13 04:38:09,811 INFO     Evaluating the model... (34500/59072)
2025-12-13 04:38:12,416 INFO     Evaluating the model... (35000/59072)
2025-12-13 04:38:14,967 INFO     Evaluating the model... (35500/59072)
2025-12-13 04:38:17,379 INFO     Evaluating the model... (36000/59072)
2025-12-13 04:38:19,904 INFO     Evaluating the model... (36500/59072)
2025-12-13 04:38:23,289 INFO     Evaluating the model... (37000/59072)
2025-12-13 04:38:25,990 INFO     Evaluating the model... (37500/59072)
2025-12-13 04:38:28,415 INFO     Evaluating the model... (38000/59072)
2025-12-13 04:38:30,903 INFO     Evaluating the model... (38500/59072)
2025-12-13 04:38:33,444 INFO     Evaluating the model... (39000/59072)
2025-12-13 04:38:36,945 INFO     Evaluating the model... (39500/59072)
2025-12-13 04:38:39,555 INFO     Evaluating the model... (40000/59072)
2025-12-13 04:38:42,237 INFO     Evaluating the model... (40500/59072)
2025-12-13 04:38:44,942 INFO     Evaluating the model... (41000/59072)
2025-12-13 04:38:47,614 INFO     Evaluating the model... (41500/59072)
2025-12-13 04:38:51,136 INFO     Evaluating the model... (42000/59072)
2025-12-13 04:38:53,574 INFO     Evaluating the model... (42500/59072)
2025-12-13 04:38:56,204 INFO     Evaluating the model... (43000/59072)
2025-12-13 04:38:58,892 INFO     Evaluating the model... (43500/59072)
2025-12-13 04:39:02,250 INFO     Evaluating the model... (44000/59072)
2025-12-13 04:39:04,676 INFO     Evaluating the model... (44500/59072)
2025-12-13 04:39:07,212 INFO     Evaluating the model... (45000/59072)
2025-12-13 04:39:09,746 INFO     Evaluating the model... (45500/59072)
2025-12-13 04:39:12,285 INFO     Evaluating the model... (46000/59072)
2025-12-13 04:39:15,691 INFO     Evaluating the model... (46500/59072)
2025-12-13 04:39:18,212 INFO     Evaluating the model... (47000/59072)
2025-12-13 04:39:20,787 INFO     Evaluating the model... (47500/59072)
2025-12-13 04:39:23,426 INFO     Evaluating the model... (48000/59072)
2025-12-13 04:39:25,938 INFO     Evaluating the model... (48500/59072)
2025-12-13 04:39:29,223 INFO     Evaluating the model... (49000/59072)
2025-12-13 04:39:31,644 INFO     Evaluating the model... (49500/59072)
2025-12-13 04:39:34,325 INFO     Evaluating the model... (50000/59072)
2025-12-13 04:39:37,042 INFO     Evaluating the model... (50500/59072)
2025-12-13 04:39:39,625 INFO     Evaluating the model... (51000/59072)
2025-12-13 04:39:43,661 INFO     Evaluating the model... (51500/59072)
2025-12-13 04:39:46,394 INFO     Evaluating the model... (52000/59072)
2025-12-13 04:39:48,781 INFO     Evaluating the model... (52500/59072)
2025-12-13 04:39:51,146 INFO     Evaluating the model... (53000/59072)
2025-12-13 04:39:53,677 INFO     Evaluating the model... (53500/59072)
2025-12-13 04:39:57,400 INFO     Evaluating the model... (54000/59072)
2025-12-13 04:39:59,876 INFO     Evaluating the model... (54500/59072)
2025-12-13 04:40:02,332 INFO     Evaluating the model... (55000/59072)
2025-12-13 04:40:04,870 INFO     Evaluating the model... (55500/59072)
2025-12-13 04:40:07,606 INFO     Evaluating the model... (56000/59072)
2025-12-13 04:40:11,343 INFO     Evaluating the model... (56500/59072)
2025-12-13 04:40:13,794 INFO     Evaluating the model... (57000/59072)
2025-12-13 04:40:16,344 INFO     Evaluating the model... (57500/59072)
2025-12-13 04:40:19,011 INFO     Evaluating the model... (58000/59072)
2025-12-13 04:40:21,604 INFO     Evaluating the model... (58500/59072)
2025-12-13 04:40:25,059 INFO     Evaluating the model... (59000/59072)
2025-12-13 04:40:25,718 INFO     Test MRR at step 230000: 0.630187
2025-12-13 04:40:25,718 INFO     Test MR at step 230000: 268.881930
2025-12-13 04:40:25,718 INFO     Test HITS@1 at step 230000: 0.543160
2025-12-13 04:40:25,719 INFO     Test HITS@3 at step 230000: 0.684464
2025-12-13 04:40:25,719 INFO     Test HITS@10 at step 230000: 0.782981
2025-12-13 04:40:27,872 INFO     Training average regularization at step 230100: 0.302033
2025-12-13 04:40:27,872 INFO     Training average positive_sample_loss at step 230100: 0.066561
2025-12-13 04:40:27,872 INFO     Training average negative_sample_loss at step 230100: 0.107322
2025-12-13 04:40:27,872 INFO     Training average loss at step 230100: 0.388974
2025-12-13 04:40:30,071 INFO     Training average regularization at step 230200: 0.302033
2025-12-13 04:40:30,072 INFO     Training average positive_sample_loss at step 230200: 0.067152
2025-12-13 04:40:30,072 INFO     Training average negative_sample_loss at step 230200: 0.105942
2025-12-13 04:40:30,072 INFO     Training average loss at step 230200: 0.388580
2025-12-13 04:40:32,238 INFO     Training average regularization at step 230300: 0.302033
2025-12-13 04:40:32,239 INFO     Training average positive_sample_loss at step 230300: 0.067035
2025-12-13 04:40:32,239 INFO     Training average negative_sample_loss at step 230300: 0.106662
2025-12-13 04:40:32,239 INFO     Training average loss at step 230300: 0.388881
2025-12-13 04:40:34,397 INFO     Training average regularization at step 230400: 0.302033
2025-12-13 04:40:34,397 INFO     Training average positive_sample_loss at step 230400: 0.066266
2025-12-13 04:40:34,397 INFO     Training average negative_sample_loss at step 230400: 0.109442
2025-12-13 04:40:34,397 INFO     Training average loss at step 230400: 0.389886
2025-12-13 04:40:36,563 INFO     Training average regularization at step 230500: 0.302032
2025-12-13 04:40:36,564 INFO     Training average positive_sample_loss at step 230500: 0.066503
2025-12-13 04:40:36,564 INFO     Training average negative_sample_loss at step 230500: 0.108547
2025-12-13 04:40:36,564 INFO     Training average loss at step 230500: 0.389557
2025-12-13 04:40:38,741 INFO     Training average regularization at step 230600: 0.302032
2025-12-13 04:40:38,741 INFO     Training average positive_sample_loss at step 230600: 0.066452
2025-12-13 04:40:38,741 INFO     Training average negative_sample_loss at step 230600: 0.109796
2025-12-13 04:40:38,741 INFO     Training average loss at step 230600: 0.390156
2025-12-13 04:40:40,917 INFO     Training average regularization at step 230700: 0.302032
2025-12-13 04:40:40,917 INFO     Training average positive_sample_loss at step 230700: 0.067390
2025-12-13 04:40:40,917 INFO     Training average negative_sample_loss at step 230700: 0.108997
2025-12-13 04:40:40,917 INFO     Training average loss at step 230700: 0.390226
2025-12-13 04:40:43,114 INFO     Training average regularization at step 230800: 0.302032
2025-12-13 04:40:43,114 INFO     Training average positive_sample_loss at step 230800: 0.066277
2025-12-13 04:40:43,114 INFO     Training average negative_sample_loss at step 230800: 0.107285
2025-12-13 04:40:43,114 INFO     Training average loss at step 230800: 0.388813
2025-12-13 04:40:45,278 INFO     Training average regularization at step 230900: 0.302032
2025-12-13 04:40:45,279 INFO     Training average positive_sample_loss at step 230900: 0.066946
2025-12-13 04:40:45,279 INFO     Training average negative_sample_loss at step 230900: 0.109483
2025-12-13 04:40:45,279 INFO     Training average loss at step 230900: 0.390246
2025-12-13 04:40:47,438 INFO     Training average regularization at step 231000: 0.302032
2025-12-13 04:40:47,438 INFO     Training average positive_sample_loss at step 231000: 0.066359
2025-12-13 04:40:47,438 INFO     Training average negative_sample_loss at step 231000: 0.107893
2025-12-13 04:40:47,438 INFO     Training average loss at step 231000: 0.389158
2025-12-13 04:40:49,581 INFO     Training average regularization at step 231100: 0.302032
2025-12-13 04:40:49,581 INFO     Training average positive_sample_loss at step 231100: 0.065671
2025-12-13 04:40:49,581 INFO     Training average negative_sample_loss at step 231100: 0.107293
2025-12-13 04:40:49,581 INFO     Training average loss at step 231100: 0.388514
2025-12-13 04:40:51,746 INFO     Training average regularization at step 231200: 0.302032
2025-12-13 04:40:51,747 INFO     Training average positive_sample_loss at step 231200: 0.067612
2025-12-13 04:40:51,747 INFO     Training average negative_sample_loss at step 231200: 0.108951
2025-12-13 04:40:51,747 INFO     Training average loss at step 231200: 0.390313
2025-12-13 04:40:53,916 INFO     Training average regularization at step 231300: 0.302032
2025-12-13 04:40:53,916 INFO     Training average positive_sample_loss at step 231300: 0.066583
2025-12-13 04:40:53,916 INFO     Training average negative_sample_loss at step 231300: 0.108397
2025-12-13 04:40:53,916 INFO     Training average loss at step 231300: 0.389522
2025-12-13 04:40:56,070 INFO     Training average regularization at step 231400: 0.302032
2025-12-13 04:40:56,071 INFO     Training average positive_sample_loss at step 231400: 0.066618
2025-12-13 04:40:56,071 INFO     Training average negative_sample_loss at step 231400: 0.110566
2025-12-13 04:40:56,071 INFO     Training average loss at step 231400: 0.390624
2025-12-13 04:40:58,226 INFO     Training average regularization at step 231500: 0.302032
2025-12-13 04:40:58,226 INFO     Training average positive_sample_loss at step 231500: 0.065356
2025-12-13 04:40:58,226 INFO     Training average negative_sample_loss at step 231500: 0.109020
2025-12-13 04:40:58,226 INFO     Training average loss at step 231500: 0.389220
2025-12-13 04:41:00,386 INFO     Training average regularization at step 231600: 0.302032
2025-12-13 04:41:00,386 INFO     Training average positive_sample_loss at step 231600: 0.067375
2025-12-13 04:41:00,386 INFO     Training average negative_sample_loss at step 231600: 0.111626
2025-12-13 04:41:00,386 INFO     Training average loss at step 231600: 0.391532
2025-12-13 04:41:02,570 INFO     Training average regularization at step 231700: 0.302032
2025-12-13 04:41:02,570 INFO     Training average positive_sample_loss at step 231700: 0.066421
2025-12-13 04:41:02,570 INFO     Training average negative_sample_loss at step 231700: 0.109855
2025-12-13 04:41:02,570 INFO     Training average loss at step 231700: 0.390170
2025-12-13 04:41:04,724 INFO     Training average regularization at step 231800: 0.302032
2025-12-13 04:41:04,724 INFO     Training average positive_sample_loss at step 231800: 0.067849
2025-12-13 04:41:04,724 INFO     Training average negative_sample_loss at step 231800: 0.107262
2025-12-13 04:41:04,724 INFO     Training average loss at step 231800: 0.389587
2025-12-13 04:41:06,885 INFO     Training average regularization at step 231900: 0.302032
2025-12-13 04:41:06,885 INFO     Training average positive_sample_loss at step 231900: 0.066660
2025-12-13 04:41:06,885 INFO     Training average negative_sample_loss at step 231900: 0.109815
2025-12-13 04:41:06,885 INFO     Training average loss at step 231900: 0.390269
2025-12-13 04:41:10,056 INFO     Training average regularization at step 232000: 0.302032
2025-12-13 04:41:10,056 INFO     Training average positive_sample_loss at step 232000: 0.067756
2025-12-13 04:41:10,056 INFO     Training average negative_sample_loss at step 232000: 0.109285
2025-12-13 04:41:10,056 INFO     Training average loss at step 232000: 0.390552
2025-12-13 04:41:12,202 INFO     Training average regularization at step 232100: 0.302031
2025-12-13 04:41:12,203 INFO     Training average positive_sample_loss at step 232100: 0.066732
2025-12-13 04:41:12,203 INFO     Training average negative_sample_loss at step 232100: 0.109022
2025-12-13 04:41:12,203 INFO     Training average loss at step 232100: 0.389908
2025-12-13 04:41:14,379 INFO     Training average regularization at step 232200: 0.302031
2025-12-13 04:41:14,379 INFO     Training average positive_sample_loss at step 232200: 0.067035
2025-12-13 04:41:14,379 INFO     Training average negative_sample_loss at step 232200: 0.108391
2025-12-13 04:41:14,379 INFO     Training average loss at step 232200: 0.389744
2025-12-13 04:41:16,536 INFO     Training average regularization at step 232300: 0.302031
2025-12-13 04:41:16,536 INFO     Training average positive_sample_loss at step 232300: 0.065795
2025-12-13 04:41:16,536 INFO     Training average negative_sample_loss at step 232300: 0.107425
2025-12-13 04:41:16,536 INFO     Training average loss at step 232300: 0.388641
2025-12-13 04:41:18,700 INFO     Training average regularization at step 232400: 0.302031
2025-12-13 04:41:18,701 INFO     Training average positive_sample_loss at step 232400: 0.067143
2025-12-13 04:41:18,701 INFO     Training average negative_sample_loss at step 232400: 0.107432
2025-12-13 04:41:18,701 INFO     Training average loss at step 232400: 0.389319
2025-12-13 04:41:20,843 INFO     Training average regularization at step 232500: 0.302031
2025-12-13 04:41:20,844 INFO     Training average positive_sample_loss at step 232500: 0.065601
2025-12-13 04:41:20,844 INFO     Training average negative_sample_loss at step 232500: 0.106740
2025-12-13 04:41:20,844 INFO     Training average loss at step 232500: 0.388201
2025-12-13 04:41:23,001 INFO     Training average regularization at step 232600: 0.302031
2025-12-13 04:41:23,001 INFO     Training average positive_sample_loss at step 232600: 0.067504
2025-12-13 04:41:23,001 INFO     Training average negative_sample_loss at step 232600: 0.109134
2025-12-13 04:41:23,001 INFO     Training average loss at step 232600: 0.390350
2025-12-13 04:41:25,181 INFO     Training average regularization at step 232700: 0.302031
2025-12-13 04:41:25,181 INFO     Training average positive_sample_loss at step 232700: 0.066655
2025-12-13 04:41:25,181 INFO     Training average negative_sample_loss at step 232700: 0.109413
2025-12-13 04:41:25,181 INFO     Training average loss at step 232700: 0.390065
2025-12-13 04:41:27,362 INFO     Training average regularization at step 232800: 0.302031
2025-12-13 04:41:27,363 INFO     Training average positive_sample_loss at step 232800: 0.066545
2025-12-13 04:41:27,363 INFO     Training average negative_sample_loss at step 232800: 0.110485
2025-12-13 04:41:27,363 INFO     Training average loss at step 232800: 0.390546
2025-12-13 04:41:29,531 INFO     Training average regularization at step 232900: 0.302031
2025-12-13 04:41:29,531 INFO     Training average positive_sample_loss at step 232900: 0.067046
2025-12-13 04:41:29,531 INFO     Training average negative_sample_loss at step 232900: 0.107694
2025-12-13 04:41:29,531 INFO     Training average loss at step 232900: 0.389401
2025-12-13 04:41:31,693 INFO     Training average regularization at step 233000: 0.302031
2025-12-13 04:41:31,693 INFO     Training average positive_sample_loss at step 233000: 0.065702
2025-12-13 04:41:31,693 INFO     Training average negative_sample_loss at step 233000: 0.106666
2025-12-13 04:41:31,693 INFO     Training average loss at step 233000: 0.388215
2025-12-13 04:41:33,858 INFO     Training average regularization at step 233100: 0.302031
2025-12-13 04:41:33,859 INFO     Training average positive_sample_loss at step 233100: 0.067730
2025-12-13 04:41:33,859 INFO     Training average negative_sample_loss at step 233100: 0.110041
2025-12-13 04:41:33,859 INFO     Training average loss at step 233100: 0.390916
2025-12-13 04:41:36,096 INFO     Training average regularization at step 233200: 0.302031
2025-12-13 04:41:36,096 INFO     Training average positive_sample_loss at step 233200: 0.065903
2025-12-13 04:41:36,097 INFO     Training average negative_sample_loss at step 233200: 0.110370
2025-12-13 04:41:36,097 INFO     Training average loss at step 233200: 0.390167
2025-12-13 04:41:38,297 INFO     Training average regularization at step 233300: 0.302031
2025-12-13 04:41:38,297 INFO     Training average positive_sample_loss at step 233300: 0.067676
2025-12-13 04:41:38,297 INFO     Training average negative_sample_loss at step 233300: 0.110571
2025-12-13 04:41:38,297 INFO     Training average loss at step 233300: 0.391155
2025-12-13 04:41:40,473 INFO     Training average regularization at step 233400: 0.302031
2025-12-13 04:41:40,473 INFO     Training average positive_sample_loss at step 233400: 0.067641
2025-12-13 04:41:40,473 INFO     Training average negative_sample_loss at step 233400: 0.109529
2025-12-13 04:41:40,474 INFO     Training average loss at step 233400: 0.390615
2025-12-13 04:41:42,638 INFO     Training average regularization at step 233500: 0.302030
2025-12-13 04:41:42,638 INFO     Training average positive_sample_loss at step 233500: 0.067113
2025-12-13 04:41:42,638 INFO     Training average negative_sample_loss at step 233500: 0.108756
2025-12-13 04:41:42,638 INFO     Training average loss at step 233500: 0.389965
2025-12-13 04:41:44,826 INFO     Training average regularization at step 233600: 0.302030
2025-12-13 04:41:44,827 INFO     Training average positive_sample_loss at step 233600: 0.068217
2025-12-13 04:41:44,827 INFO     Training average negative_sample_loss at step 233600: 0.109869
2025-12-13 04:41:44,827 INFO     Training average loss at step 233600: 0.391073
2025-12-13 04:41:46,979 INFO     Training average regularization at step 233700: 0.302030
2025-12-13 04:41:46,979 INFO     Training average positive_sample_loss at step 233700: 0.066182
2025-12-13 04:41:46,979 INFO     Training average negative_sample_loss at step 233700: 0.107218
2025-12-13 04:41:46,979 INFO     Training average loss at step 233700: 0.388730
2025-12-13 04:41:49,141 INFO     Training average regularization at step 233800: 0.302030
2025-12-13 04:41:49,141 INFO     Training average positive_sample_loss at step 233800: 0.067018
2025-12-13 04:41:49,141 INFO     Training average negative_sample_loss at step 233800: 0.108570
2025-12-13 04:41:49,141 INFO     Training average loss at step 233800: 0.389824
2025-12-13 04:41:51,300 INFO     Training average regularization at step 233900: 0.302030
2025-12-13 04:41:51,300 INFO     Training average positive_sample_loss at step 233900: 0.067143
2025-12-13 04:41:51,300 INFO     Training average negative_sample_loss at step 233900: 0.110123
2025-12-13 04:41:51,300 INFO     Training average loss at step 233900: 0.390663
2025-12-13 04:41:53,454 INFO     Training average regularization at step 234000: 0.302030
2025-12-13 04:41:53,455 INFO     Training average positive_sample_loss at step 234000: 0.066671
2025-12-13 04:41:53,455 INFO     Training average negative_sample_loss at step 234000: 0.109200
2025-12-13 04:41:53,455 INFO     Training average loss at step 234000: 0.389966
2025-12-13 04:41:55,616 INFO     Training average regularization at step 234100: 0.302030
2025-12-13 04:41:55,617 INFO     Training average positive_sample_loss at step 234100: 0.066826
2025-12-13 04:41:55,617 INFO     Training average negative_sample_loss at step 234100: 0.110428
2025-12-13 04:41:55,617 INFO     Training average loss at step 234100: 0.390657
2025-12-13 04:41:57,783 INFO     Training average regularization at step 234200: 0.302030
2025-12-13 04:41:57,784 INFO     Training average positive_sample_loss at step 234200: 0.066736
2025-12-13 04:41:57,784 INFO     Training average negative_sample_loss at step 234200: 0.110498
2025-12-13 04:41:57,784 INFO     Training average loss at step 234200: 0.390647
2025-12-13 04:41:59,962 INFO     Training average regularization at step 234300: 0.302030
2025-12-13 04:41:59,962 INFO     Training average positive_sample_loss at step 234300: 0.066363
2025-12-13 04:41:59,962 INFO     Training average negative_sample_loss at step 234300: 0.108495
2025-12-13 04:41:59,962 INFO     Training average loss at step 234300: 0.389459
2025-12-13 04:42:02,121 INFO     Training average regularization at step 234400: 0.302030
2025-12-13 04:42:02,121 INFO     Training average positive_sample_loss at step 234400: 0.066334
2025-12-13 04:42:02,121 INFO     Training average negative_sample_loss at step 234400: 0.111092
2025-12-13 04:42:02,121 INFO     Training average loss at step 234400: 0.390743
2025-12-13 04:42:04,268 INFO     Training average regularization at step 234500: 0.302030
2025-12-13 04:42:04,268 INFO     Training average positive_sample_loss at step 234500: 0.066537
2025-12-13 04:42:04,268 INFO     Training average negative_sample_loss at step 234500: 0.108847
2025-12-13 04:42:04,268 INFO     Training average loss at step 234500: 0.389722
2025-12-13 04:42:06,405 INFO     Training average regularization at step 234600: 0.302030
2025-12-13 04:42:06,405 INFO     Training average positive_sample_loss at step 234600: 0.067591
2025-12-13 04:42:06,405 INFO     Training average negative_sample_loss at step 234600: 0.107282
2025-12-13 04:42:06,405 INFO     Training average loss at step 234600: 0.389466
2025-12-13 04:42:08,548 INFO     Training average regularization at step 234700: 0.302030
2025-12-13 04:42:08,549 INFO     Training average positive_sample_loss at step 234700: 0.066681
2025-12-13 04:42:08,549 INFO     Training average negative_sample_loss at step 234700: 0.109294
2025-12-13 04:42:08,549 INFO     Training average loss at step 234700: 0.390017
2025-12-13 04:42:10,699 INFO     Training average regularization at step 234800: 0.302030
2025-12-13 04:42:10,699 INFO     Training average positive_sample_loss at step 234800: 0.066078
2025-12-13 04:42:10,699 INFO     Training average negative_sample_loss at step 234800: 0.109950
2025-12-13 04:42:10,700 INFO     Training average loss at step 234800: 0.390044
2025-12-13 04:42:12,833 INFO     Training average regularization at step 234900: 0.302030
2025-12-13 04:42:12,833 INFO     Training average positive_sample_loss at step 234900: 0.067481
2025-12-13 04:42:12,833 INFO     Training average negative_sample_loss at step 234900: 0.107366
2025-12-13 04:42:12,833 INFO     Training average loss at step 234900: 0.389453
2025-12-13 04:42:14,990 INFO     Training average regularization at step 235000: 0.302030
2025-12-13 04:42:14,991 INFO     Training average positive_sample_loss at step 235000: 0.066062
2025-12-13 04:42:14,991 INFO     Training average negative_sample_loss at step 235000: 0.108124
2025-12-13 04:42:14,991 INFO     Training average loss at step 235000: 0.389122
2025-12-13 04:42:17,160 INFO     Training average regularization at step 235100: 0.302029
2025-12-13 04:42:17,160 INFO     Training average positive_sample_loss at step 235100: 0.067430
2025-12-13 04:42:17,160 INFO     Training average negative_sample_loss at step 235100: 0.110614
2025-12-13 04:42:17,160 INFO     Training average loss at step 235100: 0.391052
2025-12-13 04:42:19,308 INFO     Training average regularization at step 235200: 0.302029
2025-12-13 04:42:19,309 INFO     Training average positive_sample_loss at step 235200: 0.067351
2025-12-13 04:42:19,309 INFO     Training average negative_sample_loss at step 235200: 0.107605
2025-12-13 04:42:19,309 INFO     Training average loss at step 235200: 0.389507
2025-12-13 04:42:21,489 INFO     Training average regularization at step 235300: 0.302029
2025-12-13 04:42:21,489 INFO     Training average positive_sample_loss at step 235300: 0.067423
2025-12-13 04:42:21,489 INFO     Training average negative_sample_loss at step 235300: 0.108404
2025-12-13 04:42:21,490 INFO     Training average loss at step 235300: 0.389942
2025-12-13 04:42:23,640 INFO     Training average regularization at step 235400: 0.302029
2025-12-13 04:42:23,640 INFO     Training average positive_sample_loss at step 235400: 0.068142
2025-12-13 04:42:23,640 INFO     Training average negative_sample_loss at step 235400: 0.108930
2025-12-13 04:42:23,640 INFO     Training average loss at step 235400: 0.390565
2025-12-13 04:42:25,777 INFO     Training average regularization at step 235500: 0.302029
2025-12-13 04:42:25,777 INFO     Training average positive_sample_loss at step 235500: 0.066775
2025-12-13 04:42:25,778 INFO     Training average negative_sample_loss at step 235500: 0.108570
2025-12-13 04:42:25,778 INFO     Training average loss at step 235500: 0.389702
2025-12-13 04:42:27,925 INFO     Training average regularization at step 235600: 0.302029
2025-12-13 04:42:27,925 INFO     Training average positive_sample_loss at step 235600: 0.066708
2025-12-13 04:42:27,925 INFO     Training average negative_sample_loss at step 235600: 0.107067
2025-12-13 04:42:27,925 INFO     Training average loss at step 235600: 0.388917
2025-12-13 04:42:30,098 INFO     Training average regularization at step 235700: 0.302029
2025-12-13 04:42:30,098 INFO     Training average positive_sample_loss at step 235700: 0.065993
2025-12-13 04:42:30,098 INFO     Training average negative_sample_loss at step 235700: 0.106745
2025-12-13 04:42:30,098 INFO     Training average loss at step 235700: 0.388398
2025-12-13 04:42:32,270 INFO     Training average regularization at step 235800: 0.302029
2025-12-13 04:42:32,270 INFO     Training average positive_sample_loss at step 235800: 0.066180
2025-12-13 04:42:32,270 INFO     Training average negative_sample_loss at step 235800: 0.106608
2025-12-13 04:42:32,270 INFO     Training average loss at step 235800: 0.388423
2025-12-13 04:42:34,413 INFO     Training average regularization at step 235900: 0.302029
2025-12-13 04:42:34,414 INFO     Training average positive_sample_loss at step 235900: 0.066173
2025-12-13 04:42:34,414 INFO     Training average negative_sample_loss at step 235900: 0.109290
2025-12-13 04:42:34,414 INFO     Training average loss at step 235900: 0.389761
2025-12-13 04:42:36,559 INFO     Training average regularization at step 236000: 0.302029
2025-12-13 04:42:36,559 INFO     Training average positive_sample_loss at step 236000: 0.066389
2025-12-13 04:42:36,559 INFO     Training average negative_sample_loss at step 236000: 0.109638
2025-12-13 04:42:36,559 INFO     Training average loss at step 236000: 0.390042
2025-12-13 04:42:38,776 INFO     Training average regularization at step 236100: 0.302029
2025-12-13 04:42:38,776 INFO     Training average positive_sample_loss at step 236100: 0.065390
2025-12-13 04:42:38,776 INFO     Training average negative_sample_loss at step 236100: 0.108855
2025-12-13 04:42:38,776 INFO     Training average loss at step 236100: 0.389151
2025-12-13 04:42:40,963 INFO     Training average regularization at step 236200: 0.302029
2025-12-13 04:42:40,963 INFO     Training average positive_sample_loss at step 236200: 0.066397
2025-12-13 04:42:40,963 INFO     Training average negative_sample_loss at step 236200: 0.111327
2025-12-13 04:42:40,963 INFO     Training average loss at step 236200: 0.390891
2025-12-13 04:42:43,184 INFO     Training average regularization at step 236300: 0.302029
2025-12-13 04:42:43,185 INFO     Training average positive_sample_loss at step 236300: 0.067354
2025-12-13 04:42:43,185 INFO     Training average negative_sample_loss at step 236300: 0.110901
2025-12-13 04:42:43,185 INFO     Training average loss at step 236300: 0.391156
2025-12-13 04:42:45,389 INFO     Training average regularization at step 236400: 0.302029
2025-12-13 04:42:45,390 INFO     Training average positive_sample_loss at step 236400: 0.065839
2025-12-13 04:42:45,390 INFO     Training average negative_sample_loss at step 236400: 0.109058
2025-12-13 04:42:45,390 INFO     Training average loss at step 236400: 0.389477
2025-12-13 04:42:47,524 INFO     Training average regularization at step 236500: 0.302029
2025-12-13 04:42:47,524 INFO     Training average positive_sample_loss at step 236500: 0.066098
2025-12-13 04:42:47,524 INFO     Training average negative_sample_loss at step 236500: 0.108912
2025-12-13 04:42:47,524 INFO     Training average loss at step 236500: 0.389534
2025-12-13 04:42:49,667 INFO     Training average regularization at step 236600: 0.302029
2025-12-13 04:42:49,667 INFO     Training average positive_sample_loss at step 236600: 0.064651
2025-12-13 04:42:49,667 INFO     Training average negative_sample_loss at step 236600: 0.109014
2025-12-13 04:42:49,667 INFO     Training average loss at step 236600: 0.388861
2025-12-13 04:42:51,814 INFO     Training average regularization at step 236700: 0.302028
2025-12-13 04:42:51,815 INFO     Training average positive_sample_loss at step 236700: 0.066948
2025-12-13 04:42:51,815 INFO     Training average negative_sample_loss at step 236700: 0.109206
2025-12-13 04:42:51,815 INFO     Training average loss at step 236700: 0.390105
2025-12-13 04:42:55,045 INFO     Training average regularization at step 236800: 0.302028
2025-12-13 04:42:55,045 INFO     Training average positive_sample_loss at step 236800: 0.066230
2025-12-13 04:42:55,045 INFO     Training average negative_sample_loss at step 236800: 0.107209
2025-12-13 04:42:55,046 INFO     Training average loss at step 236800: 0.388748
2025-12-13 04:42:57,185 INFO     Training average regularization at step 236900: 0.302028
2025-12-13 04:42:57,186 INFO     Training average positive_sample_loss at step 236900: 0.067196
2025-12-13 04:42:57,186 INFO     Training average negative_sample_loss at step 236900: 0.108425
2025-12-13 04:42:57,186 INFO     Training average loss at step 236900: 0.389839
2025-12-13 04:42:59,340 INFO     Training average regularization at step 237000: 0.302028
2025-12-13 04:42:59,340 INFO     Training average positive_sample_loss at step 237000: 0.066546
2025-12-13 04:42:59,340 INFO     Training average negative_sample_loss at step 237000: 0.106744
2025-12-13 04:42:59,340 INFO     Training average loss at step 237000: 0.388673
2025-12-13 04:43:01,507 INFO     Training average regularization at step 237100: 0.302028
2025-12-13 04:43:01,507 INFO     Training average positive_sample_loss at step 237100: 0.066599
2025-12-13 04:43:01,507 INFO     Training average negative_sample_loss at step 237100: 0.108404
2025-12-13 04:43:01,508 INFO     Training average loss at step 237100: 0.389530
2025-12-13 04:43:03,707 INFO     Training average regularization at step 237200: 0.302028
2025-12-13 04:43:03,708 INFO     Training average positive_sample_loss at step 237200: 0.067338
2025-12-13 04:43:03,708 INFO     Training average negative_sample_loss at step 237200: 0.108963
2025-12-13 04:43:03,708 INFO     Training average loss at step 237200: 0.390178
2025-12-13 04:43:05,843 INFO     Training average regularization at step 237300: 0.302028
2025-12-13 04:43:05,843 INFO     Training average positive_sample_loss at step 237300: 0.066574
2025-12-13 04:43:05,843 INFO     Training average negative_sample_loss at step 237300: 0.109782
2025-12-13 04:43:05,843 INFO     Training average loss at step 237300: 0.390206
2025-12-13 04:43:07,968 INFO     Training average regularization at step 237400: 0.302028
2025-12-13 04:43:07,968 INFO     Training average positive_sample_loss at step 237400: 0.066515
2025-12-13 04:43:07,968 INFO     Training average negative_sample_loss at step 237400: 0.108892
2025-12-13 04:43:07,968 INFO     Training average loss at step 237400: 0.389731
2025-12-13 04:43:10,120 INFO     Training average regularization at step 237500: 0.302028
2025-12-13 04:43:10,120 INFO     Training average positive_sample_loss at step 237500: 0.065723
2025-12-13 04:43:10,120 INFO     Training average negative_sample_loss at step 237500: 0.108863
2025-12-13 04:43:10,120 INFO     Training average loss at step 237500: 0.389321
2025-12-13 04:43:12,275 INFO     Training average regularization at step 237600: 0.302028
2025-12-13 04:43:12,275 INFO     Training average positive_sample_loss at step 237600: 0.067204
2025-12-13 04:43:12,275 INFO     Training average negative_sample_loss at step 237600: 0.111539
2025-12-13 04:43:12,275 INFO     Training average loss at step 237600: 0.391399
2025-12-13 04:43:14,430 INFO     Training average regularization at step 237700: 0.302028
2025-12-13 04:43:14,430 INFO     Training average positive_sample_loss at step 237700: 0.065347
2025-12-13 04:43:14,430 INFO     Training average negative_sample_loss at step 237700: 0.106290
2025-12-13 04:43:14,430 INFO     Training average loss at step 237700: 0.387846
2025-12-13 04:43:16,594 INFO     Training average regularization at step 237800: 0.302028
2025-12-13 04:43:16,594 INFO     Training average positive_sample_loss at step 237800: 0.066975
2025-12-13 04:43:16,594 INFO     Training average negative_sample_loss at step 237800: 0.107686
2025-12-13 04:43:16,594 INFO     Training average loss at step 237800: 0.389358
2025-12-13 04:43:18,745 INFO     Training average regularization at step 237900: 0.302028
2025-12-13 04:43:18,745 INFO     Training average positive_sample_loss at step 237900: 0.067212
2025-12-13 04:43:18,745 INFO     Training average negative_sample_loss at step 237900: 0.108020
2025-12-13 04:43:18,745 INFO     Training average loss at step 237900: 0.389643
2025-12-13 04:43:20,896 INFO     Training average regularization at step 238000: 0.302027
2025-12-13 04:43:20,896 INFO     Training average positive_sample_loss at step 238000: 0.065741
2025-12-13 04:43:20,896 INFO     Training average negative_sample_loss at step 238000: 0.110228
2025-12-13 04:43:20,896 INFO     Training average loss at step 238000: 0.390012
2025-12-13 04:43:23,052 INFO     Training average regularization at step 238100: 0.302027
2025-12-13 04:43:23,053 INFO     Training average positive_sample_loss at step 238100: 0.067323
2025-12-13 04:43:23,053 INFO     Training average negative_sample_loss at step 238100: 0.107636
2025-12-13 04:43:23,053 INFO     Training average loss at step 238100: 0.389507
2025-12-13 04:43:25,210 INFO     Training average regularization at step 238200: 0.302027
2025-12-13 04:43:25,210 INFO     Training average positive_sample_loss at step 238200: 0.067510
2025-12-13 04:43:25,210 INFO     Training average negative_sample_loss at step 238200: 0.109969
2025-12-13 04:43:25,210 INFO     Training average loss at step 238200: 0.390767
2025-12-13 04:43:27,423 INFO     Training average regularization at step 238300: 0.302027
2025-12-13 04:43:27,423 INFO     Training average positive_sample_loss at step 238300: 0.066588
2025-12-13 04:43:27,423 INFO     Training average negative_sample_loss at step 238300: 0.107407
2025-12-13 04:43:27,424 INFO     Training average loss at step 238300: 0.389025
2025-12-13 04:43:29,576 INFO     Training average regularization at step 238400: 0.302027
2025-12-13 04:43:29,576 INFO     Training average positive_sample_loss at step 238400: 0.064769
2025-12-13 04:43:29,576 INFO     Training average negative_sample_loss at step 238400: 0.108927
2025-12-13 04:43:29,576 INFO     Training average loss at step 238400: 0.388875
2025-12-13 04:43:31,750 INFO     Training average regularization at step 238500: 0.302027
2025-12-13 04:43:31,750 INFO     Training average positive_sample_loss at step 238500: 0.067552
2025-12-13 04:43:31,750 INFO     Training average negative_sample_loss at step 238500: 0.110162
2025-12-13 04:43:31,750 INFO     Training average loss at step 238500: 0.390884
2025-12-13 04:43:33,894 INFO     Training average regularization at step 238600: 0.302027
2025-12-13 04:43:33,895 INFO     Training average positive_sample_loss at step 238600: 0.065714
2025-12-13 04:43:33,895 INFO     Training average negative_sample_loss at step 238600: 0.106405
2025-12-13 04:43:33,895 INFO     Training average loss at step 238600: 0.388086
2025-12-13 04:43:36,053 INFO     Training average regularization at step 238700: 0.302027
2025-12-13 04:43:36,053 INFO     Training average positive_sample_loss at step 238700: 0.067900
2025-12-13 04:43:36,053 INFO     Training average negative_sample_loss at step 238700: 0.109399
2025-12-13 04:43:36,053 INFO     Training average loss at step 238700: 0.390677
2025-12-13 04:43:38,265 INFO     Training average regularization at step 238800: 0.302027
2025-12-13 04:43:38,265 INFO     Training average positive_sample_loss at step 238800: 0.067122
2025-12-13 04:43:38,265 INFO     Training average negative_sample_loss at step 238800: 0.111699
2025-12-13 04:43:38,265 INFO     Training average loss at step 238800: 0.391438
2025-12-13 04:43:40,420 INFO     Training average regularization at step 238900: 0.302027
2025-12-13 04:43:40,420 INFO     Training average positive_sample_loss at step 238900: 0.067125
2025-12-13 04:43:40,421 INFO     Training average negative_sample_loss at step 238900: 0.110794
2025-12-13 04:43:40,421 INFO     Training average loss at step 238900: 0.390986
2025-12-13 04:43:42,661 INFO     Training average regularization at step 239000: 0.302027
2025-12-13 04:43:42,661 INFO     Training average positive_sample_loss at step 239000: 0.066165
2025-12-13 04:43:42,661 INFO     Training average negative_sample_loss at step 239000: 0.107787
2025-12-13 04:43:42,661 INFO     Training average loss at step 239000: 0.389003
2025-12-13 04:43:44,828 INFO     Training average regularization at step 239100: 0.302027
2025-12-13 04:43:44,831 INFO     Training average positive_sample_loss at step 239100: 0.067143
2025-12-13 04:43:44,831 INFO     Training average negative_sample_loss at step 239100: 0.109624
2025-12-13 04:43:44,831 INFO     Training average loss at step 239100: 0.390411
2025-12-13 04:43:46,975 INFO     Training average regularization at step 239200: 0.302027
2025-12-13 04:43:46,975 INFO     Training average positive_sample_loss at step 239200: 0.066174
2025-12-13 04:43:46,975 INFO     Training average negative_sample_loss at step 239200: 0.108358
2025-12-13 04:43:46,975 INFO     Training average loss at step 239200: 0.389293
2025-12-13 04:43:49,127 INFO     Training average regularization at step 239300: 0.302027
2025-12-13 04:43:49,127 INFO     Training average positive_sample_loss at step 239300: 0.067558
2025-12-13 04:43:49,127 INFO     Training average negative_sample_loss at step 239300: 0.106850
2025-12-13 04:43:49,127 INFO     Training average loss at step 239300: 0.389231
2025-12-13 04:43:51,298 INFO     Training average regularization at step 239400: 0.302027
2025-12-13 04:43:51,298 INFO     Training average positive_sample_loss at step 239400: 0.066416
2025-12-13 04:43:51,299 INFO     Training average negative_sample_loss at step 239400: 0.110857
2025-12-13 04:43:51,299 INFO     Training average loss at step 239400: 0.390663
2025-12-13 04:43:53,455 INFO     Training average regularization at step 239500: 0.302026
2025-12-13 04:43:53,456 INFO     Training average positive_sample_loss at step 239500: 0.066001
2025-12-13 04:43:53,456 INFO     Training average negative_sample_loss at step 239500: 0.110074
2025-12-13 04:43:53,456 INFO     Training average loss at step 239500: 0.390064
2025-12-13 04:43:55,605 INFO     Training average regularization at step 239600: 0.302026
2025-12-13 04:43:55,606 INFO     Training average positive_sample_loss at step 239600: 0.066550
2025-12-13 04:43:55,606 INFO     Training average negative_sample_loss at step 239600: 0.110663
2025-12-13 04:43:55,606 INFO     Training average loss at step 239600: 0.390633
2025-12-13 04:43:57,769 INFO     Training average regularization at step 239700: 0.302026
2025-12-13 04:43:57,769 INFO     Training average positive_sample_loss at step 239700: 0.067600
2025-12-13 04:43:57,769 INFO     Training average negative_sample_loss at step 239700: 0.105290
2025-12-13 04:43:57,769 INFO     Training average loss at step 239700: 0.388471
2025-12-13 04:43:59,911 INFO     Training average regularization at step 239800: 0.302026
2025-12-13 04:43:59,911 INFO     Training average positive_sample_loss at step 239800: 0.067388
2025-12-13 04:43:59,911 INFO     Training average negative_sample_loss at step 239800: 0.106740
2025-12-13 04:43:59,911 INFO     Training average loss at step 239800: 0.389090
2025-12-13 04:44:02,078 INFO     Training average regularization at step 239900: 0.302026
2025-12-13 04:44:02,078 INFO     Training average positive_sample_loss at step 239900: 0.066275
2025-12-13 04:44:02,078 INFO     Training average negative_sample_loss at step 239900: 0.108366
2025-12-13 04:44:02,078 INFO     Training average loss at step 239900: 0.389347
2025-12-13 04:44:05,741 INFO     Training average regularization at step 240000: 0.302026
2025-12-13 04:44:05,742 INFO     Training average positive_sample_loss at step 240000: 0.066559
2025-12-13 04:44:05,742 INFO     Training average negative_sample_loss at step 240000: 0.107735
2025-12-13 04:44:05,742 INFO     Training average loss at step 240000: 0.389174
2025-12-13 04:44:05,742 INFO     Evaluating on Valid Dataset...
2025-12-13 04:44:06,362 INFO     Evaluating the model... (0/50000)
2025-12-13 04:44:08,834 INFO     Evaluating the model... (500/50000)
2025-12-13 04:44:11,504 INFO     Evaluating the model... (1000/50000)
2025-12-13 04:44:14,018 INFO     Evaluating the model... (1500/50000)
2025-12-13 04:44:17,610 INFO     Evaluating the model... (2000/50000)
2025-12-13 04:44:20,133 INFO     Evaluating the model... (2500/50000)
2025-12-13 04:44:22,723 INFO     Evaluating the model... (3000/50000)
2025-12-13 04:44:25,145 INFO     Evaluating the model... (3500/50000)
2025-12-13 04:44:27,600 INFO     Evaluating the model... (4000/50000)
2025-12-13 04:44:30,634 INFO     Evaluating the model... (4500/50000)
2025-12-13 04:44:33,109 INFO     Evaluating the model... (5000/50000)
2025-12-13 04:44:35,697 INFO     Evaluating the model... (5500/50000)
2025-12-13 04:44:38,323 INFO     Evaluating the model... (6000/50000)
2025-12-13 04:44:40,954 INFO     Evaluating the model... (6500/50000)
2025-12-13 04:44:44,101 INFO     Evaluating the model... (7000/50000)
2025-12-13 04:44:46,897 INFO     Evaluating the model... (7500/50000)
2025-12-13 04:44:49,342 INFO     Evaluating the model... (8000/50000)
2025-12-13 04:44:51,781 INFO     Evaluating the model... (8500/50000)
2025-12-13 04:44:55,055 INFO     Evaluating the model... (9000/50000)
2025-12-13 04:44:57,735 INFO     Evaluating the model... (9500/50000)
2025-12-13 04:45:00,197 INFO     Evaluating the model... (10000/50000)
2025-12-13 04:45:02,595 INFO     Evaluating the model... (10500/50000)
2025-12-13 04:45:05,129 INFO     Evaluating the model... (11000/50000)
2025-12-13 04:45:08,101 INFO     Evaluating the model... (11500/50000)
2025-12-13 04:45:10,457 INFO     Evaluating the model... (12000/50000)
2025-12-13 04:45:12,807 INFO     Evaluating the model... (12500/50000)
2025-12-13 04:45:15,249 INFO     Evaluating the model... (13000/50000)
2025-12-13 04:45:17,721 INFO     Evaluating the model... (13500/50000)
2025-12-13 04:45:21,181 INFO     Evaluating the model... (14000/50000)
2025-12-13 04:45:23,593 INFO     Evaluating the model... (14500/50000)
2025-12-13 04:45:26,015 INFO     Evaluating the model... (15000/50000)
2025-12-13 04:45:28,394 INFO     Evaluating the model... (15500/50000)
2025-12-13 04:45:31,074 INFO     Evaluating the model... (16000/50000)
2025-12-13 04:45:34,674 INFO     Evaluating the model... (16500/50000)
2025-12-13 04:45:37,240 INFO     Evaluating the model... (17000/50000)
2025-12-13 04:45:39,847 INFO     Evaluating the model... (17500/50000)
2025-12-13 04:45:42,749 INFO     Evaluating the model... (18000/50000)
2025-12-13 04:45:45,323 INFO     Evaluating the model... (18500/50000)
2025-12-13 04:45:48,912 INFO     Evaluating the model... (19000/50000)
2025-12-13 04:45:51,244 INFO     Evaluating the model... (19500/50000)
2025-12-13 04:45:53,949 INFO     Evaluating the model... (20000/50000)
2025-12-13 04:45:56,490 INFO     Evaluating the model... (20500/50000)
2025-12-13 04:45:58,855 INFO     Evaluating the model... (21000/50000)
2025-12-13 04:46:02,418 INFO     Evaluating the model... (21500/50000)
2025-12-13 04:46:04,914 INFO     Evaluating the model... (22000/50000)
2025-12-13 04:46:07,530 INFO     Evaluating the model... (22500/50000)
2025-12-13 04:46:09,901 INFO     Evaluating the model... (23000/50000)
2025-12-13 04:46:12,250 INFO     Evaluating the model... (23500/50000)
2025-12-13 04:46:15,927 INFO     Evaluating the model... (24000/50000)
2025-12-13 04:46:18,458 INFO     Evaluating the model... (24500/50000)
2025-12-13 04:46:21,210 INFO     Evaluating the model... (25000/50000)
2025-12-13 04:46:23,738 INFO     Evaluating the model... (25500/50000)
2025-12-13 04:46:26,393 INFO     Evaluating the model... (26000/50000)
2025-12-13 04:46:29,943 INFO     Evaluating the model... (26500/50000)
2025-12-13 04:46:32,609 INFO     Evaluating the model... (27000/50000)
2025-12-13 04:46:35,137 INFO     Evaluating the model... (27500/50000)
2025-12-13 04:46:37,845 INFO     Evaluating the model... (28000/50000)
2025-12-13 04:46:40,896 INFO     Evaluating the model... (28500/50000)
2025-12-13 04:46:44,480 INFO     Evaluating the model... (29000/50000)
2025-12-13 04:46:47,036 INFO     Evaluating the model... (29500/50000)
2025-12-13 04:46:49,511 INFO     Evaluating the model... (30000/50000)
2025-12-13 04:46:52,351 INFO     Evaluating the model... (30500/50000)
2025-12-13 04:46:54,809 INFO     Evaluating the model... (31000/50000)
2025-12-13 04:46:58,114 INFO     Evaluating the model... (31500/50000)
2025-12-13 04:47:00,605 INFO     Evaluating the model... (32000/50000)
2025-12-13 04:47:03,298 INFO     Evaluating the model... (32500/50000)
2025-12-13 04:47:05,822 INFO     Evaluating the model... (33000/50000)
2025-12-13 04:47:08,408 INFO     Evaluating the model... (33500/50000)
2025-12-13 04:47:11,693 INFO     Evaluating the model... (34000/50000)
2025-12-13 04:47:14,323 INFO     Evaluating the model... (34500/50000)
2025-12-13 04:47:16,979 INFO     Evaluating the model... (35000/50000)
2025-12-13 04:47:19,546 INFO     Evaluating the model... (35500/50000)
2025-12-13 04:47:22,857 INFO     Evaluating the model... (36000/50000)
2025-12-13 04:47:25,404 INFO     Evaluating the model... (36500/50000)
2025-12-13 04:47:28,054 INFO     Evaluating the model... (37000/50000)
2025-12-13 04:47:30,667 INFO     Evaluating the model... (37500/50000)
2025-12-13 04:47:33,138 INFO     Evaluating the model... (38000/50000)
2025-12-13 04:47:36,419 INFO     Evaluating the model... (38500/50000)
2025-12-13 04:47:39,299 INFO     Evaluating the model... (39000/50000)
2025-12-13 04:47:42,077 INFO     Evaluating the model... (39500/50000)
2025-12-13 04:47:44,830 INFO     Evaluating the model... (40000/50000)
2025-12-13 04:47:47,353 INFO     Evaluating the model... (40500/50000)
2025-12-13 04:47:50,943 INFO     Evaluating the model... (41000/50000)
2025-12-13 04:47:53,444 INFO     Evaluating the model... (41500/50000)
2025-12-13 04:47:56,007 INFO     Evaluating the model... (42000/50000)
2025-12-13 04:47:58,505 INFO     Evaluating the model... (42500/50000)
2025-12-13 04:48:01,162 INFO     Evaluating the model... (43000/50000)
2025-12-13 04:48:04,384 INFO     Evaluating the model... (43500/50000)
2025-12-13 04:48:06,999 INFO     Evaluating the model... (44000/50000)
2025-12-13 04:48:09,458 INFO     Evaluating the model... (44500/50000)
2025-12-13 04:48:12,197 INFO     Evaluating the model... (45000/50000)
2025-12-13 04:48:14,855 INFO     Evaluating the model... (45500/50000)
2025-12-13 04:48:18,161 INFO     Evaluating the model... (46000/50000)
2025-12-13 04:48:20,602 INFO     Evaluating the model... (46500/50000)
2025-12-13 04:48:23,247 INFO     Evaluating the model... (47000/50000)
2025-12-13 04:48:26,020 INFO     Evaluating the model... (47500/50000)
2025-12-13 04:48:28,550 INFO     Evaluating the model... (48000/50000)
2025-12-13 04:48:31,876 INFO     Evaluating the model... (48500/50000)
2025-12-13 04:48:34,433 INFO     Evaluating the model... (49000/50000)
2025-12-13 04:48:37,266 INFO     Evaluating the model... (49500/50000)
2025-12-13 04:48:40,360 INFO     Valid MRR at step 240000: 0.633419
2025-12-13 04:48:40,360 INFO     Valid MR at step 240000: 266.919120
2025-12-13 04:48:40,360 INFO     Valid HITS@1 at step 240000: 0.547880
2025-12-13 04:48:40,360 INFO     Valid HITS@3 at step 240000: 0.686150
2025-12-13 04:48:40,360 INFO     Valid HITS@10 at step 240000: 0.784830
2025-12-13 04:48:41,723 INFO     Evaluating on Test Dataset...
2025-12-13 04:48:42,356 INFO     Evaluating the model... (0/59072)
2025-12-13 04:48:45,139 INFO     Evaluating the model... (500/59072)
2025-12-13 04:48:48,831 INFO     Evaluating the model... (1000/59072)
2025-12-13 04:48:51,460 INFO     Evaluating the model... (1500/59072)
2025-12-13 04:48:54,064 INFO     Evaluating the model... (2000/59072)
2025-12-13 04:48:56,533 INFO     Evaluating the model... (2500/59072)
2025-12-13 04:48:59,229 INFO     Evaluating the model... (3000/59072)
2025-12-13 04:49:02,438 INFO     Evaluating the model... (3500/59072)
2025-12-13 04:49:04,753 INFO     Evaluating the model... (4000/59072)
2025-12-13 04:49:07,367 INFO     Evaluating the model... (4500/59072)
2025-12-13 04:49:10,271 INFO     Evaluating the model... (5000/59072)
2025-12-13 04:49:12,696 INFO     Evaluating the model... (5500/59072)
2025-12-13 04:49:15,840 INFO     Evaluating the model... (6000/59072)
2025-12-13 04:49:18,204 INFO     Evaluating the model... (6500/59072)
2025-12-13 04:49:20,800 INFO     Evaluating the model... (7000/59072)
2025-12-13 04:49:23,333 INFO     Evaluating the model... (7500/59072)
2025-12-13 04:49:25,871 INFO     Evaluating the model... (8000/59072)
2025-12-13 04:49:28,985 INFO     Evaluating the model... (8500/59072)
2025-12-13 04:49:31,521 INFO     Evaluating the model... (9000/59072)
2025-12-13 04:49:34,151 INFO     Evaluating the model... (9500/59072)
2025-12-13 04:49:36,764 INFO     Evaluating the model... (10000/59072)
2025-12-13 04:49:39,423 INFO     Evaluating the model... (10500/59072)
2025-12-13 04:49:42,851 INFO     Evaluating the model... (11000/59072)
2025-12-13 04:49:45,726 INFO     Evaluating the model... (11500/59072)
2025-12-13 04:49:48,118 INFO     Evaluating the model... (12000/59072)
2025-12-13 04:49:50,496 INFO     Evaluating the model... (12500/59072)
2025-12-13 04:49:52,983 INFO     Evaluating the model... (13000/59072)
2025-12-13 04:49:56,268 INFO     Evaluating the model... (13500/59072)
2025-12-13 04:49:58,683 INFO     Evaluating the model... (14000/59072)
2025-12-13 04:50:01,057 INFO     Evaluating the model... (14500/59072)
2025-12-13 04:50:03,586 INFO     Evaluating the model... (15000/59072)
2025-12-13 04:50:07,082 INFO     Evaluating the model... (15500/59072)
2025-12-13 04:50:09,512 INFO     Evaluating the model... (16000/59072)
2025-12-13 04:50:11,850 INFO     Evaluating the model... (16500/59072)
2025-12-13 04:50:14,345 INFO     Evaluating the model... (17000/59072)
2025-12-13 04:50:16,705 INFO     Evaluating the model... (17500/59072)
2025-12-13 04:50:20,298 INFO     Evaluating the model... (18000/59072)
2025-12-13 04:50:22,650 INFO     Evaluating the model... (18500/59072)
2025-12-13 04:50:25,077 INFO     Evaluating the model... (19000/59072)
2025-12-13 04:50:27,599 INFO     Evaluating the model... (19500/59072)
2025-12-13 04:50:30,362 INFO     Evaluating the model... (20000/59072)
2025-12-13 04:50:33,908 INFO     Evaluating the model... (20500/59072)
2025-12-13 04:50:36,490 INFO     Evaluating the model... (21000/59072)
2025-12-13 04:50:39,101 INFO     Evaluating the model... (21500/59072)
2025-12-13 04:50:42,150 INFO     Evaluating the model... (22000/59072)
2025-12-13 04:50:44,817 INFO     Evaluating the model... (22500/59072)
2025-12-13 04:50:48,512 INFO     Evaluating the model... (23000/59072)
2025-12-13 04:50:50,970 INFO     Evaluating the model... (23500/59072)
2025-12-13 04:50:53,628 INFO     Evaluating the model... (24000/59072)
2025-12-13 04:50:56,138 INFO     Evaluating the model... (24500/59072)
2025-12-13 04:50:58,557 INFO     Evaluating the model... (25000/59072)
2025-12-13 04:51:02,203 INFO     Evaluating the model... (25500/59072)
2025-12-13 04:51:04,839 INFO     Evaluating the model... (26000/59072)
2025-12-13 04:51:07,284 INFO     Evaluating the model... (26500/59072)
2025-12-13 04:51:09,756 INFO     Evaluating the model... (27000/59072)
2025-12-13 04:51:12,160 INFO     Evaluating the model... (27500/59072)
2025-12-13 04:51:16,149 INFO     Evaluating the model... (28000/59072)
2025-12-13 04:51:18,517 INFO     Evaluating the model... (28500/59072)
2025-12-13 04:51:21,001 INFO     Evaluating the model... (29000/59072)
2025-12-13 04:51:23,447 INFO     Evaluating the model... (29500/59072)
2025-12-13 04:51:27,268 INFO     Evaluating the model... (30000/59072)
2025-12-13 04:51:30,018 INFO     Evaluating the model... (30500/59072)
2025-12-13 04:51:32,637 INFO     Evaluating the model... (31000/59072)
2025-12-13 04:51:35,250 INFO     Evaluating the model... (31500/59072)
2025-12-13 04:51:38,049 INFO     Evaluating the model... (32000/59072)
2025-12-13 04:51:41,551 INFO     Evaluating the model... (32500/59072)
2025-12-13 04:51:44,245 INFO     Evaluating the model... (33000/59072)
2025-12-13 04:51:46,834 INFO     Evaluating the model... (33500/59072)
2025-12-13 04:51:49,450 INFO     Evaluating the model... (34000/59072)
2025-12-13 04:51:52,134 INFO     Evaluating the model... (34500/59072)
2025-12-13 04:51:55,020 INFO     Evaluating the model... (35000/59072)
2025-12-13 04:51:57,547 INFO     Evaluating the model... (35500/59072)
2025-12-13 04:52:00,089 INFO     Evaluating the model... (36000/59072)
2025-12-13 04:52:02,828 INFO     Evaluating the model... (36500/59072)
2025-12-13 04:52:05,312 INFO     Evaluating the model... (37000/59072)
2025-12-13 04:52:08,415 INFO     Evaluating the model... (37500/59072)
2025-12-13 04:52:10,977 INFO     Evaluating the model... (38000/59072)
2025-12-13 04:52:13,741 INFO     Evaluating the model... (38500/59072)
2025-12-13 04:52:16,283 INFO     Evaluating the model... (39000/59072)
2025-12-13 04:52:18,772 INFO     Evaluating the model... (39500/59072)
2025-12-13 04:52:21,702 INFO     Evaluating the model... (40000/59072)
2025-12-13 04:52:24,177 INFO     Evaluating the model... (40500/59072)
2025-12-13 04:52:26,920 INFO     Evaluating the model... (41000/59072)
2025-12-13 04:52:29,396 INFO     Evaluating the model... (41500/59072)
2025-12-13 04:52:31,971 INFO     Evaluating the model... (42000/59072)
2025-12-13 04:52:34,995 INFO     Evaluating the model... (42500/59072)
2025-12-13 04:52:38,032 INFO     Evaluating the model... (43000/59072)
2025-12-13 04:52:40,700 INFO     Evaluating the model... (43500/59072)
2025-12-13 04:52:43,233 INFO     Evaluating the model... (44000/59072)
2025-12-13 04:52:45,866 INFO     Evaluating the model... (44500/59072)
2025-12-13 04:52:49,536 INFO     Evaluating the model... (45000/59072)
2025-12-13 04:52:52,017 INFO     Evaluating the model... (45500/59072)
2025-12-13 04:52:54,655 INFO     Evaluating the model... (46000/59072)
2025-12-13 04:52:57,235 INFO     Evaluating the model... (46500/59072)
2025-12-13 04:53:00,730 INFO     Evaluating the model... (47000/59072)
2025-12-13 04:53:03,137 INFO     Evaluating the model... (47500/59072)
2025-12-13 04:53:05,677 INFO     Evaluating the model... (48000/59072)
2025-12-13 04:53:08,108 INFO     Evaluating the model... (48500/59072)
2025-12-13 04:53:10,783 INFO     Evaluating the model... (49000/59072)
2025-12-13 04:53:14,568 INFO     Evaluating the model... (49500/59072)
2025-12-13 04:53:17,074 INFO     Evaluating the model... (50000/59072)
2025-12-13 04:53:19,566 INFO     Evaluating the model... (50500/59072)
2025-12-13 04:53:22,160 INFO     Evaluating the model... (51000/59072)
2025-12-13 04:53:24,651 INFO     Evaluating the model... (51500/59072)
2025-12-13 04:53:29,048 INFO     Evaluating the model... (52000/59072)
2025-12-13 04:53:31,534 INFO     Evaluating the model... (52500/59072)
2025-12-13 04:53:34,302 INFO     Evaluating the model... (53000/59072)
2025-12-13 04:53:36,979 INFO     Evaluating the model... (53500/59072)
2025-12-13 04:53:39,719 INFO     Evaluating the model... (54000/59072)
2025-12-13 04:53:43,513 INFO     Evaluating the model... (54500/59072)
2025-12-13 04:53:46,448 INFO     Evaluating the model... (55000/59072)
2025-12-13 04:53:48,926 INFO     Evaluating the model... (55500/59072)
2025-12-13 04:53:51,313 INFO     Evaluating the model... (56000/59072)
2025-12-13 04:53:53,755 INFO     Evaluating the model... (56500/59072)
2025-12-13 04:53:57,640 INFO     Evaluating the model... (57000/59072)
2025-12-13 04:54:00,149 INFO     Evaluating the model... (57500/59072)
2025-12-13 04:54:02,536 INFO     Evaluating the model... (58000/59072)
2025-12-13 04:54:05,052 INFO     Evaluating the model... (58500/59072)
2025-12-13 04:54:07,589 INFO     Evaluating the model... (59000/59072)
2025-12-13 04:54:08,174 INFO     Test MRR at step 240000: 0.630223
2025-12-13 04:54:08,174 INFO     Test MR at step 240000: 268.890005
2025-12-13 04:54:08,174 INFO     Test HITS@1 at step 240000: 0.543185
2025-12-13 04:54:08,174 INFO     Test HITS@3 at step 240000: 0.684481
2025-12-13 04:54:08,174 INFO     Test HITS@10 at step 240000: 0.783049
2025-12-13 04:54:10,311 INFO     Training average regularization at step 240100: 0.302026
2025-12-13 04:54:10,311 INFO     Training average positive_sample_loss at step 240100: 0.066855
2025-12-13 04:54:10,311 INFO     Training average negative_sample_loss at step 240100: 0.108359
2025-12-13 04:54:10,311 INFO     Training average loss at step 240100: 0.389633
2025-12-13 04:54:12,443 INFO     Training average regularization at step 240200: 0.302026
2025-12-13 04:54:12,444 INFO     Training average positive_sample_loss at step 240200: 0.066147
2025-12-13 04:54:12,444 INFO     Training average negative_sample_loss at step 240200: 0.106493
2025-12-13 04:54:12,444 INFO     Training average loss at step 240200: 0.388346
2025-12-13 04:54:14,574 INFO     Training average regularization at step 240300: 0.302026
2025-12-13 04:54:14,575 INFO     Training average positive_sample_loss at step 240300: 0.067461
2025-12-13 04:54:14,575 INFO     Training average negative_sample_loss at step 240300: 0.111820
2025-12-13 04:54:14,575 INFO     Training average loss at step 240300: 0.391666
2025-12-13 04:54:16,720 INFO     Training average regularization at step 240400: 0.302026
2025-12-13 04:54:16,720 INFO     Training average positive_sample_loss at step 240400: 0.067070
2025-12-13 04:54:16,720 INFO     Training average negative_sample_loss at step 240400: 0.108630
2025-12-13 04:54:16,720 INFO     Training average loss at step 240400: 0.389876
2025-12-13 04:54:18,855 INFO     Training average regularization at step 240500: 0.302026
2025-12-13 04:54:18,855 INFO     Training average positive_sample_loss at step 240500: 0.066874
2025-12-13 04:54:18,855 INFO     Training average negative_sample_loss at step 240500: 0.110555
2025-12-13 04:54:18,855 INFO     Training average loss at step 240500: 0.390740
2025-12-13 04:54:21,044 INFO     Training average regularization at step 240600: 0.302026
2025-12-13 04:54:21,045 INFO     Training average positive_sample_loss at step 240600: 0.067363
2025-12-13 04:54:21,045 INFO     Training average negative_sample_loss at step 240600: 0.110464
2025-12-13 04:54:21,045 INFO     Training average loss at step 240600: 0.390939
2025-12-13 04:54:23,170 INFO     Training average regularization at step 240700: 0.302026
2025-12-13 04:54:23,170 INFO     Training average positive_sample_loss at step 240700: 0.065755
2025-12-13 04:54:23,170 INFO     Training average negative_sample_loss at step 240700: 0.109434
2025-12-13 04:54:23,170 INFO     Training average loss at step 240700: 0.389620
2025-12-13 04:54:25,315 INFO     Training average regularization at step 240800: 0.302026
2025-12-13 04:54:25,316 INFO     Training average positive_sample_loss at step 240800: 0.066848
2025-12-13 04:54:25,316 INFO     Training average negative_sample_loss at step 240800: 0.109285
2025-12-13 04:54:25,316 INFO     Training average loss at step 240800: 0.390092
2025-12-13 04:54:27,486 INFO     Training average regularization at step 240900: 0.302026
2025-12-13 04:54:27,487 INFO     Training average positive_sample_loss at step 240900: 0.066099
2025-12-13 04:54:27,487 INFO     Training average negative_sample_loss at step 240900: 0.109825
2025-12-13 04:54:27,487 INFO     Training average loss at step 240900: 0.389988
2025-12-13 04:54:29,641 INFO     Training average regularization at step 241000: 0.302026
2025-12-13 04:54:29,641 INFO     Training average positive_sample_loss at step 241000: 0.065709
2025-12-13 04:54:29,641 INFO     Training average negative_sample_loss at step 241000: 0.108107
2025-12-13 04:54:29,641 INFO     Training average loss at step 241000: 0.388934
2025-12-13 04:54:31,779 INFO     Training average regularization at step 241100: 0.302025
2025-12-13 04:54:31,779 INFO     Training average positive_sample_loss at step 241100: 0.066827
2025-12-13 04:54:31,779 INFO     Training average negative_sample_loss at step 241100: 0.107375
2025-12-13 04:54:31,779 INFO     Training average loss at step 241100: 0.389126
2025-12-13 04:54:33,896 INFO     Training average regularization at step 241200: 0.302025
2025-12-13 04:54:33,896 INFO     Training average positive_sample_loss at step 241200: 0.066379
2025-12-13 04:54:33,896 INFO     Training average negative_sample_loss at step 241200: 0.106634
2025-12-13 04:54:33,896 INFO     Training average loss at step 241200: 0.388532
2025-12-13 04:54:36,061 INFO     Training average regularization at step 241300: 0.302025
2025-12-13 04:54:36,061 INFO     Training average positive_sample_loss at step 241300: 0.066824
2025-12-13 04:54:36,061 INFO     Training average negative_sample_loss at step 241300: 0.107973
2025-12-13 04:54:36,061 INFO     Training average loss at step 241300: 0.389424
2025-12-13 04:54:38,240 INFO     Training average regularization at step 241400: 0.302025
2025-12-13 04:54:38,240 INFO     Training average positive_sample_loss at step 241400: 0.067740
2025-12-13 04:54:38,240 INFO     Training average negative_sample_loss at step 241400: 0.109932
2025-12-13 04:54:38,240 INFO     Training average loss at step 241400: 0.390861
2025-12-13 04:54:40,417 INFO     Training average regularization at step 241500: 0.302025
2025-12-13 04:54:40,418 INFO     Training average positive_sample_loss at step 241500: 0.066981
2025-12-13 04:54:40,418 INFO     Training average negative_sample_loss at step 241500: 0.110216
2025-12-13 04:54:40,418 INFO     Training average loss at step 241500: 0.390624
2025-12-13 04:54:42,742 INFO     Training average regularization at step 241600: 0.302025
2025-12-13 04:54:42,742 INFO     Training average positive_sample_loss at step 241600: 0.065994
2025-12-13 04:54:42,742 INFO     Training average negative_sample_loss at step 241600: 0.108520
2025-12-13 04:54:42,742 INFO     Training average loss at step 241600: 0.389282
2025-12-13 04:54:46,010 INFO     Training average regularization at step 241700: 0.302025
2025-12-13 04:54:46,010 INFO     Training average positive_sample_loss at step 241700: 0.066915
2025-12-13 04:54:46,010 INFO     Training average negative_sample_loss at step 241700: 0.111556
2025-12-13 04:54:46,010 INFO     Training average loss at step 241700: 0.391260
2025-12-13 04:54:48,179 INFO     Training average regularization at step 241800: 0.302025
2025-12-13 04:54:48,179 INFO     Training average positive_sample_loss at step 241800: 0.067171
2025-12-13 04:54:48,179 INFO     Training average negative_sample_loss at step 241800: 0.107940
2025-12-13 04:54:48,179 INFO     Training average loss at step 241800: 0.389581
2025-12-13 04:54:50,335 INFO     Training average regularization at step 241900: 0.302025
2025-12-13 04:54:50,335 INFO     Training average positive_sample_loss at step 241900: 0.066534
2025-12-13 04:54:50,335 INFO     Training average negative_sample_loss at step 241900: 0.108582
2025-12-13 04:54:50,335 INFO     Training average loss at step 241900: 0.389583
2025-12-13 04:54:52,509 INFO     Training average regularization at step 242000: 0.302025
2025-12-13 04:54:52,510 INFO     Training average positive_sample_loss at step 242000: 0.067271
2025-12-13 04:54:52,510 INFO     Training average negative_sample_loss at step 242000: 0.111618
2025-12-13 04:54:52,510 INFO     Training average loss at step 242000: 0.391470
2025-12-13 04:54:54,616 INFO     Training average regularization at step 242100: 0.302025
2025-12-13 04:54:54,616 INFO     Training average positive_sample_loss at step 242100: 0.066753
2025-12-13 04:54:54,616 INFO     Training average negative_sample_loss at step 242100: 0.109576
2025-12-13 04:54:54,616 INFO     Training average loss at step 242100: 0.390190
2025-12-13 04:54:56,736 INFO     Training average regularization at step 242200: 0.302025
2025-12-13 04:54:56,736 INFO     Training average positive_sample_loss at step 242200: 0.066099
2025-12-13 04:54:56,736 INFO     Training average negative_sample_loss at step 242200: 0.109327
2025-12-13 04:54:56,736 INFO     Training average loss at step 242200: 0.389738
2025-12-13 04:54:58,836 INFO     Training average regularization at step 242300: 0.302025
2025-12-13 04:54:58,836 INFO     Training average positive_sample_loss at step 242300: 0.067657
2025-12-13 04:54:58,836 INFO     Training average negative_sample_loss at step 242300: 0.107617
2025-12-13 04:54:58,836 INFO     Training average loss at step 242300: 0.389661
2025-12-13 04:55:00,956 INFO     Training average regularization at step 242400: 0.302025
2025-12-13 04:55:00,956 INFO     Training average positive_sample_loss at step 242400: 0.066928
2025-12-13 04:55:00,956 INFO     Training average negative_sample_loss at step 242400: 0.108560
2025-12-13 04:55:00,956 INFO     Training average loss at step 242400: 0.389769
2025-12-13 04:55:03,065 INFO     Training average regularization at step 242500: 0.302025
2025-12-13 04:55:03,065 INFO     Training average positive_sample_loss at step 242500: 0.066239
2025-12-13 04:55:03,065 INFO     Training average negative_sample_loss at step 242500: 0.107657
2025-12-13 04:55:03,065 INFO     Training average loss at step 242500: 0.388973
2025-12-13 04:55:05,182 INFO     Training average regularization at step 242600: 0.302024
2025-12-13 04:55:05,182 INFO     Training average positive_sample_loss at step 242600: 0.066263
2025-12-13 04:55:05,182 INFO     Training average negative_sample_loss at step 242600: 0.109203
2025-12-13 04:55:05,183 INFO     Training average loss at step 242600: 0.389758
2025-12-13 04:55:07,293 INFO     Training average regularization at step 242700: 0.302024
2025-12-13 04:55:07,293 INFO     Training average positive_sample_loss at step 242700: 0.066724
2025-12-13 04:55:07,293 INFO     Training average negative_sample_loss at step 242700: 0.109277
2025-12-13 04:55:07,293 INFO     Training average loss at step 242700: 0.390025
2025-12-13 04:55:09,423 INFO     Training average regularization at step 242800: 0.302024
2025-12-13 04:55:09,430 INFO     Training average positive_sample_loss at step 242800: 0.066696
2025-12-13 04:55:09,430 INFO     Training average negative_sample_loss at step 242800: 0.107634
2025-12-13 04:55:09,430 INFO     Training average loss at step 242800: 0.389189
2025-12-13 04:55:11,522 INFO     Training average regularization at step 242900: 0.302024
2025-12-13 04:55:11,522 INFO     Training average positive_sample_loss at step 242900: 0.066729
2025-12-13 04:55:11,522 INFO     Training average negative_sample_loss at step 242900: 0.108776
2025-12-13 04:55:11,522 INFO     Training average loss at step 242900: 0.389777
2025-12-13 04:55:13,654 INFO     Training average regularization at step 243000: 0.302024
2025-12-13 04:55:13,655 INFO     Training average positive_sample_loss at step 243000: 0.066549
2025-12-13 04:55:13,655 INFO     Training average negative_sample_loss at step 243000: 0.110333
2025-12-13 04:55:13,655 INFO     Training average loss at step 243000: 0.390465
2025-12-13 04:55:15,790 INFO     Training average regularization at step 243100: 0.302024
2025-12-13 04:55:15,790 INFO     Training average positive_sample_loss at step 243100: 0.065969
2025-12-13 04:55:15,790 INFO     Training average negative_sample_loss at step 243100: 0.111793
2025-12-13 04:55:15,790 INFO     Training average loss at step 243100: 0.390905
2025-12-13 04:55:17,895 INFO     Training average regularization at step 243200: 0.302024
2025-12-13 04:55:17,895 INFO     Training average positive_sample_loss at step 243200: 0.066730
2025-12-13 04:55:17,895 INFO     Training average negative_sample_loss at step 243200: 0.108569
2025-12-13 04:55:17,895 INFO     Training average loss at step 243200: 0.389674
2025-12-13 04:55:20,006 INFO     Training average regularization at step 243300: 0.302024
2025-12-13 04:55:20,006 INFO     Training average positive_sample_loss at step 243300: 0.067246
2025-12-13 04:55:20,006 INFO     Training average negative_sample_loss at step 243300: 0.110722
2025-12-13 04:55:20,006 INFO     Training average loss at step 243300: 0.391008
2025-12-13 04:55:22,111 INFO     Training average regularization at step 243400: 0.302024
2025-12-13 04:55:22,112 INFO     Training average positive_sample_loss at step 243400: 0.066692
2025-12-13 04:55:22,112 INFO     Training average negative_sample_loss at step 243400: 0.112542
2025-12-13 04:55:22,112 INFO     Training average loss at step 243400: 0.391641
2025-12-13 04:55:24,215 INFO     Training average regularization at step 243500: 0.302024
2025-12-13 04:55:24,216 INFO     Training average positive_sample_loss at step 243500: 0.066990
2025-12-13 04:55:24,216 INFO     Training average negative_sample_loss at step 243500: 0.110329
2025-12-13 04:55:24,216 INFO     Training average loss at step 243500: 0.390683
2025-12-13 04:55:26,335 INFO     Training average regularization at step 243600: 0.302024
2025-12-13 04:55:26,339 INFO     Training average positive_sample_loss at step 243600: 0.067106
2025-12-13 04:55:26,339 INFO     Training average negative_sample_loss at step 243600: 0.111187
2025-12-13 04:55:26,339 INFO     Training average loss at step 243600: 0.391170
2025-12-13 04:55:28,422 INFO     Training average regularization at step 243700: 0.302024
2025-12-13 04:55:28,422 INFO     Training average positive_sample_loss at step 243700: 0.066978
2025-12-13 04:55:28,422 INFO     Training average negative_sample_loss at step 243700: 0.108507
2025-12-13 04:55:28,422 INFO     Training average loss at step 243700: 0.389766
2025-12-13 04:55:30,533 INFO     Training average regularization at step 243800: 0.302024
2025-12-13 04:55:30,533 INFO     Training average positive_sample_loss at step 243800: 0.067116
2025-12-13 04:55:30,533 INFO     Training average negative_sample_loss at step 243800: 0.109732
2025-12-13 04:55:30,533 INFO     Training average loss at step 243800: 0.390448
2025-12-13 04:55:32,622 INFO     Training average regularization at step 243900: 0.302024
2025-12-13 04:55:32,622 INFO     Training average positive_sample_loss at step 243900: 0.065035
2025-12-13 04:55:32,622 INFO     Training average negative_sample_loss at step 243900: 0.110758
2025-12-13 04:55:32,622 INFO     Training average loss at step 243900: 0.389920
2025-12-13 04:55:34,707 INFO     Training average regularization at step 244000: 0.302023
2025-12-13 04:55:34,707 INFO     Training average positive_sample_loss at step 244000: 0.067847
2025-12-13 04:55:34,707 INFO     Training average negative_sample_loss at step 244000: 0.110489
2025-12-13 04:55:34,707 INFO     Training average loss at step 244000: 0.391191
2025-12-13 04:55:36,889 INFO     Training average regularization at step 244100: 0.302023
2025-12-13 04:55:36,890 INFO     Training average positive_sample_loss at step 244100: 0.066527
2025-12-13 04:55:36,890 INFO     Training average negative_sample_loss at step 244100: 0.109738
2025-12-13 04:55:36,890 INFO     Training average loss at step 244100: 0.390156
2025-12-13 04:55:39,027 INFO     Training average regularization at step 244200: 0.302023
2025-12-13 04:55:39,029 INFO     Training average positive_sample_loss at step 244200: 0.065727
2025-12-13 04:55:39,029 INFO     Training average negative_sample_loss at step 244200: 0.108080
2025-12-13 04:55:39,029 INFO     Training average loss at step 244200: 0.388927
2025-12-13 04:55:41,208 INFO     Training average regularization at step 244300: 0.302023
2025-12-13 04:55:41,208 INFO     Training average positive_sample_loss at step 244300: 0.066367
2025-12-13 04:55:41,208 INFO     Training average negative_sample_loss at step 244300: 0.110203
2025-12-13 04:55:41,208 INFO     Training average loss at step 244300: 0.390308
2025-12-13 04:55:43,366 INFO     Training average regularization at step 244400: 0.302023
2025-12-13 04:55:43,366 INFO     Training average positive_sample_loss at step 244400: 0.065456
2025-12-13 04:55:43,366 INFO     Training average negative_sample_loss at step 244400: 0.113959
2025-12-13 04:55:43,366 INFO     Training average loss at step 244400: 0.391730
2025-12-13 04:55:45,470 INFO     Training average regularization at step 244500: 0.302023
2025-12-13 04:55:45,470 INFO     Training average positive_sample_loss at step 244500: 0.067309
2025-12-13 04:55:45,471 INFO     Training average negative_sample_loss at step 244500: 0.106459
2025-12-13 04:55:45,471 INFO     Training average loss at step 244500: 0.388907
2025-12-13 04:55:47,614 INFO     Training average regularization at step 244600: 0.302023
2025-12-13 04:55:47,614 INFO     Training average positive_sample_loss at step 244600: 0.068509
2025-12-13 04:55:47,614 INFO     Training average negative_sample_loss at step 244600: 0.108054
2025-12-13 04:55:47,614 INFO     Training average loss at step 244600: 0.390304
2025-12-13 04:55:49,710 INFO     Training average regularization at step 244700: 0.302023
2025-12-13 04:55:49,711 INFO     Training average positive_sample_loss at step 244700: 0.066537
2025-12-13 04:55:49,711 INFO     Training average negative_sample_loss at step 244700: 0.112196
2025-12-13 04:55:49,711 INFO     Training average loss at step 244700: 0.391389
2025-12-13 04:55:51,811 INFO     Training average regularization at step 244800: 0.302023
2025-12-13 04:55:51,811 INFO     Training average positive_sample_loss at step 244800: 0.066319
2025-12-13 04:55:51,811 INFO     Training average negative_sample_loss at step 244800: 0.111366
2025-12-13 04:55:51,811 INFO     Training average loss at step 244800: 0.390865
2025-12-13 04:55:53,909 INFO     Training average regularization at step 244900: 0.302023
2025-12-13 04:55:53,909 INFO     Training average positive_sample_loss at step 244900: 0.067344
2025-12-13 04:55:53,909 INFO     Training average negative_sample_loss at step 244900: 0.109622
2025-12-13 04:55:53,909 INFO     Training average loss at step 244900: 0.390506
2025-12-13 04:55:56,028 INFO     Training average regularization at step 245000: 0.302023
2025-12-13 04:55:56,030 INFO     Training average positive_sample_loss at step 245000: 0.067001
2025-12-13 04:55:56,030 INFO     Training average negative_sample_loss at step 245000: 0.107017
2025-12-13 04:55:56,030 INFO     Training average loss at step 245000: 0.389032
2025-12-13 04:55:58,170 INFO     Training average regularization at step 245100: 0.302023
2025-12-13 04:55:58,170 INFO     Training average positive_sample_loss at step 245100: 0.066919
2025-12-13 04:55:58,170 INFO     Training average negative_sample_loss at step 245100: 0.109878
2025-12-13 04:55:58,171 INFO     Training average loss at step 245100: 0.390421
2025-12-13 04:56:00,299 INFO     Training average regularization at step 245200: 0.302023
2025-12-13 04:56:00,299 INFO     Training average positive_sample_loss at step 245200: 0.065901
2025-12-13 04:56:00,299 INFO     Training average negative_sample_loss at step 245200: 0.106239
2025-12-13 04:56:00,299 INFO     Training average loss at step 245200: 0.388093
2025-12-13 04:56:02,424 INFO     Training average regularization at step 245300: 0.302023
2025-12-13 04:56:02,424 INFO     Training average positive_sample_loss at step 245300: 0.067133
2025-12-13 04:56:02,424 INFO     Training average negative_sample_loss at step 245300: 0.108657
2025-12-13 04:56:02,424 INFO     Training average loss at step 245300: 0.389918
2025-12-13 04:56:04,510 INFO     Training average regularization at step 245400: 0.302023
2025-12-13 04:56:04,510 INFO     Training average positive_sample_loss at step 245400: 0.065695
2025-12-13 04:56:04,510 INFO     Training average negative_sample_loss at step 245400: 0.108196
2025-12-13 04:56:04,510 INFO     Training average loss at step 245400: 0.388968
2025-12-13 04:56:06,613 INFO     Training average regularization at step 245500: 0.302023
2025-12-13 04:56:06,613 INFO     Training average positive_sample_loss at step 245500: 0.066062
2025-12-13 04:56:06,613 INFO     Training average negative_sample_loss at step 245500: 0.106500
2025-12-13 04:56:06,613 INFO     Training average loss at step 245500: 0.388304
2025-12-13 04:56:08,731 INFO     Training average regularization at step 245600: 0.302022
2025-12-13 04:56:08,732 INFO     Training average positive_sample_loss at step 245600: 0.067455
2025-12-13 04:56:08,732 INFO     Training average negative_sample_loss at step 245600: 0.109724
2025-12-13 04:56:08,732 INFO     Training average loss at step 245600: 0.390612
2025-12-13 04:56:10,848 INFO     Training average regularization at step 245700: 0.302022
2025-12-13 04:56:10,848 INFO     Training average positive_sample_loss at step 245700: 0.067300
2025-12-13 04:56:10,848 INFO     Training average negative_sample_loss at step 245700: 0.109757
2025-12-13 04:56:10,848 INFO     Training average loss at step 245700: 0.390551
2025-12-13 04:56:12,950 INFO     Training average regularization at step 245800: 0.302022
2025-12-13 04:56:12,951 INFO     Training average positive_sample_loss at step 245800: 0.065597
2025-12-13 04:56:12,951 INFO     Training average negative_sample_loss at step 245800: 0.107810
2025-12-13 04:56:12,951 INFO     Training average loss at step 245800: 0.388726
2025-12-13 04:56:15,040 INFO     Training average regularization at step 245900: 0.302022
2025-12-13 04:56:15,040 INFO     Training average positive_sample_loss at step 245900: 0.067304
2025-12-13 04:56:15,040 INFO     Training average negative_sample_loss at step 245900: 0.108533
2025-12-13 04:56:15,040 INFO     Training average loss at step 245900: 0.389941
2025-12-13 04:56:17,172 INFO     Training average regularization at step 246000: 0.302022
2025-12-13 04:56:17,173 INFO     Training average positive_sample_loss at step 246000: 0.066843
2025-12-13 04:56:17,173 INFO     Training average negative_sample_loss at step 246000: 0.110864
2025-12-13 04:56:17,173 INFO     Training average loss at step 246000: 0.390876
2025-12-13 04:56:19,287 INFO     Training average regularization at step 246100: 0.302022
2025-12-13 04:56:19,287 INFO     Training average positive_sample_loss at step 246100: 0.066345
2025-12-13 04:56:19,287 INFO     Training average negative_sample_loss at step 246100: 0.111952
2025-12-13 04:56:19,287 INFO     Training average loss at step 246100: 0.391170
2025-12-13 04:56:21,403 INFO     Training average regularization at step 246200: 0.302022
2025-12-13 04:56:21,403 INFO     Training average positive_sample_loss at step 246200: 0.066546
2025-12-13 04:56:21,403 INFO     Training average negative_sample_loss at step 246200: 0.112050
2025-12-13 04:56:21,403 INFO     Training average loss at step 246200: 0.391320
2025-12-13 04:56:23,489 INFO     Training average regularization at step 246300: 0.302022
2025-12-13 04:56:23,489 INFO     Training average positive_sample_loss at step 246300: 0.066278
2025-12-13 04:56:23,489 INFO     Training average negative_sample_loss at step 246300: 0.107981
2025-12-13 04:56:23,489 INFO     Training average loss at step 246300: 0.389152
2025-12-13 04:56:25,581 INFO     Training average regularization at step 246400: 0.302022
2025-12-13 04:56:25,581 INFO     Training average positive_sample_loss at step 246400: 0.066436
2025-12-13 04:56:25,581 INFO     Training average negative_sample_loss at step 246400: 0.109729
2025-12-13 04:56:25,582 INFO     Training average loss at step 246400: 0.390104
2025-12-13 04:56:28,704 INFO     Training average regularization at step 246500: 0.302022
2025-12-13 04:56:28,704 INFO     Training average positive_sample_loss at step 246500: 0.067398
2025-12-13 04:56:28,704 INFO     Training average negative_sample_loss at step 246500: 0.107552
2025-12-13 04:56:28,704 INFO     Training average loss at step 246500: 0.389497
2025-12-13 04:56:30,895 INFO     Training average regularization at step 246600: 0.302022
2025-12-13 04:56:30,896 INFO     Training average positive_sample_loss at step 246600: 0.066872
2025-12-13 04:56:30,897 INFO     Training average negative_sample_loss at step 246600: 0.109910
2025-12-13 04:56:30,897 INFO     Training average loss at step 246600: 0.390413
2025-12-13 04:56:33,047 INFO     Training average regularization at step 246700: 0.302022
2025-12-13 04:56:33,047 INFO     Training average positive_sample_loss at step 246700: 0.065940
2025-12-13 04:56:33,048 INFO     Training average negative_sample_loss at step 246700: 0.108897
2025-12-13 04:56:33,048 INFO     Training average loss at step 246700: 0.389440
2025-12-13 04:56:35,225 INFO     Training average regularization at step 246800: 0.302022
2025-12-13 04:56:35,225 INFO     Training average positive_sample_loss at step 246800: 0.066226
2025-12-13 04:56:35,225 INFO     Training average negative_sample_loss at step 246800: 0.108197
2025-12-13 04:56:35,225 INFO     Training average loss at step 246800: 0.389233
2025-12-13 04:56:37,447 INFO     Training average regularization at step 246900: 0.302022
2025-12-13 04:56:37,448 INFO     Training average positive_sample_loss at step 246900: 0.067019
2025-12-13 04:56:37,448 INFO     Training average negative_sample_loss at step 246900: 0.109733
2025-12-13 04:56:37,448 INFO     Training average loss at step 246900: 0.390397
2025-12-13 04:56:39,615 INFO     Training average regularization at step 247000: 0.302021
2025-12-13 04:56:39,616 INFO     Training average positive_sample_loss at step 247000: 0.067641
2025-12-13 04:56:39,616 INFO     Training average negative_sample_loss at step 247000: 0.106659
2025-12-13 04:56:39,616 INFO     Training average loss at step 247000: 0.389171
2025-12-13 04:56:41,812 INFO     Training average regularization at step 247100: 0.302021
2025-12-13 04:56:41,813 INFO     Training average positive_sample_loss at step 247100: 0.067357
2025-12-13 04:56:41,813 INFO     Training average negative_sample_loss at step 247100: 0.108980
2025-12-13 04:56:41,813 INFO     Training average loss at step 247100: 0.390190
2025-12-13 04:56:43,959 INFO     Training average regularization at step 247200: 0.302021
2025-12-13 04:56:43,959 INFO     Training average positive_sample_loss at step 247200: 0.066577
2025-12-13 04:56:43,959 INFO     Training average negative_sample_loss at step 247200: 0.109910
2025-12-13 04:56:43,959 INFO     Training average loss at step 247200: 0.390265
2025-12-13 04:56:46,097 INFO     Training average regularization at step 247300: 0.302021
2025-12-13 04:56:46,097 INFO     Training average positive_sample_loss at step 247300: 0.067594
2025-12-13 04:56:46,097 INFO     Training average negative_sample_loss at step 247300: 0.110135
2025-12-13 04:56:46,097 INFO     Training average loss at step 247300: 0.390886
2025-12-13 04:56:48,200 INFO     Training average regularization at step 247400: 0.302021
2025-12-13 04:56:48,200 INFO     Training average positive_sample_loss at step 247400: 0.066746
2025-12-13 04:56:48,200 INFO     Training average negative_sample_loss at step 247400: 0.108608
2025-12-13 04:56:48,200 INFO     Training average loss at step 247400: 0.389698
2025-12-13 04:56:50,313 INFO     Training average regularization at step 247500: 0.302021
2025-12-13 04:56:50,313 INFO     Training average positive_sample_loss at step 247500: 0.066726
2025-12-13 04:56:50,313 INFO     Training average negative_sample_loss at step 247500: 0.109210
2025-12-13 04:56:50,313 INFO     Training average loss at step 247500: 0.389989
2025-12-13 04:56:52,446 INFO     Training average regularization at step 247600: 0.302021
2025-12-13 04:56:52,446 INFO     Training average positive_sample_loss at step 247600: 0.064954
2025-12-13 04:56:52,446 INFO     Training average negative_sample_loss at step 247600: 0.108915
2025-12-13 04:56:52,446 INFO     Training average loss at step 247600: 0.388956
2025-12-13 04:56:54,585 INFO     Training average regularization at step 247700: 0.302021
2025-12-13 04:56:54,585 INFO     Training average positive_sample_loss at step 247700: 0.067733
2025-12-13 04:56:54,585 INFO     Training average negative_sample_loss at step 247700: 0.110207
2025-12-13 04:56:54,585 INFO     Training average loss at step 247700: 0.390991
2025-12-13 04:56:56,699 INFO     Training average regularization at step 247800: 0.302021
2025-12-13 04:56:56,700 INFO     Training average positive_sample_loss at step 247800: 0.065089
2025-12-13 04:56:56,700 INFO     Training average negative_sample_loss at step 247800: 0.107848
2025-12-13 04:56:56,700 INFO     Training average loss at step 247800: 0.388489
2025-12-13 04:56:58,815 INFO     Training average regularization at step 247900: 0.302021
2025-12-13 04:56:58,815 INFO     Training average positive_sample_loss at step 247900: 0.066094
2025-12-13 04:56:58,815 INFO     Training average negative_sample_loss at step 247900: 0.109135
2025-12-13 04:56:58,815 INFO     Training average loss at step 247900: 0.389635
2025-12-13 04:57:00,926 INFO     Training average regularization at step 248000: 0.302021
2025-12-13 04:57:00,926 INFO     Training average positive_sample_loss at step 248000: 0.067718
2025-12-13 04:57:00,926 INFO     Training average negative_sample_loss at step 248000: 0.109883
2025-12-13 04:57:00,927 INFO     Training average loss at step 248000: 0.390821
2025-12-13 04:57:03,015 INFO     Training average regularization at step 248100: 0.302021
2025-12-13 04:57:03,015 INFO     Training average positive_sample_loss at step 248100: 0.066455
2025-12-13 04:57:03,015 INFO     Training average negative_sample_loss at step 248100: 0.109927
2025-12-13 04:57:03,015 INFO     Training average loss at step 248100: 0.390212
2025-12-13 04:57:05,128 INFO     Training average regularization at step 248200: 0.302021
2025-12-13 04:57:05,128 INFO     Training average positive_sample_loss at step 248200: 0.067468
2025-12-13 04:57:05,128 INFO     Training average negative_sample_loss at step 248200: 0.107988
2025-12-13 04:57:05,128 INFO     Training average loss at step 248200: 0.389748
2025-12-13 04:57:07,228 INFO     Training average regularization at step 248300: 0.302021
2025-12-13 04:57:07,228 INFO     Training average positive_sample_loss at step 248300: 0.066653
2025-12-13 04:57:07,228 INFO     Training average negative_sample_loss at step 248300: 0.109312
2025-12-13 04:57:07,228 INFO     Training average loss at step 248300: 0.390003
2025-12-13 04:57:09,330 INFO     Training average regularization at step 248400: 0.302020
2025-12-13 04:57:09,331 INFO     Training average positive_sample_loss at step 248400: 0.067330
2025-12-13 04:57:09,331 INFO     Training average negative_sample_loss at step 248400: 0.109812
2025-12-13 04:57:09,331 INFO     Training average loss at step 248400: 0.390591
2025-12-13 04:57:11,431 INFO     Training average regularization at step 248500: 0.302020
2025-12-13 04:57:11,431 INFO     Training average positive_sample_loss at step 248500: 0.066826
2025-12-13 04:57:11,431 INFO     Training average negative_sample_loss at step 248500: 0.106221
2025-12-13 04:57:11,431 INFO     Training average loss at step 248500: 0.388544
2025-12-13 04:57:13,538 INFO     Training average regularization at step 248600: 0.302020
2025-12-13 04:57:13,538 INFO     Training average positive_sample_loss at step 248600: 0.066767
2025-12-13 04:57:13,538 INFO     Training average negative_sample_loss at step 248600: 0.107992
2025-12-13 04:57:13,538 INFO     Training average loss at step 248600: 0.389400
2025-12-13 04:57:15,688 INFO     Training average regularization at step 248700: 0.302020
2025-12-13 04:57:15,688 INFO     Training average positive_sample_loss at step 248700: 0.066920
2025-12-13 04:57:15,688 INFO     Training average negative_sample_loss at step 248700: 0.108356
2025-12-13 04:57:15,688 INFO     Training average loss at step 248700: 0.389658
2025-12-13 04:57:17,826 INFO     Training average regularization at step 248800: 0.302020
2025-12-13 04:57:17,827 INFO     Training average positive_sample_loss at step 248800: 0.066471
2025-12-13 04:57:17,827 INFO     Training average negative_sample_loss at step 248800: 0.106867
2025-12-13 04:57:17,827 INFO     Training average loss at step 248800: 0.388689
2025-12-13 04:57:19,973 INFO     Training average regularization at step 248900: 0.302020
2025-12-13 04:57:19,974 INFO     Training average positive_sample_loss at step 248900: 0.066769
2025-12-13 04:57:19,974 INFO     Training average negative_sample_loss at step 248900: 0.108789
2025-12-13 04:57:19,974 INFO     Training average loss at step 248900: 0.389799
2025-12-13 04:57:22,068 INFO     Training average regularization at step 249000: 0.302020
2025-12-13 04:57:22,068 INFO     Training average positive_sample_loss at step 249000: 0.065830
2025-12-13 04:57:22,068 INFO     Training average negative_sample_loss at step 249000: 0.110694
2025-12-13 04:57:22,068 INFO     Training average loss at step 249000: 0.390282
2025-12-13 04:57:24,158 INFO     Training average regularization at step 249100: 0.302020
2025-12-13 04:57:24,158 INFO     Training average positive_sample_loss at step 249100: 0.066612
2025-12-13 04:57:24,159 INFO     Training average negative_sample_loss at step 249100: 0.105801
2025-12-13 04:57:24,159 INFO     Training average loss at step 249100: 0.388227
2025-12-13 04:57:26,302 INFO     Training average regularization at step 249200: 0.302020
2025-12-13 04:57:26,303 INFO     Training average positive_sample_loss at step 249200: 0.066401
2025-12-13 04:57:26,303 INFO     Training average negative_sample_loss at step 249200: 0.107863
2025-12-13 04:57:26,303 INFO     Training average loss at step 249200: 0.389152
2025-12-13 04:57:28,413 INFO     Training average regularization at step 249300: 0.302020
2025-12-13 04:57:28,414 INFO     Training average positive_sample_loss at step 249300: 0.065847
2025-12-13 04:57:28,414 INFO     Training average negative_sample_loss at step 249300: 0.108106
2025-12-13 04:57:28,414 INFO     Training average loss at step 249300: 0.388997
2025-12-13 04:57:30,547 INFO     Training average regularization at step 249400: 0.302020
2025-12-13 04:57:30,547 INFO     Training average positive_sample_loss at step 249400: 0.067039
2025-12-13 04:57:30,547 INFO     Training average negative_sample_loss at step 249400: 0.107672
2025-12-13 04:57:30,547 INFO     Training average loss at step 249400: 0.389375
2025-12-13 04:57:32,653 INFO     Training average regularization at step 249500: 0.302020
2025-12-13 04:57:32,653 INFO     Training average positive_sample_loss at step 249500: 0.066025
2025-12-13 04:57:32,653 INFO     Training average negative_sample_loss at step 249500: 0.108573
2025-12-13 04:57:32,653 INFO     Training average loss at step 249500: 0.389319
2025-12-13 04:57:34,754 INFO     Training average regularization at step 249600: 0.302020
2025-12-13 04:57:34,754 INFO     Training average positive_sample_loss at step 249600: 0.065122
2025-12-13 04:57:34,754 INFO     Training average negative_sample_loss at step 249600: 0.107785
2025-12-13 04:57:34,754 INFO     Training average loss at step 249600: 0.388473
2025-12-13 04:57:36,947 INFO     Training average regularization at step 249700: 0.302020
2025-12-13 04:57:36,947 INFO     Training average positive_sample_loss at step 249700: 0.066673
2025-12-13 04:57:36,947 INFO     Training average negative_sample_loss at step 249700: 0.106446
2025-12-13 04:57:36,947 INFO     Training average loss at step 249700: 0.388579
2025-12-13 04:57:39,129 INFO     Training average regularization at step 249800: 0.302020
2025-12-13 04:57:39,134 INFO     Training average positive_sample_loss at step 249800: 0.067743
2025-12-13 04:57:39,134 INFO     Training average negative_sample_loss at step 249800: 0.110863
2025-12-13 04:57:39,134 INFO     Training average loss at step 249800: 0.391323
2025-12-13 04:57:41,366 INFO     Training average regularization at step 249900: 0.302019
2025-12-13 04:57:41,366 INFO     Training average positive_sample_loss at step 249900: 0.066989
2025-12-13 04:57:41,366 INFO     Training average negative_sample_loss at step 249900: 0.109991
2025-12-13 04:57:41,366 INFO     Training average loss at step 249900: 0.390510
2025-12-13 04:57:43,597 INFO     Training average regularization at step 250000: 0.302019
2025-12-13 04:57:43,597 INFO     Training average positive_sample_loss at step 250000: 0.067779
2025-12-13 04:57:43,597 INFO     Training average negative_sample_loss at step 250000: 0.106665
2025-12-13 04:57:43,597 INFO     Training average loss at step 250000: 0.389241
2025-12-13 04:57:43,597 INFO     Evaluating on Valid Dataset...
2025-12-13 04:57:44,282 INFO     Evaluating the model... (0/50000)
2025-12-13 04:57:46,933 INFO     Evaluating the model... (500/50000)
2025-12-13 04:57:49,726 INFO     Evaluating the model... (1000/50000)
2025-12-13 04:57:52,255 INFO     Evaluating the model... (1500/50000)
2025-12-13 04:57:54,870 INFO     Evaluating the model... (2000/50000)
2025-12-13 04:57:58,154 INFO     Evaluating the model... (2500/50000)
2025-12-13 04:58:00,741 INFO     Evaluating the model... (3000/50000)
2025-12-13 04:58:03,110 INFO     Evaluating the model... (3500/50000)
2025-12-13 04:58:05,699 INFO     Evaluating the model... (4000/50000)
2025-12-13 04:58:08,120 INFO     Evaluating the model... (4500/50000)
2025-12-13 04:58:11,209 INFO     Evaluating the model... (5000/50000)
2025-12-13 04:58:13,824 INFO     Evaluating the model... (5500/50000)
2025-12-13 04:58:16,353 INFO     Evaluating the model... (6000/50000)
2025-12-13 04:58:18,767 INFO     Evaluating the model... (6500/50000)
2025-12-13 04:58:21,123 INFO     Evaluating the model... (7000/50000)
2025-12-13 04:58:24,164 INFO     Evaluating the model... (7500/50000)
2025-12-13 04:58:26,743 INFO     Evaluating the model... (8000/50000)
2025-12-13 04:58:29,208 INFO     Evaluating the model... (8500/50000)
2025-12-13 04:58:31,598 INFO     Evaluating the model... (9000/50000)
2025-12-13 04:58:34,066 INFO     Evaluating the model... (9500/50000)
2025-12-13 04:58:37,123 INFO     Evaluating the model... (10000/50000)
2025-12-13 04:58:39,625 INFO     Evaluating the model... (10500/50000)
2025-12-13 04:58:42,334 INFO     Evaluating the model... (11000/50000)
2025-12-13 04:58:44,876 INFO     Evaluating the model... (11500/50000)
2025-12-13 04:58:47,843 INFO     Evaluating the model... (12000/50000)
2025-12-13 04:58:50,237 INFO     Evaluating the model... (12500/50000)
2025-12-13 04:58:52,630 INFO     Evaluating the model... (13000/50000)
2025-12-13 04:58:55,108 INFO     Evaluating the model... (13500/50000)
2025-12-13 04:58:57,721 INFO     Evaluating the model... (14000/50000)
2025-12-13 04:59:00,745 INFO     Evaluating the model... (14500/50000)
2025-12-13 04:59:03,038 INFO     Evaluating the model... (15000/50000)
2025-12-13 04:59:05,466 INFO     Evaluating the model... (15500/50000)
2025-12-13 04:59:07,977 INFO     Evaluating the model... (16000/50000)
2025-12-13 04:59:10,642 INFO     Evaluating the model... (16500/50000)
2025-12-13 04:59:13,931 INFO     Evaluating the model... (17000/50000)
2025-12-13 04:59:16,497 INFO     Evaluating the model... (17500/50000)
2025-12-13 04:59:19,014 INFO     Evaluating the model... (18000/50000)
2025-12-13 04:59:21,588 INFO     Evaluating the model... (18500/50000)
2025-12-13 04:59:24,073 INFO     Evaluating the model... (19000/50000)
2025-12-13 04:59:27,432 INFO     Evaluating the model... (19500/50000)
2025-12-13 04:59:29,804 INFO     Evaluating the model... (20000/50000)
2025-12-13 04:59:32,385 INFO     Evaluating the model... (20500/50000)
2025-12-13 04:59:35,003 INFO     Evaluating the model... (21000/50000)
2025-12-13 04:59:37,538 INFO     Evaluating the model... (21500/50000)
2025-12-13 04:59:41,155 INFO     Evaluating the model... (22000/50000)
2025-12-13 04:59:44,047 INFO     Evaluating the model... (22500/50000)
2025-12-13 04:59:46,743 INFO     Evaluating the model... (23000/50000)
2025-12-13 04:59:49,186 INFO     Evaluating the model... (23500/50000)
2025-12-13 04:59:51,640 INFO     Evaluating the model... (24000/50000)
2025-12-13 04:59:55,009 INFO     Evaluating the model... (24500/50000)
2025-12-13 04:59:58,016 INFO     Evaluating the model... (25000/50000)
2025-12-13 05:00:00,680 INFO     Evaluating the model... (25500/50000)
2025-12-13 05:00:03,258 INFO     Evaluating the model... (26000/50000)
2025-12-13 05:00:05,734 INFO     Evaluating the model... (26500/50000)
2025-12-13 05:00:09,234 INFO     Evaluating the model... (27000/50000)
2025-12-13 05:00:11,740 INFO     Evaluating the model... (27500/50000)
2025-12-13 05:00:14,292 INFO     Evaluating the model... (28000/50000)
2025-12-13 05:00:17,048 INFO     Evaluating the model... (28500/50000)
2025-12-13 05:00:19,777 INFO     Evaluating the model... (29000/50000)
2025-12-13 05:00:23,330 INFO     Evaluating the model... (29500/50000)
2025-12-13 05:00:25,880 INFO     Evaluating the model... (30000/50000)
2025-12-13 05:00:28,356 INFO     Evaluating the model... (30500/50000)
2025-12-13 05:00:31,042 INFO     Evaluating the model... (31000/50000)
2025-12-13 05:00:33,511 INFO     Evaluating the model... (31500/50000)
2025-12-13 05:00:37,074 INFO     Evaluating the model... (32000/50000)
2025-12-13 05:00:39,803 INFO     Evaluating the model... (32500/50000)
2025-12-13 05:00:42,781 INFO     Evaluating the model... (33000/50000)
2025-12-13 05:00:45,493 INFO     Evaluating the model... (33500/50000)
2025-12-13 05:00:48,001 INFO     Evaluating the model... (34000/50000)
2025-12-13 05:00:51,278 INFO     Evaluating the model... (34500/50000)
2025-12-13 05:00:54,003 INFO     Evaluating the model... (35000/50000)
2025-12-13 05:00:56,603 INFO     Evaluating the model... (35500/50000)
2025-12-13 05:00:59,217 INFO     Evaluating the model... (36000/50000)
2025-12-13 05:01:01,727 INFO     Evaluating the model... (36500/50000)
2025-12-13 05:01:05,352 INFO     Evaluating the model... (37000/50000)
2025-12-13 05:01:07,873 INFO     Evaluating the model... (37500/50000)
2025-12-13 05:01:10,389 INFO     Evaluating the model... (38000/50000)
2025-12-13 05:01:12,795 INFO     Evaluating the model... (38500/50000)
2025-12-13 05:01:15,932 INFO     Evaluating the model... (39000/50000)
2025-12-13 05:01:18,467 INFO     Evaluating the model... (39500/50000)
2025-12-13 05:01:20,925 INFO     Evaluating the model... (40000/50000)
2025-12-13 05:01:23,501 INFO     Evaluating the model... (40500/50000)
2025-12-13 05:01:26,059 INFO     Evaluating the model... (41000/50000)
2025-12-13 05:01:29,182 INFO     Evaluating the model... (41500/50000)
2025-12-13 05:01:31,589 INFO     Evaluating the model... (42000/50000)
2025-12-13 05:01:34,084 INFO     Evaluating the model... (42500/50000)
2025-12-13 05:01:36,680 INFO     Evaluating the model... (43000/50000)
2025-12-13 05:01:39,538 INFO     Evaluating the model... (43500/50000)
2025-12-13 05:01:42,983 INFO     Evaluating the model... (44000/50000)
2025-12-13 05:01:45,624 INFO     Evaluating the model... (44500/50000)
2025-12-13 05:01:48,204 INFO     Evaluating the model... (45000/50000)
2025-12-13 05:01:50,894 INFO     Evaluating the model... (45500/50000)
2025-12-13 05:01:53,434 INFO     Evaluating the model... (46000/50000)
2025-12-13 05:01:56,696 INFO     Evaluating the model... (46500/50000)
2025-12-13 05:01:59,141 INFO     Evaluating the model... (47000/50000)
2025-12-13 05:02:01,747 INFO     Evaluating the model... (47500/50000)
2025-12-13 05:02:04,642 INFO     Evaluating the model... (48000/50000)
2025-12-13 05:02:07,153 INFO     Evaluating the model... (48500/50000)
2025-12-13 05:02:10,591 INFO     Evaluating the model... (49000/50000)
2025-12-13 05:02:13,201 INFO     Evaluating the model... (49500/50000)
2025-12-13 05:02:16,153 INFO     Valid MRR at step 250000: 0.633471
2025-12-13 05:02:16,153 INFO     Valid MR at step 250000: 266.935880
2025-12-13 05:02:16,153 INFO     Valid HITS@1 at step 250000: 0.547970
2025-12-13 05:02:16,153 INFO     Valid HITS@3 at step 250000: 0.686180
2025-12-13 05:02:16,153 INFO     Valid HITS@10 at step 250000: 0.784810
2025-12-13 05:02:17,964 INFO     Evaluating on Test Dataset...
2025-12-13 05:02:18,482 INFO     Evaluating the model... (0/59072)
2025-12-13 05:02:21,008 INFO     Evaluating the model... (500/59072)
2025-12-13 05:02:23,519 INFO     Evaluating the model... (1000/59072)
2025-12-13 05:02:26,923 INFO     Evaluating the model... (1500/59072)
2025-12-13 05:02:29,406 INFO     Evaluating the model... (2000/59072)
2025-12-13 05:02:31,952 INFO     Evaluating the model... (2500/59072)
2025-12-13 05:02:34,388 INFO     Evaluating the model... (3000/59072)
2025-12-13 05:02:37,284 INFO     Evaluating the model... (3500/59072)
2025-12-13 05:02:40,990 INFO     Evaluating the model... (4000/59072)
2025-12-13 05:02:43,562 INFO     Evaluating the model... (4500/59072)
2025-12-13 05:02:46,063 INFO     Evaluating the model... (5000/59072)
2025-12-13 05:02:48,748 INFO     Evaluating the model... (5500/59072)
2025-12-13 05:02:51,275 INFO     Evaluating the model... (6000/59072)
2025-12-13 05:02:54,596 INFO     Evaluating the model... (6500/59072)
2025-12-13 05:02:57,053 INFO     Evaluating the model... (7000/59072)
2025-12-13 05:02:59,622 INFO     Evaluating the model... (7500/59072)
2025-12-13 05:03:02,271 INFO     Evaluating the model... (8000/59072)
2025-12-13 05:03:04,664 INFO     Evaluating the model... (8500/59072)
2025-12-13 05:03:07,762 INFO     Evaluating the model... (9000/59072)
2025-12-13 05:03:10,224 INFO     Evaluating the model... (9500/59072)
2025-12-13 05:03:12,900 INFO     Evaluating the model... (10000/59072)
2025-12-13 05:03:15,350 INFO     Evaluating the model... (10500/59072)
2025-12-13 05:03:17,778 INFO     Evaluating the model... (11000/59072)
2025-12-13 05:03:20,935 INFO     Evaluating the model... (11500/59072)
2025-12-13 05:03:23,475 INFO     Evaluating the model... (12000/59072)
2025-12-13 05:03:26,029 INFO     Evaluating the model... (12500/59072)
2025-12-13 05:03:28,530 INFO     Evaluating the model... (13000/59072)
2025-12-13 05:03:30,918 INFO     Evaluating the model... (13500/59072)
2025-12-13 05:03:33,985 INFO     Evaluating the model... (14000/59072)
2025-12-13 05:03:36,881 INFO     Evaluating the model... (14500/59072)
2025-12-13 05:03:39,573 INFO     Evaluating the model... (15000/59072)
2025-12-13 05:03:42,111 INFO     Evaluating the model... (15500/59072)
2025-12-13 05:03:45,733 INFO     Evaluating the model... (16000/59072)
2025-12-13 05:03:48,244 INFO     Evaluating the model... (16500/59072)
2025-12-13 05:03:50,605 INFO     Evaluating the model... (17000/59072)
2025-12-13 05:03:53,117 INFO     Evaluating the model... (17500/59072)
2025-12-13 05:03:55,475 INFO     Evaluating the model... (18000/59072)
2025-12-13 05:03:59,076 INFO     Evaluating the model... (18500/59072)
2025-12-13 05:04:01,575 INFO     Evaluating the model... (19000/59072)
2025-12-13 05:04:04,044 INFO     Evaluating the model... (19500/59072)
2025-12-13 05:04:06,517 INFO     Evaluating the model... (20000/59072)
2025-12-13 05:04:09,075 INFO     Evaluating the model... (20500/59072)
2025-12-13 05:04:12,450 INFO     Evaluating the model... (21000/59072)
2025-12-13 05:04:14,871 INFO     Evaluating the model... (21500/59072)
2025-12-13 05:04:17,312 INFO     Evaluating the model... (22000/59072)
2025-12-13 05:04:19,754 INFO     Evaluating the model... (22500/59072)
2025-12-13 05:04:22,373 INFO     Evaluating the model... (23000/59072)
2025-12-13 05:04:25,752 INFO     Evaluating the model... (23500/59072)
2025-12-13 05:04:28,221 INFO     Evaluating the model... (24000/59072)
2025-12-13 05:04:30,715 INFO     Evaluating the model... (24500/59072)
2025-12-13 05:04:33,372 INFO     Evaluating the model... (25000/59072)
2025-12-13 05:04:35,909 INFO     Evaluating the model... (25500/59072)
2025-12-13 05:04:39,988 INFO     Evaluating the model... (26000/59072)
2025-12-13 05:04:42,662 INFO     Evaluating the model... (26500/59072)
2025-12-13 05:04:45,568 INFO     Evaluating the model... (27000/59072)
2025-12-13 05:04:48,009 INFO     Evaluating the model... (27500/59072)
2025-12-13 05:04:50,433 INFO     Evaluating the model... (28000/59072)
2025-12-13 05:04:54,022 INFO     Evaluating the model... (28500/59072)
2025-12-13 05:04:56,794 INFO     Evaluating the model... (29000/59072)
2025-12-13 05:04:59,238 INFO     Evaluating the model... (29500/59072)
2025-12-13 05:05:02,198 INFO     Evaluating the model... (30000/59072)
2025-12-13 05:05:05,715 INFO     Evaluating the model... (30500/59072)
2025-12-13 05:05:08,391 INFO     Evaluating the model... (31000/59072)
2025-12-13 05:05:10,868 INFO     Evaluating the model... (31500/59072)
2025-12-13 05:05:13,304 INFO     Evaluating the model... (32000/59072)
2025-12-13 05:05:15,780 INFO     Evaluating the model... (32500/59072)
2025-12-13 05:05:19,148 INFO     Evaluating the model... (33000/59072)
2025-12-13 05:05:21,643 INFO     Evaluating the model... (33500/59072)
2025-12-13 05:05:24,124 INFO     Evaluating the model... (34000/59072)
2025-12-13 05:05:26,724 INFO     Evaluating the model... (34500/59072)
2025-12-13 05:05:29,268 INFO     Evaluating the model... (35000/59072)
2025-12-13 05:05:32,871 INFO     Evaluating the model... (35500/59072)
2025-12-13 05:05:35,410 INFO     Evaluating the model... (36000/59072)
2025-12-13 05:05:38,258 INFO     Evaluating the model... (36500/59072)
2025-12-13 05:05:41,020 INFO     Evaluating the model... (37000/59072)
2025-12-13 05:05:43,840 INFO     Evaluating the model... (37500/59072)
2025-12-13 05:05:47,359 INFO     Evaluating the model... (38000/59072)
2025-12-13 05:05:49,929 INFO     Evaluating the model... (38500/59072)
2025-12-13 05:05:52,477 INFO     Evaluating the model... (39000/59072)
2025-12-13 05:05:55,249 INFO     Evaluating the model... (39500/59072)
2025-12-13 05:05:57,766 INFO     Evaluating the model... (40000/59072)
2025-12-13 05:06:01,076 INFO     Evaluating the model... (40500/59072)
2025-12-13 05:06:03,702 INFO     Evaluating the model... (41000/59072)
2025-12-13 05:06:06,465 INFO     Evaluating the model... (41500/59072)
2025-12-13 05:06:09,006 INFO     Evaluating the model... (42000/59072)
2025-12-13 05:06:11,439 INFO     Evaluating the model... (42500/59072)
2025-12-13 05:06:14,577 INFO     Evaluating the model... (43000/59072)
2025-12-13 05:06:17,318 INFO     Evaluating the model... (43500/59072)
2025-12-13 05:06:19,790 INFO     Evaluating the model... (44000/59072)
2025-12-13 05:06:22,245 INFO     Evaluating the model... (44500/59072)
2025-12-13 05:06:24,706 INFO     Evaluating the model... (45000/59072)
2025-12-13 05:06:28,470 INFO     Evaluating the model... (45500/59072)
2025-12-13 05:06:30,912 INFO     Evaluating the model... (46000/59072)
2025-12-13 05:06:33,360 INFO     Evaluating the model... (46500/59072)
2025-12-13 05:06:35,973 INFO     Evaluating the model... (47000/59072)
2025-12-13 05:06:39,419 INFO     Evaluating the model... (47500/59072)
2025-12-13 05:06:42,318 INFO     Evaluating the model... (48000/59072)
2025-12-13 05:06:45,109 INFO     Evaluating the model... (48500/59072)
2025-12-13 05:06:47,803 INFO     Evaluating the model... (49000/59072)
2025-12-13 05:06:50,379 INFO     Evaluating the model... (49500/59072)
2025-12-13 05:06:53,952 INFO     Evaluating the model... (50000/59072)
2025-12-13 05:06:56,451 INFO     Evaluating the model... (50500/59072)
2025-12-13 05:06:58,984 INFO     Evaluating the model... (51000/59072)
2025-12-13 05:07:01,441 INFO     Evaluating the model... (51500/59072)
2025-12-13 05:07:04,078 INFO     Evaluating the model... (52000/59072)
2025-12-13 05:07:07,471 INFO     Evaluating the model... (52500/59072)
2025-12-13 05:07:09,914 INFO     Evaluating the model... (53000/59072)
2025-12-13 05:07:12,289 INFO     Evaluating the model... (53500/59072)
2025-12-13 05:07:14,883 INFO     Evaluating the model... (54000/59072)
2025-12-13 05:07:17,383 INFO     Evaluating the model... (54500/59072)
2025-12-13 05:07:21,010 INFO     Evaluating the model... (55000/59072)
2025-12-13 05:07:23,528 INFO     Evaluating the model... (55500/59072)
2025-12-13 05:07:26,290 INFO     Evaluating the model... (56000/59072)
2025-12-13 05:07:28,637 INFO     Evaluating the model... (56500/59072)
2025-12-13 05:07:31,151 INFO     Evaluating the model... (57000/59072)
2025-12-13 05:07:34,653 INFO     Evaluating the model... (57500/59072)
2025-12-13 05:07:37,652 INFO     Evaluating the model... (58000/59072)
2025-12-13 05:07:40,309 INFO     Evaluating the model... (58500/59072)
2025-12-13 05:07:42,951 INFO     Evaluating the model... (59000/59072)
2025-12-13 05:07:43,581 INFO     Test MRR at step 250000: 0.630208
2025-12-13 05:07:43,581 INFO     Test MR at step 250000: 268.914078
2025-12-13 05:07:43,581 INFO     Test HITS@1 at step 250000: 0.543126
2025-12-13 05:07:43,581 INFO     Test HITS@3 at step 250000: 0.684515
2025-12-13 05:07:43,581 INFO     Test HITS@10 at step 250000: 0.782990
2025-12-13 05:07:44,944 INFO     Evaluating on Valid Dataset with Best Model...
2025-12-13 05:07:45,689 INFO     Evaluating the model... (0/50000)
2025-12-13 05:07:49,199 INFO     Evaluating the model... (500/50000)
2025-12-13 05:07:51,781 INFO     Evaluating the model... (1000/50000)
2025-12-13 05:07:54,196 INFO     Evaluating the model... (1500/50000)
2025-12-13 05:07:56,801 INFO     Evaluating the model... (2000/50000)
2025-12-13 05:07:59,337 INFO     Evaluating the model... (2500/50000)
2025-12-13 05:08:02,464 INFO     Evaluating the model... (3000/50000)
2025-12-13 05:08:04,983 INFO     Evaluating the model... (3500/50000)
2025-12-13 05:08:07,455 INFO     Evaluating the model... (4000/50000)
2025-12-13 05:08:09,895 INFO     Evaluating the model... (4500/50000)
2025-12-13 05:08:12,638 INFO     Evaluating the model... (5000/50000)
2025-12-13 05:08:15,748 INFO     Evaluating the model... (5500/50000)
2025-12-13 05:08:18,407 INFO     Evaluating the model... (6000/50000)
2025-12-13 05:08:20,840 INFO     Evaluating the model... (6500/50000)
2025-12-13 05:08:23,549 INFO     Evaluating the model... (7000/50000)
2025-12-13 05:08:26,121 INFO     Evaluating the model... (7500/50000)
2025-12-13 05:08:29,185 INFO     Evaluating the model... (8000/50000)
2025-12-13 05:08:31,587 INFO     Evaluating the model... (8500/50000)
2025-12-13 05:08:34,169 INFO     Evaluating the model... (9000/50000)
2025-12-13 05:08:36,828 INFO     Evaluating the model... (9500/50000)
2025-12-13 05:08:39,466 INFO     Evaluating the model... (10000/50000)
2025-12-13 05:08:43,100 INFO     Evaluating the model... (10500/50000)
2025-12-13 05:08:45,943 INFO     Evaluating the model... (11000/50000)
2025-12-13 05:08:48,574 INFO     Evaluating the model... (11500/50000)
2025-12-13 05:08:51,038 INFO     Evaluating the model... (12000/50000)
2025-12-13 05:08:53,581 INFO     Evaluating the model... (12500/50000)
2025-12-13 05:08:56,965 INFO     Evaluating the model... (13000/50000)
2025-12-13 05:08:59,575 INFO     Evaluating the model... (13500/50000)
2025-12-13 05:09:01,985 INFO     Evaluating the model... (14000/50000)
2025-12-13 05:09:04,387 INFO     Evaluating the model... (14500/50000)
2025-12-13 05:09:06,779 INFO     Evaluating the model... (15000/50000)
2025-12-13 05:09:10,285 INFO     Evaluating the model... (15500/50000)
2025-12-13 05:09:12,745 INFO     Evaluating the model... (16000/50000)
2025-12-13 05:09:15,228 INFO     Evaluating the model... (16500/50000)
2025-12-13 05:09:17,682 INFO     Evaluating the model... (17000/50000)
2025-12-13 05:09:21,363 INFO     Evaluating the model... (17500/50000)
2025-12-13 05:09:23,804 INFO     Evaluating the model... (18000/50000)
2025-12-13 05:09:26,369 INFO     Evaluating the model... (18500/50000)
2025-12-13 05:09:28,810 INFO     Evaluating the model... (19000/50000)
2025-12-13 05:09:31,432 INFO     Evaluating the model... (19500/50000)
2025-12-13 05:09:35,680 INFO     Evaluating the model... (20000/50000)
2025-12-13 05:09:38,282 INFO     Evaluating the model... (20500/50000)
2025-12-13 05:09:40,843 INFO     Evaluating the model... (21000/50000)
2025-12-13 05:09:43,615 INFO     Evaluating the model... (21500/50000)
2025-12-13 05:09:46,334 INFO     Evaluating the model... (22000/50000)
2025-12-13 05:09:50,286 INFO     Evaluating the model... (22500/50000)
2025-12-13 05:09:52,750 INFO     Evaluating the model... (23000/50000)
2025-12-13 05:09:55,425 INFO     Evaluating the model... (23500/50000)
2025-12-13 05:09:57,937 INFO     Evaluating the model... (24000/50000)
2025-12-13 05:10:00,383 INFO     Evaluating the model... (24500/50000)
2025-12-13 05:10:04,824 INFO     Evaluating the model... (25000/50000)
2025-12-13 05:10:07,614 INFO     Evaluating the model... (25500/50000)
2025-12-13 05:10:10,180 INFO     Evaluating the model... (26000/50000)
2025-12-13 05:10:12,629 INFO     Evaluating the model... (26500/50000)
2025-12-13 05:10:15,545 INFO     Evaluating the model... (27000/50000)
2025-12-13 05:10:18,829 INFO     Evaluating the model... (27500/50000)
2025-12-13 05:10:21,298 INFO     Evaluating the model... (28000/50000)
2025-12-13 05:10:23,960 INFO     Evaluating the model... (28500/50000)
2025-12-13 05:10:26,440 INFO     Evaluating the model... (29000/50000)
2025-12-13 05:10:29,088 INFO     Evaluating the model... (29500/50000)
2025-12-13 05:10:32,445 INFO     Evaluating the model... (30000/50000)
2025-12-13 05:10:35,050 INFO     Evaluating the model... (30500/50000)
2025-12-13 05:10:37,746 INFO     Evaluating the model... (31000/50000)
2025-12-13 05:10:40,446 INFO     Evaluating the model... (31500/50000)
2025-12-13 05:10:43,363 INFO     Evaluating the model... (32000/50000)
2025-12-13 05:10:46,939 INFO     Evaluating the model... (32500/50000)
2025-12-13 05:10:49,447 INFO     Evaluating the model... (33000/50000)
2025-12-13 05:10:51,934 INFO     Evaluating the model... (33500/50000)
2025-12-13 05:10:54,675 INFO     Evaluating the model... (34000/50000)
2025-12-13 05:10:57,283 INFO     Evaluating the model... (34500/50000)
2025-12-13 05:11:00,793 INFO     Evaluating the model... (35000/50000)
2025-12-13 05:11:03,186 INFO     Evaluating the model... (35500/50000)
2025-12-13 05:11:05,873 INFO     Evaluating the model... (36000/50000)
2025-12-13 05:11:08,314 INFO     Evaluating the model... (36500/50000)
2025-12-13 05:11:10,877 INFO     Evaluating the model... (37000/50000)
2025-12-13 05:11:14,644 INFO     Evaluating the model... (37500/50000)
2025-12-13 05:11:17,485 INFO     Evaluating the model... (38000/50000)
2025-12-13 05:11:19,992 INFO     Evaluating the model... (38500/50000)
2025-12-13 05:11:22,439 INFO     Evaluating the model... (39000/50000)
2025-12-13 05:11:24,953 INFO     Evaluating the model... (39500/50000)
2025-12-13 05:11:29,056 INFO     Evaluating the model... (40000/50000)
2025-12-13 05:11:31,539 INFO     Evaluating the model... (40500/50000)
2025-12-13 05:11:33,964 INFO     Evaluating the model... (41000/50000)
2025-12-13 05:11:36,739 INFO     Evaluating the model... (41500/50000)
2025-12-13 05:11:39,694 INFO     Evaluating the model... (42000/50000)
2025-12-13 05:11:43,650 INFO     Evaluating the model... (42500/50000)
2025-12-13 05:11:46,306 INFO     Evaluating the model... (43000/50000)
2025-12-13 05:11:48,770 INFO     Evaluating the model... (43500/50000)
2025-12-13 05:11:51,434 INFO     Evaluating the model... (44000/50000)
2025-12-13 05:11:54,321 INFO     Evaluating the model... (44500/50000)
2025-12-13 05:11:57,526 INFO     Evaluating the model... (45000/50000)
2025-12-13 05:11:59,962 INFO     Evaluating the model... (45500/50000)
2025-12-13 05:12:02,654 INFO     Evaluating the model... (46000/50000)
2025-12-13 05:12:05,153 INFO     Evaluating the model... (46500/50000)
2025-12-13 05:12:09,062 INFO     Evaluating the model... (47000/50000)
2025-12-13 05:12:11,691 INFO     Evaluating the model... (47500/50000)
2025-12-13 05:12:14,432 INFO     Evaluating the model... (48000/50000)
2025-12-13 05:12:17,010 INFO     Evaluating the model... (48500/50000)
2025-12-13 05:12:19,522 INFO     Evaluating the model... (49000/50000)
2025-12-13 05:12:23,562 INFO     Evaluating the model... (49500/50000)
2025-12-13 05:12:26,510 INFO     Valid MRR at step 250000: 0.633471
2025-12-13 05:12:26,510 INFO     Valid MR at step 250000: 266.935880
2025-12-13 05:12:26,510 INFO     Valid HITS@1 at step 250000: 0.547970
2025-12-13 05:12:26,510 INFO     Valid HITS@3 at step 250000: 0.686180
2025-12-13 05:12:26,510 INFO     Valid HITS@10 at step 250000: 0.784810
2025-12-13 05:12:26,510 INFO     Evaluating on Test Dataset with Best Model...
2025-12-13 05:12:27,241 INFO     Evaluating the model... (0/59072)
2025-12-13 05:12:29,877 INFO     Evaluating the model... (500/59072)
2025-12-13 05:12:32,411 INFO     Evaluating the model... (1000/59072)
2025-12-13 05:12:34,882 INFO     Evaluating the model... (1500/59072)
2025-12-13 05:12:37,773 INFO     Evaluating the model... (2000/59072)
2025-12-13 05:12:41,409 INFO     Evaluating the model... (2500/59072)
2025-12-13 05:12:44,034 INFO     Evaluating the model... (3000/59072)
2025-12-13 05:12:46,575 INFO     Evaluating the model... (3500/59072)
2025-12-13 05:12:49,337 INFO     Evaluating the model... (4000/59072)
2025-12-13 05:12:51,770 INFO     Evaluating the model... (4500/59072)
2025-12-13 05:12:54,812 INFO     Evaluating the model... (5000/59072)
2025-12-13 05:12:57,316 INFO     Evaluating the model... (5500/59072)
2025-12-13 05:12:59,924 INFO     Evaluating the model... (6000/59072)
2025-12-13 05:13:02,503 INFO     Evaluating the model... (6500/59072)
2025-12-13 05:13:05,682 INFO     Evaluating the model... (7000/59072)
2025-12-13 05:13:08,228 INFO     Evaluating the model... (7500/59072)
2025-12-13 05:13:10,654 INFO     Evaluating the model... (8000/59072)
2025-12-13 05:13:13,137 INFO     Evaluating the model... (8500/59072)
2025-12-13 05:13:15,539 INFO     Evaluating the model... (9000/59072)
2025-12-13 05:13:18,832 INFO     Evaluating the model... (9500/59072)
2025-12-13 05:13:21,245 INFO     Evaluating the model... (10000/59072)
2025-12-13 05:13:23,815 INFO     Evaluating the model... (10500/59072)
2025-12-13 05:13:26,313 INFO     Evaluating the model... (11000/59072)
2025-12-13 05:13:28,704 INFO     Evaluating the model... (11500/59072)
2025-12-13 05:13:32,063 INFO     Evaluating the model... (12000/59072)
2025-12-13 05:13:34,618 INFO     Evaluating the model... (12500/59072)
2025-12-13 05:13:37,346 INFO     Evaluating the model... (13000/59072)
2025-12-13 05:13:39,937 INFO     Evaluating the model... (13500/59072)
2025-12-13 05:13:42,557 INFO     Evaluating the model... (14000/59072)
2025-12-13 05:13:46,316 INFO     Evaluating the model... (14500/59072)
2025-12-13 05:13:48,762 INFO     Evaluating the model... (15000/59072)
2025-12-13 05:13:51,154 INFO     Evaluating the model... (15500/59072)
2025-12-13 05:13:53,640 INFO     Evaluating the model... (16000/59072)
2025-12-13 05:13:56,209 INFO     Evaluating the model... (16500/59072)
2025-12-13 05:13:59,720 INFO     Evaluating the model... (17000/59072)
2025-12-13 05:14:02,151 INFO     Evaluating the model... (17500/59072)
2025-12-13 05:14:04,557 INFO     Evaluating the model... (18000/59072)
2025-12-13 05:14:07,031 INFO     Evaluating the model... (18500/59072)
2025-12-13 05:14:09,691 INFO     Evaluating the model... (19000/59072)
2025-12-13 05:14:13,103 INFO     Evaluating the model... (19500/59072)
2025-12-13 05:14:15,501 INFO     Evaluating the model... (20000/59072)
2025-12-13 05:14:18,024 INFO     Evaluating the model... (20500/59072)
2025-12-13 05:14:20,495 INFO     Evaluating the model... (21000/59072)
2025-12-13 05:14:23,005 INFO     Evaluating the model... (21500/59072)
2025-12-13 05:14:26,615 INFO     Evaluating the model... (22000/59072)
2025-12-13 05:14:29,073 INFO     Evaluating the model... (22500/59072)
2025-12-13 05:14:31,666 INFO     Evaluating the model... (23000/59072)
2025-12-13 05:14:34,232 INFO     Evaluating the model... (23500/59072)
2025-12-13 05:14:36,876 INFO     Evaluating the model... (24000/59072)
2025-12-13 05:14:40,490 INFO     Evaluating the model... (24500/59072)
2025-12-13 05:14:43,210 INFO     Evaluating the model... (25000/59072)
2025-12-13 05:14:45,975 INFO     Evaluating the model... (25500/59072)
2025-12-13 05:14:48,488 INFO     Evaluating the model... (26000/59072)
2025-12-13 05:14:52,338 INFO     Evaluating the model... (26500/59072)
2025-12-13 05:14:54,968 INFO     Evaluating the model... (27000/59072)
2025-12-13 05:14:57,615 INFO     Evaluating the model... (27500/59072)
2025-12-13 05:14:59,950 INFO     Evaluating the model... (28000/59072)
2025-12-13 05:15:02,442 INFO     Evaluating the model... (28500/59072)
2025-12-13 05:15:06,032 INFO     Evaluating the model... (29000/59072)
2025-12-13 05:15:08,799 INFO     Evaluating the model... (29500/59072)
2025-12-13 05:15:11,672 INFO     Evaluating the model... (30000/59072)
2025-12-13 05:15:14,234 INFO     Evaluating the model... (30500/59072)
2025-12-13 05:15:16,684 INFO     Evaluating the model... (31000/59072)
2025-12-13 05:15:20,460 INFO     Evaluating the model... (31500/59072)
2025-12-13 05:15:22,995 INFO     Evaluating the model... (32000/59072)
2025-12-13 05:15:25,462 INFO     Evaluating the model... (32500/59072)
2025-12-13 05:15:28,027 INFO     Evaluating the model... (33000/59072)
2025-12-13 05:15:30,778 INFO     Evaluating the model... (33500/59072)
2025-12-13 05:15:34,286 INFO     Evaluating the model... (34000/59072)
2025-12-13 05:15:36,990 INFO     Evaluating the model... (34500/59072)
2025-12-13 05:15:39,663 INFO     Evaluating the model... (35000/59072)
2025-12-13 05:15:42,646 INFO     Evaluating the model... (35500/59072)
2025-12-13 05:15:46,274 INFO     Evaluating the model... (36000/59072)
2025-12-13 05:15:48,741 INFO     Evaluating the model... (36500/59072)
2025-12-13 05:15:51,240 INFO     Evaluating the model... (37000/59072)
2025-12-13 05:15:53,940 INFO     Evaluating the model... (37500/59072)
2025-12-13 05:15:56,521 INFO     Evaluating the model... (38000/59072)
2025-12-13 05:15:59,822 INFO     Evaluating the model... (38500/59072)
2025-12-13 05:16:02,244 INFO     Evaluating the model... (39000/59072)
2025-12-13 05:16:04,894 INFO     Evaluating the model... (39500/59072)
2025-12-13 05:16:07,415 INFO     Evaluating the model... (40000/59072)
2025-12-13 05:16:09,932 INFO     Evaluating the model... (40500/59072)
2025-12-13 05:16:13,364 INFO     Evaluating the model... (41000/59072)
2025-12-13 05:16:15,973 INFO     Evaluating the model... (41500/59072)
2025-12-13 05:16:18,431 INFO     Evaluating the model... (42000/59072)
2025-12-13 05:16:20,886 INFO     Evaluating the model... (42500/59072)
2025-12-13 05:16:23,431 INFO     Evaluating the model... (43000/59072)
2025-12-13 05:16:27,190 INFO     Evaluating the model... (43500/59072)
2025-12-13 05:16:29,811 INFO     Evaluating the model... (44000/59072)
2025-12-13 05:16:32,262 INFO     Evaluating the model... (44500/59072)
2025-12-13 05:16:34,697 INFO     Evaluating the model... (45000/59072)
2025-12-13 05:16:37,466 INFO     Evaluating the model... (45500/59072)
2025-12-13 05:16:41,532 INFO     Evaluating the model... (46000/59072)
2025-12-13 05:16:44,373 INFO     Evaluating the model... (46500/59072)
2025-12-13 05:16:47,079 INFO     Evaluating the model... (47000/59072)
2025-12-13 05:16:49,548 INFO     Evaluating the model... (47500/59072)
2025-12-13 05:16:52,268 INFO     Evaluating the model... (48000/59072)
2025-12-13 05:16:55,832 INFO     Evaluating the model... (48500/59072)
2025-12-13 05:16:58,268 INFO     Evaluating the model... (49000/59072)
2025-12-13 05:17:00,748 INFO     Evaluating the model... (49500/59072)
2025-12-13 05:17:03,374 INFO     Evaluating the model... (50000/59072)
2025-12-13 05:17:05,891 INFO     Evaluating the model... (50500/59072)
2025-12-13 05:17:09,216 INFO     Evaluating the model... (51000/59072)
2025-12-13 05:17:11,686 INFO     Evaluating the model... (51500/59072)
2025-12-13 05:17:14,348 INFO     Evaluating the model... (52000/59072)
2025-12-13 05:17:16,911 INFO     Evaluating the model... (52500/59072)
2025-12-13 05:17:19,338 INFO     Evaluating the model... (53000/59072)
2025-12-13 05:17:22,749 INFO     Evaluating the model... (53500/59072)
2025-12-13 05:17:25,543 INFO     Evaluating the model... (54000/59072)
2025-12-13 05:17:28,010 INFO     Evaluating the model... (54500/59072)
2025-12-13 05:17:30,586 INFO     Evaluating the model... (55000/59072)
2025-12-13 05:17:33,791 INFO     Evaluating the model... (55500/59072)
2025-12-13 05:17:36,768 INFO     Evaluating the model... (56000/59072)
2025-12-13 05:17:39,532 INFO     Evaluating the model... (56500/59072)
2025-12-13 05:17:42,179 INFO     Evaluating the model... (57000/59072)
2025-12-13 05:17:44,849 INFO     Evaluating the model... (57500/59072)
2025-12-13 05:17:48,750 INFO     Evaluating the model... (58000/59072)
2025-12-13 05:17:51,192 INFO     Evaluating the model... (58500/59072)
2025-12-13 05:17:53,632 INFO     Evaluating the model... (59000/59072)
2025-12-13 05:17:54,300 INFO     Test MRR at step 250000: 0.630208
2025-12-13 05:17:54,300 INFO     Test MR at step 250000: 268.914078
2025-12-13 05:17:54,300 INFO     Test HITS@1 at step 250000: 0.543126
2025-12-13 05:17:54,300 INFO     Test HITS@3 at step 250000: 0.684515
2025-12-13 05:17:54,300 INFO     Test HITS@10 at step 250000: 0.782990
