2025-12-13 11:09:51,742 INFO     Parameters: Namespace(cuda='True', seed=10, do_train='True', do_valid='True', do_test='True', evaluate_train=False, countries=False, regions=None, data_path='/home/25171213997/ITI/data/FB15k/', model='ITI_DistMult', double_entity_embedding=False, double_relation_embedding=False, negative_sample_size=300, hidden_dim=1000, house_dim=2, house_num=2, housd_num=2, types_num=2, thred=0.7, gamma=26.0, negative_adversarial_sampling=True, adversarial_temperature=1.16010547465235, batch_size=200, regularization=0.0881968094660471, ent_reg=0.0, rel_reg=0.0, test_batch_size=2, uni_weight=False, learning_rate=0.00258708538141072, cpu_num=10, init_checkpoint=None, save_path='/home/25171213997/ITI/FB15k/ITI_DistMult/', max_steps=250000, warm_up_steps=20000, save_checkpoint_steps=20000, valid_steps=10000, log_steps=100, test_log_steps=500, nentity=14951, nrelation=1345)
2025-12-13 11:09:51,742 INFO     Model: ITI_DistMult
2025-12-13 11:09:51,742 INFO     Data Path: /home/25171213997/ITI/data/FB15k/
2025-12-13 11:09:51,742 INFO     #entity: 14951
2025-12-13 11:09:51,742 INFO     #relation: 1345
2025-12-13 11:09:52,359 INFO     #train: 483142
2025-12-13 11:09:52,454 INFO     #valid: 50000
2025-12-13 11:09:52,546 INFO     #test: 59071
2025-12-13 11:09:52,981 INFO     Model Parameter Configuration:
2025-12-13 11:09:52,981 INFO     Parameter gamma: torch.Size([1]), require_grad = False
2025-12-13 11:09:52,981 INFO     Parameter embedding_range: torch.Size([1]), require_grad = False
2025-12-13 11:09:52,981 INFO     Parameter entity_embedding: torch.Size([14951, 500, 2]), require_grad = True
2025-12-13 11:09:52,981 INFO     Parameter head_type_vec: torch.Size([14951]), require_grad = False
2025-12-13 11:09:52,981 INFO     Parameter head_type_mat: torch.Size([571, 500, 2]), require_grad = True
2025-12-13 11:09:52,982 INFO     Parameter tail_type_mat: torch.Size([571, 500, 2]), require_grad = True
2025-12-13 11:09:52,982 INFO     Parameter relation_embedding: torch.Size([1345, 500, 4]), require_grad = True
2025-12-13 11:09:52,982 INFO     Parameter r1_dir_head: torch.Size([571, 1, 1]), require_grad = True
2025-12-13 11:09:52,982 INFO     Parameter r2_dir_tail: torch.Size([571, 1, 1]), require_grad = True
2025-12-13 11:09:52,982 INFO     Parameter r1_scale_head: torch.Size([571, 500, 1]), require_grad = True
2025-12-13 11:09:52,982 INFO     Parameter r2_scale_tail: torch.Size([571, 500, 1]), require_grad = True
2025-12-13 11:09:52,982 INFO     Parameter k_dir_head: torch.Size([1345, 1, 2]), require_grad = True
2025-12-13 11:09:52,982 INFO     Parameter k_dir_tail: torch.Size([1345, 1, 2]), require_grad = True
2025-12-13 11:09:52,982 INFO     Parameter k_scale_head: torch.Size([1345, 500, 2]), require_grad = True
2025-12-13 11:09:52,982 INFO     Parameter k_scale_tail: torch.Size([1345, 500, 2]), require_grad = True
2025-12-13 11:09:52,982 INFO     Parameter relation_weight: torch.Size([1345, 500, 2]), require_grad = True
2025-12-13 11:10:01,231 INFO     Ramdomly Initializing ITI_DistMult Model...
2025-12-13 11:10:01,231 INFO     Start Training...
2025-12-13 11:10:01,231 INFO     init_step = 1
2025-12-13 11:10:01,231 INFO     batch_size = 200
2025-12-13 11:10:01,231 INFO     negative_adversarial_sampling = 1
2025-12-13 11:10:01,231 INFO     hidden_dim = 1000
2025-12-13 11:10:01,231 INFO     gamma = 26.000000
2025-12-13 11:10:01,231 INFO     negative_adversarial_sampling = True
2025-12-13 11:10:01,231 INFO     adversarial_temperature = 1.160105
2025-12-13 11:10:01,231 INFO     learning_rate = 0
2025-12-13 11:10:07,457 INFO     Training average regularization at step 100: 0.014027
2025-12-13 11:10:07,457 INFO     Training average positive_sample_loss at step 100: 0.692954
2025-12-13 11:10:07,458 INFO     Training average negative_sample_loss at step 100: 0.693150
2025-12-13 11:10:07,458 INFO     Training average loss at step 100: 0.707079
2025-12-13 11:10:12,862 INFO     Training average regularization at step 200: 0.011277
2025-12-13 11:10:12,863 INFO     Training average positive_sample_loss at step 200: 0.688518
2025-12-13 11:10:12,863 INFO     Training average negative_sample_loss at step 200: 0.693284
2025-12-13 11:10:12,863 INFO     Training average loss at step 200: 0.702178
2025-12-13 11:10:18,101 INFO     Training average regularization at step 300: 0.031111
2025-12-13 11:10:18,101 INFO     Training average positive_sample_loss at step 300: 0.639800
2025-12-13 11:10:18,101 INFO     Training average negative_sample_loss at step 300: 0.705733
2025-12-13 11:10:18,101 INFO     Training average loss at step 300: 0.703878
2025-12-13 11:10:23,360 INFO     Training average regularization at step 400: 0.071017
2025-12-13 11:10:23,361 INFO     Training average positive_sample_loss at step 400: 0.524345
2025-12-13 11:10:23,361 INFO     Training average negative_sample_loss at step 400: 0.748001
2025-12-13 11:10:23,361 INFO     Training average loss at step 400: 0.707190
2025-12-13 11:10:28,740 INFO     Training average regularization at step 500: 0.100152
2025-12-13 11:10:28,741 INFO     Training average positive_sample_loss at step 500: 0.420155
2025-12-13 11:10:28,741 INFO     Training average negative_sample_loss at step 500: 0.773913
2025-12-13 11:10:28,741 INFO     Training average loss at step 500: 0.697186
2025-12-13 11:10:34,066 INFO     Training average regularization at step 600: 0.120440
2025-12-13 11:10:34,066 INFO     Training average positive_sample_loss at step 600: 0.408945
2025-12-13 11:10:34,066 INFO     Training average negative_sample_loss at step 600: 0.718847
2025-12-13 11:10:34,066 INFO     Training average loss at step 600: 0.684336
2025-12-13 11:10:39,338 INFO     Training average regularization at step 700: 0.138626
2025-12-13 11:10:39,339 INFO     Training average positive_sample_loss at step 700: 0.440124
2025-12-13 11:10:39,339 INFO     Training average negative_sample_loss at step 700: 0.636797
2025-12-13 11:10:39,339 INFO     Training average loss at step 700: 0.677086
2025-12-13 11:10:44,768 INFO     Training average regularization at step 800: 0.153320
2025-12-13 11:10:44,770 INFO     Training average positive_sample_loss at step 800: 0.431828
2025-12-13 11:10:44,770 INFO     Training average negative_sample_loss at step 800: 0.597193
2025-12-13 11:10:44,770 INFO     Training average loss at step 800: 0.667830
2025-12-13 11:10:50,154 INFO     Training average regularization at step 900: 0.164705
2025-12-13 11:10:50,154 INFO     Training average positive_sample_loss at step 900: 0.412013
2025-12-13 11:10:50,154 INFO     Training average negative_sample_loss at step 900: 0.560692
2025-12-13 11:10:50,154 INFO     Training average loss at step 900: 0.651057
2025-12-13 11:10:55,564 INFO     Training average regularization at step 1000: 0.174147
2025-12-13 11:10:55,564 INFO     Training average positive_sample_loss at step 1000: 0.400454
2025-12-13 11:10:55,564 INFO     Training average negative_sample_loss at step 1000: 0.548754
2025-12-13 11:10:55,564 INFO     Training average loss at step 1000: 0.648751
2025-12-13 11:11:00,976 INFO     Training average regularization at step 1100: 0.182241
2025-12-13 11:11:00,976 INFO     Training average positive_sample_loss at step 1100: 0.388866
2025-12-13 11:11:00,976 INFO     Training average negative_sample_loss at step 1100: 0.519359
2025-12-13 11:11:00,976 INFO     Training average loss at step 1100: 0.636353
2025-12-13 11:11:06,397 INFO     Training average regularization at step 1200: 0.189177
2025-12-13 11:11:06,397 INFO     Training average positive_sample_loss at step 1200: 0.374442
2025-12-13 11:11:06,397 INFO     Training average negative_sample_loss at step 1200: 0.493371
2025-12-13 11:11:06,397 INFO     Training average loss at step 1200: 0.623084
2025-12-13 11:11:11,734 INFO     Training average regularization at step 1300: 0.195328
2025-12-13 11:11:11,734 INFO     Training average positive_sample_loss at step 1300: 0.366689
2025-12-13 11:11:11,734 INFO     Training average negative_sample_loss at step 1300: 0.480528
2025-12-13 11:11:11,734 INFO     Training average loss at step 1300: 0.618937
2025-12-13 11:11:17,090 INFO     Training average regularization at step 1400: 0.200709
2025-12-13 11:11:17,091 INFO     Training average positive_sample_loss at step 1400: 0.354813
2025-12-13 11:11:17,091 INFO     Training average negative_sample_loss at step 1400: 0.466334
2025-12-13 11:11:17,091 INFO     Training average loss at step 1400: 0.611282
2025-12-13 11:11:22,507 INFO     Training average regularization at step 1500: 0.205617
2025-12-13 11:11:22,507 INFO     Training average positive_sample_loss at step 1500: 0.351365
2025-12-13 11:11:22,507 INFO     Training average negative_sample_loss at step 1500: 0.450231
2025-12-13 11:11:22,508 INFO     Training average loss at step 1500: 0.606415
2025-12-13 11:11:27,793 INFO     Training average regularization at step 1600: 0.210129
2025-12-13 11:11:27,793 INFO     Training average positive_sample_loss at step 1600: 0.336238
2025-12-13 11:11:27,793 INFO     Training average negative_sample_loss at step 1600: 0.434252
2025-12-13 11:11:27,793 INFO     Training average loss at step 1600: 0.595374
2025-12-13 11:11:33,200 INFO     Training average regularization at step 1700: 0.214240
2025-12-13 11:11:33,201 INFO     Training average positive_sample_loss at step 1700: 0.331622
2025-12-13 11:11:33,201 INFO     Training average negative_sample_loss at step 1700: 0.428446
2025-12-13 11:11:33,201 INFO     Training average loss at step 1700: 0.594274
2025-12-13 11:11:38,482 INFO     Training average regularization at step 1800: 0.218089
2025-12-13 11:11:38,482 INFO     Training average positive_sample_loss at step 1800: 0.317641
2025-12-13 11:11:38,482 INFO     Training average negative_sample_loss at step 1800: 0.407952
2025-12-13 11:11:38,482 INFO     Training average loss at step 1800: 0.580886
2025-12-13 11:11:43,822 INFO     Training average regularization at step 1900: 0.221849
2025-12-13 11:11:43,822 INFO     Training average positive_sample_loss at step 1900: 0.312519
2025-12-13 11:11:43,822 INFO     Training average negative_sample_loss at step 1900: 0.402777
2025-12-13 11:11:43,822 INFO     Training average loss at step 1900: 0.579496
2025-12-13 11:11:49,146 INFO     Training average regularization at step 2000: 0.225242
2025-12-13 11:11:49,147 INFO     Training average positive_sample_loss at step 2000: 0.307015
2025-12-13 11:11:49,147 INFO     Training average negative_sample_loss at step 2000: 0.386740
2025-12-13 11:11:49,147 INFO     Training average loss at step 2000: 0.572120
2025-12-13 11:11:54,464 INFO     Training average regularization at step 2100: 0.228301
2025-12-13 11:11:54,464 INFO     Training average positive_sample_loss at step 2100: 0.308739
2025-12-13 11:11:54,464 INFO     Training average negative_sample_loss at step 2100: 0.382606
2025-12-13 11:11:54,464 INFO     Training average loss at step 2100: 0.573974
2025-12-13 11:11:59,631 INFO     Training average regularization at step 2200: 0.231251
2025-12-13 11:11:59,634 INFO     Training average positive_sample_loss at step 2200: 0.296389
2025-12-13 11:11:59,634 INFO     Training average negative_sample_loss at step 2200: 0.375113
2025-12-13 11:11:59,634 INFO     Training average loss at step 2200: 0.567002
2025-12-13 11:12:04,628 INFO     Training average regularization at step 2300: 0.234103
2025-12-13 11:12:04,632 INFO     Training average positive_sample_loss at step 2300: 0.288456
2025-12-13 11:12:04,632 INFO     Training average negative_sample_loss at step 2300: 0.361301
2025-12-13 11:12:04,632 INFO     Training average loss at step 2300: 0.558981
2025-12-13 11:12:09,724 INFO     Training average regularization at step 2400: 0.236703
2025-12-13 11:12:09,733 INFO     Training average positive_sample_loss at step 2400: 0.285159
2025-12-13 11:12:09,733 INFO     Training average negative_sample_loss at step 2400: 0.360781
2025-12-13 11:12:09,733 INFO     Training average loss at step 2400: 0.559673
2025-12-13 11:12:15,012 INFO     Training average regularization at step 2500: 0.239097
2025-12-13 11:12:15,012 INFO     Training average positive_sample_loss at step 2500: 0.278149
2025-12-13 11:12:15,012 INFO     Training average negative_sample_loss at step 2500: 0.352559
2025-12-13 11:12:15,012 INFO     Training average loss at step 2500: 0.554451
2025-12-13 11:12:20,380 INFO     Training average regularization at step 2600: 0.241517
2025-12-13 11:12:20,380 INFO     Training average positive_sample_loss at step 2600: 0.282326
2025-12-13 11:12:20,380 INFO     Training average negative_sample_loss at step 2600: 0.342490
2025-12-13 11:12:20,380 INFO     Training average loss at step 2600: 0.553925
2025-12-13 11:12:25,549 INFO     Training average regularization at step 2700: 0.243996
2025-12-13 11:12:25,549 INFO     Training average positive_sample_loss at step 2700: 0.269608
2025-12-13 11:12:25,550 INFO     Training average negative_sample_loss at step 2700: 0.338803
2025-12-13 11:12:25,550 INFO     Training average loss at step 2700: 0.548202
2025-12-13 11:12:31,014 INFO     Training average regularization at step 2800: 0.246195
2025-12-13 11:12:31,015 INFO     Training average positive_sample_loss at step 2800: 0.260957
2025-12-13 11:12:31,015 INFO     Training average negative_sample_loss at step 2800: 0.329020
2025-12-13 11:12:31,015 INFO     Training average loss at step 2800: 0.541183
2025-12-13 11:12:36,502 INFO     Training average regularization at step 2900: 0.248345
2025-12-13 11:12:36,502 INFO     Training average positive_sample_loss at step 2900: 0.259509
2025-12-13 11:12:36,502 INFO     Training average negative_sample_loss at step 2900: 0.329249
2025-12-13 11:12:36,502 INFO     Training average loss at step 2900: 0.542724
2025-12-13 11:12:41,881 INFO     Training average regularization at step 3000: 0.250560
2025-12-13 11:12:41,882 INFO     Training average positive_sample_loss at step 3000: 0.251239
2025-12-13 11:12:41,882 INFO     Training average negative_sample_loss at step 3000: 0.314630
2025-12-13 11:12:41,882 INFO     Training average loss at step 3000: 0.533495
2025-12-13 11:12:47,419 INFO     Training average regularization at step 3100: 0.252586
2025-12-13 11:12:47,420 INFO     Training average positive_sample_loss at step 3100: 0.251354
2025-12-13 11:12:47,420 INFO     Training average negative_sample_loss at step 3100: 0.314725
2025-12-13 11:12:47,420 INFO     Training average loss at step 3100: 0.535625
2025-12-13 11:12:52,695 INFO     Training average regularization at step 3200: 0.254502
2025-12-13 11:12:52,695 INFO     Training average positive_sample_loss at step 3200: 0.254288
2025-12-13 11:12:52,695 INFO     Training average negative_sample_loss at step 3200: 0.309935
2025-12-13 11:12:52,695 INFO     Training average loss at step 3200: 0.536613
2025-12-13 11:12:57,982 INFO     Training average regularization at step 3300: 0.256312
2025-12-13 11:12:57,982 INFO     Training average positive_sample_loss at step 3300: 0.248719
2025-12-13 11:12:57,982 INFO     Training average negative_sample_loss at step 3300: 0.308493
2025-12-13 11:12:57,982 INFO     Training average loss at step 3300: 0.534918
2025-12-13 11:13:03,355 INFO     Training average regularization at step 3400: 0.258159
2025-12-13 11:13:03,355 INFO     Training average positive_sample_loss at step 3400: 0.247152
2025-12-13 11:13:03,355 INFO     Training average negative_sample_loss at step 3400: 0.299252
2025-12-13 11:13:03,356 INFO     Training average loss at step 3400: 0.531361
2025-12-13 11:13:08,780 INFO     Training average regularization at step 3500: 0.259958
2025-12-13 11:13:08,781 INFO     Training average positive_sample_loss at step 3500: 0.232892
2025-12-13 11:13:08,781 INFO     Training average negative_sample_loss at step 3500: 0.291885
2025-12-13 11:13:08,781 INFO     Training average loss at step 3500: 0.522346
2025-12-13 11:13:14,004 INFO     Training average regularization at step 3600: 0.261673
2025-12-13 11:13:14,007 INFO     Training average positive_sample_loss at step 3600: 0.234110
2025-12-13 11:13:14,007 INFO     Training average negative_sample_loss at step 3600: 0.296209
2025-12-13 11:13:14,008 INFO     Training average loss at step 3600: 0.526833
2025-12-13 11:13:19,135 INFO     Training average regularization at step 3700: 0.263302
2025-12-13 11:13:19,135 INFO     Training average positive_sample_loss at step 3700: 0.228343
2025-12-13 11:13:19,135 INFO     Training average negative_sample_loss at step 3700: 0.288829
2025-12-13 11:13:19,135 INFO     Training average loss at step 3700: 0.521888
2025-12-13 11:13:24,315 INFO     Training average regularization at step 3800: 0.264805
2025-12-13 11:13:24,316 INFO     Training average positive_sample_loss at step 3800: 0.225449
2025-12-13 11:13:24,316 INFO     Training average negative_sample_loss at step 3800: 0.279928
2025-12-13 11:13:24,316 INFO     Training average loss at step 3800: 0.517494
2025-12-13 11:13:29,419 INFO     Training average regularization at step 3900: 0.266379
2025-12-13 11:13:29,420 INFO     Training average positive_sample_loss at step 3900: 0.231235
2025-12-13 11:13:29,420 INFO     Training average negative_sample_loss at step 3900: 0.280372
2025-12-13 11:13:29,420 INFO     Training average loss at step 3900: 0.522182
2025-12-13 11:13:34,710 INFO     Training average regularization at step 4000: 0.268051
2025-12-13 11:13:34,711 INFO     Training average positive_sample_loss at step 4000: 0.223582
2025-12-13 11:13:34,711 INFO     Training average negative_sample_loss at step 4000: 0.277516
2025-12-13 11:13:34,711 INFO     Training average loss at step 4000: 0.518600
2025-12-13 11:13:40,033 INFO     Training average regularization at step 4100: 0.269616
2025-12-13 11:13:40,033 INFO     Training average positive_sample_loss at step 4100: 0.227521
2025-12-13 11:13:40,033 INFO     Training average negative_sample_loss at step 4100: 0.274714
2025-12-13 11:13:40,033 INFO     Training average loss at step 4100: 0.520734
2025-12-13 11:13:45,359 INFO     Training average regularization at step 4200: 0.271014
2025-12-13 11:13:45,359 INFO     Training average positive_sample_loss at step 4200: 0.217639
2025-12-13 11:13:45,359 INFO     Training average negative_sample_loss at step 4200: 0.271965
2025-12-13 11:13:45,359 INFO     Training average loss at step 4200: 0.515815
2025-12-13 11:13:50,518 INFO     Training average regularization at step 4300: 0.272347
2025-12-13 11:13:50,518 INFO     Training average positive_sample_loss at step 4300: 0.216168
2025-12-13 11:13:50,518 INFO     Training average negative_sample_loss at step 4300: 0.263452
2025-12-13 11:13:50,518 INFO     Training average loss at step 4300: 0.512157
2025-12-13 11:13:55,782 INFO     Training average regularization at step 4400: 0.273831
2025-12-13 11:13:55,782 INFO     Training average positive_sample_loss at step 4400: 0.214755
2025-12-13 11:13:55,782 INFO     Training average negative_sample_loss at step 4400: 0.269199
2025-12-13 11:13:55,782 INFO     Training average loss at step 4400: 0.515808
2025-12-13 11:14:01,206 INFO     Training average regularization at step 4500: 0.275095
2025-12-13 11:14:01,207 INFO     Training average positive_sample_loss at step 4500: 0.206858
2025-12-13 11:14:01,207 INFO     Training average negative_sample_loss at step 4500: 0.255416
2025-12-13 11:14:01,207 INFO     Training average loss at step 4500: 0.506232
2025-12-13 11:14:06,629 INFO     Training average regularization at step 4600: 0.276404
2025-12-13 11:14:06,629 INFO     Training average positive_sample_loss at step 4600: 0.210573
2025-12-13 11:14:06,629 INFO     Training average negative_sample_loss at step 4600: 0.261108
2025-12-13 11:14:06,629 INFO     Training average loss at step 4600: 0.512244
2025-12-13 11:14:11,773 INFO     Training average regularization at step 4700: 0.277860
2025-12-13 11:14:11,773 INFO     Training average positive_sample_loss at step 4700: 0.211957
2025-12-13 11:14:11,773 INFO     Training average negative_sample_loss at step 4700: 0.256139
2025-12-13 11:14:11,773 INFO     Training average loss at step 4700: 0.511908
2025-12-13 11:14:16,966 INFO     Training average regularization at step 4800: 0.279054
2025-12-13 11:14:16,966 INFO     Training average positive_sample_loss at step 4800: 0.201893
2025-12-13 11:14:16,966 INFO     Training average negative_sample_loss at step 4800: 0.247959
2025-12-13 11:14:16,966 INFO     Training average loss at step 4800: 0.503980
2025-12-13 11:14:23,333 INFO     Training average regularization at step 4900: 0.280179
2025-12-13 11:14:23,335 INFO     Training average positive_sample_loss at step 4900: 0.173185
2025-12-13 11:14:23,335 INFO     Training average negative_sample_loss at step 4900: 0.226131
2025-12-13 11:14:23,335 INFO     Training average loss at step 4900: 0.479837
2025-12-13 11:14:28,804 INFO     Training average regularization at step 5000: 0.280833
2025-12-13 11:14:28,805 INFO     Training average positive_sample_loss at step 5000: 0.169826
2025-12-13 11:14:28,805 INFO     Training average negative_sample_loss at step 5000: 0.212920
2025-12-13 11:14:28,805 INFO     Training average loss at step 5000: 0.472206
2025-12-13 11:14:34,261 INFO     Training average regularization at step 5100: 0.281800
2025-12-13 11:14:34,262 INFO     Training average positive_sample_loss at step 5100: 0.168300
2025-12-13 11:14:34,262 INFO     Training average negative_sample_loss at step 5100: 0.219390
2025-12-13 11:14:34,262 INFO     Training average loss at step 5100: 0.475645
2025-12-13 11:14:39,522 INFO     Training average regularization at step 5200: 0.282925
2025-12-13 11:14:39,523 INFO     Training average positive_sample_loss at step 5200: 0.172239
2025-12-13 11:14:39,523 INFO     Training average negative_sample_loss at step 5200: 0.216269
2025-12-13 11:14:39,523 INFO     Training average loss at step 5200: 0.477179
2025-12-13 11:14:44,764 INFO     Training average regularization at step 5300: 0.284127
2025-12-13 11:14:44,764 INFO     Training average positive_sample_loss at step 5300: 0.175108
2025-12-13 11:14:44,764 INFO     Training average negative_sample_loss at step 5300: 0.212145
2025-12-13 11:14:44,764 INFO     Training average loss at step 5300: 0.477754
2025-12-13 11:14:49,921 INFO     Training average regularization at step 5400: 0.285277
2025-12-13 11:14:49,922 INFO     Training average positive_sample_loss at step 5400: 0.176072
2025-12-13 11:14:49,922 INFO     Training average negative_sample_loss at step 5400: 0.212370
2025-12-13 11:14:49,922 INFO     Training average loss at step 5400: 0.479498
2025-12-13 11:14:55,165 INFO     Training average regularization at step 5500: 0.286410
2025-12-13 11:14:55,165 INFO     Training average positive_sample_loss at step 5500: 0.183920
2025-12-13 11:14:55,165 INFO     Training average negative_sample_loss at step 5500: 0.221835
2025-12-13 11:14:55,165 INFO     Training average loss at step 5500: 0.489288
2025-12-13 11:15:00,428 INFO     Training average regularization at step 5600: 0.287707
2025-12-13 11:15:00,429 INFO     Training average positive_sample_loss at step 5600: 0.183560
2025-12-13 11:15:00,429 INFO     Training average negative_sample_loss at step 5600: 0.213506
2025-12-13 11:15:00,429 INFO     Training average loss at step 5600: 0.486240
2025-12-13 11:15:05,675 INFO     Training average regularization at step 5700: 0.288860
2025-12-13 11:15:05,675 INFO     Training average positive_sample_loss at step 5700: 0.176641
2025-12-13 11:15:05,675 INFO     Training average negative_sample_loss at step 5700: 0.212273
2025-12-13 11:15:05,675 INFO     Training average loss at step 5700: 0.483317
2025-12-13 11:15:10,907 INFO     Training average regularization at step 5800: 0.289956
2025-12-13 11:15:10,907 INFO     Training average positive_sample_loss at step 5800: 0.179181
2025-12-13 11:15:10,907 INFO     Training average negative_sample_loss at step 5800: 0.210658
2025-12-13 11:15:10,907 INFO     Training average loss at step 5800: 0.484875
2025-12-13 11:15:16,179 INFO     Training average regularization at step 5900: 0.291100
2025-12-13 11:15:16,179 INFO     Training average positive_sample_loss at step 5900: 0.181582
2025-12-13 11:15:16,179 INFO     Training average negative_sample_loss at step 5900: 0.214432
2025-12-13 11:15:16,179 INFO     Training average loss at step 5900: 0.489107
2025-12-13 11:15:21,425 INFO     Training average regularization at step 6000: 0.292444
2025-12-13 11:15:21,426 INFO     Training average positive_sample_loss at step 6000: 0.187367
2025-12-13 11:15:21,426 INFO     Training average negative_sample_loss at step 6000: 0.214861
2025-12-13 11:15:21,426 INFO     Training average loss at step 6000: 0.493558
2025-12-13 11:15:26,759 INFO     Training average regularization at step 6100: 0.293771
2025-12-13 11:15:26,759 INFO     Training average positive_sample_loss at step 6100: 0.188151
2025-12-13 11:15:26,759 INFO     Training average negative_sample_loss at step 6100: 0.218646
2025-12-13 11:15:26,759 INFO     Training average loss at step 6100: 0.497169
2025-12-13 11:15:32,038 INFO     Training average regularization at step 6200: 0.294975
2025-12-13 11:15:32,038 INFO     Training average positive_sample_loss at step 6200: 0.179124
2025-12-13 11:15:32,038 INFO     Training average negative_sample_loss at step 6200: 0.221853
2025-12-13 11:15:32,038 INFO     Training average loss at step 6200: 0.495463
2025-12-13 11:15:37,304 INFO     Training average regularization at step 6300: 0.296315
2025-12-13 11:15:37,304 INFO     Training average positive_sample_loss at step 6300: 0.182399
2025-12-13 11:15:37,305 INFO     Training average negative_sample_loss at step 6300: 0.215689
2025-12-13 11:15:37,305 INFO     Training average loss at step 6300: 0.495359
2025-12-13 11:15:42,606 INFO     Training average regularization at step 6400: 0.297517
2025-12-13 11:15:42,606 INFO     Training average positive_sample_loss at step 6400: 0.179778
2025-12-13 11:15:42,606 INFO     Training average negative_sample_loss at step 6400: 0.217335
2025-12-13 11:15:42,606 INFO     Training average loss at step 6400: 0.496073
2025-12-13 11:15:47,881 INFO     Training average regularization at step 6500: 0.298625
2025-12-13 11:15:47,881 INFO     Training average positive_sample_loss at step 6500: 0.180977
2025-12-13 11:15:47,882 INFO     Training average negative_sample_loss at step 6500: 0.217521
2025-12-13 11:15:47,882 INFO     Training average loss at step 6500: 0.497874
2025-12-13 11:15:53,154 INFO     Training average regularization at step 6600: 0.299835
2025-12-13 11:15:53,155 INFO     Training average positive_sample_loss at step 6600: 0.183439
2025-12-13 11:15:53,155 INFO     Training average negative_sample_loss at step 6600: 0.223699
2025-12-13 11:15:53,155 INFO     Training average loss at step 6600: 0.503404
2025-12-13 11:15:58,358 INFO     Training average regularization at step 6700: 0.300993
2025-12-13 11:15:58,358 INFO     Training average positive_sample_loss at step 6700: 0.182937
2025-12-13 11:15:58,358 INFO     Training average negative_sample_loss at step 6700: 0.209917
2025-12-13 11:15:58,358 INFO     Training average loss at step 6700: 0.497420
2025-12-13 11:16:03,686 INFO     Training average regularization at step 6800: 0.302028
2025-12-13 11:16:03,686 INFO     Training average positive_sample_loss at step 6800: 0.177232
2025-12-13 11:16:03,686 INFO     Training average negative_sample_loss at step 6800: 0.213432
2025-12-13 11:16:03,686 INFO     Training average loss at step 6800: 0.497360
2025-12-13 11:16:09,007 INFO     Training average regularization at step 6900: 0.302918
2025-12-13 11:16:09,007 INFO     Training average positive_sample_loss at step 6900: 0.178146
2025-12-13 11:16:09,007 INFO     Training average negative_sample_loss at step 6900: 0.211488
2025-12-13 11:16:09,008 INFO     Training average loss at step 6900: 0.497735
2025-12-13 11:16:14,214 INFO     Training average regularization at step 7000: 0.303892
2025-12-13 11:16:14,216 INFO     Training average positive_sample_loss at step 7000: 0.187843
2025-12-13 11:16:14,216 INFO     Training average negative_sample_loss at step 7000: 0.217370
2025-12-13 11:16:14,216 INFO     Training average loss at step 7000: 0.506499
2025-12-13 11:16:19,503 INFO     Training average regularization at step 7100: 0.304857
2025-12-13 11:16:19,504 INFO     Training average positive_sample_loss at step 7100: 0.182407
2025-12-13 11:16:19,504 INFO     Training average negative_sample_loss at step 7100: 0.214581
2025-12-13 11:16:19,504 INFO     Training average loss at step 7100: 0.503351
2025-12-13 11:16:24,752 INFO     Training average regularization at step 7200: 0.305665
2025-12-13 11:16:24,752 INFO     Training average positive_sample_loss at step 7200: 0.179599
2025-12-13 11:16:24,752 INFO     Training average negative_sample_loss at step 7200: 0.205261
2025-12-13 11:16:24,752 INFO     Training average loss at step 7200: 0.498094
2025-12-13 11:16:30,009 INFO     Training average regularization at step 7300: 0.306515
2025-12-13 11:16:30,009 INFO     Training average positive_sample_loss at step 7300: 0.173433
2025-12-13 11:16:30,009 INFO     Training average negative_sample_loss at step 7300: 0.199549
2025-12-13 11:16:30,009 INFO     Training average loss at step 7300: 0.493006
2025-12-13 11:16:35,087 INFO     Training average regularization at step 7400: 0.307337
2025-12-13 11:16:35,088 INFO     Training average positive_sample_loss at step 7400: 0.174677
2025-12-13 11:16:35,088 INFO     Training average negative_sample_loss at step 7400: 0.202727
2025-12-13 11:16:35,088 INFO     Training average loss at step 7400: 0.496039
2025-12-13 11:16:40,425 INFO     Training average regularization at step 7500: 0.308210
2025-12-13 11:16:40,426 INFO     Training average positive_sample_loss at step 7500: 0.170175
2025-12-13 11:16:40,426 INFO     Training average negative_sample_loss at step 7500: 0.208037
2025-12-13 11:16:40,426 INFO     Training average loss at step 7500: 0.497316
2025-12-13 11:16:45,540 INFO     Training average regularization at step 7600: 0.309037
2025-12-13 11:16:45,540 INFO     Training average positive_sample_loss at step 7600: 0.173350
2025-12-13 11:16:45,540 INFO     Training average negative_sample_loss at step 7600: 0.202515
2025-12-13 11:16:45,540 INFO     Training average loss at step 7600: 0.496969
2025-12-13 11:16:50,611 INFO     Training average regularization at step 7700: 0.309640
2025-12-13 11:16:50,611 INFO     Training average positive_sample_loss at step 7700: 0.177209
2025-12-13 11:16:50,611 INFO     Training average negative_sample_loss at step 7700: 0.203708
2025-12-13 11:16:50,611 INFO     Training average loss at step 7700: 0.500099
2025-12-13 11:16:55,739 INFO     Training average regularization at step 7800: 0.310308
2025-12-13 11:16:55,739 INFO     Training average positive_sample_loss at step 7800: 0.173620
2025-12-13 11:16:55,739 INFO     Training average negative_sample_loss at step 7800: 0.208018
2025-12-13 11:16:55,739 INFO     Training average loss at step 7800: 0.501127
2025-12-13 11:17:00,854 INFO     Training average regularization at step 7900: 0.310966
2025-12-13 11:17:00,854 INFO     Training average positive_sample_loss at step 7900: 0.176910
2025-12-13 11:17:00,854 INFO     Training average negative_sample_loss at step 7900: 0.207444
2025-12-13 11:17:00,854 INFO     Training average loss at step 7900: 0.503144
2025-12-13 11:17:06,148 INFO     Training average regularization at step 8000: 0.311803
2025-12-13 11:17:06,149 INFO     Training average positive_sample_loss at step 8000: 0.162013
2025-12-13 11:17:06,149 INFO     Training average negative_sample_loss at step 8000: 0.199554
2025-12-13 11:17:06,149 INFO     Training average loss at step 8000: 0.492586
2025-12-13 11:17:11,286 INFO     Training average regularization at step 8100: 0.312418
2025-12-13 11:17:11,286 INFO     Training average positive_sample_loss at step 8100: 0.171877
2025-12-13 11:17:11,286 INFO     Training average negative_sample_loss at step 8100: 0.194459
2025-12-13 11:17:11,286 INFO     Training average loss at step 8100: 0.495586
2025-12-13 11:17:16,509 INFO     Training average regularization at step 8200: 0.313044
2025-12-13 11:17:16,509 INFO     Training average positive_sample_loss at step 8200: 0.166242
2025-12-13 11:17:16,509 INFO     Training average negative_sample_loss at step 8200: 0.203223
2025-12-13 11:17:16,509 INFO     Training average loss at step 8200: 0.497777
2025-12-13 11:17:21,695 INFO     Training average regularization at step 8300: 0.313684
2025-12-13 11:17:21,696 INFO     Training average positive_sample_loss at step 8300: 0.162894
2025-12-13 11:17:21,696 INFO     Training average negative_sample_loss at step 8300: 0.194486
2025-12-13 11:17:21,696 INFO     Training average loss at step 8300: 0.492374
2025-12-13 11:17:26,824 INFO     Training average regularization at step 8400: 0.314369
2025-12-13 11:17:26,824 INFO     Training average positive_sample_loss at step 8400: 0.164854
2025-12-13 11:17:26,824 INFO     Training average negative_sample_loss at step 8400: 0.192505
2025-12-13 11:17:26,824 INFO     Training average loss at step 8400: 0.493049
2025-12-13 11:17:32,041 INFO     Training average regularization at step 8500: 0.314949
2025-12-13 11:17:32,041 INFO     Training average positive_sample_loss at step 8500: 0.169183
2025-12-13 11:17:32,041 INFO     Training average negative_sample_loss at step 8500: 0.197165
2025-12-13 11:17:32,041 INFO     Training average loss at step 8500: 0.498123
2025-12-13 11:17:37,320 INFO     Training average regularization at step 8600: 0.315375
2025-12-13 11:17:37,320 INFO     Training average positive_sample_loss at step 8600: 0.167485
2025-12-13 11:17:37,320 INFO     Training average negative_sample_loss at step 8600: 0.190604
2025-12-13 11:17:37,320 INFO     Training average loss at step 8600: 0.494420
2025-12-13 11:17:42,663 INFO     Training average regularization at step 8700: 0.315770
2025-12-13 11:17:42,663 INFO     Training average positive_sample_loss at step 8700: 0.157173
2025-12-13 11:17:42,663 INFO     Training average negative_sample_loss at step 8700: 0.188361
2025-12-13 11:17:42,664 INFO     Training average loss at step 8700: 0.488537
2025-12-13 11:17:47,970 INFO     Training average regularization at step 8800: 0.316121
2025-12-13 11:17:47,970 INFO     Training average positive_sample_loss at step 8800: 0.157677
2025-12-13 11:17:47,970 INFO     Training average negative_sample_loss at step 8800: 0.185532
2025-12-13 11:17:47,970 INFO     Training average loss at step 8800: 0.487725
2025-12-13 11:17:53,253 INFO     Training average regularization at step 8900: 0.316618
2025-12-13 11:17:53,253 INFO     Training average positive_sample_loss at step 8900: 0.167981
2025-12-13 11:17:53,253 INFO     Training average negative_sample_loss at step 8900: 0.191268
2025-12-13 11:17:53,253 INFO     Training average loss at step 8900: 0.496243
2025-12-13 11:17:58,546 INFO     Training average regularization at step 9000: 0.317133
2025-12-13 11:17:58,547 INFO     Training average positive_sample_loss at step 9000: 0.166544
2025-12-13 11:17:58,547 INFO     Training average negative_sample_loss at step 9000: 0.195526
2025-12-13 11:17:58,547 INFO     Training average loss at step 9000: 0.498168
2025-12-13 11:18:03,554 INFO     Training average regularization at step 9100: 0.317810
2025-12-13 11:18:03,555 INFO     Training average positive_sample_loss at step 9100: 0.157571
2025-12-13 11:18:03,555 INFO     Training average negative_sample_loss at step 9100: 0.187534
2025-12-13 11:18:03,555 INFO     Training average loss at step 9100: 0.490362
2025-12-13 11:18:08,452 INFO     Training average regularization at step 9200: 0.318313
2025-12-13 11:18:08,453 INFO     Training average positive_sample_loss at step 9200: 0.158912
2025-12-13 11:18:08,453 INFO     Training average negative_sample_loss at step 9200: 0.180634
2025-12-13 11:18:08,453 INFO     Training average loss at step 9200: 0.488086
2025-12-13 11:18:13,478 INFO     Training average regularization at step 9300: 0.318708
2025-12-13 11:18:13,479 INFO     Training average positive_sample_loss at step 9300: 0.152693
2025-12-13 11:18:13,479 INFO     Training average negative_sample_loss at step 9300: 0.184682
2025-12-13 11:18:13,479 INFO     Training average loss at step 9300: 0.487395
2025-12-13 11:18:18,497 INFO     Training average regularization at step 9400: 0.319092
2025-12-13 11:18:18,497 INFO     Training average positive_sample_loss at step 9400: 0.152675
2025-12-13 11:18:18,497 INFO     Training average negative_sample_loss at step 9400: 0.183145
2025-12-13 11:18:18,497 INFO     Training average loss at step 9400: 0.487002
2025-12-13 11:18:24,223 INFO     Training average regularization at step 9500: 0.319569
2025-12-13 11:18:24,224 INFO     Training average positive_sample_loss at step 9500: 0.156759
2025-12-13 11:18:24,224 INFO     Training average negative_sample_loss at step 9500: 0.179015
2025-12-13 11:18:24,224 INFO     Training average loss at step 9500: 0.487455
2025-12-13 11:18:29,927 INFO     Training average regularization at step 9600: 0.319976
2025-12-13 11:18:29,929 INFO     Training average positive_sample_loss at step 9600: 0.149125
2025-12-13 11:18:29,929 INFO     Training average negative_sample_loss at step 9600: 0.175747
2025-12-13 11:18:29,929 INFO     Training average loss at step 9600: 0.482412
2025-12-13 11:18:36,293 INFO     Training average regularization at step 9700: 0.320486
2025-12-13 11:18:36,293 INFO     Training average positive_sample_loss at step 9700: 0.148557
2025-12-13 11:18:36,293 INFO     Training average negative_sample_loss at step 9700: 0.177290
2025-12-13 11:18:36,293 INFO     Training average loss at step 9700: 0.483410
2025-12-13 11:18:41,743 INFO     Training average regularization at step 9800: 0.320494
2025-12-13 11:18:41,743 INFO     Training average positive_sample_loss at step 9800: 0.124614
2025-12-13 11:18:41,743 INFO     Training average negative_sample_loss at step 9800: 0.153140
2025-12-13 11:18:41,743 INFO     Training average loss at step 9800: 0.459371
2025-12-13 11:18:47,143 INFO     Training average regularization at step 9900: 0.320510
2025-12-13 11:18:47,143 INFO     Training average positive_sample_loss at step 9900: 0.128553
2025-12-13 11:18:47,143 INFO     Training average negative_sample_loss at step 9900: 0.157474
2025-12-13 11:18:47,143 INFO     Training average loss at step 9900: 0.463523
2025-12-13 11:18:52,580 INFO     Training average regularization at step 10000: 0.320582
2025-12-13 11:18:52,580 INFO     Training average positive_sample_loss at step 10000: 0.137194
2025-12-13 11:18:52,580 INFO     Training average negative_sample_loss at step 10000: 0.156446
2025-12-13 11:18:52,580 INFO     Training average loss at step 10000: 0.467402
2025-12-13 11:18:52,580 INFO     Evaluating on Valid Dataset...
2025-12-13 11:18:53,270 INFO     Evaluating the model... (0/50000)
2025-12-13 11:18:58,055 INFO     Evaluating the model... (500/50000)
2025-12-13 11:19:02,564 INFO     Evaluating the model... (1000/50000)
2025-12-13 11:19:07,026 INFO     Evaluating the model... (1500/50000)
2025-12-13 11:19:11,642 INFO     Evaluating the model... (2000/50000)
2025-12-13 11:19:16,364 INFO     Evaluating the model... (2500/50000)
2025-12-13 11:19:20,874 INFO     Evaluating the model... (3000/50000)
2025-12-13 11:19:26,586 INFO     Evaluating the model... (3500/50000)
2025-12-13 11:19:31,565 INFO     Evaluating the model... (4000/50000)
2025-12-13 11:19:36,131 INFO     Evaluating the model... (4500/50000)
2025-12-13 11:19:40,514 INFO     Evaluating the model... (5000/50000)
2025-12-13 11:19:44,834 INFO     Evaluating the model... (5500/50000)
2025-12-13 11:19:50,007 INFO     Evaluating the model... (6000/50000)
2025-12-13 11:19:54,326 INFO     Evaluating the model... (6500/50000)
2025-12-13 11:19:59,051 INFO     Evaluating the model... (7000/50000)
2025-12-13 11:20:03,349 INFO     Evaluating the model... (7500/50000)
2025-12-13 11:20:07,702 INFO     Evaluating the model... (8000/50000)
2025-12-13 11:20:12,638 INFO     Evaluating the model... (8500/50000)
2025-12-13 11:20:16,996 INFO     Evaluating the model... (9000/50000)
2025-12-13 11:20:21,329 INFO     Evaluating the model... (9500/50000)
2025-12-13 11:20:25,563 INFO     Evaluating the model... (10000/50000)
2025-12-13 11:20:30,044 INFO     Evaluating the model... (10500/50000)
2025-12-13 11:20:34,925 INFO     Evaluating the model... (11000/50000)
2025-12-13 11:20:39,270 INFO     Evaluating the model... (11500/50000)
2025-12-13 11:20:43,710 INFO     Evaluating the model... (12000/50000)
2025-12-13 11:20:48,301 INFO     Evaluating the model... (12500/50000)
2025-12-13 11:20:52,669 INFO     Evaluating the model... (13000/50000)
2025-12-13 11:20:57,920 INFO     Evaluating the model... (13500/50000)
2025-12-13 11:21:02,146 INFO     Evaluating the model... (14000/50000)
2025-12-13 11:21:06,418 INFO     Evaluating the model... (14500/50000)
2025-12-13 11:21:10,821 INFO     Evaluating the model... (15000/50000)
2025-12-13 11:21:15,168 INFO     Evaluating the model... (15500/50000)
2025-12-13 11:21:20,180 INFO     Evaluating the model... (16000/50000)
2025-12-13 11:21:24,413 INFO     Evaluating the model... (16500/50000)
2025-12-13 11:21:28,748 INFO     Evaluating the model... (17000/50000)
2025-12-13 11:21:33,021 INFO     Evaluating the model... (17500/50000)
2025-12-13 11:21:37,371 INFO     Evaluating the model... (18000/50000)
2025-12-13 11:21:42,432 INFO     Evaluating the model... (18500/50000)
2025-12-13 11:21:46,592 INFO     Evaluating the model... (19000/50000)
2025-12-13 11:21:50,825 INFO     Evaluating the model... (19500/50000)
2025-12-13 11:21:54,965 INFO     Evaluating the model... (20000/50000)
2025-12-13 11:21:59,240 INFO     Evaluating the model... (20500/50000)
2025-12-13 11:22:04,775 INFO     Evaluating the model... (21000/50000)
2025-12-13 11:22:09,050 INFO     Evaluating the model... (21500/50000)
2025-12-13 11:22:13,333 INFO     Evaluating the model... (22000/50000)
2025-12-13 11:22:17,666 INFO     Evaluating the model... (22500/50000)
2025-12-13 11:22:21,888 INFO     Evaluating the model... (23000/50000)
2025-12-13 11:22:27,175 INFO     Evaluating the model... (23500/50000)
2025-12-13 11:22:31,518 INFO     Evaluating the model... (24000/50000)
2025-12-13 11:22:35,583 INFO     Evaluating the model... (24500/50000)
2025-12-13 11:22:40,185 INFO     Evaluating the model... (25000/50000)
2025-12-13 11:22:44,681 INFO     Evaluating the model... (25500/50000)
2025-12-13 11:22:49,242 INFO     Evaluating the model... (26000/50000)
2025-12-13 11:22:53,602 INFO     Evaluating the model... (26500/50000)
2025-12-13 11:22:57,827 INFO     Evaluating the model... (27000/50000)
2025-12-13 11:23:02,212 INFO     Evaluating the model... (27500/50000)
2025-12-13 11:23:06,429 INFO     Evaluating the model... (28000/50000)
2025-12-13 11:23:12,010 INFO     Evaluating the model... (28500/50000)
2025-12-13 11:23:16,169 INFO     Evaluating the model... (29000/50000)
2025-12-13 11:23:20,368 INFO     Evaluating the model... (29500/50000)
2025-12-13 11:23:24,585 INFO     Evaluating the model... (30000/50000)
2025-12-13 11:23:28,776 INFO     Evaluating the model... (30500/50000)
2025-12-13 11:23:33,877 INFO     Evaluating the model... (31000/50000)
2025-12-13 11:23:38,255 INFO     Evaluating the model... (31500/50000)
2025-12-13 11:23:42,473 INFO     Evaluating the model... (32000/50000)
2025-12-13 11:23:47,000 INFO     Evaluating the model... (32500/50000)
2025-12-13 11:23:51,911 INFO     Evaluating the model... (33000/50000)
2025-12-13 11:23:56,258 INFO     Evaluating the model... (33500/50000)
2025-12-13 11:24:00,476 INFO     Evaluating the model... (34000/50000)
2025-12-13 11:24:04,740 INFO     Evaluating the model... (34500/50000)
2025-12-13 11:24:08,946 INFO     Evaluating the model... (35000/50000)
2025-12-13 11:24:14,052 INFO     Evaluating the model... (35500/50000)
2025-12-13 11:24:18,291 INFO     Evaluating the model... (36000/50000)
2025-12-13 11:24:22,318 INFO     Evaluating the model... (36500/50000)
2025-12-13 11:24:26,432 INFO     Evaluating the model... (37000/50000)
2025-12-13 11:24:30,755 INFO     Evaluating the model... (37500/50000)
2025-12-13 11:24:35,705 INFO     Evaluating the model... (38000/50000)
2025-12-13 11:24:39,793 INFO     Evaluating the model... (38500/50000)
2025-12-13 11:24:44,107 INFO     Evaluating the model... (39000/50000)
2025-12-13 11:24:48,236 INFO     Evaluating the model... (39500/50000)
2025-12-13 11:24:52,352 INFO     Evaluating the model... (40000/50000)
2025-12-13 11:24:57,486 INFO     Evaluating the model... (40500/50000)
2025-12-13 11:25:01,682 INFO     Evaluating the model... (41000/50000)
2025-12-13 11:25:05,863 INFO     Evaluating the model... (41500/50000)
2025-12-13 11:25:10,212 INFO     Evaluating the model... (42000/50000)
2025-12-13 11:25:14,603 INFO     Evaluating the model... (42500/50000)
2025-12-13 11:25:19,609 INFO     Evaluating the model... (43000/50000)
2025-12-13 11:25:23,677 INFO     Evaluating the model... (43500/50000)
2025-12-13 11:25:27,822 INFO     Evaluating the model... (44000/50000)
2025-12-13 11:25:31,902 INFO     Evaluating the model... (44500/50000)
2025-12-13 11:25:35,926 INFO     Evaluating the model... (45000/50000)
2025-12-13 11:25:41,229 INFO     Evaluating the model... (45500/50000)
2025-12-13 11:25:45,395 INFO     Evaluating the model... (46000/50000)
2025-12-13 11:25:49,548 INFO     Evaluating the model... (46500/50000)
2025-12-13 11:25:53,830 INFO     Evaluating the model... (47000/50000)
2025-12-13 11:25:57,917 INFO     Evaluating the model... (47500/50000)
2025-12-13 11:26:03,023 INFO     Evaluating the model... (48000/50000)
2025-12-13 11:26:07,227 INFO     Evaluating the model... (48500/50000)
2025-12-13 11:26:11,657 INFO     Evaluating the model... (49000/50000)
2025-12-13 11:26:15,734 INFO     Evaluating the model... (49500/50000)
2025-12-13 11:26:20,383 INFO     Valid MRR at step 10000: 0.639914
2025-12-13 11:26:20,383 INFO     Valid MR at step 10000: 331.286370
2025-12-13 11:26:20,383 INFO     Valid HITS@1 at step 10000: 0.562420
2025-12-13 11:26:20,383 INFO     Valid HITS@3 at step 10000: 0.689580
2025-12-13 11:26:20,383 INFO     Valid HITS@10 at step 10000: 0.777780
2025-12-13 11:26:22,315 INFO     Evaluating on Test Dataset...
2025-12-13 11:26:23,016 INFO     Evaluating the model... (0/59072)
2025-12-13 11:26:27,683 INFO     Evaluating the model... (500/59072)
2025-12-13 11:26:32,206 INFO     Evaluating the model... (1000/59072)
2025-12-13 11:26:36,575 INFO     Evaluating the model... (1500/59072)
2025-12-13 11:26:41,131 INFO     Evaluating the model... (2000/59072)
2025-12-13 11:26:45,701 INFO     Evaluating the model... (2500/59072)
2025-12-13 11:26:52,334 INFO     Evaluating the model... (3000/59072)
2025-12-13 11:26:56,988 INFO     Evaluating the model... (3500/59072)
2025-12-13 11:27:01,597 INFO     Evaluating the model... (4000/59072)
2025-12-13 11:27:06,256 INFO     Evaluating the model... (4500/59072)
2025-12-13 11:27:10,778 INFO     Evaluating the model... (5000/59072)
2025-12-13 11:27:16,443 INFO     Evaluating the model... (5500/59072)
2025-12-13 11:27:20,981 INFO     Evaluating the model... (6000/59072)
2025-12-13 11:27:25,541 INFO     Evaluating the model... (6500/59072)
2025-12-13 11:27:30,059 INFO     Evaluating the model... (7000/59072)
2025-12-13 11:27:34,807 INFO     Evaluating the model... (7500/59072)
2025-12-13 11:27:39,823 INFO     Evaluating the model... (8000/59072)
2025-12-13 11:27:44,469 INFO     Evaluating the model... (8500/59072)
2025-12-13 11:27:48,938 INFO     Evaluating the model... (9000/59072)
2025-12-13 11:27:53,358 INFO     Evaluating the model... (9500/59072)
2025-12-13 11:27:58,441 INFO     Evaluating the model... (10000/59072)
2025-12-13 11:28:02,747 INFO     Evaluating the model... (10500/59072)
2025-12-13 11:28:07,019 INFO     Evaluating the model... (11000/59072)
2025-12-13 11:28:11,847 INFO     Evaluating the model... (11500/59072)
2025-12-13 11:28:16,361 INFO     Evaluating the model... (12000/59072)
2025-12-13 11:28:21,805 INFO     Evaluating the model... (12500/59072)
2025-12-13 11:28:26,367 INFO     Evaluating the model... (13000/59072)
2025-12-13 11:28:30,740 INFO     Evaluating the model... (13500/59072)
2025-12-13 11:28:35,067 INFO     Evaluating the model... (14000/59072)
2025-12-13 11:28:39,527 INFO     Evaluating the model... (14500/59072)
2025-12-13 11:28:44,893 INFO     Evaluating the model... (15000/59072)
2025-12-13 11:28:49,368 INFO     Evaluating the model... (15500/59072)
2025-12-13 11:28:53,782 INFO     Evaluating the model... (16000/59072)
2025-12-13 11:28:58,187 INFO     Evaluating the model... (16500/59072)
2025-12-13 11:29:02,627 INFO     Evaluating the model... (17000/59072)
2025-12-13 11:29:08,211 INFO     Evaluating the model... (17500/59072)
2025-12-13 11:29:12,775 INFO     Evaluating the model... (18000/59072)
2025-12-13 11:29:17,197 INFO     Evaluating the model... (18500/59072)
2025-12-13 11:29:21,505 INFO     Evaluating the model... (19000/59072)
2025-12-13 11:29:25,773 INFO     Evaluating the model... (19500/59072)
2025-12-13 11:29:30,785 INFO     Evaluating the model... (20000/59072)
2025-12-13 11:29:34,965 INFO     Evaluating the model... (20500/59072)
2025-12-13 11:29:39,319 INFO     Evaluating the model... (21000/59072)
2025-12-13 11:29:43,598 INFO     Evaluating the model... (21500/59072)
2025-12-13 11:29:48,108 INFO     Evaluating the model... (22000/59072)
2025-12-13 11:29:53,503 INFO     Evaluating the model... (22500/59072)
2025-12-13 11:29:57,789 INFO     Evaluating the model... (23000/59072)
2025-12-13 11:30:02,052 INFO     Evaluating the model... (23500/59072)
2025-12-13 11:30:06,305 INFO     Evaluating the model... (24000/59072)
2025-12-13 11:30:10,559 INFO     Evaluating the model... (24500/59072)
2025-12-13 11:30:15,858 INFO     Evaluating the model... (25000/59072)
2025-12-13 11:30:20,176 INFO     Evaluating the model... (25500/59072)
2025-12-13 11:30:24,404 INFO     Evaluating the model... (26000/59072)
2025-12-13 11:30:28,757 INFO     Evaluating the model... (26500/59072)
2025-12-13 11:30:33,059 INFO     Evaluating the model... (27000/59072)
2025-12-13 11:30:38,399 INFO     Evaluating the model... (27500/59072)
2025-12-13 11:30:42,780 INFO     Evaluating the model... (28000/59072)
2025-12-13 11:30:47,047 INFO     Evaluating the model... (28500/59072)
2025-12-13 11:30:51,702 INFO     Evaluating the model... (29000/59072)
2025-12-13 11:30:57,349 INFO     Evaluating the model... (29500/59072)
2025-12-13 11:31:02,430 INFO     Evaluating the model... (30000/59072)
2025-12-13 11:31:06,902 INFO     Evaluating the model... (30500/59072)
2025-12-13 11:31:11,263 INFO     Evaluating the model... (31000/59072)
2025-12-13 11:31:15,691 INFO     Evaluating the model... (31500/59072)
2025-12-13 11:31:21,387 INFO     Evaluating the model... (32000/59072)
2025-12-13 11:31:25,682 INFO     Evaluating the model... (32500/59072)
2025-12-13 11:31:30,095 INFO     Evaluating the model... (33000/59072)
2025-12-13 11:31:34,349 INFO     Evaluating the model... (33500/59072)
2025-12-13 11:31:38,657 INFO     Evaluating the model... (34000/59072)
2025-12-13 11:31:44,173 INFO     Evaluating the model... (34500/59072)
2025-12-13 11:31:48,551 INFO     Evaluating the model... (35000/59072)
2025-12-13 11:31:53,016 INFO     Evaluating the model... (35500/59072)
2025-12-13 11:31:57,484 INFO     Evaluating the model... (36000/59072)
2025-12-13 11:32:02,002 INFO     Evaluating the model... (36500/59072)
2025-12-13 11:32:07,447 INFO     Evaluating the model... (37000/59072)
2025-12-13 11:32:12,240 INFO     Evaluating the model... (37500/59072)
2025-12-13 11:32:16,899 INFO     Evaluating the model... (38000/59072)
2025-12-13 11:32:21,626 INFO     Evaluating the model... (38500/59072)
2025-12-13 11:32:26,328 INFO     Evaluating the model... (39000/59072)
2025-12-13 11:32:31,687 INFO     Evaluating the model... (39500/59072)
2025-12-13 11:32:36,206 INFO     Evaluating the model... (40000/59072)
2025-12-13 11:32:40,888 INFO     Evaluating the model... (40500/59072)
2025-12-13 11:32:45,511 INFO     Evaluating the model... (41000/59072)
2025-12-13 11:32:51,212 INFO     Evaluating the model... (41500/59072)
2025-12-13 11:32:55,996 INFO     Evaluating the model... (42000/59072)
2025-12-13 11:33:00,808 INFO     Evaluating the model... (42500/59072)
2025-12-13 11:33:05,408 INFO     Evaluating the model... (43000/59072)
2025-12-13 11:33:09,994 INFO     Evaluating the model... (43500/59072)
2025-12-13 11:33:15,688 INFO     Evaluating the model... (44000/59072)
2025-12-13 11:33:20,271 INFO     Evaluating the model... (44500/59072)
2025-12-13 11:33:24,742 INFO     Evaluating the model... (45000/59072)
2025-12-13 11:33:29,176 INFO     Evaluating the model... (45500/59072)
2025-12-13 11:33:33,615 INFO     Evaluating the model... (46000/59072)
2025-12-13 11:33:39,589 INFO     Evaluating the model... (46500/59072)
2025-12-13 11:33:43,927 INFO     Evaluating the model... (47000/59072)
2025-12-13 11:33:48,448 INFO     Evaluating the model... (47500/59072)
2025-12-13 11:33:52,922 INFO     Evaluating the model... (48000/59072)
2025-12-13 11:33:57,253 INFO     Evaluating the model... (48500/59072)
2025-12-13 11:34:03,047 INFO     Evaluating the model... (49000/59072)
2025-12-13 11:34:07,775 INFO     Evaluating the model... (49500/59072)
2025-12-13 11:34:12,299 INFO     Evaluating the model... (50000/59072)
2025-12-13 11:34:16,917 INFO     Evaluating the model... (50500/59072)
2025-12-13 11:34:21,431 INFO     Evaluating the model... (51000/59072)
2025-12-13 11:34:27,789 INFO     Evaluating the model... (51500/59072)
2025-12-13 11:34:32,301 INFO     Evaluating the model... (52000/59072)
2025-12-13 11:34:36,683 INFO     Evaluating the model... (52500/59072)
2025-12-13 11:34:41,310 INFO     Evaluating the model... (53000/59072)
2025-12-13 11:34:45,795 INFO     Evaluating the model... (53500/59072)
2025-12-13 11:34:52,122 INFO     Evaluating the model... (54000/59072)
2025-12-13 11:34:57,095 INFO     Evaluating the model... (54500/59072)
2025-12-13 11:35:01,843 INFO     Evaluating the model... (55000/59072)
2025-12-13 11:35:06,705 INFO     Evaluating the model... (55500/59072)
2025-12-13 11:35:11,400 INFO     Evaluating the model... (56000/59072)
2025-12-13 11:35:17,161 INFO     Evaluating the model... (56500/59072)
2025-12-13 11:35:21,508 INFO     Evaluating the model... (57000/59072)
2025-12-13 11:35:26,006 INFO     Evaluating the model... (57500/59072)
2025-12-13 11:35:30,499 INFO     Evaluating the model... (58000/59072)
2025-12-13 11:35:34,924 INFO     Evaluating the model... (58500/59072)
2025-12-13 11:35:40,490 INFO     Evaluating the model... (59000/59072)
2025-12-13 11:35:41,382 INFO     Test MRR at step 10000: 0.636849
2025-12-13 11:35:41,382 INFO     Test MR at step 10000: 336.510191
2025-12-13 11:35:41,382 INFO     Test HITS@1 at step 10000: 0.558049
2025-12-13 11:35:41,382 INFO     Test HITS@3 at step 10000: 0.687698
2025-12-13 11:35:41,382 INFO     Test HITS@10 at step 10000: 0.776286
2025-12-13 11:35:46,633 INFO     Training average regularization at step 10100: 0.320953
2025-12-13 11:35:46,636 INFO     Training average positive_sample_loss at step 10100: 0.139558
2025-12-13 11:35:46,636 INFO     Training average negative_sample_loss at step 10100: 0.165197
2025-12-13 11:35:46,636 INFO     Training average loss at step 10100: 0.473331
2025-12-13 11:35:51,952 INFO     Training average regularization at step 10200: 0.321315
2025-12-13 11:35:51,952 INFO     Training average positive_sample_loss at step 10200: 0.137293
2025-12-13 11:35:51,952 INFO     Training average negative_sample_loss at step 10200: 0.162182
2025-12-13 11:35:51,952 INFO     Training average loss at step 10200: 0.471053
2025-12-13 11:35:57,398 INFO     Training average regularization at step 10300: 0.321620
2025-12-13 11:35:57,399 INFO     Training average positive_sample_loss at step 10300: 0.137499
2025-12-13 11:35:57,399 INFO     Training average negative_sample_loss at step 10300: 0.157983
2025-12-13 11:35:57,399 INFO     Training average loss at step 10300: 0.469362
2025-12-13 11:36:02,672 INFO     Training average regularization at step 10400: 0.321858
2025-12-13 11:36:02,672 INFO     Training average positive_sample_loss at step 10400: 0.133884
2025-12-13 11:36:02,672 INFO     Training average negative_sample_loss at step 10400: 0.157752
2025-12-13 11:36:02,672 INFO     Training average loss at step 10400: 0.467676
2025-12-13 11:36:08,258 INFO     Training average regularization at step 10500: 0.322252
2025-12-13 11:36:08,259 INFO     Training average positive_sample_loss at step 10500: 0.139684
2025-12-13 11:36:08,259 INFO     Training average negative_sample_loss at step 10500: 0.160625
2025-12-13 11:36:08,259 INFO     Training average loss at step 10500: 0.472406
2025-12-13 11:36:13,617 INFO     Training average regularization at step 10600: 0.322734
2025-12-13 11:36:13,617 INFO     Training average positive_sample_loss at step 10600: 0.146645
2025-12-13 11:36:13,617 INFO     Training average negative_sample_loss at step 10600: 0.164943
2025-12-13 11:36:13,617 INFO     Training average loss at step 10600: 0.478529
2025-12-13 11:36:18,919 INFO     Training average regularization at step 10700: 0.323279
2025-12-13 11:36:18,919 INFO     Training average positive_sample_loss at step 10700: 0.145179
2025-12-13 11:36:18,919 INFO     Training average negative_sample_loss at step 10700: 0.162144
2025-12-13 11:36:18,919 INFO     Training average loss at step 10700: 0.476941
2025-12-13 11:36:24,199 INFO     Training average regularization at step 10800: 0.323850
2025-12-13 11:36:24,199 INFO     Training average positive_sample_loss at step 10800: 0.139348
2025-12-13 11:36:24,199 INFO     Training average negative_sample_loss at step 10800: 0.162611
2025-12-13 11:36:24,199 INFO     Training average loss at step 10800: 0.474829
2025-12-13 11:36:29,643 INFO     Training average regularization at step 10900: 0.324329
2025-12-13 11:36:29,643 INFO     Training average positive_sample_loss at step 10900: 0.147277
2025-12-13 11:36:29,643 INFO     Training average negative_sample_loss at step 10900: 0.163946
2025-12-13 11:36:29,643 INFO     Training average loss at step 10900: 0.479941
2025-12-13 11:36:34,880 INFO     Training average regularization at step 11000: 0.324964
2025-12-13 11:36:34,881 INFO     Training average positive_sample_loss at step 11000: 0.142177
2025-12-13 11:36:34,881 INFO     Training average negative_sample_loss at step 11000: 0.163627
2025-12-13 11:36:34,881 INFO     Training average loss at step 11000: 0.477866
2025-12-13 11:36:40,071 INFO     Training average regularization at step 11100: 0.325474
2025-12-13 11:36:40,072 INFO     Training average positive_sample_loss at step 11100: 0.146477
2025-12-13 11:36:40,072 INFO     Training average negative_sample_loss at step 11100: 0.167688
2025-12-13 11:36:40,072 INFO     Training average loss at step 11100: 0.482556
2025-12-13 11:36:45,313 INFO     Training average regularization at step 11200: 0.326134
2025-12-13 11:36:45,313 INFO     Training average positive_sample_loss at step 11200: 0.146452
2025-12-13 11:36:45,314 INFO     Training average negative_sample_loss at step 11200: 0.165079
2025-12-13 11:36:45,314 INFO     Training average loss at step 11200: 0.481900
2025-12-13 11:36:50,721 INFO     Training average regularization at step 11300: 0.326744
2025-12-13 11:36:50,721 INFO     Training average positive_sample_loss at step 11300: 0.156456
2025-12-13 11:36:50,721 INFO     Training average negative_sample_loss at step 11300: 0.169812
2025-12-13 11:36:50,721 INFO     Training average loss at step 11300: 0.489878
2025-12-13 11:36:55,891 INFO     Training average regularization at step 11400: 0.327235
2025-12-13 11:36:55,891 INFO     Training average positive_sample_loss at step 11400: 0.149253
2025-12-13 11:36:55,892 INFO     Training average negative_sample_loss at step 11400: 0.173308
2025-12-13 11:36:55,892 INFO     Training average loss at step 11400: 0.488515
2025-12-13 11:37:01,105 INFO     Training average regularization at step 11500: 0.327672
2025-12-13 11:37:01,105 INFO     Training average positive_sample_loss at step 11500: 0.145847
2025-12-13 11:37:01,105 INFO     Training average negative_sample_loss at step 11500: 0.172632
2025-12-13 11:37:01,105 INFO     Training average loss at step 11500: 0.486911
2025-12-13 11:37:06,398 INFO     Training average regularization at step 11600: 0.328156
2025-12-13 11:37:06,398 INFO     Training average positive_sample_loss at step 11600: 0.145409
2025-12-13 11:37:06,398 INFO     Training average negative_sample_loss at step 11600: 0.171185
2025-12-13 11:37:06,398 INFO     Training average loss at step 11600: 0.486453
2025-12-13 11:37:11,910 INFO     Training average regularization at step 11700: 0.328553
2025-12-13 11:37:11,910 INFO     Training average positive_sample_loss at step 11700: 0.145763
2025-12-13 11:37:11,910 INFO     Training average negative_sample_loss at step 11700: 0.164284
2025-12-13 11:37:11,910 INFO     Training average loss at step 11700: 0.483576
2025-12-13 11:37:17,294 INFO     Training average regularization at step 11800: 0.328915
2025-12-13 11:37:17,295 INFO     Training average positive_sample_loss at step 11800: 0.147470
2025-12-13 11:37:17,295 INFO     Training average negative_sample_loss at step 11800: 0.164438
2025-12-13 11:37:17,295 INFO     Training average loss at step 11800: 0.484869
2025-12-13 11:37:22,678 INFO     Training average regularization at step 11900: 0.329426
2025-12-13 11:37:22,678 INFO     Training average positive_sample_loss at step 11900: 0.145123
2025-12-13 11:37:22,678 INFO     Training average negative_sample_loss at step 11900: 0.160199
2025-12-13 11:37:22,678 INFO     Training average loss at step 11900: 0.482088
2025-12-13 11:37:28,087 INFO     Training average regularization at step 12000: 0.329946
2025-12-13 11:37:28,088 INFO     Training average positive_sample_loss at step 12000: 0.151693
2025-12-13 11:37:28,088 INFO     Training average negative_sample_loss at step 12000: 0.169251
2025-12-13 11:37:28,088 INFO     Training average loss at step 12000: 0.490418
2025-12-13 11:37:33,498 INFO     Training average regularization at step 12100: 0.330387
2025-12-13 11:37:33,498 INFO     Training average positive_sample_loss at step 12100: 0.141123
2025-12-13 11:37:33,498 INFO     Training average negative_sample_loss at step 12100: 0.166014
2025-12-13 11:37:33,498 INFO     Training average loss at step 12100: 0.483955
2025-12-13 11:37:39,380 INFO     Training average regularization at step 12200: 0.330624
2025-12-13 11:37:39,381 INFO     Training average positive_sample_loss at step 12200: 0.142303
2025-12-13 11:37:39,381 INFO     Training average negative_sample_loss at step 12200: 0.169237
2025-12-13 11:37:39,381 INFO     Training average loss at step 12200: 0.486394
2025-12-13 11:37:44,840 INFO     Training average regularization at step 12300: 0.331209
2025-12-13 11:37:44,840 INFO     Training average positive_sample_loss at step 12300: 0.146618
2025-12-13 11:37:44,840 INFO     Training average negative_sample_loss at step 12300: 0.166335
2025-12-13 11:37:44,840 INFO     Training average loss at step 12300: 0.487686
2025-12-13 11:37:50,081 INFO     Training average regularization at step 12400: 0.331630
2025-12-13 11:37:50,082 INFO     Training average positive_sample_loss at step 12400: 0.145476
2025-12-13 11:37:50,082 INFO     Training average negative_sample_loss at step 12400: 0.163869
2025-12-13 11:37:50,082 INFO     Training average loss at step 12400: 0.486303
2025-12-13 11:37:55,363 INFO     Training average regularization at step 12500: 0.332074
2025-12-13 11:37:55,363 INFO     Training average positive_sample_loss at step 12500: 0.140420
2025-12-13 11:37:55,363 INFO     Training average negative_sample_loss at step 12500: 0.166232
2025-12-13 11:37:55,363 INFO     Training average loss at step 12500: 0.485400
2025-12-13 11:38:00,734 INFO     Training average regularization at step 12600: 0.332414
2025-12-13 11:38:00,735 INFO     Training average positive_sample_loss at step 12600: 0.145063
2025-12-13 11:38:00,735 INFO     Training average negative_sample_loss at step 12600: 0.168289
2025-12-13 11:38:00,735 INFO     Training average loss at step 12600: 0.489090
2025-12-13 11:38:05,929 INFO     Training average regularization at step 12700: 0.332823
2025-12-13 11:38:05,929 INFO     Training average positive_sample_loss at step 12700: 0.144343
2025-12-13 11:38:05,929 INFO     Training average negative_sample_loss at step 12700: 0.164087
2025-12-13 11:38:05,929 INFO     Training average loss at step 12700: 0.487038
2025-12-13 11:38:11,172 INFO     Training average regularization at step 12800: 0.333232
2025-12-13 11:38:11,189 INFO     Training average positive_sample_loss at step 12800: 0.146120
2025-12-13 11:38:11,189 INFO     Training average negative_sample_loss at step 12800: 0.164852
2025-12-13 11:38:11,189 INFO     Training average loss at step 12800: 0.488718
2025-12-13 11:38:16,490 INFO     Training average regularization at step 12900: 0.333665
2025-12-13 11:38:16,491 INFO     Training average positive_sample_loss at step 12900: 0.150299
2025-12-13 11:38:16,491 INFO     Training average negative_sample_loss at step 12900: 0.168305
2025-12-13 11:38:16,491 INFO     Training average loss at step 12900: 0.492967
2025-12-13 11:38:21,786 INFO     Training average regularization at step 13000: 0.334058
2025-12-13 11:38:21,787 INFO     Training average positive_sample_loss at step 13000: 0.146191
2025-12-13 11:38:21,787 INFO     Training average negative_sample_loss at step 13000: 0.161640
2025-12-13 11:38:21,787 INFO     Training average loss at step 13000: 0.487973
2025-12-13 11:38:27,207 INFO     Training average regularization at step 13100: 0.334270
2025-12-13 11:38:27,207 INFO     Training average positive_sample_loss at step 13100: 0.147893
2025-12-13 11:38:27,208 INFO     Training average negative_sample_loss at step 13100: 0.169075
2025-12-13 11:38:27,208 INFO     Training average loss at step 13100: 0.492755
2025-12-13 11:38:32,571 INFO     Training average regularization at step 13200: 0.334644
2025-12-13 11:38:32,571 INFO     Training average positive_sample_loss at step 13200: 0.135978
2025-12-13 11:38:32,571 INFO     Training average negative_sample_loss at step 13200: 0.152590
2025-12-13 11:38:32,571 INFO     Training average loss at step 13200: 0.478928
2025-12-13 11:38:37,983 INFO     Training average regularization at step 13300: 0.334877
2025-12-13 11:38:37,984 INFO     Training average positive_sample_loss at step 13300: 0.142277
2025-12-13 11:38:37,984 INFO     Training average negative_sample_loss at step 13300: 0.166812
2025-12-13 11:38:37,984 INFO     Training average loss at step 13300: 0.489421
2025-12-13 11:38:43,487 INFO     Training average regularization at step 13400: 0.335207
2025-12-13 11:38:43,488 INFO     Training average positive_sample_loss at step 13400: 0.149517
2025-12-13 11:38:43,488 INFO     Training average negative_sample_loss at step 13400: 0.155430
2025-12-13 11:38:43,488 INFO     Training average loss at step 13400: 0.487681
2025-12-13 11:38:49,124 INFO     Training average regularization at step 13500: 0.335375
2025-12-13 11:38:49,124 INFO     Training average positive_sample_loss at step 13500: 0.137515
2025-12-13 11:38:49,124 INFO     Training average negative_sample_loss at step 13500: 0.160793
2025-12-13 11:38:49,124 INFO     Training average loss at step 13500: 0.484529
2025-12-13 11:38:54,347 INFO     Training average regularization at step 13600: 0.335475
2025-12-13 11:38:54,347 INFO     Training average positive_sample_loss at step 13600: 0.148812
2025-12-13 11:38:54,347 INFO     Training average negative_sample_loss at step 13600: 0.160126
2025-12-13 11:38:54,347 INFO     Training average loss at step 13600: 0.489944
2025-12-13 11:38:59,440 INFO     Training average regularization at step 13700: 0.335475
2025-12-13 11:38:59,441 INFO     Training average positive_sample_loss at step 13700: 0.135700
2025-12-13 11:38:59,441 INFO     Training average negative_sample_loss at step 13700: 0.166113
2025-12-13 11:38:59,441 INFO     Training average loss at step 13700: 0.486381
2025-12-13 11:39:04,674 INFO     Training average regularization at step 13800: 0.335574
2025-12-13 11:39:04,675 INFO     Training average positive_sample_loss at step 13800: 0.135361
2025-12-13 11:39:04,675 INFO     Training average negative_sample_loss at step 13800: 0.154859
2025-12-13 11:39:04,675 INFO     Training average loss at step 13800: 0.480684
2025-12-13 11:39:09,823 INFO     Training average regularization at step 13900: 0.335839
2025-12-13 11:39:09,824 INFO     Training average positive_sample_loss at step 13900: 0.139781
2025-12-13 11:39:09,824 INFO     Training average negative_sample_loss at step 13900: 0.161376
2025-12-13 11:39:09,824 INFO     Training average loss at step 13900: 0.486418
2025-12-13 11:39:14,977 INFO     Training average regularization at step 14000: 0.336143
2025-12-13 11:39:14,978 INFO     Training average positive_sample_loss at step 14000: 0.144442
2025-12-13 11:39:14,978 INFO     Training average negative_sample_loss at step 14000: 0.163637
2025-12-13 11:39:14,978 INFO     Training average loss at step 14000: 0.490182
2025-12-13 11:39:20,038 INFO     Training average regularization at step 14100: 0.336381
2025-12-13 11:39:20,038 INFO     Training average positive_sample_loss at step 14100: 0.143946
2025-12-13 11:39:20,038 INFO     Training average negative_sample_loss at step 14100: 0.159711
2025-12-13 11:39:20,038 INFO     Training average loss at step 14100: 0.488209
2025-12-13 11:39:25,208 INFO     Training average regularization at step 14200: 0.336625
2025-12-13 11:39:25,209 INFO     Training average positive_sample_loss at step 14200: 0.136437
2025-12-13 11:39:25,209 INFO     Training average negative_sample_loss at step 14200: 0.155989
2025-12-13 11:39:25,209 INFO     Training average loss at step 14200: 0.482838
2025-12-13 11:39:30,444 INFO     Training average regularization at step 14300: 0.336809
2025-12-13 11:39:30,444 INFO     Training average positive_sample_loss at step 14300: 0.136165
2025-12-13 11:39:30,444 INFO     Training average negative_sample_loss at step 14300: 0.156400
2025-12-13 11:39:30,444 INFO     Training average loss at step 14300: 0.483092
2025-12-13 11:39:35,544 INFO     Training average regularization at step 14400: 0.336949
2025-12-13 11:39:35,544 INFO     Training average positive_sample_loss at step 14400: 0.137954
2025-12-13 11:39:35,544 INFO     Training average negative_sample_loss at step 14400: 0.158000
2025-12-13 11:39:35,544 INFO     Training average loss at step 14400: 0.484926
2025-12-13 11:39:41,628 INFO     Training average regularization at step 14500: 0.337123
2025-12-13 11:39:41,628 INFO     Training average positive_sample_loss at step 14500: 0.138637
2025-12-13 11:39:41,628 INFO     Training average negative_sample_loss at step 14500: 0.157440
2025-12-13 11:39:41,628 INFO     Training average loss at step 14500: 0.485161
2025-12-13 11:39:47,003 INFO     Training average regularization at step 14600: 0.336937
2025-12-13 11:39:47,004 INFO     Training average positive_sample_loss at step 14600: 0.108736
2025-12-13 11:39:47,004 INFO     Training average negative_sample_loss at step 14600: 0.129123
2025-12-13 11:39:47,004 INFO     Training average loss at step 14600: 0.455867
2025-12-13 11:39:52,415 INFO     Training average regularization at step 14700: 0.336477
2025-12-13 11:39:52,416 INFO     Training average positive_sample_loss at step 14700: 0.113404
2025-12-13 11:39:52,416 INFO     Training average negative_sample_loss at step 14700: 0.138723
2025-12-13 11:39:52,416 INFO     Training average loss at step 14700: 0.462540
2025-12-13 11:39:57,850 INFO     Training average regularization at step 14800: 0.336169
2025-12-13 11:39:57,850 INFO     Training average positive_sample_loss at step 14800: 0.115642
2025-12-13 11:39:57,850 INFO     Training average negative_sample_loss at step 14800: 0.136564
2025-12-13 11:39:57,850 INFO     Training average loss at step 14800: 0.462272
2025-12-13 11:40:03,170 INFO     Training average regularization at step 14900: 0.336068
2025-12-13 11:40:03,170 INFO     Training average positive_sample_loss at step 14900: 0.118436
2025-12-13 11:40:03,171 INFO     Training average negative_sample_loss at step 14900: 0.136660
2025-12-13 11:40:03,171 INFO     Training average loss at step 14900: 0.463616
2025-12-13 11:40:08,468 INFO     Training average regularization at step 15000: 0.335970
2025-12-13 11:40:08,469 INFO     Training average positive_sample_loss at step 15000: 0.122803
2025-12-13 11:40:08,469 INFO     Training average negative_sample_loss at step 15000: 0.135668
2025-12-13 11:40:08,469 INFO     Training average loss at step 15000: 0.465206
2025-12-13 11:40:13,630 INFO     Training average regularization at step 15100: 0.335800
2025-12-13 11:40:13,631 INFO     Training average positive_sample_loss at step 15100: 0.119537
2025-12-13 11:40:13,631 INFO     Training average negative_sample_loss at step 15100: 0.140854
2025-12-13 11:40:13,631 INFO     Training average loss at step 15100: 0.465995
2025-12-13 11:40:18,939 INFO     Training average regularization at step 15200: 0.335773
2025-12-13 11:40:18,940 INFO     Training average positive_sample_loss at step 15200: 0.121743
2025-12-13 11:40:18,940 INFO     Training average negative_sample_loss at step 15200: 0.137473
2025-12-13 11:40:18,940 INFO     Training average loss at step 15200: 0.465382
2025-12-13 11:40:24,343 INFO     Training average regularization at step 15300: 0.335809
2025-12-13 11:40:24,343 INFO     Training average positive_sample_loss at step 15300: 0.121460
2025-12-13 11:40:24,343 INFO     Training average negative_sample_loss at step 15300: 0.131760
2025-12-13 11:40:24,343 INFO     Training average loss at step 15300: 0.462419
2025-12-13 11:40:29,691 INFO     Training average regularization at step 15400: 0.335977
2025-12-13 11:40:29,692 INFO     Training average positive_sample_loss at step 15400: 0.116648
2025-12-13 11:40:29,692 INFO     Training average negative_sample_loss at step 15400: 0.140119
2025-12-13 11:40:29,692 INFO     Training average loss at step 15400: 0.464361
2025-12-13 11:40:35,047 INFO     Training average regularization at step 15500: 0.336190
2025-12-13 11:40:35,047 INFO     Training average positive_sample_loss at step 15500: 0.121197
2025-12-13 11:40:35,047 INFO     Training average negative_sample_loss at step 15500: 0.142866
2025-12-13 11:40:35,047 INFO     Training average loss at step 15500: 0.468222
2025-12-13 11:40:40,359 INFO     Training average regularization at step 15600: 0.336493
2025-12-13 11:40:40,362 INFO     Training average positive_sample_loss at step 15600: 0.127736
2025-12-13 11:40:40,362 INFO     Training average negative_sample_loss at step 15600: 0.135565
2025-12-13 11:40:40,362 INFO     Training average loss at step 15600: 0.468144
2025-12-13 11:40:45,701 INFO     Training average regularization at step 15700: 0.336701
2025-12-13 11:40:45,702 INFO     Training average positive_sample_loss at step 15700: 0.124098
2025-12-13 11:40:45,702 INFO     Training average negative_sample_loss at step 15700: 0.146728
2025-12-13 11:40:45,702 INFO     Training average loss at step 15700: 0.472114
2025-12-13 11:40:50,990 INFO     Training average regularization at step 15800: 0.336922
2025-12-13 11:40:50,990 INFO     Training average positive_sample_loss at step 15800: 0.129497
2025-12-13 11:40:50,990 INFO     Training average negative_sample_loss at step 15800: 0.140666
2025-12-13 11:40:50,991 INFO     Training average loss at step 15800: 0.472003
2025-12-13 11:40:56,222 INFO     Training average regularization at step 15900: 0.337200
2025-12-13 11:40:56,224 INFO     Training average positive_sample_loss at step 15900: 0.133017
2025-12-13 11:40:56,224 INFO     Training average negative_sample_loss at step 15900: 0.147534
2025-12-13 11:40:56,224 INFO     Training average loss at step 15900: 0.477475
2025-12-13 11:41:01,655 INFO     Training average regularization at step 16000: 0.337507
2025-12-13 11:41:01,656 INFO     Training average positive_sample_loss at step 16000: 0.126853
2025-12-13 11:41:01,656 INFO     Training average negative_sample_loss at step 16000: 0.145611
2025-12-13 11:41:01,656 INFO     Training average loss at step 16000: 0.473739
2025-12-13 11:41:06,945 INFO     Training average regularization at step 16100: 0.337578
2025-12-13 11:41:06,945 INFO     Training average positive_sample_loss at step 16100: 0.126928
2025-12-13 11:41:06,945 INFO     Training average negative_sample_loss at step 16100: 0.149015
2025-12-13 11:41:06,946 INFO     Training average loss at step 16100: 0.475550
2025-12-13 11:41:12,272 INFO     Training average regularization at step 16200: 0.337946
2025-12-13 11:41:12,272 INFO     Training average positive_sample_loss at step 16200: 0.136363
2025-12-13 11:41:12,272 INFO     Training average negative_sample_loss at step 16200: 0.146994
2025-12-13 11:41:12,272 INFO     Training average loss at step 16200: 0.479624
2025-12-13 11:41:17,658 INFO     Training average regularization at step 16300: 0.338251
2025-12-13 11:41:17,658 INFO     Training average positive_sample_loss at step 16300: 0.136584
2025-12-13 11:41:17,658 INFO     Training average negative_sample_loss at step 16300: 0.156468
2025-12-13 11:41:17,659 INFO     Training average loss at step 16300: 0.484777
2025-12-13 11:41:22,995 INFO     Training average regularization at step 16400: 0.338530
2025-12-13 11:41:22,995 INFO     Training average positive_sample_loss at step 16400: 0.127723
2025-12-13 11:41:22,995 INFO     Training average negative_sample_loss at step 16400: 0.150703
2025-12-13 11:41:22,995 INFO     Training average loss at step 16400: 0.477743
2025-12-13 11:41:28,232 INFO     Training average regularization at step 16500: 0.338945
2025-12-13 11:41:28,234 INFO     Training average positive_sample_loss at step 16500: 0.135350
2025-12-13 11:41:28,234 INFO     Training average negative_sample_loss at step 16500: 0.151070
2025-12-13 11:41:28,234 INFO     Training average loss at step 16500: 0.482155
2025-12-13 11:41:33,780 INFO     Training average regularization at step 16600: 0.339449
2025-12-13 11:41:33,781 INFO     Training average positive_sample_loss at step 16600: 0.133663
2025-12-13 11:41:33,781 INFO     Training average negative_sample_loss at step 16600: 0.150076
2025-12-13 11:41:33,781 INFO     Training average loss at step 16600: 0.481318
2025-12-13 11:41:39,106 INFO     Training average regularization at step 16700: 0.339788
2025-12-13 11:41:39,106 INFO     Training average positive_sample_loss at step 16700: 0.133995
2025-12-13 11:41:39,106 INFO     Training average negative_sample_loss at step 16700: 0.154566
2025-12-13 11:41:39,106 INFO     Training average loss at step 16700: 0.484068
2025-12-13 11:41:44,405 INFO     Training average regularization at step 16800: 0.340176
2025-12-13 11:41:44,405 INFO     Training average positive_sample_loss at step 16800: 0.137084
2025-12-13 11:41:44,405 INFO     Training average negative_sample_loss at step 16800: 0.148554
2025-12-13 11:41:44,405 INFO     Training average loss at step 16800: 0.482996
2025-12-13 11:41:49,608 INFO     Training average regularization at step 16900: 0.340388
2025-12-13 11:41:49,608 INFO     Training average positive_sample_loss at step 16900: 0.130039
2025-12-13 11:41:49,608 INFO     Training average negative_sample_loss at step 16900: 0.148624
2025-12-13 11:41:49,609 INFO     Training average loss at step 16900: 0.479720
2025-12-13 11:41:54,868 INFO     Training average regularization at step 17000: 0.340600
2025-12-13 11:41:54,868 INFO     Training average positive_sample_loss at step 17000: 0.134683
2025-12-13 11:41:54,868 INFO     Training average negative_sample_loss at step 17000: 0.154177
2025-12-13 11:41:54,868 INFO     Training average loss at step 17000: 0.485030
2025-12-13 11:42:00,370 INFO     Training average regularization at step 17100: 0.341088
2025-12-13 11:42:00,371 INFO     Training average positive_sample_loss at step 17100: 0.133861
2025-12-13 11:42:00,371 INFO     Training average negative_sample_loss at step 17100: 0.148870
2025-12-13 11:42:00,371 INFO     Training average loss at step 17100: 0.482454
2025-12-13 11:42:05,615 INFO     Training average regularization at step 17200: 0.341399
2025-12-13 11:42:05,616 INFO     Training average positive_sample_loss at step 17200: 0.138316
2025-12-13 11:42:05,616 INFO     Training average negative_sample_loss at step 17200: 0.147967
2025-12-13 11:42:05,616 INFO     Training average loss at step 17200: 0.484540
2025-12-13 11:42:11,119 INFO     Training average regularization at step 17300: 0.341674
2025-12-13 11:42:11,120 INFO     Training average positive_sample_loss at step 17300: 0.134000
2025-12-13 11:42:11,120 INFO     Training average negative_sample_loss at step 17300: 0.157122
2025-12-13 11:42:11,120 INFO     Training average loss at step 17300: 0.487235
2025-12-13 11:42:16,472 INFO     Training average regularization at step 17400: 0.341809
2025-12-13 11:42:16,472 INFO     Training average positive_sample_loss at step 17400: 0.126435
2025-12-13 11:42:16,472 INFO     Training average negative_sample_loss at step 17400: 0.149842
2025-12-13 11:42:16,472 INFO     Training average loss at step 17400: 0.479948
2025-12-13 11:42:21,832 INFO     Training average regularization at step 17500: 0.341991
2025-12-13 11:42:21,833 INFO     Training average positive_sample_loss at step 17500: 0.129485
2025-12-13 11:42:21,833 INFO     Training average negative_sample_loss at step 17500: 0.146526
2025-12-13 11:42:21,833 INFO     Training average loss at step 17500: 0.479997
2025-12-13 11:42:27,181 INFO     Training average regularization at step 17600: 0.342150
2025-12-13 11:42:27,181 INFO     Training average positive_sample_loss at step 17600: 0.132999
2025-12-13 11:42:27,181 INFO     Training average negative_sample_loss at step 17600: 0.151913
2025-12-13 11:42:27,181 INFO     Training average loss at step 17600: 0.484606
2025-12-13 11:42:32,492 INFO     Training average regularization at step 17700: 0.342288
2025-12-13 11:42:32,492 INFO     Training average positive_sample_loss at step 17700: 0.134532
2025-12-13 11:42:32,493 INFO     Training average negative_sample_loss at step 17700: 0.148626
2025-12-13 11:42:32,493 INFO     Training average loss at step 17700: 0.483867
2025-12-13 11:42:37,917 INFO     Training average regularization at step 17800: 0.342489
2025-12-13 11:42:37,917 INFO     Training average positive_sample_loss at step 17800: 0.131001
2025-12-13 11:42:37,917 INFO     Training average negative_sample_loss at step 17800: 0.149055
2025-12-13 11:42:37,917 INFO     Training average loss at step 17800: 0.482517
2025-12-13 11:42:43,319 INFO     Training average regularization at step 17900: 0.342635
2025-12-13 11:42:43,319 INFO     Training average positive_sample_loss at step 17900: 0.128183
2025-12-13 11:42:43,319 INFO     Training average negative_sample_loss at step 17900: 0.149169
2025-12-13 11:42:43,319 INFO     Training average loss at step 17900: 0.481311
2025-12-13 11:42:48,571 INFO     Training average regularization at step 18000: 0.342754
2025-12-13 11:42:48,572 INFO     Training average positive_sample_loss at step 18000: 0.136620
2025-12-13 11:42:48,572 INFO     Training average negative_sample_loss at step 18000: 0.149473
2025-12-13 11:42:48,572 INFO     Training average loss at step 18000: 0.485800
2025-12-13 11:42:53,955 INFO     Training average regularization at step 18100: 0.342958
2025-12-13 11:42:53,955 INFO     Training average positive_sample_loss at step 18100: 0.128595
2025-12-13 11:42:53,955 INFO     Training average negative_sample_loss at step 18100: 0.142111
2025-12-13 11:42:53,955 INFO     Training average loss at step 18100: 0.478311
2025-12-13 11:42:59,350 INFO     Training average regularization at step 18200: 0.343230
2025-12-13 11:42:59,350 INFO     Training average positive_sample_loss at step 18200: 0.134781
2025-12-13 11:42:59,350 INFO     Training average negative_sample_loss at step 18200: 0.153250
2025-12-13 11:42:59,350 INFO     Training average loss at step 18200: 0.487245
2025-12-13 11:43:04,649 INFO     Training average regularization at step 18300: 0.343403
2025-12-13 11:43:04,649 INFO     Training average positive_sample_loss at step 18300: 0.124387
2025-12-13 11:43:04,650 INFO     Training average negative_sample_loss at step 18300: 0.149919
2025-12-13 11:43:04,650 INFO     Training average loss at step 18300: 0.480556
2025-12-13 11:43:09,973 INFO     Training average regularization at step 18400: 0.343459
2025-12-13 11:43:09,974 INFO     Training average positive_sample_loss at step 18400: 0.128643
2025-12-13 11:43:09,974 INFO     Training average negative_sample_loss at step 18400: 0.143729
2025-12-13 11:43:09,974 INFO     Training average loss at step 18400: 0.479645
2025-12-13 11:43:15,408 INFO     Training average regularization at step 18500: 0.343581
2025-12-13 11:43:15,409 INFO     Training average positive_sample_loss at step 18500: 0.133830
2025-12-13 11:43:15,409 INFO     Training average negative_sample_loss at step 18500: 0.150104
2025-12-13 11:43:15,409 INFO     Training average loss at step 18500: 0.485548
2025-12-13 11:43:20,746 INFO     Training average regularization at step 18600: 0.343704
2025-12-13 11:43:20,746 INFO     Training average positive_sample_loss at step 18600: 0.128623
2025-12-13 11:43:20,746 INFO     Training average negative_sample_loss at step 18600: 0.136024
2025-12-13 11:43:20,746 INFO     Training average loss at step 18600: 0.476028
2025-12-13 11:43:26,006 INFO     Training average regularization at step 18700: 0.343648
2025-12-13 11:43:26,007 INFO     Training average positive_sample_loss at step 18700: 0.127327
2025-12-13 11:43:26,007 INFO     Training average negative_sample_loss at step 18700: 0.146231
2025-12-13 11:43:26,007 INFO     Training average loss at step 18700: 0.480427
2025-12-13 11:43:31,397 INFO     Training average regularization at step 18800: 0.343721
2025-12-13 11:43:31,397 INFO     Training average positive_sample_loss at step 18800: 0.131443
2025-12-13 11:43:31,397 INFO     Training average negative_sample_loss at step 18800: 0.146806
2025-12-13 11:43:31,398 INFO     Training average loss at step 18800: 0.482845
2025-12-13 11:43:36,712 INFO     Training average regularization at step 18900: 0.343817
2025-12-13 11:43:36,713 INFO     Training average positive_sample_loss at step 18900: 0.124382
2025-12-13 11:43:36,713 INFO     Training average negative_sample_loss at step 18900: 0.137311
2025-12-13 11:43:36,713 INFO     Training average loss at step 18900: 0.474663
2025-12-13 11:43:41,945 INFO     Training average regularization at step 19000: 0.343789
2025-12-13 11:43:41,946 INFO     Training average positive_sample_loss at step 19000: 0.122939
2025-12-13 11:43:41,946 INFO     Training average negative_sample_loss at step 19000: 0.143126
2025-12-13 11:43:41,946 INFO     Training average loss at step 19000: 0.476821
2025-12-13 11:43:47,343 INFO     Training average regularization at step 19100: 0.343931
2025-12-13 11:43:47,344 INFO     Training average positive_sample_loss at step 19100: 0.121939
2025-12-13 11:43:47,344 INFO     Training average negative_sample_loss at step 19100: 0.143763
2025-12-13 11:43:47,344 INFO     Training average loss at step 19100: 0.476782
2025-12-13 11:43:52,718 INFO     Training average regularization at step 19200: 0.344044
2025-12-13 11:43:52,719 INFO     Training average positive_sample_loss at step 19200: 0.130477
2025-12-13 11:43:52,719 INFO     Training average negative_sample_loss at step 19200: 0.141010
2025-12-13 11:43:52,719 INFO     Training average loss at step 19200: 0.479787
2025-12-13 11:43:58,130 INFO     Training average regularization at step 19300: 0.344181
2025-12-13 11:43:58,135 INFO     Training average positive_sample_loss at step 19300: 0.128375
2025-12-13 11:43:58,135 INFO     Training average negative_sample_loss at step 19300: 0.139597
2025-12-13 11:43:58,135 INFO     Training average loss at step 19300: 0.478167
2025-12-13 11:44:04,672 INFO     Training average regularization at step 19400: 0.344141
2025-12-13 11:44:04,673 INFO     Training average positive_sample_loss at step 19400: 0.103597
2025-12-13 11:44:04,673 INFO     Training average negative_sample_loss at step 19400: 0.128337
2025-12-13 11:44:04,673 INFO     Training average loss at step 19400: 0.460108
2025-12-13 11:44:09,914 INFO     Training average regularization at step 19500: 0.343740
2025-12-13 11:44:09,914 INFO     Training average positive_sample_loss at step 19500: 0.113633
2025-12-13 11:44:09,914 INFO     Training average negative_sample_loss at step 19500: 0.123444
2025-12-13 11:44:09,914 INFO     Training average loss at step 19500: 0.462279
2025-12-13 11:44:15,188 INFO     Training average regularization at step 19600: 0.343490
2025-12-13 11:44:15,189 INFO     Training average positive_sample_loss at step 19600: 0.107976
2025-12-13 11:44:15,189 INFO     Training average negative_sample_loss at step 19600: 0.116884
2025-12-13 11:44:15,189 INFO     Training average loss at step 19600: 0.455920
2025-12-13 11:44:20,687 INFO     Training average regularization at step 19700: 0.343037
2025-12-13 11:44:20,687 INFO     Training average positive_sample_loss at step 19700: 0.102436
2025-12-13 11:44:20,687 INFO     Training average negative_sample_loss at step 19700: 0.121869
2025-12-13 11:44:20,687 INFO     Training average loss at step 19700: 0.455190
2025-12-13 11:44:25,920 INFO     Training average regularization at step 19800: 0.342762
2025-12-13 11:44:25,920 INFO     Training average positive_sample_loss at step 19800: 0.105878
2025-12-13 11:44:25,920 INFO     Training average negative_sample_loss at step 19800: 0.116388
2025-12-13 11:44:25,920 INFO     Training average loss at step 19800: 0.453894
2025-12-13 11:44:31,295 INFO     Training average regularization at step 19900: 0.342610
2025-12-13 11:44:31,295 INFO     Training average positive_sample_loss at step 19900: 0.110497
2025-12-13 11:44:31,295 INFO     Training average negative_sample_loss at step 19900: 0.122161
2025-12-13 11:44:31,295 INFO     Training average loss at step 19900: 0.458939
2025-12-13 11:44:36,591 INFO     Change learning_rate to 0.000259 at step 20000
2025-12-13 11:44:37,585 INFO     Training average regularization at step 20000: 0.342526
2025-12-13 11:44:37,586 INFO     Training average positive_sample_loss at step 20000: 0.111514
2025-12-13 11:44:37,586 INFO     Training average negative_sample_loss at step 20000: 0.125457
2025-12-13 11:44:37,586 INFO     Training average loss at step 20000: 0.461012
2025-12-13 11:44:37,586 INFO     Evaluating on Valid Dataset...
2025-12-13 11:44:38,405 INFO     Evaluating the model... (0/50000)
2025-12-13 11:44:43,520 INFO     Evaluating the model... (500/50000)
2025-12-13 11:44:48,296 INFO     Evaluating the model... (1000/50000)
2025-12-13 11:44:53,164 INFO     Evaluating the model... (1500/50000)
2025-12-13 11:44:59,365 INFO     Evaluating the model... (2000/50000)
2025-12-13 11:45:04,251 INFO     Evaluating the model... (2500/50000)
2025-12-13 11:45:09,401 INFO     Evaluating the model... (3000/50000)
2025-12-13 11:45:13,858 INFO     Evaluating the model... (3500/50000)
2025-12-13 11:45:18,272 INFO     Evaluating the model... (4000/50000)
2025-12-13 11:45:23,831 INFO     Evaluating the model... (4500/50000)
2025-12-13 11:45:28,350 INFO     Evaluating the model... (5000/50000)
2025-12-13 11:45:32,844 INFO     Evaluating the model... (5500/50000)
2025-12-13 11:45:37,296 INFO     Evaluating the model... (6000/50000)
2025-12-13 11:45:42,744 INFO     Evaluating the model... (6500/50000)
2025-12-13 11:45:47,444 INFO     Evaluating the model... (7000/50000)
2025-12-13 11:45:52,055 INFO     Evaluating the model... (7500/50000)
2025-12-13 11:45:56,940 INFO     Evaluating the model... (8000/50000)
2025-12-13 11:46:01,709 INFO     Evaluating the model... (8500/50000)
2025-12-13 11:46:07,509 INFO     Evaluating the model... (9000/50000)
2025-12-13 11:46:12,106 INFO     Evaluating the model... (9500/50000)
2025-12-13 11:46:16,584 INFO     Evaluating the model... (10000/50000)
2025-12-13 11:46:21,423 INFO     Evaluating the model... (10500/50000)
2025-12-13 11:46:26,400 INFO     Evaluating the model... (11000/50000)
2025-12-13 11:46:31,748 INFO     Evaluating the model... (11500/50000)
2025-12-13 11:46:36,334 INFO     Evaluating the model... (12000/50000)
2025-12-13 11:46:40,972 INFO     Evaluating the model... (12500/50000)
2025-12-13 11:46:45,557 INFO     Evaluating the model... (13000/50000)
2025-12-13 11:46:50,133 INFO     Evaluating the model... (13500/50000)
2025-12-13 11:46:55,361 INFO     Evaluating the model... (14000/50000)
2025-12-13 11:46:59,990 INFO     Evaluating the model... (14500/50000)
2025-12-13 11:47:04,443 INFO     Evaluating the model... (15000/50000)
2025-12-13 11:47:09,076 INFO     Evaluating the model... (15500/50000)
2025-12-13 11:47:13,572 INFO     Evaluating the model... (16000/50000)
2025-12-13 11:47:18,686 INFO     Evaluating the model... (16500/50000)
2025-12-13 11:47:22,927 INFO     Evaluating the model... (17000/50000)
2025-12-13 11:47:27,450 INFO     Evaluating the model... (17500/50000)
2025-12-13 11:47:31,812 INFO     Evaluating the model... (18000/50000)
2025-12-13 11:47:36,368 INFO     Evaluating the model... (18500/50000)
2025-12-13 11:47:41,452 INFO     Evaluating the model... (19000/50000)
2025-12-13 11:47:46,007 INFO     Evaluating the model... (19500/50000)
2025-12-13 11:47:50,529 INFO     Evaluating the model... (20000/50000)
2025-12-13 11:47:55,270 INFO     Evaluating the model... (20500/50000)
2025-12-13 11:47:59,863 INFO     Evaluating the model... (21000/50000)
2025-12-13 11:48:05,511 INFO     Evaluating the model... (21500/50000)
2025-12-13 11:48:10,007 INFO     Evaluating the model... (22000/50000)
2025-12-13 11:48:14,287 INFO     Evaluating the model... (22500/50000)
2025-12-13 11:48:18,681 INFO     Evaluating the model... (23000/50000)
2025-12-13 11:48:23,248 INFO     Evaluating the model... (23500/50000)
2025-12-13 11:48:28,683 INFO     Evaluating the model... (24000/50000)
2025-12-13 11:48:33,384 INFO     Evaluating the model... (24500/50000)
2025-12-13 11:48:38,428 INFO     Evaluating the model... (25000/50000)
2025-12-13 11:48:43,387 INFO     Evaluating the model... (25500/50000)
2025-12-13 11:48:48,415 INFO     Evaluating the model... (26000/50000)
2025-12-13 11:48:54,369 INFO     Evaluating the model... (26500/50000)
2025-12-13 11:48:59,165 INFO     Evaluating the model... (27000/50000)
2025-12-13 11:49:03,849 INFO     Evaluating the model... (27500/50000)
2025-12-13 11:49:08,599 INFO     Evaluating the model... (28000/50000)
2025-12-13 11:49:13,280 INFO     Evaluating the model... (28500/50000)
2025-12-13 11:49:18,668 INFO     Evaluating the model... (29000/50000)
2025-12-13 11:49:22,975 INFO     Evaluating the model... (29500/50000)
2025-12-13 11:49:27,443 INFO     Evaluating the model... (30000/50000)
2025-12-13 11:49:32,258 INFO     Evaluating the model... (30500/50000)
2025-12-13 11:49:36,714 INFO     Evaluating the model... (31000/50000)
2025-12-13 11:49:41,973 INFO     Evaluating the model... (31500/50000)
2025-12-13 11:49:46,444 INFO     Evaluating the model... (32000/50000)
2025-12-13 11:49:51,052 INFO     Evaluating the model... (32500/50000)
2025-12-13 11:49:55,619 INFO     Evaluating the model... (33000/50000)
2025-12-13 11:50:00,547 INFO     Evaluating the model... (33500/50000)
2025-12-13 11:50:05,003 INFO     Evaluating the model... (34000/50000)
2025-12-13 11:50:09,608 INFO     Evaluating the model... (34500/50000)
2025-12-13 11:50:13,974 INFO     Evaluating the model... (35000/50000)
2025-12-13 11:50:18,411 INFO     Evaluating the model... (35500/50000)
2025-12-13 11:50:23,409 INFO     Evaluating the model... (36000/50000)
2025-12-13 11:50:27,677 INFO     Evaluating the model... (36500/50000)
2025-12-13 11:50:31,862 INFO     Evaluating the model... (37000/50000)
2025-12-13 11:50:36,123 INFO     Evaluating the model... (37500/50000)
2025-12-13 11:50:40,329 INFO     Evaluating the model... (38000/50000)
2025-12-13 11:50:45,298 INFO     Evaluating the model... (38500/50000)
2025-12-13 11:50:49,572 INFO     Evaluating the model... (39000/50000)
2025-12-13 11:50:53,783 INFO     Evaluating the model... (39500/50000)
2025-12-13 11:50:58,197 INFO     Evaluating the model... (40000/50000)
2025-12-13 11:51:02,671 INFO     Evaluating the model... (40500/50000)
2025-12-13 11:51:07,956 INFO     Evaluating the model... (41000/50000)
2025-12-13 11:51:12,275 INFO     Evaluating the model... (41500/50000)
2025-12-13 11:51:16,559 INFO     Evaluating the model... (42000/50000)
2025-12-13 11:51:20,981 INFO     Evaluating the model... (42500/50000)
2025-12-13 11:51:25,431 INFO     Evaluating the model... (43000/50000)
2025-12-13 11:51:30,796 INFO     Evaluating the model... (43500/50000)
2025-12-13 11:51:34,988 INFO     Evaluating the model... (44000/50000)
2025-12-13 11:51:39,359 INFO     Evaluating the model... (44500/50000)
2025-12-13 11:51:43,790 INFO     Evaluating the model... (45000/50000)
2025-12-13 11:51:48,239 INFO     Evaluating the model... (45500/50000)
2025-12-13 11:51:53,648 INFO     Evaluating the model... (46000/50000)
2025-12-13 11:51:57,898 INFO     Evaluating the model... (46500/50000)
2025-12-13 11:52:02,118 INFO     Evaluating the model... (47000/50000)
2025-12-13 11:52:06,493 INFO     Evaluating the model... (47500/50000)
2025-12-13 11:52:10,791 INFO     Evaluating the model... (48000/50000)
2025-12-13 11:52:16,373 INFO     Evaluating the model... (48500/50000)
2025-12-13 11:52:20,913 INFO     Evaluating the model... (49000/50000)
2025-12-13 11:52:25,287 INFO     Evaluating the model... (49500/50000)
2025-12-13 11:52:30,249 INFO     Valid MRR at step 20000: 0.602556
2025-12-13 11:52:30,250 INFO     Valid MR at step 20000: 527.795390
2025-12-13 11:52:30,250 INFO     Valid HITS@1 at step 20000: 0.530570
2025-12-13 11:52:30,250 INFO     Valid HITS@3 at step 20000: 0.647190
2025-12-13 11:52:30,250 INFO     Valid HITS@10 at step 20000: 0.729720
2025-12-13 11:52:30,250 INFO     Evaluating on Test Dataset...
2025-12-13 11:52:30,831 INFO     Evaluating the model... (0/59072)
2025-12-13 11:52:35,807 INFO     Evaluating the model... (500/59072)
2025-12-13 11:52:41,880 INFO     Evaluating the model... (1000/59072)
2025-12-13 11:52:46,303 INFO     Evaluating the model... (1500/59072)
2025-12-13 11:52:51,017 INFO     Evaluating the model... (2000/59072)
2025-12-13 11:52:55,894 INFO     Evaluating the model... (2500/59072)
2025-12-13 11:53:00,399 INFO     Evaluating the model... (3000/59072)
2025-12-13 11:53:05,895 INFO     Evaluating the model... (3500/59072)
2025-12-13 11:53:10,402 INFO     Evaluating the model... (4000/59072)
2025-12-13 11:53:14,836 INFO     Evaluating the model... (4500/59072)
2025-12-13 11:53:19,342 INFO     Evaluating the model... (5000/59072)
2025-12-13 11:53:23,619 INFO     Evaluating the model... (5500/59072)
2025-12-13 11:53:29,051 INFO     Evaluating the model... (6000/59072)
2025-12-13 11:53:33,646 INFO     Evaluating the model... (6500/59072)
2025-12-13 11:53:38,428 INFO     Evaluating the model... (7000/59072)
2025-12-13 11:53:42,934 INFO     Evaluating the model... (7500/59072)
2025-12-13 11:53:47,288 INFO     Evaluating the model... (8000/59072)
2025-12-13 11:53:52,586 INFO     Evaluating the model... (8500/59072)
2025-12-13 11:53:57,042 INFO     Evaluating the model... (9000/59072)
2025-12-13 11:54:01,618 INFO     Evaluating the model... (9500/59072)
2025-12-13 11:54:06,339 INFO     Evaluating the model... (10000/59072)
2025-12-13 11:54:11,095 INFO     Evaluating the model... (10500/59072)
2025-12-13 11:54:16,563 INFO     Evaluating the model... (11000/59072)
2025-12-13 11:54:21,048 INFO     Evaluating the model... (11500/59072)
2025-12-13 11:54:25,945 INFO     Evaluating the model... (12000/59072)
2025-12-13 11:54:30,369 INFO     Evaluating the model... (12500/59072)
2025-12-13 11:54:35,929 INFO     Evaluating the model... (13000/59072)
2025-12-13 11:54:40,610 INFO     Evaluating the model... (13500/59072)
2025-12-13 11:54:45,326 INFO     Evaluating the model... (14000/59072)
2025-12-13 11:54:49,935 INFO     Evaluating the model... (14500/59072)
2025-12-13 11:54:54,733 INFO     Evaluating the model... (15000/59072)
2025-12-13 11:55:00,006 INFO     Evaluating the model... (15500/59072)
2025-12-13 11:55:04,442 INFO     Evaluating the model... (16000/59072)
2025-12-13 11:55:09,156 INFO     Evaluating the model... (16500/59072)
2025-12-13 11:55:13,513 INFO     Evaluating the model... (17000/59072)
2025-12-13 11:55:17,792 INFO     Evaluating the model... (17500/59072)
2025-12-13 11:55:23,304 INFO     Evaluating the model... (18000/59072)
2025-12-13 11:55:27,760 INFO     Evaluating the model... (18500/59072)
2025-12-13 11:55:32,165 INFO     Evaluating the model... (19000/59072)
2025-12-13 11:55:36,508 INFO     Evaluating the model... (19500/59072)
2025-12-13 11:55:41,076 INFO     Evaluating the model... (20000/59072)
2025-12-13 11:55:46,863 INFO     Evaluating the model... (20500/59072)
2025-12-13 11:55:51,294 INFO     Evaluating the model... (21000/59072)
2025-12-13 11:55:55,805 INFO     Evaluating the model... (21500/59072)
2025-12-13 11:56:00,493 INFO     Evaluating the model... (22000/59072)
2025-12-13 11:56:05,001 INFO     Evaluating the model... (22500/59072)
2025-12-13 11:56:10,457 INFO     Evaluating the model... (23000/59072)
2025-12-13 11:56:14,686 INFO     Evaluating the model... (23500/59072)
2025-12-13 11:56:18,837 INFO     Evaluating the model... (24000/59072)
2025-12-13 11:56:23,075 INFO     Evaluating the model... (24500/59072)
2025-12-13 11:56:27,318 INFO     Evaluating the model... (25000/59072)
2025-12-13 11:56:32,463 INFO     Evaluating the model... (25500/59072)
2025-12-13 11:56:36,776 INFO     Evaluating the model... (26000/59072)
2025-12-13 11:56:41,187 INFO     Evaluating the model... (26500/59072)
2025-12-13 11:56:45,602 INFO     Evaluating the model... (27000/59072)
2025-12-13 11:56:50,012 INFO     Evaluating the model... (27500/59072)
2025-12-13 11:56:55,429 INFO     Evaluating the model... (28000/59072)
2025-12-13 11:56:59,824 INFO     Evaluating the model... (28500/59072)
2025-12-13 11:57:04,101 INFO     Evaluating the model... (29000/59072)
2025-12-13 11:57:08,461 INFO     Evaluating the model... (29500/59072)
2025-12-13 11:57:14,628 INFO     Evaluating the model... (30000/59072)
2025-12-13 11:57:19,035 INFO     Evaluating the model... (30500/59072)
2025-12-13 11:57:23,591 INFO     Evaluating the model... (31000/59072)
2025-12-13 11:57:28,129 INFO     Evaluating the model... (31500/59072)
2025-12-13 11:57:32,669 INFO     Evaluating the model... (32000/59072)
2025-12-13 11:57:37,804 INFO     Evaluating the model... (32500/59072)
2025-12-13 11:57:42,413 INFO     Evaluating the model... (33000/59072)
2025-12-13 11:57:46,969 INFO     Evaluating the model... (33500/59072)
2025-12-13 11:57:51,674 INFO     Evaluating the model... (34000/59072)
2025-12-13 11:57:56,101 INFO     Evaluating the model... (34500/59072)
2025-12-13 11:58:00,884 INFO     Evaluating the model... (35000/59072)
2025-12-13 11:58:05,323 INFO     Evaluating the model... (35500/59072)
2025-12-13 11:58:09,838 INFO     Evaluating the model... (36000/59072)
2025-12-13 11:58:14,366 INFO     Evaluating the model... (36500/59072)
2025-12-13 11:58:18,792 INFO     Evaluating the model... (37000/59072)
2025-12-13 11:58:23,689 INFO     Evaluating the model... (37500/59072)
2025-12-13 11:58:28,306 INFO     Evaluating the model... (38000/59072)
2025-12-13 11:58:33,022 INFO     Evaluating the model... (38500/59072)
2025-12-13 11:58:37,571 INFO     Evaluating the model... (39000/59072)
2025-12-13 11:58:42,100 INFO     Evaluating the model... (39500/59072)
2025-12-13 11:58:47,418 INFO     Evaluating the model... (40000/59072)
2025-12-13 11:58:52,075 INFO     Evaluating the model... (40500/59072)
2025-12-13 11:58:56,731 INFO     Evaluating the model... (41000/59072)
2025-12-13 11:59:01,173 INFO     Evaluating the model... (41500/59072)
2025-12-13 11:59:06,738 INFO     Evaluating the model... (42000/59072)
2025-12-13 11:59:11,648 INFO     Evaluating the model... (42500/59072)
2025-12-13 11:59:16,210 INFO     Evaluating the model... (43000/59072)
2025-12-13 11:59:20,632 INFO     Evaluating the model... (43500/59072)
2025-12-13 11:59:25,220 INFO     Evaluating the model... (44000/59072)
2025-12-13 11:59:30,614 INFO     Evaluating the model... (44500/59072)
2025-12-13 11:59:35,143 INFO     Evaluating the model... (45000/59072)
2025-12-13 11:59:39,974 INFO     Evaluating the model... (45500/59072)
2025-12-13 11:59:44,520 INFO     Evaluating the model... (46000/59072)
2025-12-13 11:59:49,130 INFO     Evaluating the model... (46500/59072)
2025-12-13 11:59:54,495 INFO     Evaluating the model... (47000/59072)
2025-12-13 11:59:58,944 INFO     Evaluating the model... (47500/59072)
2025-12-13 12:00:03,788 INFO     Evaluating the model... (48000/59072)
2025-12-13 12:00:08,898 INFO     Evaluating the model... (48500/59072)
2025-12-13 12:00:13,398 INFO     Evaluating the model... (49000/59072)
2025-12-13 12:00:18,512 INFO     Evaluating the model... (49500/59072)
2025-12-13 12:00:22,663 INFO     Evaluating the model... (50000/59072)
2025-12-13 12:00:26,768 INFO     Evaluating the model... (50500/59072)
2025-12-13 12:00:31,050 INFO     Evaluating the model... (51000/59072)
2025-12-13 12:00:35,270 INFO     Evaluating the model... (51500/59072)
2025-12-13 12:00:40,671 INFO     Evaluating the model... (52000/59072)
2025-12-13 12:00:44,777 INFO     Evaluating the model... (52500/59072)
2025-12-13 12:00:48,906 INFO     Evaluating the model... (53000/59072)
2025-12-13 12:00:52,993 INFO     Evaluating the model... (53500/59072)
2025-12-13 12:00:57,146 INFO     Evaluating the model... (54000/59072)
2025-12-13 12:01:02,434 INFO     Evaluating the model... (54500/59072)
2025-12-13 12:01:06,676 INFO     Evaluating the model... (55000/59072)
2025-12-13 12:01:10,952 INFO     Evaluating the model... (55500/59072)
2025-12-13 12:01:15,101 INFO     Evaluating the model... (56000/59072)
2025-12-13 12:01:19,242 INFO     Evaluating the model... (56500/59072)
2025-12-13 12:01:24,630 INFO     Evaluating the model... (57000/59072)
2025-12-13 12:01:28,956 INFO     Evaluating the model... (57500/59072)
2025-12-13 12:01:33,152 INFO     Evaluating the model... (58000/59072)
2025-12-13 12:01:37,165 INFO     Evaluating the model... (58500/59072)
2025-12-13 12:01:41,212 INFO     Evaluating the model... (59000/59072)
2025-12-13 12:01:42,874 INFO     Test MRR at step 20000: 0.597250
2025-12-13 12:01:42,874 INFO     Test MR at step 20000: 544.868082
2025-12-13 12:01:42,874 INFO     Test HITS@1 at step 20000: 0.523946
2025-12-13 12:01:42,874 INFO     Test HITS@3 at step 20000: 0.642820
2025-12-13 12:01:42,874 INFO     Test HITS@10 at step 20000: 0.727684
2025-12-13 12:01:48,373 INFO     Training average regularization at step 20100: 0.329549
2025-12-13 12:01:48,373 INFO     Training average positive_sample_loss at step 20100: 0.127540
2025-12-13 12:01:48,374 INFO     Training average negative_sample_loss at step 20100: 0.104752
2025-12-13 12:01:48,374 INFO     Training average loss at step 20100: 0.445695
2025-12-13 12:01:53,536 INFO     Training average regularization at step 20200: 0.316604
2025-12-13 12:01:53,536 INFO     Training average positive_sample_loss at step 20200: 0.136723
2025-12-13 12:01:53,536 INFO     Training average negative_sample_loss at step 20200: 0.107640
2025-12-13 12:01:53,536 INFO     Training average loss at step 20200: 0.438785
2025-12-13 12:01:58,876 INFO     Training average regularization at step 20300: 0.310517
2025-12-13 12:01:58,876 INFO     Training average positive_sample_loss at step 20300: 0.129915
2025-12-13 12:01:58,876 INFO     Training average negative_sample_loss at step 20300: 0.110781
2025-12-13 12:01:58,876 INFO     Training average loss at step 20300: 0.430865
2025-12-13 12:02:04,277 INFO     Training average regularization at step 20400: 0.306903
2025-12-13 12:02:04,277 INFO     Training average positive_sample_loss at step 20400: 0.131368
2025-12-13 12:02:04,278 INFO     Training average negative_sample_loss at step 20400: 0.110622
2025-12-13 12:02:04,278 INFO     Training average loss at step 20400: 0.427898
2025-12-13 12:02:09,694 INFO     Training average regularization at step 20500: 0.304465
2025-12-13 12:02:09,695 INFO     Training average positive_sample_loss at step 20500: 0.125683
2025-12-13 12:02:09,695 INFO     Training average negative_sample_loss at step 20500: 0.108077
2025-12-13 12:02:09,695 INFO     Training average loss at step 20500: 0.421345
2025-12-13 12:02:14,938 INFO     Training average regularization at step 20600: 0.302677
2025-12-13 12:02:14,938 INFO     Training average positive_sample_loss at step 20600: 0.134280
2025-12-13 12:02:14,938 INFO     Training average negative_sample_loss at step 20600: 0.104646
2025-12-13 12:02:14,938 INFO     Training average loss at step 20600: 0.422140
2025-12-13 12:02:20,129 INFO     Training average regularization at step 20700: 0.301277
2025-12-13 12:02:20,129 INFO     Training average positive_sample_loss at step 20700: 0.123682
2025-12-13 12:02:20,129 INFO     Training average negative_sample_loss at step 20700: 0.102127
2025-12-13 12:02:20,129 INFO     Training average loss at step 20700: 0.414182
2025-12-13 12:02:25,382 INFO     Training average regularization at step 20800: 0.300109
2025-12-13 12:02:25,382 INFO     Training average positive_sample_loss at step 20800: 0.122913
2025-12-13 12:02:25,382 INFO     Training average negative_sample_loss at step 20800: 0.096621
2025-12-13 12:02:25,382 INFO     Training average loss at step 20800: 0.409876
2025-12-13 12:02:30,638 INFO     Training average regularization at step 20900: 0.299084
2025-12-13 12:02:30,639 INFO     Training average positive_sample_loss at step 20900: 0.114051
2025-12-13 12:02:30,639 INFO     Training average negative_sample_loss at step 20900: 0.095006
2025-12-13 12:02:30,639 INFO     Training average loss at step 20900: 0.403613
2025-12-13 12:02:35,893 INFO     Training average regularization at step 21000: 0.298173
2025-12-13 12:02:35,893 INFO     Training average positive_sample_loss at step 21000: 0.119654
2025-12-13 12:02:35,893 INFO     Training average negative_sample_loss at step 21000: 0.094677
2025-12-13 12:02:35,893 INFO     Training average loss at step 21000: 0.405338
2025-12-13 12:02:41,250 INFO     Training average regularization at step 21100: 0.297339
2025-12-13 12:02:41,251 INFO     Training average positive_sample_loss at step 21100: 0.105753
2025-12-13 12:02:41,251 INFO     Training average negative_sample_loss at step 21100: 0.094186
2025-12-13 12:02:41,251 INFO     Training average loss at step 21100: 0.397308
2025-12-13 12:02:46,522 INFO     Training average regularization at step 21200: 0.296561
2025-12-13 12:02:46,522 INFO     Training average positive_sample_loss at step 21200: 0.103253
2025-12-13 12:02:46,522 INFO     Training average negative_sample_loss at step 21200: 0.083794
2025-12-13 12:02:46,522 INFO     Training average loss at step 21200: 0.390084
2025-12-13 12:02:51,853 INFO     Training average regularization at step 21300: 0.295822
2025-12-13 12:02:51,853 INFO     Training average positive_sample_loss at step 21300: 0.103596
2025-12-13 12:02:51,853 INFO     Training average negative_sample_loss at step 21300: 0.086022
2025-12-13 12:02:51,853 INFO     Training average loss at step 21300: 0.390632
2025-12-13 12:02:57,328 INFO     Training average regularization at step 21400: 0.295117
2025-12-13 12:02:57,329 INFO     Training average positive_sample_loss at step 21400: 0.103121
2025-12-13 12:02:57,329 INFO     Training average negative_sample_loss at step 21400: 0.086464
2025-12-13 12:02:57,329 INFO     Training average loss at step 21400: 0.389910
2025-12-13 12:03:02,719 INFO     Training average regularization at step 21500: 0.294442
2025-12-13 12:03:02,720 INFO     Training average positive_sample_loss at step 21500: 0.101188
2025-12-13 12:03:02,720 INFO     Training average negative_sample_loss at step 21500: 0.086156
2025-12-13 12:03:02,720 INFO     Training average loss at step 21500: 0.388114
2025-12-13 12:03:08,023 INFO     Training average regularization at step 21600: 0.293795
2025-12-13 12:03:08,024 INFO     Training average positive_sample_loss at step 21600: 0.097378
2025-12-13 12:03:08,024 INFO     Training average negative_sample_loss at step 21600: 0.079224
2025-12-13 12:03:08,024 INFO     Training average loss at step 21600: 0.382096
2025-12-13 12:03:13,413 INFO     Training average regularization at step 21700: 0.293161
2025-12-13 12:03:13,414 INFO     Training average positive_sample_loss at step 21700: 0.095424
2025-12-13 12:03:13,414 INFO     Training average negative_sample_loss at step 21700: 0.084775
2025-12-13 12:03:13,414 INFO     Training average loss at step 21700: 0.383261
2025-12-13 12:03:18,674 INFO     Training average regularization at step 21800: 0.292542
2025-12-13 12:03:18,674 INFO     Training average positive_sample_loss at step 21800: 0.085358
2025-12-13 12:03:18,674 INFO     Training average negative_sample_loss at step 21800: 0.079044
2025-12-13 12:03:18,674 INFO     Training average loss at step 21800: 0.374743
2025-12-13 12:03:24,023 INFO     Training average regularization at step 21900: 0.291951
2025-12-13 12:03:24,023 INFO     Training average positive_sample_loss at step 21900: 0.090595
2025-12-13 12:03:24,023 INFO     Training average negative_sample_loss at step 21900: 0.077604
2025-12-13 12:03:24,023 INFO     Training average loss at step 21900: 0.376050
2025-12-13 12:03:29,252 INFO     Training average regularization at step 22000: 0.291373
2025-12-13 12:03:29,252 INFO     Training average positive_sample_loss at step 22000: 0.080745
2025-12-13 12:03:29,252 INFO     Training average negative_sample_loss at step 22000: 0.078827
2025-12-13 12:03:29,252 INFO     Training average loss at step 22000: 0.371159
2025-12-13 12:03:34,553 INFO     Training average regularization at step 22100: 0.290805
2025-12-13 12:03:34,553 INFO     Training average positive_sample_loss at step 22100: 0.085682
2025-12-13 12:03:34,553 INFO     Training average negative_sample_loss at step 22100: 0.078218
2025-12-13 12:03:34,553 INFO     Training average loss at step 22100: 0.372755
2025-12-13 12:03:39,813 INFO     Training average regularization at step 22200: 0.290243
2025-12-13 12:03:39,814 INFO     Training average positive_sample_loss at step 22200: 0.078723
2025-12-13 12:03:39,814 INFO     Training average negative_sample_loss at step 22200: 0.069245
2025-12-13 12:03:39,814 INFO     Training average loss at step 22200: 0.364227
2025-12-13 12:03:45,000 INFO     Training average regularization at step 22300: 0.289690
2025-12-13 12:03:45,001 INFO     Training average positive_sample_loss at step 22300: 0.073757
2025-12-13 12:03:45,001 INFO     Training average negative_sample_loss at step 22300: 0.074786
2025-12-13 12:03:45,001 INFO     Training average loss at step 22300: 0.363962
2025-12-13 12:03:50,296 INFO     Training average regularization at step 22400: 0.289134
2025-12-13 12:03:50,297 INFO     Training average positive_sample_loss at step 22400: 0.079564
2025-12-13 12:03:50,297 INFO     Training average negative_sample_loss at step 22400: 0.076110
2025-12-13 12:03:50,297 INFO     Training average loss at step 22400: 0.366970
2025-12-13 12:03:55,664 INFO     Training average regularization at step 22500: 0.288590
2025-12-13 12:03:55,664 INFO     Training average positive_sample_loss at step 22500: 0.079401
2025-12-13 12:03:55,664 INFO     Training average negative_sample_loss at step 22500: 0.069559
2025-12-13 12:03:55,664 INFO     Training average loss at step 22500: 0.363070
2025-12-13 12:04:00,939 INFO     Training average regularization at step 22600: 0.288046
2025-12-13 12:04:00,940 INFO     Training average positive_sample_loss at step 22600: 0.071208
2025-12-13 12:04:00,940 INFO     Training average negative_sample_loss at step 22600: 0.070938
2025-12-13 12:04:00,940 INFO     Training average loss at step 22600: 0.359119
2025-12-13 12:04:06,272 INFO     Training average regularization at step 22700: 0.287496
2025-12-13 12:04:06,272 INFO     Training average positive_sample_loss at step 22700: 0.066309
2025-12-13 12:04:06,272 INFO     Training average negative_sample_loss at step 22700: 0.068318
2025-12-13 12:04:06,272 INFO     Training average loss at step 22700: 0.354810
2025-12-13 12:04:11,538 INFO     Training average regularization at step 22800: 0.286963
2025-12-13 12:04:11,538 INFO     Training average positive_sample_loss at step 22800: 0.068202
2025-12-13 12:04:11,538 INFO     Training average negative_sample_loss at step 22800: 0.063350
2025-12-13 12:04:11,538 INFO     Training average loss at step 22800: 0.352739
2025-12-13 12:04:16,796 INFO     Training average regularization at step 22900: 0.286440
2025-12-13 12:04:16,796 INFO     Training average positive_sample_loss at step 22900: 0.066290
2025-12-13 12:04:16,796 INFO     Training average negative_sample_loss at step 22900: 0.065697
2025-12-13 12:04:16,796 INFO     Training average loss at step 22900: 0.352433
2025-12-13 12:04:22,049 INFO     Training average regularization at step 23000: 0.285914
2025-12-13 12:04:22,050 INFO     Training average positive_sample_loss at step 23000: 0.060586
2025-12-13 12:04:22,050 INFO     Training average negative_sample_loss at step 23000: 0.068907
2025-12-13 12:04:22,050 INFO     Training average loss at step 23000: 0.350661
2025-12-13 12:04:27,383 INFO     Training average regularization at step 23100: 0.285384
2025-12-13 12:04:27,383 INFO     Training average positive_sample_loss at step 23100: 0.066504
2025-12-13 12:04:27,383 INFO     Training average negative_sample_loss at step 23100: 0.068129
2025-12-13 12:04:27,383 INFO     Training average loss at step 23100: 0.352701
2025-12-13 12:04:32,663 INFO     Training average regularization at step 23200: 0.284869
2025-12-13 12:04:32,663 INFO     Training average positive_sample_loss at step 23200: 0.062413
2025-12-13 12:04:32,663 INFO     Training average negative_sample_loss at step 23200: 0.061538
2025-12-13 12:04:32,663 INFO     Training average loss at step 23200: 0.346844
2025-12-13 12:04:37,942 INFO     Training average regularization at step 23300: 0.284345
2025-12-13 12:04:37,942 INFO     Training average positive_sample_loss at step 23300: 0.060922
2025-12-13 12:04:37,942 INFO     Training average negative_sample_loss at step 23300: 0.063927
2025-12-13 12:04:37,942 INFO     Training average loss at step 23300: 0.346770
2025-12-13 12:04:43,268 INFO     Training average regularization at step 23400: 0.283830
2025-12-13 12:04:43,269 INFO     Training average positive_sample_loss at step 23400: 0.058962
2025-12-13 12:04:43,269 INFO     Training average negative_sample_loss at step 23400: 0.063769
2025-12-13 12:04:43,269 INFO     Training average loss at step 23400: 0.345195
2025-12-13 12:04:48,647 INFO     Training average regularization at step 23500: 0.283308
2025-12-13 12:04:48,647 INFO     Training average positive_sample_loss at step 23500: 0.058738
2025-12-13 12:04:48,647 INFO     Training average negative_sample_loss at step 23500: 0.061282
2025-12-13 12:04:48,647 INFO     Training average loss at step 23500: 0.343318
2025-12-13 12:04:53,979 INFO     Training average regularization at step 23600: 0.282791
2025-12-13 12:04:53,979 INFO     Training average positive_sample_loss at step 23600: 0.059408
2025-12-13 12:04:53,979 INFO     Training average negative_sample_loss at step 23600: 0.062327
2025-12-13 12:04:53,979 INFO     Training average loss at step 23600: 0.343659
2025-12-13 12:04:59,301 INFO     Training average regularization at step 23700: 0.282271
2025-12-13 12:04:59,301 INFO     Training average positive_sample_loss at step 23700: 0.053377
2025-12-13 12:04:59,301 INFO     Training average negative_sample_loss at step 23700: 0.062383
2025-12-13 12:04:59,301 INFO     Training average loss at step 23700: 0.340151
2025-12-13 12:05:04,675 INFO     Training average regularization at step 23800: 0.281759
2025-12-13 12:05:04,676 INFO     Training average positive_sample_loss at step 23800: 0.052218
2025-12-13 12:05:04,676 INFO     Training average negative_sample_loss at step 23800: 0.058355
2025-12-13 12:05:04,676 INFO     Training average loss at step 23800: 0.337046
2025-12-13 12:05:09,959 INFO     Training average regularization at step 23900: 0.281250
2025-12-13 12:05:09,961 INFO     Training average positive_sample_loss at step 23900: 0.055561
2025-12-13 12:05:09,961 INFO     Training average negative_sample_loss at step 23900: 0.060352
2025-12-13 12:05:09,961 INFO     Training average loss at step 23900: 0.339206
2025-12-13 12:05:15,186 INFO     Training average regularization at step 24000: 0.280736
2025-12-13 12:05:15,186 INFO     Training average positive_sample_loss at step 24000: 0.051399
2025-12-13 12:05:15,186 INFO     Training average negative_sample_loss at step 24000: 0.053966
2025-12-13 12:05:15,186 INFO     Training average loss at step 24000: 0.333418
2025-12-13 12:05:20,425 INFO     Training average regularization at step 24100: 0.280210
2025-12-13 12:05:20,425 INFO     Training average positive_sample_loss at step 24100: 0.050380
2025-12-13 12:05:20,425 INFO     Training average negative_sample_loss at step 24100: 0.053556
2025-12-13 12:05:20,425 INFO     Training average loss at step 24100: 0.332178
2025-12-13 12:05:26,682 INFO     Training average regularization at step 24200: 0.279673
2025-12-13 12:05:26,682 INFO     Training average positive_sample_loss at step 24200: 0.038332
2025-12-13 12:05:26,683 INFO     Training average negative_sample_loss at step 24200: 0.053760
2025-12-13 12:05:26,683 INFO     Training average loss at step 24200: 0.325719
2025-12-13 12:05:31,971 INFO     Training average regularization at step 24300: 0.279112
2025-12-13 12:05:31,972 INFO     Training average positive_sample_loss at step 24300: 0.030638
2025-12-13 12:05:31,972 INFO     Training average negative_sample_loss at step 24300: 0.045555
2025-12-13 12:05:31,972 INFO     Training average loss at step 24300: 0.317208
2025-12-13 12:05:37,224 INFO     Training average regularization at step 24400: 0.278565
2025-12-13 12:05:37,224 INFO     Training average positive_sample_loss at step 24400: 0.031630
2025-12-13 12:05:37,224 INFO     Training average negative_sample_loss at step 24400: 0.046444
2025-12-13 12:05:37,224 INFO     Training average loss at step 24400: 0.317602
2025-12-13 12:05:42,366 INFO     Training average regularization at step 24500: 0.278022
2025-12-13 12:05:42,366 INFO     Training average positive_sample_loss at step 24500: 0.032957
2025-12-13 12:05:42,366 INFO     Training average negative_sample_loss at step 24500: 0.047165
2025-12-13 12:05:42,366 INFO     Training average loss at step 24500: 0.318083
2025-12-13 12:05:47,695 INFO     Training average regularization at step 24600: 0.277480
2025-12-13 12:05:47,695 INFO     Training average positive_sample_loss at step 24600: 0.031892
2025-12-13 12:05:47,695 INFO     Training average negative_sample_loss at step 24600: 0.046956
2025-12-13 12:05:47,695 INFO     Training average loss at step 24600: 0.316904
2025-12-13 12:05:52,933 INFO     Training average regularization at step 24700: 0.276929
2025-12-13 12:05:52,933 INFO     Training average positive_sample_loss at step 24700: 0.031078
2025-12-13 12:05:52,933 INFO     Training average negative_sample_loss at step 24700: 0.040396
2025-12-13 12:05:52,933 INFO     Training average loss at step 24700: 0.312666
2025-12-13 12:05:58,203 INFO     Training average regularization at step 24800: 0.276371
2025-12-13 12:05:58,204 INFO     Training average positive_sample_loss at step 24800: 0.032978
2025-12-13 12:05:58,204 INFO     Training average negative_sample_loss at step 24800: 0.039410
2025-12-13 12:05:58,204 INFO     Training average loss at step 24800: 0.312565
2025-12-13 12:06:03,537 INFO     Training average regularization at step 24900: 0.275816
2025-12-13 12:06:03,537 INFO     Training average positive_sample_loss at step 24900: 0.033947
2025-12-13 12:06:03,537 INFO     Training average negative_sample_loss at step 24900: 0.044294
2025-12-13 12:06:03,537 INFO     Training average loss at step 24900: 0.314936
2025-12-13 12:06:08,897 INFO     Training average regularization at step 25000: 0.275263
2025-12-13 12:06:08,897 INFO     Training average positive_sample_loss at step 25000: 0.030793
2025-12-13 12:06:08,897 INFO     Training average negative_sample_loss at step 25000: 0.039752
2025-12-13 12:06:08,897 INFO     Training average loss at step 25000: 0.310536
2025-12-13 12:06:14,018 INFO     Training average regularization at step 25100: 0.274696
2025-12-13 12:06:14,018 INFO     Training average positive_sample_loss at step 25100: 0.029125
2025-12-13 12:06:14,018 INFO     Training average negative_sample_loss at step 25100: 0.039874
2025-12-13 12:06:14,018 INFO     Training average loss at step 25100: 0.309196
2025-12-13 12:06:19,111 INFO     Training average regularization at step 25200: 0.274117
2025-12-13 12:06:19,111 INFO     Training average positive_sample_loss at step 25200: 0.030778
2025-12-13 12:06:19,111 INFO     Training average negative_sample_loss at step 25200: 0.039866
2025-12-13 12:06:19,111 INFO     Training average loss at step 25200: 0.309439
2025-12-13 12:06:24,377 INFO     Training average regularization at step 25300: 0.273537
2025-12-13 12:06:24,378 INFO     Training average positive_sample_loss at step 25300: 0.029128
2025-12-13 12:06:24,378 INFO     Training average negative_sample_loss at step 25300: 0.038430
2025-12-13 12:06:24,378 INFO     Training average loss at step 25300: 0.307317
2025-12-13 12:06:29,674 INFO     Training average regularization at step 25400: 0.272950
2025-12-13 12:06:29,674 INFO     Training average positive_sample_loss at step 25400: 0.029527
2025-12-13 12:06:29,674 INFO     Training average negative_sample_loss at step 25400: 0.036575
2025-12-13 12:06:29,674 INFO     Training average loss at step 25400: 0.306001
2025-12-13 12:06:34,936 INFO     Training average regularization at step 25500: 0.272359
2025-12-13 12:06:34,936 INFO     Training average positive_sample_loss at step 25500: 0.027603
2025-12-13 12:06:34,936 INFO     Training average negative_sample_loss at step 25500: 0.038093
2025-12-13 12:06:34,937 INFO     Training average loss at step 25500: 0.305207
2025-12-13 12:06:40,201 INFO     Training average regularization at step 25600: 0.271774
2025-12-13 12:06:40,201 INFO     Training average positive_sample_loss at step 25600: 0.028557
2025-12-13 12:06:40,201 INFO     Training average negative_sample_loss at step 25600: 0.041146
2025-12-13 12:06:40,201 INFO     Training average loss at step 25600: 0.306626
2025-12-13 12:06:45,406 INFO     Training average regularization at step 25700: 0.271183
2025-12-13 12:06:45,406 INFO     Training average positive_sample_loss at step 25700: 0.028834
2025-12-13 12:06:45,407 INFO     Training average negative_sample_loss at step 25700: 0.044319
2025-12-13 12:06:45,407 INFO     Training average loss at step 25700: 0.307760
2025-12-13 12:06:50,393 INFO     Training average regularization at step 25800: 0.270596
2025-12-13 12:06:50,393 INFO     Training average positive_sample_loss at step 25800: 0.028799
2025-12-13 12:06:50,393 INFO     Training average negative_sample_loss at step 25800: 0.039400
2025-12-13 12:06:50,393 INFO     Training average loss at step 25800: 0.304696
2025-12-13 12:06:55,488 INFO     Training average regularization at step 25900: 0.270006
2025-12-13 12:06:55,488 INFO     Training average positive_sample_loss at step 25900: 0.029120
2025-12-13 12:06:55,488 INFO     Training average negative_sample_loss at step 25900: 0.039665
2025-12-13 12:06:55,488 INFO     Training average loss at step 25900: 0.304398
2025-12-13 12:07:00,564 INFO     Training average regularization at step 26000: 0.269402
2025-12-13 12:07:00,565 INFO     Training average positive_sample_loss at step 26000: 0.031905
2025-12-13 12:07:00,565 INFO     Training average negative_sample_loss at step 26000: 0.041535
2025-12-13 12:07:00,565 INFO     Training average loss at step 26000: 0.306123
2025-12-13 12:07:05,647 INFO     Training average regularization at step 26100: 0.268802
2025-12-13 12:07:05,648 INFO     Training average positive_sample_loss at step 26100: 0.026580
2025-12-13 12:07:05,648 INFO     Training average negative_sample_loss at step 26100: 0.038166
2025-12-13 12:07:05,648 INFO     Training average loss at step 26100: 0.301174
2025-12-13 12:07:10,664 INFO     Training average regularization at step 26200: 0.268203
2025-12-13 12:07:10,665 INFO     Training average positive_sample_loss at step 26200: 0.028881
2025-12-13 12:07:10,665 INFO     Training average negative_sample_loss at step 26200: 0.034678
2025-12-13 12:07:10,665 INFO     Training average loss at step 26200: 0.299983
2025-12-13 12:07:15,747 INFO     Training average regularization at step 26300: 0.267590
2025-12-13 12:07:15,748 INFO     Training average positive_sample_loss at step 26300: 0.026939
2025-12-13 12:07:15,748 INFO     Training average negative_sample_loss at step 26300: 0.037072
2025-12-13 12:07:15,748 INFO     Training average loss at step 26300: 0.299595
2025-12-13 12:07:20,779 INFO     Training average regularization at step 26400: 0.266972
2025-12-13 12:07:20,779 INFO     Training average positive_sample_loss at step 26400: 0.028566
2025-12-13 12:07:20,779 INFO     Training average negative_sample_loss at step 26400: 0.042825
2025-12-13 12:07:20,779 INFO     Training average loss at step 26400: 0.302667
2025-12-13 12:07:25,867 INFO     Training average regularization at step 26500: 0.266374
2025-12-13 12:07:25,867 INFO     Training average positive_sample_loss at step 26500: 0.027982
2025-12-13 12:07:25,867 INFO     Training average negative_sample_loss at step 26500: 0.041560
2025-12-13 12:07:25,867 INFO     Training average loss at step 26500: 0.301145
2025-12-13 12:07:30,942 INFO     Training average regularization at step 26600: 0.265763
2025-12-13 12:07:30,942 INFO     Training average positive_sample_loss at step 26600: 0.024540
2025-12-13 12:07:30,942 INFO     Training average negative_sample_loss at step 26600: 0.034846
2025-12-13 12:07:30,942 INFO     Training average loss at step 26600: 0.295456
2025-12-13 12:07:36,192 INFO     Training average regularization at step 26700: 0.265147
2025-12-13 12:07:36,192 INFO     Training average positive_sample_loss at step 26700: 0.028158
2025-12-13 12:07:36,192 INFO     Training average negative_sample_loss at step 26700: 0.037610
2025-12-13 12:07:36,192 INFO     Training average loss at step 26700: 0.298031
2025-12-13 12:07:41,546 INFO     Training average regularization at step 26800: 0.264526
2025-12-13 12:07:41,546 INFO     Training average positive_sample_loss at step 26800: 0.024519
2025-12-13 12:07:41,546 INFO     Training average negative_sample_loss at step 26800: 0.041111
2025-12-13 12:07:41,546 INFO     Training average loss at step 26800: 0.297341
2025-12-13 12:07:46,892 INFO     Training average regularization at step 26900: 0.263913
2025-12-13 12:07:46,894 INFO     Training average positive_sample_loss at step 26900: 0.025832
2025-12-13 12:07:46,894 INFO     Training average negative_sample_loss at step 26900: 0.039996
2025-12-13 12:07:46,894 INFO     Training average loss at step 26900: 0.296827
2025-12-13 12:07:52,052 INFO     Training average regularization at step 27000: 0.263295
2025-12-13 12:07:52,052 INFO     Training average positive_sample_loss at step 27000: 0.026619
2025-12-13 12:07:52,052 INFO     Training average negative_sample_loss at step 27000: 0.039847
2025-12-13 12:07:52,052 INFO     Training average loss at step 27000: 0.296527
2025-12-13 12:07:57,112 INFO     Training average regularization at step 27100: 0.262680
2025-12-13 12:07:57,113 INFO     Training average positive_sample_loss at step 27100: 0.025229
2025-12-13 12:07:57,113 INFO     Training average negative_sample_loss at step 27100: 0.036898
2025-12-13 12:07:57,113 INFO     Training average loss at step 27100: 0.293744
2025-12-13 12:08:02,127 INFO     Training average regularization at step 27200: 0.262057
2025-12-13 12:08:02,127 INFO     Training average positive_sample_loss at step 27200: 0.023485
2025-12-13 12:08:02,127 INFO     Training average negative_sample_loss at step 27200: 0.037250
2025-12-13 12:08:02,127 INFO     Training average loss at step 27200: 0.292424
2025-12-13 12:08:07,279 INFO     Training average regularization at step 27300: 0.261429
2025-12-13 12:08:07,279 INFO     Training average positive_sample_loss at step 27300: 0.025519
2025-12-13 12:08:07,280 INFO     Training average negative_sample_loss at step 27300: 0.032967
2025-12-13 12:08:07,280 INFO     Training average loss at step 27300: 0.290673
2025-12-13 12:08:12,615 INFO     Training average regularization at step 27400: 0.260793
2025-12-13 12:08:12,615 INFO     Training average positive_sample_loss at step 27400: 0.023096
2025-12-13 12:08:12,615 INFO     Training average negative_sample_loss at step 27400: 0.038341
2025-12-13 12:08:12,615 INFO     Training average loss at step 27400: 0.291511
2025-12-13 12:08:17,877 INFO     Training average regularization at step 27500: 0.260175
2025-12-13 12:08:17,877 INFO     Training average positive_sample_loss at step 27500: 0.026304
2025-12-13 12:08:17,878 INFO     Training average negative_sample_loss at step 27500: 0.033920
2025-12-13 12:08:17,878 INFO     Training average loss at step 27500: 0.290286
2025-12-13 12:08:23,199 INFO     Training average regularization at step 27600: 0.259554
2025-12-13 12:08:23,200 INFO     Training average positive_sample_loss at step 27600: 0.025826
2025-12-13 12:08:23,200 INFO     Training average negative_sample_loss at step 27600: 0.041535
2025-12-13 12:08:23,200 INFO     Training average loss at step 27600: 0.293234
2025-12-13 12:08:28,341 INFO     Training average regularization at step 27700: 0.258922
2025-12-13 12:08:28,341 INFO     Training average positive_sample_loss at step 27700: 0.022580
2025-12-13 12:08:28,341 INFO     Training average negative_sample_loss at step 27700: 0.035046
2025-12-13 12:08:28,341 INFO     Training average loss at step 27700: 0.287735
2025-12-13 12:08:33,642 INFO     Training average regularization at step 27800: 0.258294
2025-12-13 12:08:33,642 INFO     Training average positive_sample_loss at step 27800: 0.023143
2025-12-13 12:08:33,642 INFO     Training average negative_sample_loss at step 27800: 0.037617
2025-12-13 12:08:33,642 INFO     Training average loss at step 27800: 0.288674
2025-12-13 12:08:38,856 INFO     Training average regularization at step 27900: 0.257667
2025-12-13 12:08:38,857 INFO     Training average positive_sample_loss at step 27900: 0.022878
2025-12-13 12:08:38,857 INFO     Training average negative_sample_loss at step 27900: 0.033877
2025-12-13 12:08:38,857 INFO     Training average loss at step 27900: 0.286044
2025-12-13 12:08:44,151 INFO     Training average regularization at step 28000: 0.257034
2025-12-13 12:08:44,152 INFO     Training average positive_sample_loss at step 28000: 0.021544
2025-12-13 12:08:44,152 INFO     Training average negative_sample_loss at step 28000: 0.037746
2025-12-13 12:08:44,152 INFO     Training average loss at step 28000: 0.286679
2025-12-13 12:08:49,454 INFO     Training average regularization at step 28100: 0.256417
2025-12-13 12:08:49,455 INFO     Training average positive_sample_loss at step 28100: 0.023802
2025-12-13 12:08:49,455 INFO     Training average negative_sample_loss at step 28100: 0.039640
2025-12-13 12:08:49,455 INFO     Training average loss at step 28100: 0.288138
2025-12-13 12:08:54,671 INFO     Training average regularization at step 28200: 0.255806
2025-12-13 12:08:54,671 INFO     Training average positive_sample_loss at step 28200: 0.023703
2025-12-13 12:08:54,671 INFO     Training average negative_sample_loss at step 28200: 0.037475
2025-12-13 12:08:54,671 INFO     Training average loss at step 28200: 0.286395
2025-12-13 12:08:59,927 INFO     Training average regularization at step 28300: 0.255184
2025-12-13 12:08:59,927 INFO     Training average positive_sample_loss at step 28300: 0.022066
2025-12-13 12:08:59,928 INFO     Training average negative_sample_loss at step 28300: 0.033851
2025-12-13 12:08:59,928 INFO     Training average loss at step 28300: 0.283142
2025-12-13 12:09:05,116 INFO     Training average regularization at step 28400: 0.254551
2025-12-13 12:09:05,117 INFO     Training average positive_sample_loss at step 28400: 0.022573
2025-12-13 12:09:05,117 INFO     Training average negative_sample_loss at step 28400: 0.032839
2025-12-13 12:09:05,117 INFO     Training average loss at step 28400: 0.282256
2025-12-13 12:09:10,202 INFO     Training average regularization at step 28500: 0.253926
2025-12-13 12:09:10,203 INFO     Training average positive_sample_loss at step 28500: 0.020054
2025-12-13 12:09:10,203 INFO     Training average negative_sample_loss at step 28500: 0.034583
2025-12-13 12:09:10,203 INFO     Training average loss at step 28500: 0.281245
2025-12-13 12:09:15,406 INFO     Training average regularization at step 28600: 0.253283
2025-12-13 12:09:15,407 INFO     Training average positive_sample_loss at step 28600: 0.020031
2025-12-13 12:09:15,407 INFO     Training average negative_sample_loss at step 28600: 0.033617
2025-12-13 12:09:15,407 INFO     Training average loss at step 28600: 0.280107
2025-12-13 12:09:20,707 INFO     Training average regularization at step 28700: 0.252648
2025-12-13 12:09:20,707 INFO     Training average positive_sample_loss at step 28700: 0.017269
2025-12-13 12:09:20,707 INFO     Training average negative_sample_loss at step 28700: 0.032973
2025-12-13 12:09:20,707 INFO     Training average loss at step 28700: 0.277769
2025-12-13 12:09:25,962 INFO     Training average regularization at step 28800: 0.252017
2025-12-13 12:09:25,962 INFO     Training average positive_sample_loss at step 28800: 0.020966
2025-12-13 12:09:25,962 INFO     Training average negative_sample_loss at step 28800: 0.030996
2025-12-13 12:09:25,962 INFO     Training average loss at step 28800: 0.277998
2025-12-13 12:09:31,256 INFO     Training average regularization at step 28900: 0.251391
2025-12-13 12:09:31,256 INFO     Training average positive_sample_loss at step 28900: 0.019846
2025-12-13 12:09:31,256 INFO     Training average negative_sample_loss at step 28900: 0.037561
2025-12-13 12:09:31,256 INFO     Training average loss at step 28900: 0.280094
2025-12-13 12:09:37,661 INFO     Training average regularization at step 29000: 0.250753
2025-12-13 12:09:37,661 INFO     Training average positive_sample_loss at step 29000: 0.020369
2025-12-13 12:09:37,661 INFO     Training average negative_sample_loss at step 29000: 0.034733
2025-12-13 12:09:37,661 INFO     Training average loss at step 29000: 0.278304
2025-12-13 12:09:43,022 INFO     Training average regularization at step 29100: 0.250093
2025-12-13 12:09:43,022 INFO     Training average positive_sample_loss at step 29100: 0.013671
2025-12-13 12:09:43,022 INFO     Training average negative_sample_loss at step 29100: 0.035268
2025-12-13 12:09:43,022 INFO     Training average loss at step 29100: 0.274562
2025-12-13 12:09:48,288 INFO     Training average regularization at step 29200: 0.249420
2025-12-13 12:09:48,288 INFO     Training average positive_sample_loss at step 29200: 0.014727
2025-12-13 12:09:48,288 INFO     Training average negative_sample_loss at step 29200: 0.028638
2025-12-13 12:09:48,288 INFO     Training average loss at step 29200: 0.271102
2025-12-13 12:09:53,601 INFO     Training average regularization at step 29300: 0.248767
2025-12-13 12:09:53,601 INFO     Training average positive_sample_loss at step 29300: 0.015917
2025-12-13 12:09:53,601 INFO     Training average negative_sample_loss at step 29300: 0.027724
2025-12-13 12:09:53,601 INFO     Training average loss at step 29300: 0.270587
2025-12-13 12:09:58,936 INFO     Training average regularization at step 29400: 0.248110
2025-12-13 12:09:58,936 INFO     Training average positive_sample_loss at step 29400: 0.015279
2025-12-13 12:09:58,936 INFO     Training average negative_sample_loss at step 29400: 0.032746
2025-12-13 12:09:58,936 INFO     Training average loss at step 29400: 0.272123
2025-12-13 12:10:04,260 INFO     Training average regularization at step 29500: 0.247461
2025-12-13 12:10:04,260 INFO     Training average positive_sample_loss at step 29500: 0.015554
2025-12-13 12:10:04,261 INFO     Training average negative_sample_loss at step 29500: 0.025185
2025-12-13 12:10:04,261 INFO     Training average loss at step 29500: 0.267830
2025-12-13 12:10:09,496 INFO     Training average regularization at step 29600: 0.246800
2025-12-13 12:10:09,497 INFO     Training average positive_sample_loss at step 29600: 0.014823
2025-12-13 12:10:09,497 INFO     Training average negative_sample_loss at step 29600: 0.030170
2025-12-13 12:10:09,497 INFO     Training average loss at step 29600: 0.269296
2025-12-13 12:10:14,823 INFO     Training average regularization at step 29700: 0.246137
2025-12-13 12:10:14,823 INFO     Training average positive_sample_loss at step 29700: 0.016025
2025-12-13 12:10:14,823 INFO     Training average negative_sample_loss at step 29700: 0.026947
2025-12-13 12:10:14,823 INFO     Training average loss at step 29700: 0.267624
2025-12-13 12:10:19,997 INFO     Training average regularization at step 29800: 0.245479
2025-12-13 12:10:19,997 INFO     Training average positive_sample_loss at step 29800: 0.015832
2025-12-13 12:10:19,997 INFO     Training average negative_sample_loss at step 29800: 0.031835
2025-12-13 12:10:19,997 INFO     Training average loss at step 29800: 0.269313
2025-12-13 12:10:25,251 INFO     Training average regularization at step 29900: 0.244817
2025-12-13 12:10:25,251 INFO     Training average positive_sample_loss at step 29900: 0.015327
2025-12-13 12:10:25,251 INFO     Training average negative_sample_loss at step 29900: 0.028458
2025-12-13 12:10:25,251 INFO     Training average loss at step 29900: 0.266709
2025-12-13 12:10:30,503 INFO     Training average regularization at step 30000: 0.244161
2025-12-13 12:10:30,508 INFO     Training average positive_sample_loss at step 30000: 0.016338
2025-12-13 12:10:30,508 INFO     Training average negative_sample_loss at step 30000: 0.025050
2025-12-13 12:10:30,508 INFO     Training average loss at step 30000: 0.264855
2025-12-13 12:10:30,508 INFO     Evaluating on Valid Dataset...
2025-12-13 12:10:31,147 INFO     Evaluating the model... (0/50000)
2025-12-13 12:10:35,569 INFO     Evaluating the model... (500/50000)
2025-12-13 12:10:39,927 INFO     Evaluating the model... (1000/50000)
2025-12-13 12:10:44,548 INFO     Evaluating the model... (1500/50000)
2025-12-13 12:10:49,091 INFO     Evaluating the model... (2000/50000)
2025-12-13 12:10:54,408 INFO     Evaluating the model... (2500/50000)
2025-12-13 12:10:58,744 INFO     Evaluating the model... (3000/50000)
2025-12-13 12:11:03,034 INFO     Evaluating the model... (3500/50000)
2025-12-13 12:11:07,384 INFO     Evaluating the model... (4000/50000)
2025-12-13 12:11:11,788 INFO     Evaluating the model... (4500/50000)
2025-12-13 12:11:16,556 INFO     Evaluating the model... (5000/50000)
2025-12-13 12:11:20,766 INFO     Evaluating the model... (5500/50000)
2025-12-13 12:11:24,936 INFO     Evaluating the model... (6000/50000)
2025-12-13 12:11:29,142 INFO     Evaluating the model... (6500/50000)
2025-12-13 12:11:33,400 INFO     Evaluating the model... (7000/50000)
2025-12-13 12:11:38,281 INFO     Evaluating the model... (7500/50000)
2025-12-13 12:11:42,637 INFO     Evaluating the model... (8000/50000)
2025-12-13 12:11:47,216 INFO     Evaluating the model... (8500/50000)
2025-12-13 12:11:51,843 INFO     Evaluating the model... (9000/50000)
2025-12-13 12:11:57,044 INFO     Evaluating the model... (9500/50000)
2025-12-13 12:12:01,643 INFO     Evaluating the model... (10000/50000)
2025-12-13 12:12:06,050 INFO     Evaluating the model... (10500/50000)
2025-12-13 12:12:10,389 INFO     Evaluating the model... (11000/50000)
2025-12-13 12:12:14,774 INFO     Evaluating the model... (11500/50000)
2025-12-13 12:12:20,292 INFO     Evaluating the model... (12000/50000)
2025-12-13 12:12:24,728 INFO     Evaluating the model... (12500/50000)
2025-12-13 12:12:29,227 INFO     Evaluating the model... (13000/50000)
2025-12-13 12:12:33,537 INFO     Evaluating the model... (13500/50000)
2025-12-13 12:12:37,761 INFO     Evaluating the model... (14000/50000)
2025-12-13 12:12:42,910 INFO     Evaluating the model... (14500/50000)
2025-12-13 12:12:47,206 INFO     Evaluating the model... (15000/50000)
2025-12-13 12:12:51,485 INFO     Evaluating the model... (15500/50000)
2025-12-13 12:12:55,754 INFO     Evaluating the model... (16000/50000)
2025-12-13 12:13:00,020 INFO     Evaluating the model... (16500/50000)
2025-12-13 12:13:05,104 INFO     Evaluating the model... (17000/50000)
2025-12-13 12:13:09,434 INFO     Evaluating the model... (17500/50000)
2025-12-13 12:13:13,661 INFO     Evaluating the model... (18000/50000)
2025-12-13 12:13:17,862 INFO     Evaluating the model... (18500/50000)
2025-12-13 12:13:22,326 INFO     Evaluating the model... (19000/50000)
2025-12-13 12:13:27,776 INFO     Evaluating the model... (19500/50000)
2025-12-13 12:13:32,011 INFO     Evaluating the model... (20000/50000)
2025-12-13 12:13:36,209 INFO     Evaluating the model... (20500/50000)
2025-12-13 12:13:40,485 INFO     Evaluating the model... (21000/50000)
2025-12-13 12:13:44,661 INFO     Evaluating the model... (21500/50000)
2025-12-13 12:13:50,162 INFO     Evaluating the model... (22000/50000)
2025-12-13 12:13:54,427 INFO     Evaluating the model... (22500/50000)
2025-12-13 12:13:58,753 INFO     Evaluating the model... (23000/50000)
2025-12-13 12:14:03,139 INFO     Evaluating the model... (23500/50000)
2025-12-13 12:14:07,534 INFO     Evaluating the model... (24000/50000)
2025-12-13 12:14:12,978 INFO     Evaluating the model... (24500/50000)
2025-12-13 12:14:17,716 INFO     Evaluating the model... (25000/50000)
2025-12-13 12:14:22,221 INFO     Evaluating the model... (25500/50000)
2025-12-13 12:14:26,449 INFO     Evaluating the model... (26000/50000)
2025-12-13 12:14:30,926 INFO     Evaluating the model... (26500/50000)
2025-12-13 12:14:36,306 INFO     Evaluating the model... (27000/50000)
2025-12-13 12:14:40,644 INFO     Evaluating the model... (27500/50000)
2025-12-13 12:14:44,896 INFO     Evaluating the model... (28000/50000)
2025-12-13 12:14:48,980 INFO     Evaluating the model... (28500/50000)
2025-12-13 12:14:53,164 INFO     Evaluating the model... (29000/50000)
2025-12-13 12:14:58,284 INFO     Evaluating the model... (29500/50000)
2025-12-13 12:15:02,528 INFO     Evaluating the model... (30000/50000)
2025-12-13 12:15:06,584 INFO     Evaluating the model... (30500/50000)
2025-12-13 12:15:10,759 INFO     Evaluating the model... (31000/50000)
2025-12-13 12:15:14,831 INFO     Evaluating the model... (31500/50000)
2025-12-13 12:15:19,544 INFO     Evaluating the model... (32000/50000)
2025-12-13 12:15:23,638 INFO     Evaluating the model... (32500/50000)
2025-12-13 12:15:27,792 INFO     Evaluating the model... (33000/50000)
2025-12-13 12:15:32,055 INFO     Evaluating the model... (33500/50000)
2025-12-13 12:15:36,200 INFO     Evaluating the model... (34000/50000)
2025-12-13 12:15:41,089 INFO     Evaluating the model... (34500/50000)
2025-12-13 12:15:45,453 INFO     Evaluating the model... (35000/50000)
2025-12-13 12:15:49,847 INFO     Evaluating the model... (35500/50000)
2025-12-13 12:15:54,368 INFO     Evaluating the model... (36000/50000)
2025-12-13 12:15:59,362 INFO     Evaluating the model... (36500/50000)
2025-12-13 12:16:03,724 INFO     Evaluating the model... (37000/50000)
2025-12-13 12:16:07,944 INFO     Evaluating the model... (37500/50000)
2025-12-13 12:16:12,050 INFO     Evaluating the model... (38000/50000)
2025-12-13 12:16:16,265 INFO     Evaluating the model... (38500/50000)
2025-12-13 12:16:21,285 INFO     Evaluating the model... (39000/50000)
2025-12-13 12:16:25,439 INFO     Evaluating the model... (39500/50000)
2025-12-13 12:16:29,442 INFO     Evaluating the model... (40000/50000)
2025-12-13 12:16:33,478 INFO     Evaluating the model... (40500/50000)
2025-12-13 12:16:37,429 INFO     Evaluating the model... (41000/50000)
2025-12-13 12:16:42,237 INFO     Evaluating the model... (41500/50000)
2025-12-13 12:16:46,307 INFO     Evaluating the model... (42000/50000)
2025-12-13 12:16:50,521 INFO     Evaluating the model... (42500/50000)
2025-12-13 12:16:54,867 INFO     Evaluating the model... (43000/50000)
2025-12-13 12:16:59,132 INFO     Evaluating the model... (43500/50000)
2025-12-13 12:17:04,542 INFO     Evaluating the model... (44000/50000)
2025-12-13 12:17:08,733 INFO     Evaluating the model... (44500/50000)
2025-12-13 12:17:12,907 INFO     Evaluating the model... (45000/50000)
2025-12-13 12:17:17,275 INFO     Evaluating the model... (45500/50000)
2025-12-13 12:17:21,583 INFO     Evaluating the model... (46000/50000)
2025-12-13 12:17:27,065 INFO     Evaluating the model... (46500/50000)
2025-12-13 12:17:31,275 INFO     Evaluating the model... (47000/50000)
2025-12-13 12:17:35,485 INFO     Evaluating the model... (47500/50000)
2025-12-13 12:17:39,656 INFO     Evaluating the model... (48000/50000)
2025-12-13 12:17:43,930 INFO     Evaluating the model... (48500/50000)
2025-12-13 12:17:48,949 INFO     Evaluating the model... (49000/50000)
2025-12-13 12:17:53,218 INFO     Evaluating the model... (49500/50000)
2025-12-13 12:17:58,049 INFO     Valid MRR at step 30000: 0.717694
2025-12-13 12:17:58,049 INFO     Valid MR at step 30000: 234.946130
2025-12-13 12:17:58,049 INFO     Valid HITS@1 at step 30000: 0.649550
2025-12-13 12:17:58,049 INFO     Valid HITS@3 at step 30000: 0.764490
2025-12-13 12:17:58,049 INFO     Valid HITS@10 at step 30000: 0.836170
2025-12-13 12:17:59,633 INFO     Evaluating on Test Dataset...
2025-12-13 12:18:00,329 INFO     Evaluating the model... (0/59072)
2025-12-13 12:18:05,108 INFO     Evaluating the model... (500/59072)
2025-12-13 12:18:09,639 INFO     Evaluating the model... (1000/59072)
2025-12-13 12:18:14,976 INFO     Evaluating the model... (1500/59072)
2025-12-13 12:18:19,436 INFO     Evaluating the model... (2000/59072)
2025-12-13 12:18:23,909 INFO     Evaluating the model... (2500/59072)
2025-12-13 12:18:28,269 INFO     Evaluating the model... (3000/59072)
2025-12-13 12:18:32,688 INFO     Evaluating the model... (3500/59072)
2025-12-13 12:18:37,933 INFO     Evaluating the model... (4000/59072)
2025-12-13 12:18:42,287 INFO     Evaluating the model... (4500/59072)
2025-12-13 12:18:46,769 INFO     Evaluating the model... (5000/59072)
2025-12-13 12:18:51,349 INFO     Evaluating the model... (5500/59072)
2025-12-13 12:18:55,890 INFO     Evaluating the model... (6000/59072)
2025-12-13 12:19:01,245 INFO     Evaluating the model... (6500/59072)
2025-12-13 12:19:05,897 INFO     Evaluating the model... (7000/59072)
2025-12-13 12:19:10,286 INFO     Evaluating the model... (7500/59072)
2025-12-13 12:19:14,677 INFO     Evaluating the model... (8000/59072)
2025-12-13 12:19:19,198 INFO     Evaluating the model... (8500/59072)
2025-12-13 12:19:24,273 INFO     Evaluating the model... (9000/59072)
2025-12-13 12:19:28,730 INFO     Evaluating the model... (9500/59072)
2025-12-13 12:19:33,239 INFO     Evaluating the model... (10000/59072)
2025-12-13 12:19:37,708 INFO     Evaluating the model... (10500/59072)
2025-12-13 12:19:42,466 INFO     Evaluating the model... (11000/59072)
2025-12-13 12:19:47,753 INFO     Evaluating the model... (11500/59072)
2025-12-13 12:19:52,463 INFO     Evaluating the model... (12000/59072)
2025-12-13 12:19:56,905 INFO     Evaluating the model... (12500/59072)
2025-12-13 12:20:01,384 INFO     Evaluating the model... (13000/59072)
2025-12-13 12:20:05,944 INFO     Evaluating the model... (13500/59072)
2025-12-13 12:20:11,325 INFO     Evaluating the model... (14000/59072)
2025-12-13 12:20:15,805 INFO     Evaluating the model... (14500/59072)
2025-12-13 12:20:20,113 INFO     Evaluating the model... (15000/59072)
2025-12-13 12:20:24,369 INFO     Evaluating the model... (15500/59072)
2025-12-13 12:20:29,558 INFO     Evaluating the model... (16000/59072)
2025-12-13 12:20:34,245 INFO     Evaluating the model... (16500/59072)
2025-12-13 12:20:38,962 INFO     Evaluating the model... (17000/59072)
2025-12-13 12:20:43,707 INFO     Evaluating the model... (17500/59072)
2025-12-13 12:20:48,157 INFO     Evaluating the model... (18000/59072)
2025-12-13 12:20:53,817 INFO     Evaluating the model... (18500/59072)
2025-12-13 12:20:58,645 INFO     Evaluating the model... (19000/59072)
2025-12-13 12:21:03,487 INFO     Evaluating the model... (19500/59072)
2025-12-13 12:21:08,356 INFO     Evaluating the model... (20000/59072)
2025-12-13 12:21:13,080 INFO     Evaluating the model... (20500/59072)
2025-12-13 12:21:18,903 INFO     Evaluating the model... (21000/59072)
2025-12-13 12:21:23,309 INFO     Evaluating the model... (21500/59072)
2025-12-13 12:21:28,024 INFO     Evaluating the model... (22000/59072)
2025-12-13 12:21:32,607 INFO     Evaluating the model... (22500/59072)
2025-12-13 12:21:37,039 INFO     Evaluating the model... (23000/59072)
2025-12-13 12:21:42,876 INFO     Evaluating the model... (23500/59072)
2025-12-13 12:21:47,341 INFO     Evaluating the model... (24000/59072)
2025-12-13 12:21:51,879 INFO     Evaluating the model... (24500/59072)
2025-12-13 12:21:56,571 INFO     Evaluating the model... (25000/59072)
2025-12-13 12:22:00,931 INFO     Evaluating the model... (25500/59072)
2025-12-13 12:22:06,706 INFO     Evaluating the model... (26000/59072)
2025-12-13 12:22:11,227 INFO     Evaluating the model... (26500/59072)
2025-12-13 12:22:15,521 INFO     Evaluating the model... (27000/59072)
2025-12-13 12:22:19,839 INFO     Evaluating the model... (27500/59072)
2025-12-13 12:22:24,096 INFO     Evaluating the model... (28000/59072)
2025-12-13 12:22:29,992 INFO     Evaluating the model... (28500/59072)
2025-12-13 12:22:34,483 INFO     Evaluating the model... (29000/59072)
2025-12-13 12:22:38,923 INFO     Evaluating the model... (29500/59072)
2025-12-13 12:22:43,999 INFO     Evaluating the model... (30000/59072)
2025-12-13 12:22:50,372 INFO     Evaluating the model... (30500/59072)
2025-12-13 12:22:54,757 INFO     Evaluating the model... (31000/59072)
2025-12-13 12:22:59,293 INFO     Evaluating the model... (31500/59072)
2025-12-13 12:23:03,923 INFO     Evaluating the model... (32000/59072)
2025-12-13 12:23:08,631 INFO     Evaluating the model... (32500/59072)
2025-12-13 12:23:14,150 INFO     Evaluating the model... (33000/59072)
2025-12-13 12:23:18,785 INFO     Evaluating the model... (33500/59072)
2025-12-13 12:23:23,307 INFO     Evaluating the model... (34000/59072)
2025-12-13 12:23:27,963 INFO     Evaluating the model... (34500/59072)
2025-12-13 12:23:32,651 INFO     Evaluating the model... (35000/59072)
2025-12-13 12:23:37,869 INFO     Evaluating the model... (35500/59072)
2025-12-13 12:23:42,477 INFO     Evaluating the model... (36000/59072)
2025-12-13 12:23:47,163 INFO     Evaluating the model... (36500/59072)
2025-12-13 12:23:51,518 INFO     Evaluating the model... (37000/59072)
2025-12-13 12:23:55,924 INFO     Evaluating the model... (37500/59072)
2025-12-13 12:24:01,239 INFO     Evaluating the model... (38000/59072)
2025-12-13 12:24:05,915 INFO     Evaluating the model... (38500/59072)
2025-12-13 12:24:10,732 INFO     Evaluating the model... (39000/59072)
2025-12-13 12:24:15,054 INFO     Evaluating the model... (39500/59072)
2025-12-13 12:24:19,449 INFO     Evaluating the model... (40000/59072)
2025-12-13 12:24:24,662 INFO     Evaluating the model... (40500/59072)
2025-12-13 12:24:29,344 INFO     Evaluating the model... (41000/59072)
2025-12-13 12:24:33,773 INFO     Evaluating the model... (41500/59072)
2025-12-13 12:24:38,370 INFO     Evaluating the model... (42000/59072)
2025-12-13 12:24:42,852 INFO     Evaluating the model... (42500/59072)
2025-12-13 12:24:48,623 INFO     Evaluating the model... (43000/59072)
2025-12-13 12:24:53,320 INFO     Evaluating the model... (43500/59072)
2025-12-13 12:24:58,042 INFO     Evaluating the model... (44000/59072)
2025-12-13 12:25:02,744 INFO     Evaluating the model... (44500/59072)
2025-12-13 12:25:07,451 INFO     Evaluating the model... (45000/59072)
2025-12-13 12:25:12,861 INFO     Evaluating the model... (45500/59072)
2025-12-13 12:25:17,455 INFO     Evaluating the model... (46000/59072)
2025-12-13 12:25:22,151 INFO     Evaluating the model... (46500/59072)
2025-12-13 12:25:26,810 INFO     Evaluating the model... (47000/59072)
2025-12-13 12:25:32,949 INFO     Evaluating the model... (47500/59072)
2025-12-13 12:25:37,713 INFO     Evaluating the model... (48000/59072)
2025-12-13 12:25:42,474 INFO     Evaluating the model... (48500/59072)
2025-12-13 12:25:47,467 INFO     Evaluating the model... (49000/59072)
2025-12-13 12:25:52,294 INFO     Evaluating the model... (49500/59072)
2025-12-13 12:25:58,540 INFO     Evaluating the model... (50000/59072)
2025-12-13 12:26:03,147 INFO     Evaluating the model... (50500/59072)
2025-12-13 12:26:07,697 INFO     Evaluating the model... (51000/59072)
2025-12-13 12:26:12,075 INFO     Evaluating the model... (51500/59072)
2025-12-13 12:26:16,399 INFO     Evaluating the model... (52000/59072)
2025-12-13 12:26:22,529 INFO     Evaluating the model... (52500/59072)
2025-12-13 12:26:27,082 INFO     Evaluating the model... (53000/59072)
2025-12-13 12:26:31,504 INFO     Evaluating the model... (53500/59072)
2025-12-13 12:26:36,091 INFO     Evaluating the model... (54000/59072)
2025-12-13 12:26:40,948 INFO     Evaluating the model... (54500/59072)
2025-12-13 12:26:46,621 INFO     Evaluating the model... (55000/59072)
2025-12-13 12:26:50,977 INFO     Evaluating the model... (55500/59072)
2025-12-13 12:26:55,718 INFO     Evaluating the model... (56000/59072)
2025-12-13 12:27:00,209 INFO     Evaluating the model... (56500/59072)
2025-12-13 12:27:04,583 INFO     Evaluating the model... (57000/59072)
2025-12-13 12:27:10,037 INFO     Evaluating the model... (57500/59072)
2025-12-13 12:27:14,537 INFO     Evaluating the model... (58000/59072)
2025-12-13 12:27:18,967 INFO     Evaluating the model... (58500/59072)
2025-12-13 12:27:23,192 INFO     Evaluating the model... (59000/59072)
2025-12-13 12:27:24,128 INFO     Test MRR at step 30000: 0.713240
2025-12-13 12:27:24,128 INFO     Test MR at step 30000: 237.080099
2025-12-13 12:27:24,128 INFO     Test HITS@1 at step 30000: 0.644538
2025-12-13 12:27:24,128 INFO     Test HITS@3 at step 30000: 0.760043
2025-12-13 12:27:24,128 INFO     Test HITS@10 at step 30000: 0.832778
2025-12-13 12:27:29,440 INFO     Training average regularization at step 30100: 0.243492
2025-12-13 12:27:29,441 INFO     Training average positive_sample_loss at step 30100: 0.016152
2025-12-13 12:27:29,441 INFO     Training average negative_sample_loss at step 30100: 0.029888
2025-12-13 12:27:29,441 INFO     Training average loss at step 30100: 0.266512
2025-12-13 12:27:34,790 INFO     Training average regularization at step 30200: 0.242821
2025-12-13 12:27:34,791 INFO     Training average positive_sample_loss at step 30200: 0.014987
2025-12-13 12:27:34,791 INFO     Training average negative_sample_loss at step 30200: 0.025523
2025-12-13 12:27:34,791 INFO     Training average loss at step 30200: 0.263076
2025-12-13 12:27:40,175 INFO     Training average regularization at step 30300: 0.242149
2025-12-13 12:27:40,176 INFO     Training average positive_sample_loss at step 30300: 0.015723
2025-12-13 12:27:40,176 INFO     Training average negative_sample_loss at step 30300: 0.030651
2025-12-13 12:27:40,176 INFO     Training average loss at step 30300: 0.265336
2025-12-13 12:27:45,547 INFO     Training average regularization at step 30400: 0.241489
2025-12-13 12:27:45,547 INFO     Training average positive_sample_loss at step 30400: 0.016409
2025-12-13 12:27:45,547 INFO     Training average negative_sample_loss at step 30400: 0.028876
2025-12-13 12:27:45,547 INFO     Training average loss at step 30400: 0.264131
2025-12-13 12:27:50,899 INFO     Training average regularization at step 30500: 0.240821
2025-12-13 12:27:50,899 INFO     Training average positive_sample_loss at step 30500: 0.013985
2025-12-13 12:27:50,899 INFO     Training average negative_sample_loss at step 30500: 0.027878
2025-12-13 12:27:50,899 INFO     Training average loss at step 30500: 0.261752
2025-12-13 12:27:56,334 INFO     Training average regularization at step 30600: 0.240147
2025-12-13 12:27:56,336 INFO     Training average positive_sample_loss at step 30600: 0.015536
2025-12-13 12:27:56,336 INFO     Training average negative_sample_loss at step 30600: 0.034144
2025-12-13 12:27:56,336 INFO     Training average loss at step 30600: 0.264987
2025-12-13 12:28:01,786 INFO     Training average regularization at step 30700: 0.239491
2025-12-13 12:28:01,786 INFO     Training average positive_sample_loss at step 30700: 0.016230
2025-12-13 12:28:01,786 INFO     Training average negative_sample_loss at step 30700: 0.029189
2025-12-13 12:28:01,786 INFO     Training average loss at step 30700: 0.262201
2025-12-13 12:28:07,362 INFO     Training average regularization at step 30800: 0.238831
2025-12-13 12:28:07,364 INFO     Training average positive_sample_loss at step 30800: 0.015766
2025-12-13 12:28:07,364 INFO     Training average negative_sample_loss at step 30800: 0.034722
2025-12-13 12:28:07,364 INFO     Training average loss at step 30800: 0.264076
2025-12-13 12:28:12,733 INFO     Training average regularization at step 30900: 0.238177
2025-12-13 12:28:12,734 INFO     Training average positive_sample_loss at step 30900: 0.016765
2025-12-13 12:28:12,734 INFO     Training average negative_sample_loss at step 30900: 0.031472
2025-12-13 12:28:12,734 INFO     Training average loss at step 30900: 0.262295
2025-12-13 12:28:18,045 INFO     Training average regularization at step 31000: 0.237529
2025-12-13 12:28:18,047 INFO     Training average positive_sample_loss at step 31000: 0.016124
2025-12-13 12:28:18,047 INFO     Training average negative_sample_loss at step 31000: 0.029570
2025-12-13 12:28:18,047 INFO     Training average loss at step 31000: 0.260376
2025-12-13 12:28:23,289 INFO     Training average regularization at step 31100: 0.236883
2025-12-13 12:28:23,289 INFO     Training average positive_sample_loss at step 31100: 0.016183
2025-12-13 12:28:23,289 INFO     Training average negative_sample_loss at step 31100: 0.034779
2025-12-13 12:28:23,289 INFO     Training average loss at step 31100: 0.262364
2025-12-13 12:28:28,541 INFO     Training average regularization at step 31200: 0.236251
2025-12-13 12:28:28,541 INFO     Training average positive_sample_loss at step 31200: 0.016486
2025-12-13 12:28:28,541 INFO     Training average negative_sample_loss at step 31200: 0.026654
2025-12-13 12:28:28,541 INFO     Training average loss at step 31200: 0.257821
2025-12-13 12:28:33,784 INFO     Training average regularization at step 31300: 0.235607
2025-12-13 12:28:33,784 INFO     Training average positive_sample_loss at step 31300: 0.016080
2025-12-13 12:28:33,785 INFO     Training average negative_sample_loss at step 31300: 0.029516
2025-12-13 12:28:33,785 INFO     Training average loss at step 31300: 0.258405
2025-12-13 12:28:39,073 INFO     Training average regularization at step 31400: 0.234964
2025-12-13 12:28:39,073 INFO     Training average positive_sample_loss at step 31400: 0.016940
2025-12-13 12:28:39,073 INFO     Training average negative_sample_loss at step 31400: 0.031894
2025-12-13 12:28:39,074 INFO     Training average loss at step 31400: 0.259381
2025-12-13 12:28:44,404 INFO     Training average regularization at step 31500: 0.234339
2025-12-13 12:28:44,404 INFO     Training average positive_sample_loss at step 31500: 0.014879
2025-12-13 12:28:44,404 INFO     Training average negative_sample_loss at step 31500: 0.026688
2025-12-13 12:28:44,405 INFO     Training average loss at step 31500: 0.255122
2025-12-13 12:28:49,732 INFO     Training average regularization at step 31600: 0.233711
2025-12-13 12:28:49,733 INFO     Training average positive_sample_loss at step 31600: 0.016470
2025-12-13 12:28:49,733 INFO     Training average negative_sample_loss at step 31600: 0.031596
2025-12-13 12:28:49,733 INFO     Training average loss at step 31600: 0.257744
2025-12-13 12:28:55,072 INFO     Training average regularization at step 31700: 0.233084
2025-12-13 12:28:55,072 INFO     Training average positive_sample_loss at step 31700: 0.016975
2025-12-13 12:28:55,072 INFO     Training average negative_sample_loss at step 31700: 0.027733
2025-12-13 12:28:55,072 INFO     Training average loss at step 31700: 0.255438
2025-12-13 12:29:00,409 INFO     Training average regularization at step 31800: 0.232452
2025-12-13 12:29:00,409 INFO     Training average positive_sample_loss at step 31800: 0.016912
2025-12-13 12:29:00,409 INFO     Training average negative_sample_loss at step 31800: 0.037323
2025-12-13 12:29:00,409 INFO     Training average loss at step 31800: 0.259570
2025-12-13 12:29:05,662 INFO     Training average regularization at step 31900: 0.231835
2025-12-13 12:29:05,663 INFO     Training average positive_sample_loss at step 31900: 0.016030
2025-12-13 12:29:05,663 INFO     Training average negative_sample_loss at step 31900: 0.029536
2025-12-13 12:29:05,663 INFO     Training average loss at step 31900: 0.254619
2025-12-13 12:29:11,054 INFO     Training average regularization at step 32000: 0.231224
2025-12-13 12:29:11,054 INFO     Training average positive_sample_loss at step 32000: 0.017783
2025-12-13 12:29:11,054 INFO     Training average negative_sample_loss at step 32000: 0.030675
2025-12-13 12:29:11,054 INFO     Training average loss at step 32000: 0.255453
2025-12-13 12:29:16,354 INFO     Training average regularization at step 32100: 0.230612
2025-12-13 12:29:16,354 INFO     Training average positive_sample_loss at step 32100: 0.016506
2025-12-13 12:29:16,354 INFO     Training average negative_sample_loss at step 32100: 0.029020
2025-12-13 12:29:16,355 INFO     Training average loss at step 32100: 0.253375
2025-12-13 12:29:21,629 INFO     Training average regularization at step 32200: 0.229991
2025-12-13 12:29:21,629 INFO     Training average positive_sample_loss at step 32200: 0.015852
2025-12-13 12:29:21,629 INFO     Training average negative_sample_loss at step 32200: 0.031615
2025-12-13 12:29:21,629 INFO     Training average loss at step 32200: 0.253725
2025-12-13 12:29:26,878 INFO     Training average regularization at step 32300: 0.229390
2025-12-13 12:29:26,878 INFO     Training average positive_sample_loss at step 32300: 0.017625
2025-12-13 12:29:26,878 INFO     Training average negative_sample_loss at step 32300: 0.035921
2025-12-13 12:29:26,878 INFO     Training average loss at step 32300: 0.256164
2025-12-13 12:29:32,152 INFO     Training average regularization at step 32400: 0.228798
2025-12-13 12:29:32,153 INFO     Training average positive_sample_loss at step 32400: 0.016171
2025-12-13 12:29:32,153 INFO     Training average negative_sample_loss at step 32400: 0.027841
2025-12-13 12:29:32,153 INFO     Training average loss at step 32400: 0.250804
2025-12-13 12:29:37,384 INFO     Training average regularization at step 32500: 0.228199
2025-12-13 12:29:37,384 INFO     Training average positive_sample_loss at step 32500: 0.016336
2025-12-13 12:29:37,384 INFO     Training average negative_sample_loss at step 32500: 0.031188
2025-12-13 12:29:37,384 INFO     Training average loss at step 32500: 0.251961
2025-12-13 12:29:42,656 INFO     Training average regularization at step 32600: 0.227605
2025-12-13 12:29:42,656 INFO     Training average positive_sample_loss at step 32600: 0.017151
2025-12-13 12:29:42,656 INFO     Training average negative_sample_loss at step 32600: 0.031323
2025-12-13 12:29:42,656 INFO     Training average loss at step 32600: 0.251842
2025-12-13 12:29:47,880 INFO     Training average regularization at step 32700: 0.227018
2025-12-13 12:29:47,881 INFO     Training average positive_sample_loss at step 32700: 0.017786
2025-12-13 12:29:47,881 INFO     Training average negative_sample_loss at step 32700: 0.031693
2025-12-13 12:29:47,881 INFO     Training average loss at step 32700: 0.251757
2025-12-13 12:29:52,902 INFO     Training average regularization at step 32800: 0.226420
2025-12-13 12:29:52,902 INFO     Training average positive_sample_loss at step 32800: 0.013713
2025-12-13 12:29:52,902 INFO     Training average negative_sample_loss at step 32800: 0.029672
2025-12-13 12:29:52,902 INFO     Training average loss at step 32800: 0.248112
2025-12-13 12:29:58,061 INFO     Training average regularization at step 32900: 0.225818
2025-12-13 12:29:58,061 INFO     Training average positive_sample_loss at step 32900: 0.016414
2025-12-13 12:29:58,061 INFO     Training average negative_sample_loss at step 32900: 0.031596
2025-12-13 12:29:58,061 INFO     Training average loss at step 32900: 0.249823
2025-12-13 12:30:03,217 INFO     Training average regularization at step 33000: 0.225243
2025-12-13 12:30:03,217 INFO     Training average positive_sample_loss at step 33000: 0.015832
2025-12-13 12:30:03,217 INFO     Training average negative_sample_loss at step 33000: 0.034693
2025-12-13 12:30:03,217 INFO     Training average loss at step 33000: 0.250506
2025-12-13 12:30:08,544 INFO     Training average regularization at step 33100: 0.224690
2025-12-13 12:30:08,545 INFO     Training average positive_sample_loss at step 33100: 0.016148
2025-12-13 12:30:08,545 INFO     Training average negative_sample_loss at step 33100: 0.030530
2025-12-13 12:30:08,545 INFO     Training average loss at step 33100: 0.248030
2025-12-13 12:30:13,824 INFO     Training average regularization at step 33200: 0.224128
2025-12-13 12:30:13,825 INFO     Training average positive_sample_loss at step 33200: 0.016844
2025-12-13 12:30:13,825 INFO     Training average negative_sample_loss at step 33200: 0.027697
2025-12-13 12:30:13,825 INFO     Training average loss at step 33200: 0.246399
2025-12-13 12:30:19,101 INFO     Training average regularization at step 33300: 0.223567
2025-12-13 12:30:19,102 INFO     Training average positive_sample_loss at step 33300: 0.015439
2025-12-13 12:30:19,102 INFO     Training average negative_sample_loss at step 33300: 0.032418
2025-12-13 12:30:19,102 INFO     Training average loss at step 33300: 0.247495
2025-12-13 12:30:24,320 INFO     Training average regularization at step 33400: 0.223007
2025-12-13 12:30:24,320 INFO     Training average positive_sample_loss at step 33400: 0.015701
2025-12-13 12:30:24,320 INFO     Training average negative_sample_loss at step 33400: 0.032052
2025-12-13 12:30:24,320 INFO     Training average loss at step 33400: 0.246883
2025-12-13 12:30:29,573 INFO     Training average regularization at step 33500: 0.222454
2025-12-13 12:30:29,574 INFO     Training average positive_sample_loss at step 33500: 0.014573
2025-12-13 12:30:29,574 INFO     Training average negative_sample_loss at step 33500: 0.029273
2025-12-13 12:30:29,574 INFO     Training average loss at step 33500: 0.244378
2025-12-13 12:30:34,835 INFO     Training average regularization at step 33600: 0.221880
2025-12-13 12:30:34,835 INFO     Training average positive_sample_loss at step 33600: 0.015143
2025-12-13 12:30:34,835 INFO     Training average negative_sample_loss at step 33600: 0.032569
2025-12-13 12:30:34,835 INFO     Training average loss at step 33600: 0.245736
2025-12-13 12:30:40,162 INFO     Training average regularization at step 33700: 0.221324
2025-12-13 12:30:40,162 INFO     Training average positive_sample_loss at step 33700: 0.015177
2025-12-13 12:30:40,162 INFO     Training average negative_sample_loss at step 33700: 0.032305
2025-12-13 12:30:40,163 INFO     Training average loss at step 33700: 0.245065
2025-12-13 12:30:45,480 INFO     Training average regularization at step 33800: 0.220767
2025-12-13 12:30:45,480 INFO     Training average positive_sample_loss at step 33800: 0.014640
2025-12-13 12:30:45,480 INFO     Training average negative_sample_loss at step 33800: 0.028975
2025-12-13 12:30:45,480 INFO     Training average loss at step 33800: 0.242574
2025-12-13 12:30:52,037 INFO     Training average regularization at step 33900: 0.220199
2025-12-13 12:30:52,037 INFO     Training average positive_sample_loss at step 33900: 0.012628
2025-12-13 12:30:52,037 INFO     Training average negative_sample_loss at step 33900: 0.027347
2025-12-13 12:30:52,037 INFO     Training average loss at step 33900: 0.240187
2025-12-13 12:30:57,169 INFO     Training average regularization at step 34000: 0.219622
2025-12-13 12:30:57,169 INFO     Training average positive_sample_loss at step 34000: 0.012087
2025-12-13 12:30:57,169 INFO     Training average negative_sample_loss at step 34000: 0.026635
2025-12-13 12:30:57,169 INFO     Training average loss at step 34000: 0.238983
2025-12-13 12:31:02,465 INFO     Training average regularization at step 34100: 0.219060
2025-12-13 12:31:02,465 INFO     Training average positive_sample_loss at step 34100: 0.012000
2025-12-13 12:31:02,465 INFO     Training average negative_sample_loss at step 34100: 0.026113
2025-12-13 12:31:02,465 INFO     Training average loss at step 34100: 0.238116
2025-12-13 12:31:07,833 INFO     Training average regularization at step 34200: 0.218484
2025-12-13 12:31:07,833 INFO     Training average positive_sample_loss at step 34200: 0.012090
2025-12-13 12:31:07,833 INFO     Training average negative_sample_loss at step 34200: 0.028622
2025-12-13 12:31:07,833 INFO     Training average loss at step 34200: 0.238840
2025-12-13 12:31:12,941 INFO     Training average regularization at step 34300: 0.217915
2025-12-13 12:31:12,941 INFO     Training average positive_sample_loss at step 34300: 0.012549
2025-12-13 12:31:12,941 INFO     Training average negative_sample_loss at step 34300: 0.027397
2025-12-13 12:31:12,941 INFO     Training average loss at step 34300: 0.237888
2025-12-13 12:31:18,033 INFO     Training average regularization at step 34400: 0.217352
2025-12-13 12:31:18,033 INFO     Training average positive_sample_loss at step 34400: 0.012733
2025-12-13 12:31:18,033 INFO     Training average negative_sample_loss at step 34400: 0.024647
2025-12-13 12:31:18,033 INFO     Training average loss at step 34400: 0.236042
2025-12-13 12:31:23,258 INFO     Training average regularization at step 34500: 0.216777
2025-12-13 12:31:23,258 INFO     Training average positive_sample_loss at step 34500: 0.012521
2025-12-13 12:31:23,258 INFO     Training average negative_sample_loss at step 34500: 0.025225
2025-12-13 12:31:23,258 INFO     Training average loss at step 34500: 0.235650
2025-12-13 12:31:28,473 INFO     Training average regularization at step 34600: 0.216198
2025-12-13 12:31:28,474 INFO     Training average positive_sample_loss at step 34600: 0.012166
2025-12-13 12:31:28,474 INFO     Training average negative_sample_loss at step 34600: 0.028163
2025-12-13 12:31:28,474 INFO     Training average loss at step 34600: 0.236362
2025-12-13 12:31:33,813 INFO     Training average regularization at step 34700: 0.215639
2025-12-13 12:31:33,813 INFO     Training average positive_sample_loss at step 34700: 0.013427
2025-12-13 12:31:33,813 INFO     Training average negative_sample_loss at step 34700: 0.029841
2025-12-13 12:31:33,813 INFO     Training average loss at step 34700: 0.237273
2025-12-13 12:31:39,130 INFO     Training average regularization at step 34800: 0.215089
2025-12-13 12:31:39,130 INFO     Training average positive_sample_loss at step 34800: 0.013272
2025-12-13 12:31:39,130 INFO     Training average negative_sample_loss at step 34800: 0.024900
2025-12-13 12:31:39,130 INFO     Training average loss at step 34800: 0.234176
2025-12-13 12:31:44,504 INFO     Training average regularization at step 34900: 0.214539
2025-12-13 12:31:44,504 INFO     Training average positive_sample_loss at step 34900: 0.013764
2025-12-13 12:31:44,504 INFO     Training average negative_sample_loss at step 34900: 0.028642
2025-12-13 12:31:44,504 INFO     Training average loss at step 34900: 0.235742
2025-12-13 12:31:49,872 INFO     Training average regularization at step 35000: 0.214000
2025-12-13 12:31:49,872 INFO     Training average positive_sample_loss at step 35000: 0.014381
2025-12-13 12:31:49,872 INFO     Training average negative_sample_loss at step 35000: 0.025051
2025-12-13 12:31:49,873 INFO     Training average loss at step 35000: 0.233716
2025-12-13 12:31:55,227 INFO     Training average regularization at step 35100: 0.213445
2025-12-13 12:31:55,228 INFO     Training average positive_sample_loss at step 35100: 0.013721
2025-12-13 12:31:55,228 INFO     Training average negative_sample_loss at step 35100: 0.024087
2025-12-13 12:31:55,228 INFO     Training average loss at step 35100: 0.232349
2025-12-13 12:32:00,599 INFO     Training average regularization at step 35200: 0.212892
2025-12-13 12:32:00,599 INFO     Training average positive_sample_loss at step 35200: 0.015048
2025-12-13 12:32:00,599 INFO     Training average negative_sample_loss at step 35200: 0.027284
2025-12-13 12:32:00,599 INFO     Training average loss at step 35200: 0.234058
2025-12-13 12:32:05,903 INFO     Training average regularization at step 35300: 0.212352
2025-12-13 12:32:05,903 INFO     Training average positive_sample_loss at step 35300: 0.014064
2025-12-13 12:32:05,903 INFO     Training average negative_sample_loss at step 35300: 0.025595
2025-12-13 12:32:05,903 INFO     Training average loss at step 35300: 0.232181
2025-12-13 12:32:11,239 INFO     Training average regularization at step 35400: 0.211826
2025-12-13 12:32:11,239 INFO     Training average positive_sample_loss at step 35400: 0.014215
2025-12-13 12:32:11,239 INFO     Training average negative_sample_loss at step 35400: 0.028918
2025-12-13 12:32:11,239 INFO     Training average loss at step 35400: 0.233393
2025-12-13 12:32:16,523 INFO     Training average regularization at step 35500: 0.211301
2025-12-13 12:32:16,525 INFO     Training average positive_sample_loss at step 35500: 0.014289
2025-12-13 12:32:16,525 INFO     Training average negative_sample_loss at step 35500: 0.028165
2025-12-13 12:32:16,525 INFO     Training average loss at step 35500: 0.232528
2025-12-13 12:32:21,799 INFO     Training average regularization at step 35600: 0.210771
2025-12-13 12:32:21,799 INFO     Training average positive_sample_loss at step 35600: 0.015007
2025-12-13 12:32:21,799 INFO     Training average negative_sample_loss at step 35600: 0.032202
2025-12-13 12:32:21,799 INFO     Training average loss at step 35600: 0.234375
2025-12-13 12:32:27,068 INFO     Training average regularization at step 35700: 0.210270
2025-12-13 12:32:27,068 INFO     Training average positive_sample_loss at step 35700: 0.014048
2025-12-13 12:32:27,068 INFO     Training average negative_sample_loss at step 35700: 0.026178
2025-12-13 12:32:27,068 INFO     Training average loss at step 35700: 0.230383
2025-12-13 12:32:32,195 INFO     Training average regularization at step 35800: 0.209750
2025-12-13 12:32:32,196 INFO     Training average positive_sample_loss at step 35800: 0.013582
2025-12-13 12:32:32,196 INFO     Training average negative_sample_loss at step 35800: 0.027171
2025-12-13 12:32:32,196 INFO     Training average loss at step 35800: 0.230127
2025-12-13 12:32:37,282 INFO     Training average regularization at step 35900: 0.209225
2025-12-13 12:32:37,283 INFO     Training average positive_sample_loss at step 35900: 0.013594
2025-12-13 12:32:37,283 INFO     Training average negative_sample_loss at step 35900: 0.026640
2025-12-13 12:32:37,283 INFO     Training average loss at step 35900: 0.229342
2025-12-13 12:32:42,308 INFO     Training average regularization at step 36000: 0.208704
2025-12-13 12:32:42,308 INFO     Training average positive_sample_loss at step 36000: 0.013968
2025-12-13 12:32:42,308 INFO     Training average negative_sample_loss at step 36000: 0.027676
2025-12-13 12:32:42,308 INFO     Training average loss at step 36000: 0.229526
2025-12-13 12:32:47,516 INFO     Training average regularization at step 36100: 0.208195
2025-12-13 12:32:47,517 INFO     Training average positive_sample_loss at step 36100: 0.013393
2025-12-13 12:32:47,517 INFO     Training average negative_sample_loss at step 36100: 0.025348
2025-12-13 12:32:47,517 INFO     Training average loss at step 36100: 0.227566
2025-12-13 12:32:52,891 INFO     Training average regularization at step 36200: 0.207683
2025-12-13 12:32:52,891 INFO     Training average positive_sample_loss at step 36200: 0.013403
2025-12-13 12:32:52,891 INFO     Training average negative_sample_loss at step 36200: 0.025872
2025-12-13 12:32:52,891 INFO     Training average loss at step 36200: 0.227321
2025-12-13 12:32:58,219 INFO     Training average regularization at step 36300: 0.207160
2025-12-13 12:32:58,219 INFO     Training average positive_sample_loss at step 36300: 0.014701
2025-12-13 12:32:58,219 INFO     Training average negative_sample_loss at step 36300: 0.028832
2025-12-13 12:32:58,219 INFO     Training average loss at step 36300: 0.228927
2025-12-13 12:33:03,506 INFO     Training average regularization at step 36400: 0.206665
2025-12-13 12:33:03,507 INFO     Training average positive_sample_loss at step 36400: 0.015792
2025-12-13 12:33:03,507 INFO     Training average negative_sample_loss at step 36400: 0.032175
2025-12-13 12:33:03,507 INFO     Training average loss at step 36400: 0.230649
2025-12-13 12:33:08,889 INFO     Training average regularization at step 36500: 0.206187
2025-12-13 12:33:08,890 INFO     Training average positive_sample_loss at step 36500: 0.014447
2025-12-13 12:33:08,890 INFO     Training average negative_sample_loss at step 36500: 0.029444
2025-12-13 12:33:08,890 INFO     Training average loss at step 36500: 0.228133
2025-12-13 12:33:14,214 INFO     Training average regularization at step 36600: 0.205701
2025-12-13 12:33:14,214 INFO     Training average positive_sample_loss at step 36600: 0.013975
2025-12-13 12:33:14,214 INFO     Training average negative_sample_loss at step 36600: 0.026428
2025-12-13 12:33:14,214 INFO     Training average loss at step 36600: 0.225903
2025-12-13 12:33:19,523 INFO     Training average regularization at step 36700: 0.205217
2025-12-13 12:33:19,524 INFO     Training average positive_sample_loss at step 36700: 0.013226
2025-12-13 12:33:19,524 INFO     Training average negative_sample_loss at step 36700: 0.027740
2025-12-13 12:33:19,524 INFO     Training average loss at step 36700: 0.225699
2025-12-13 12:33:24,808 INFO     Training average regularization at step 36800: 0.204739
2025-12-13 12:33:24,809 INFO     Training average positive_sample_loss at step 36800: 0.014381
2025-12-13 12:33:24,809 INFO     Training average negative_sample_loss at step 36800: 0.031494
2025-12-13 12:33:24,809 INFO     Training average loss at step 36800: 0.227676
2025-12-13 12:33:30,011 INFO     Training average regularization at step 36900: 0.204268
2025-12-13 12:33:30,011 INFO     Training average positive_sample_loss at step 36900: 0.014068
2025-12-13 12:33:30,011 INFO     Training average negative_sample_loss at step 36900: 0.022736
2025-12-13 12:33:30,011 INFO     Training average loss at step 36900: 0.222670
2025-12-13 12:33:35,189 INFO     Training average regularization at step 37000: 0.203791
2025-12-13 12:33:35,189 INFO     Training average positive_sample_loss at step 37000: 0.015110
2025-12-13 12:33:35,189 INFO     Training average negative_sample_loss at step 37000: 0.029813
2025-12-13 12:33:35,189 INFO     Training average loss at step 37000: 0.226252
2025-12-13 12:33:40,532 INFO     Training average regularization at step 37100: 0.203324
2025-12-13 12:33:40,533 INFO     Training average positive_sample_loss at step 37100: 0.016095
2025-12-13 12:33:40,533 INFO     Training average negative_sample_loss at step 37100: 0.029947
2025-12-13 12:33:40,533 INFO     Training average loss at step 37100: 0.226344
2025-12-13 12:33:45,912 INFO     Training average regularization at step 37200: 0.202846
2025-12-13 12:33:45,913 INFO     Training average positive_sample_loss at step 37200: 0.015101
2025-12-13 12:33:45,913 INFO     Training average negative_sample_loss at step 37200: 0.028934
2025-12-13 12:33:45,913 INFO     Training average loss at step 37200: 0.224864
2025-12-13 12:33:51,287 INFO     Training average regularization at step 37300: 0.202388
2025-12-13 12:33:51,288 INFO     Training average positive_sample_loss at step 37300: 0.015272
2025-12-13 12:33:51,288 INFO     Training average negative_sample_loss at step 37300: 0.032070
2025-12-13 12:33:51,288 INFO     Training average loss at step 37300: 0.226059
2025-12-13 12:33:56,651 INFO     Training average regularization at step 37400: 0.201945
2025-12-13 12:33:56,651 INFO     Training average positive_sample_loss at step 37400: 0.016926
2025-12-13 12:33:56,651 INFO     Training average negative_sample_loss at step 37400: 0.031487
2025-12-13 12:33:56,651 INFO     Training average loss at step 37400: 0.226152
2025-12-13 12:34:02,033 INFO     Training average regularization at step 37500: 0.201510
2025-12-13 12:34:02,034 INFO     Training average positive_sample_loss at step 37500: 0.015061
2025-12-13 12:34:02,034 INFO     Training average negative_sample_loss at step 37500: 0.027459
2025-12-13 12:34:02,034 INFO     Training average loss at step 37500: 0.222770
2025-12-13 12:34:07,313 INFO     Training average regularization at step 37600: 0.201069
2025-12-13 12:34:07,314 INFO     Training average positive_sample_loss at step 37600: 0.014959
2025-12-13 12:34:07,314 INFO     Training average negative_sample_loss at step 37600: 0.024971
2025-12-13 12:34:07,314 INFO     Training average loss at step 37600: 0.221034
2025-12-13 12:34:12,467 INFO     Training average regularization at step 37700: 0.200625
2025-12-13 12:34:12,467 INFO     Training average positive_sample_loss at step 37700: 0.015013
2025-12-13 12:34:12,467 INFO     Training average negative_sample_loss at step 37700: 0.032857
2025-12-13 12:34:12,467 INFO     Training average loss at step 37700: 0.224561
2025-12-13 12:34:17,666 INFO     Training average regularization at step 37800: 0.200184
2025-12-13 12:34:17,667 INFO     Training average positive_sample_loss at step 37800: 0.015386
2025-12-13 12:34:17,667 INFO     Training average negative_sample_loss at step 37800: 0.031181
2025-12-13 12:34:17,667 INFO     Training average loss at step 37800: 0.223467
2025-12-13 12:34:22,959 INFO     Training average regularization at step 37900: 0.199754
2025-12-13 12:34:22,959 INFO     Training average positive_sample_loss at step 37900: 0.014928
2025-12-13 12:34:22,959 INFO     Training average negative_sample_loss at step 37900: 0.028215
2025-12-13 12:34:22,959 INFO     Training average loss at step 37900: 0.221325
2025-12-13 12:34:28,139 INFO     Training average regularization at step 38000: 0.199315
2025-12-13 12:34:28,139 INFO     Training average positive_sample_loss at step 38000: 0.014047
2025-12-13 12:34:28,139 INFO     Training average negative_sample_loss at step 38000: 0.029817
2025-12-13 12:34:28,139 INFO     Training average loss at step 38000: 0.221248
2025-12-13 12:34:33,452 INFO     Training average regularization at step 38100: 0.198894
2025-12-13 12:34:33,452 INFO     Training average positive_sample_loss at step 38100: 0.014990
2025-12-13 12:34:33,452 INFO     Training average negative_sample_loss at step 38100: 0.024193
2025-12-13 12:34:33,452 INFO     Training average loss at step 38100: 0.218485
2025-12-13 12:34:38,688 INFO     Training average regularization at step 38200: 0.198473
2025-12-13 12:34:38,689 INFO     Training average positive_sample_loss at step 38200: 0.014606
2025-12-13 12:34:38,689 INFO     Training average negative_sample_loss at step 38200: 0.036773
2025-12-13 12:34:38,689 INFO     Training average loss at step 38200: 0.224162
2025-12-13 12:34:43,943 INFO     Training average regularization at step 38300: 0.198077
2025-12-13 12:34:43,943 INFO     Training average positive_sample_loss at step 38300: 0.014873
2025-12-13 12:34:43,943 INFO     Training average negative_sample_loss at step 38300: 0.030319
2025-12-13 12:34:43,943 INFO     Training average loss at step 38300: 0.220673
2025-12-13 12:34:49,254 INFO     Training average regularization at step 38400: 0.197675
2025-12-13 12:34:49,255 INFO     Training average positive_sample_loss at step 38400: 0.015598
2025-12-13 12:34:49,255 INFO     Training average negative_sample_loss at step 38400: 0.029319
2025-12-13 12:34:49,255 INFO     Training average loss at step 38400: 0.220133
2025-12-13 12:34:54,597 INFO     Training average regularization at step 38500: 0.197280
2025-12-13 12:34:54,597 INFO     Training average positive_sample_loss at step 38500: 0.014061
2025-12-13 12:34:54,597 INFO     Training average negative_sample_loss at step 38500: 0.026386
2025-12-13 12:34:54,597 INFO     Training average loss at step 38500: 0.217504
2025-12-13 12:34:59,963 INFO     Training average regularization at step 38600: 0.196871
2025-12-13 12:34:59,964 INFO     Training average positive_sample_loss at step 38600: 0.013924
2025-12-13 12:34:59,964 INFO     Training average negative_sample_loss at step 38600: 0.026767
2025-12-13 12:34:59,964 INFO     Training average loss at step 38600: 0.217217
2025-12-13 12:35:06,404 INFO     Training average regularization at step 38700: 0.196456
2025-12-13 12:35:06,405 INFO     Training average positive_sample_loss at step 38700: 0.011867
2025-12-13 12:35:06,405 INFO     Training average negative_sample_loss at step 38700: 0.028271
2025-12-13 12:35:06,405 INFO     Training average loss at step 38700: 0.216524
2025-12-13 12:35:11,761 INFO     Training average regularization at step 38800: 0.196013
2025-12-13 12:35:11,762 INFO     Training average positive_sample_loss at step 38800: 0.011659
2025-12-13 12:35:11,762 INFO     Training average negative_sample_loss at step 38800: 0.028761
2025-12-13 12:35:11,762 INFO     Training average loss at step 38800: 0.216223
2025-12-13 12:35:16,931 INFO     Training average regularization at step 38900: 0.195588
2025-12-13 12:35:16,932 INFO     Training average positive_sample_loss at step 38900: 0.010848
2025-12-13 12:35:16,932 INFO     Training average negative_sample_loss at step 38900: 0.024467
2025-12-13 12:35:16,932 INFO     Training average loss at step 38900: 0.213245
2025-12-13 12:35:22,251 INFO     Training average regularization at step 39000: 0.195181
2025-12-13 12:35:22,252 INFO     Training average positive_sample_loss at step 39000: 0.012090
2025-12-13 12:35:22,252 INFO     Training average negative_sample_loss at step 39000: 0.026789
2025-12-13 12:35:22,252 INFO     Training average loss at step 39000: 0.214621
2025-12-13 12:35:27,583 INFO     Training average regularization at step 39100: 0.194767
2025-12-13 12:35:27,583 INFO     Training average positive_sample_loss at step 39100: 0.012444
2025-12-13 12:35:27,583 INFO     Training average negative_sample_loss at step 39100: 0.024198
2025-12-13 12:35:27,583 INFO     Training average loss at step 39100: 0.213089
2025-12-13 12:35:32,861 INFO     Training average regularization at step 39200: 0.194351
2025-12-13 12:35:32,861 INFO     Training average positive_sample_loss at step 39200: 0.013177
2025-12-13 12:35:32,861 INFO     Training average negative_sample_loss at step 39200: 0.026465
2025-12-13 12:35:32,861 INFO     Training average loss at step 39200: 0.214171
2025-12-13 12:35:38,040 INFO     Training average regularization at step 39300: 0.193935
2025-12-13 12:35:38,040 INFO     Training average positive_sample_loss at step 39300: 0.012715
2025-12-13 12:35:38,040 INFO     Training average negative_sample_loss at step 39300: 0.028805
2025-12-13 12:35:38,040 INFO     Training average loss at step 39300: 0.214695
2025-12-13 12:35:43,300 INFO     Training average regularization at step 39400: 0.193527
2025-12-13 12:35:43,300 INFO     Training average positive_sample_loss at step 39400: 0.012214
2025-12-13 12:35:43,301 INFO     Training average negative_sample_loss at step 39400: 0.024761
2025-12-13 12:35:43,301 INFO     Training average loss at step 39400: 0.212015
2025-12-13 12:35:48,603 INFO     Training average regularization at step 39500: 0.193120
2025-12-13 12:35:48,604 INFO     Training average positive_sample_loss at step 39500: 0.011983
2025-12-13 12:35:48,604 INFO     Training average negative_sample_loss at step 39500: 0.025855
2025-12-13 12:35:48,604 INFO     Training average loss at step 39500: 0.212039
2025-12-13 12:35:53,820 INFO     Training average regularization at step 39600: 0.192702
2025-12-13 12:35:53,820 INFO     Training average positive_sample_loss at step 39600: 0.012302
2025-12-13 12:35:53,820 INFO     Training average negative_sample_loss at step 39600: 0.026647
2025-12-13 12:35:53,820 INFO     Training average loss at step 39600: 0.212176
2025-12-13 12:35:59,204 INFO     Training average regularization at step 39700: 0.192310
2025-12-13 12:35:59,204 INFO     Training average positive_sample_loss at step 39700: 0.014036
2025-12-13 12:35:59,204 INFO     Training average negative_sample_loss at step 39700: 0.028256
2025-12-13 12:35:59,204 INFO     Training average loss at step 39700: 0.213456
2025-12-13 12:36:04,608 INFO     Training average regularization at step 39800: 0.191928
2025-12-13 12:36:04,608 INFO     Training average positive_sample_loss at step 39800: 0.013433
2025-12-13 12:36:04,608 INFO     Training average negative_sample_loss at step 39800: 0.030154
2025-12-13 12:36:04,608 INFO     Training average loss at step 39800: 0.213722
2025-12-13 12:36:09,836 INFO     Training average regularization at step 39900: 0.191541
2025-12-13 12:36:09,837 INFO     Training average positive_sample_loss at step 39900: 0.013290
2025-12-13 12:36:09,837 INFO     Training average negative_sample_loss at step 39900: 0.027859
2025-12-13 12:36:09,837 INFO     Training average loss at step 39900: 0.212116
2025-12-13 12:36:15,118 INFO     Change learning_rate to 0.000026 at step 40000
2025-12-13 12:36:16,012 INFO     Training average regularization at step 40000: 0.191156
2025-12-13 12:36:16,013 INFO     Training average positive_sample_loss at step 40000: 0.013184
2025-12-13 12:36:16,013 INFO     Training average negative_sample_loss at step 40000: 0.027032
2025-12-13 12:36:16,013 INFO     Training average loss at step 40000: 0.211264
2025-12-13 12:36:16,013 INFO     Evaluating on Valid Dataset...
2025-12-13 12:36:16,729 INFO     Evaluating the model... (0/50000)
2025-12-13 12:36:22,375 INFO     Evaluating the model... (500/50000)
2025-12-13 12:36:27,091 INFO     Evaluating the model... (1000/50000)
2025-12-13 12:36:31,931 INFO     Evaluating the model... (1500/50000)
2025-12-13 12:36:36,607 INFO     Evaluating the model... (2000/50000)
2025-12-13 12:36:41,347 INFO     Evaluating the model... (2500/50000)
2025-12-13 12:36:46,861 INFO     Evaluating the model... (3000/50000)
2025-12-13 12:36:51,558 INFO     Evaluating the model... (3500/50000)
2025-12-13 12:36:56,137 INFO     Evaluating the model... (4000/50000)
2025-12-13 12:37:00,823 INFO     Evaluating the model... (4500/50000)
2025-12-13 12:37:05,530 INFO     Evaluating the model... (5000/50000)
2025-12-13 12:37:10,653 INFO     Evaluating the model... (5500/50000)
2025-12-13 12:37:15,146 INFO     Evaluating the model... (6000/50000)
2025-12-13 12:37:19,550 INFO     Evaluating the model... (6500/50000)
2025-12-13 12:37:24,346 INFO     Evaluating the model... (7000/50000)
2025-12-13 12:37:28,905 INFO     Evaluating the model... (7500/50000)
2025-12-13 12:37:34,308 INFO     Evaluating the model... (8000/50000)
2025-12-13 12:37:39,187 INFO     Evaluating the model... (8500/50000)
2025-12-13 12:37:43,874 INFO     Evaluating the model... (9000/50000)
2025-12-13 12:37:48,522 INFO     Evaluating the model... (9500/50000)
2025-12-13 12:37:53,041 INFO     Evaluating the model... (10000/50000)
2025-12-13 12:37:58,320 INFO     Evaluating the model... (10500/50000)
2025-12-13 12:38:02,808 INFO     Evaluating the model... (11000/50000)
2025-12-13 12:38:07,186 INFO     Evaluating the model... (11500/50000)
2025-12-13 12:38:11,587 INFO     Evaluating the model... (12000/50000)
2025-12-13 12:38:16,248 INFO     Evaluating the model... (12500/50000)
2025-12-13 12:38:20,849 INFO     Evaluating the model... (13000/50000)
2025-12-13 12:38:25,153 INFO     Evaluating the model... (13500/50000)
2025-12-13 12:38:29,421 INFO     Evaluating the model... (14000/50000)
2025-12-13 12:38:33,958 INFO     Evaluating the model... (14500/50000)
2025-12-13 12:38:38,709 INFO     Evaluating the model... (15000/50000)
2025-12-13 12:38:43,139 INFO     Evaluating the model... (15500/50000)
2025-12-13 12:38:47,617 INFO     Evaluating the model... (16000/50000)
2025-12-13 12:38:51,970 INFO     Evaluating the model... (16500/50000)
2025-12-13 12:38:56,371 INFO     Evaluating the model... (17000/50000)
2025-12-13 12:39:01,399 INFO     Evaluating the model... (17500/50000)
2025-12-13 12:39:05,800 INFO     Evaluating the model... (18000/50000)
2025-12-13 12:39:10,481 INFO     Evaluating the model... (18500/50000)
2025-12-13 12:39:14,681 INFO     Evaluating the model... (19000/50000)
2025-12-13 12:39:19,211 INFO     Evaluating the model... (19500/50000)
2025-12-13 12:39:24,181 INFO     Evaluating the model... (20000/50000)
2025-12-13 12:39:28,461 INFO     Evaluating the model... (20500/50000)
2025-12-13 12:39:33,047 INFO     Evaluating the model... (21000/50000)
2025-12-13 12:39:37,524 INFO     Evaluating the model... (21500/50000)
2025-12-13 12:39:41,819 INFO     Evaluating the model... (22000/50000)
2025-12-13 12:39:47,036 INFO     Evaluating the model... (22500/50000)
2025-12-13 12:39:51,461 INFO     Evaluating the model... (23000/50000)
2025-12-13 12:39:56,005 INFO     Evaluating the model... (23500/50000)
2025-12-13 12:40:00,616 INFO     Evaluating the model... (24000/50000)
2025-12-13 12:40:04,945 INFO     Evaluating the model... (24500/50000)
2025-12-13 12:40:10,667 INFO     Evaluating the model... (25000/50000)
2025-12-13 12:40:15,272 INFO     Evaluating the model... (25500/50000)
2025-12-13 12:40:20,113 INFO     Evaluating the model... (26000/50000)
2025-12-13 12:40:24,724 INFO     Evaluating the model... (26500/50000)
2025-12-13 12:40:29,405 INFO     Evaluating the model... (27000/50000)
2025-12-13 12:40:35,003 INFO     Evaluating the model... (27500/50000)
2025-12-13 12:40:39,505 INFO     Evaluating the model... (28000/50000)
2025-12-13 12:40:43,882 INFO     Evaluating the model... (28500/50000)
2025-12-13 12:40:48,203 INFO     Evaluating the model... (29000/50000)
2025-12-13 12:40:53,003 INFO     Evaluating the model... (29500/50000)
2025-12-13 12:40:58,278 INFO     Evaluating the model... (30000/50000)
2025-12-13 12:41:02,682 INFO     Evaluating the model... (30500/50000)
2025-12-13 12:41:07,196 INFO     Evaluating the model... (31000/50000)
2025-12-13 12:41:11,744 INFO     Evaluating the model... (31500/50000)
2025-12-13 12:41:15,884 INFO     Evaluating the model... (32000/50000)
2025-12-13 12:41:20,481 INFO     Evaluating the model... (32500/50000)
2025-12-13 12:41:24,779 INFO     Evaluating the model... (33000/50000)
2025-12-13 12:41:29,108 INFO     Evaluating the model... (33500/50000)
2025-12-13 12:41:33,224 INFO     Evaluating the model... (34000/50000)
2025-12-13 12:41:37,368 INFO     Evaluating the model... (34500/50000)
2025-12-13 12:41:42,222 INFO     Evaluating the model... (35000/50000)
2025-12-13 12:41:46,489 INFO     Evaluating the model... (35500/50000)
2025-12-13 12:41:50,957 INFO     Evaluating the model... (36000/50000)
2025-12-13 12:41:55,323 INFO     Evaluating the model... (36500/50000)
2025-12-13 12:41:59,845 INFO     Evaluating the model... (37000/50000)
2025-12-13 12:42:04,921 INFO     Evaluating the model... (37500/50000)
2025-12-13 12:42:09,327 INFO     Evaluating the model... (38000/50000)
2025-12-13 12:42:13,809 INFO     Evaluating the model... (38500/50000)
2025-12-13 12:42:18,170 INFO     Evaluating the model... (39000/50000)
2025-12-13 12:42:22,572 INFO     Evaluating the model... (39500/50000)
2025-12-13 12:42:27,870 INFO     Evaluating the model... (40000/50000)
2025-12-13 12:42:32,105 INFO     Evaluating the model... (40500/50000)
2025-12-13 12:42:36,371 INFO     Evaluating the model... (41000/50000)
2025-12-13 12:42:40,554 INFO     Evaluating the model... (41500/50000)
2025-12-13 12:42:45,931 INFO     Evaluating the model... (42000/50000)
2025-12-13 12:42:50,359 INFO     Evaluating the model... (42500/50000)
2025-12-13 12:42:54,628 INFO     Evaluating the model... (43000/50000)
2025-12-13 12:42:58,917 INFO     Evaluating the model... (43500/50000)
2025-12-13 12:43:03,339 INFO     Evaluating the model... (44000/50000)
2025-12-13 12:43:09,036 INFO     Evaluating the model... (44500/50000)
2025-12-13 12:43:13,195 INFO     Evaluating the model... (45000/50000)
2025-12-13 12:43:17,324 INFO     Evaluating the model... (45500/50000)
2025-12-13 12:43:21,579 INFO     Evaluating the model... (46000/50000)
2025-12-13 12:43:25,734 INFO     Evaluating the model... (46500/50000)
2025-12-13 12:43:31,361 INFO     Evaluating the model... (47000/50000)
2025-12-13 12:43:35,537 INFO     Evaluating the model... (47500/50000)
2025-12-13 12:43:39,679 INFO     Evaluating the model... (48000/50000)
2025-12-13 12:43:43,864 INFO     Evaluating the model... (48500/50000)
2025-12-13 12:43:48,365 INFO     Evaluating the model... (49000/50000)
2025-12-13 12:43:54,089 INFO     Evaluating the model... (49500/50000)
2025-12-13 12:43:58,619 INFO     Valid MRR at step 40000: 0.703039
2025-12-13 12:43:58,619 INFO     Valid MR at step 40000: 264.514650
2025-12-13 12:43:58,619 INFO     Valid HITS@1 at step 40000: 0.637940
2025-12-13 12:43:58,619 INFO     Valid HITS@3 at step 40000: 0.745920
2025-12-13 12:43:58,619 INFO     Valid HITS@10 at step 40000: 0.817290
2025-12-13 12:43:58,619 INFO     Evaluating on Test Dataset...
2025-12-13 12:43:59,203 INFO     Evaluating the model... (0/59072)
2025-12-13 12:44:04,331 INFO     Evaluating the model... (500/59072)
2025-12-13 12:44:08,857 INFO     Evaluating the model... (1000/59072)
2025-12-13 12:44:13,417 INFO     Evaluating the model... (1500/59072)
2025-12-13 12:44:19,241 INFO     Evaluating the model... (2000/59072)
2025-12-13 12:44:24,060 INFO     Evaluating the model... (2500/59072)
2025-12-13 12:44:28,601 INFO     Evaluating the model... (3000/59072)
2025-12-13 12:44:33,286 INFO     Evaluating the model... (3500/59072)
2025-12-13 12:44:37,517 INFO     Evaluating the model... (4000/59072)
2025-12-13 12:44:43,003 INFO     Evaluating the model... (4500/59072)
2025-12-13 12:44:47,495 INFO     Evaluating the model... (5000/59072)
2025-12-13 12:44:51,775 INFO     Evaluating the model... (5500/59072)
2025-12-13 12:44:56,310 INFO     Evaluating the model... (6000/59072)
2025-12-13 12:45:00,747 INFO     Evaluating the model... (6500/59072)
2025-12-13 12:45:05,496 INFO     Evaluating the model... (7000/59072)
2025-12-13 12:45:10,026 INFO     Evaluating the model... (7500/59072)
2025-12-13 12:45:14,394 INFO     Evaluating the model... (8000/59072)
2025-12-13 12:45:19,003 INFO     Evaluating the model... (8500/59072)
2025-12-13 12:45:23,469 INFO     Evaluating the model... (9000/59072)
2025-12-13 12:45:28,094 INFO     Evaluating the model... (9500/59072)
2025-12-13 12:45:32,472 INFO     Evaluating the model... (10000/59072)
2025-12-13 12:45:36,779 INFO     Evaluating the model... (10500/59072)
2025-12-13 12:45:41,054 INFO     Evaluating the model... (11000/59072)
2025-12-13 12:45:45,252 INFO     Evaluating the model... (11500/59072)
2025-12-13 12:45:50,099 INFO     Evaluating the model... (12000/59072)
2025-12-13 12:45:54,344 INFO     Evaluating the model... (12500/59072)
2025-12-13 12:45:58,713 INFO     Evaluating the model... (13000/59072)
2025-12-13 12:46:02,933 INFO     Evaluating the model... (13500/59072)
2025-12-13 12:46:07,228 INFO     Evaluating the model... (14000/59072)
2025-12-13 12:46:12,030 INFO     Evaluating the model... (14500/59072)
2025-12-13 12:46:16,334 INFO     Evaluating the model... (15000/59072)
2025-12-13 12:46:20,875 INFO     Evaluating the model... (15500/59072)
2025-12-13 12:46:25,222 INFO     Evaluating the model... (16000/59072)
2025-12-13 12:46:29,798 INFO     Evaluating the model... (16500/59072)
2025-12-13 12:46:34,600 INFO     Evaluating the model... (17000/59072)
2025-12-13 12:46:38,816 INFO     Evaluating the model... (17500/59072)
2025-12-13 12:46:43,092 INFO     Evaluating the model... (18000/59072)
2025-12-13 12:46:47,311 INFO     Evaluating the model... (18500/59072)
2025-12-13 12:46:52,618 INFO     Evaluating the model... (19000/59072)
2025-12-13 12:46:57,002 INFO     Evaluating the model... (19500/59072)
2025-12-13 12:47:01,500 INFO     Evaluating the model... (20000/59072)
2025-12-13 12:47:05,723 INFO     Evaluating the model... (20500/59072)
2025-12-13 12:47:09,946 INFO     Evaluating the model... (21000/59072)
2025-12-13 12:47:14,994 INFO     Evaluating the model... (21500/59072)
2025-12-13 12:47:19,412 INFO     Evaluating the model... (22000/59072)
2025-12-13 12:47:23,585 INFO     Evaluating the model... (22500/59072)
2025-12-13 12:47:27,803 INFO     Evaluating the model... (23000/59072)
2025-12-13 12:47:32,087 INFO     Evaluating the model... (23500/59072)
2025-12-13 12:47:37,350 INFO     Evaluating the model... (24000/59072)
2025-12-13 12:47:41,908 INFO     Evaluating the model... (24500/59072)
2025-12-13 12:47:46,389 INFO     Evaluating the model... (25000/59072)
2025-12-13 12:47:50,663 INFO     Evaluating the model... (25500/59072)
2025-12-13 12:47:54,981 INFO     Evaluating the model... (26000/59072)
2025-12-13 12:48:00,087 INFO     Evaluating the model... (26500/59072)
2025-12-13 12:48:04,673 INFO     Evaluating the model... (27000/59072)
2025-12-13 12:48:09,034 INFO     Evaluating the model... (27500/59072)
2025-12-13 12:48:13,266 INFO     Evaluating the model... (28000/59072)
2025-12-13 12:48:17,536 INFO     Evaluating the model... (28500/59072)
2025-12-13 12:48:22,735 INFO     Evaluating the model... (29000/59072)
2025-12-13 12:48:27,184 INFO     Evaluating the model... (29500/59072)
2025-12-13 12:48:32,285 INFO     Evaluating the model... (30000/59072)
2025-12-13 12:48:36,644 INFO     Evaluating the model... (30500/59072)
2025-12-13 12:48:42,131 INFO     Evaluating the model... (31000/59072)
2025-12-13 12:48:46,601 INFO     Evaluating the model... (31500/59072)
2025-12-13 12:48:50,967 INFO     Evaluating the model... (32000/59072)
2025-12-13 12:48:55,323 INFO     Evaluating the model... (32500/59072)
2025-12-13 12:48:59,565 INFO     Evaluating the model... (33000/59072)
2025-12-13 12:49:04,556 INFO     Evaluating the model... (33500/59072)
2025-12-13 12:49:09,114 INFO     Evaluating the model... (34000/59072)
2025-12-13 12:49:13,538 INFO     Evaluating the model... (34500/59072)
2025-12-13 12:49:17,956 INFO     Evaluating the model... (35000/59072)
2025-12-13 12:49:22,196 INFO     Evaluating the model... (35500/59072)
2025-12-13 12:49:27,085 INFO     Evaluating the model... (36000/59072)
2025-12-13 12:49:31,377 INFO     Evaluating the model... (36500/59072)
2025-12-13 12:49:35,526 INFO     Evaluating the model... (37000/59072)
2025-12-13 12:49:39,962 INFO     Evaluating the model... (37500/59072)
2025-12-13 12:49:44,117 INFO     Evaluating the model... (38000/59072)
2025-12-13 12:49:48,663 INFO     Evaluating the model... (38500/59072)
2025-12-13 12:49:52,902 INFO     Evaluating the model... (39000/59072)
2025-12-13 12:49:57,083 INFO     Evaluating the model... (39500/59072)
2025-12-13 12:50:01,237 INFO     Evaluating the model... (40000/59072)
2025-12-13 12:50:05,506 INFO     Evaluating the model... (40500/59072)
2025-12-13 12:50:10,417 INFO     Evaluating the model... (41000/59072)
2025-12-13 12:50:14,611 INFO     Evaluating the model... (41500/59072)
2025-12-13 12:50:18,769 INFO     Evaluating the model... (42000/59072)
2025-12-13 12:50:23,186 INFO     Evaluating the model... (42500/59072)
2025-12-13 12:50:27,330 INFO     Evaluating the model... (43000/59072)
2025-12-13 12:50:31,934 INFO     Evaluating the model... (43500/59072)
2025-12-13 12:50:36,149 INFO     Evaluating the model... (44000/59072)
2025-12-13 12:50:40,351 INFO     Evaluating the model... (44500/59072)
2025-12-13 12:50:44,699 INFO     Evaluating the model... (45000/59072)
2025-12-13 12:50:48,973 INFO     Evaluating the model... (45500/59072)
2025-12-13 12:50:53,892 INFO     Evaluating the model... (46000/59072)
2025-12-13 12:50:58,119 INFO     Evaluating the model... (46500/59072)
2025-12-13 12:51:02,395 INFO     Evaluating the model... (47000/59072)
2025-12-13 12:51:06,885 INFO     Evaluating the model... (47500/59072)
2025-12-13 12:51:11,195 INFO     Evaluating the model... (48000/59072)
2025-12-13 12:51:16,410 INFO     Evaluating the model... (48500/59072)
2025-12-13 12:51:20,503 INFO     Evaluating the model... (49000/59072)
2025-12-13 12:51:24,749 INFO     Evaluating the model... (49500/59072)
2025-12-13 12:51:28,852 INFO     Evaluating the model... (50000/59072)
2025-12-13 12:51:33,974 INFO     Evaluating the model... (50500/59072)
2025-12-13 12:51:38,203 INFO     Evaluating the model... (51000/59072)
2025-12-13 12:51:42,496 INFO     Evaluating the model... (51500/59072)
2025-12-13 12:51:46,852 INFO     Evaluating the model... (52000/59072)
2025-12-13 12:51:51,045 INFO     Evaluating the model... (52500/59072)
2025-12-13 12:51:56,327 INFO     Evaluating the model... (53000/59072)
2025-12-13 12:52:00,756 INFO     Evaluating the model... (53500/59072)
2025-12-13 12:52:05,038 INFO     Evaluating the model... (54000/59072)
2025-12-13 12:52:09,441 INFO     Evaluating the model... (54500/59072)
2025-12-13 12:52:13,645 INFO     Evaluating the model... (55000/59072)
2025-12-13 12:52:18,584 INFO     Evaluating the model... (55500/59072)
2025-12-13 12:52:22,935 INFO     Evaluating the model... (56000/59072)
2025-12-13 12:52:27,295 INFO     Evaluating the model... (56500/59072)
2025-12-13 12:52:31,552 INFO     Evaluating the model... (57000/59072)
2025-12-13 12:52:35,836 INFO     Evaluating the model... (57500/59072)
2025-12-13 12:52:40,828 INFO     Evaluating the model... (58000/59072)
2025-12-13 12:52:45,166 INFO     Evaluating the model... (58500/59072)
2025-12-13 12:52:49,683 INFO     Evaluating the model... (59000/59072)
2025-12-13 12:52:50,610 INFO     Test MRR at step 40000: 0.697124
2025-12-13 12:52:50,610 INFO     Test MR at step 40000: 266.749920
2025-12-13 12:52:50,610 INFO     Test HITS@1 at step 40000: 0.631080
2025-12-13 12:52:50,610 INFO     Test HITS@3 at step 40000: 0.740456
2025-12-13 12:52:50,610 INFO     Test HITS@10 at step 40000: 0.814020
2025-12-13 12:52:56,030 INFO     Training average regularization at step 40100: 0.189733
2025-12-13 12:52:56,030 INFO     Training average positive_sample_loss at step 40100: 0.014827
2025-12-13 12:52:56,030 INFO     Training average negative_sample_loss at step 40100: 0.025283
2025-12-13 12:52:56,031 INFO     Training average loss at step 40100: 0.209789
2025-12-13 12:53:01,454 INFO     Training average regularization at step 40200: 0.188210
2025-12-13 12:53:01,454 INFO     Training average positive_sample_loss at step 40200: 0.018285
2025-12-13 12:53:01,454 INFO     Training average negative_sample_loss at step 40200: 0.027641
2025-12-13 12:53:01,454 INFO     Training average loss at step 40200: 0.211173
2025-12-13 12:53:06,856 INFO     Training average regularization at step 40300: 0.187354
2025-12-13 12:53:06,856 INFO     Training average positive_sample_loss at step 40300: 0.022013
2025-12-13 12:53:06,857 INFO     Training average negative_sample_loss at step 40300: 0.026753
2025-12-13 12:53:06,857 INFO     Training average loss at step 40300: 0.211737
2025-12-13 12:53:12,287 INFO     Training average regularization at step 40400: 0.186797
2025-12-13 12:53:12,288 INFO     Training average positive_sample_loss at step 40400: 0.019876
2025-12-13 12:53:12,288 INFO     Training average negative_sample_loss at step 40400: 0.028252
2025-12-13 12:53:12,288 INFO     Training average loss at step 40400: 0.210861
2025-12-13 12:53:17,522 INFO     Training average regularization at step 40500: 0.186397
2025-12-13 12:53:17,526 INFO     Training average positive_sample_loss at step 40500: 0.021043
2025-12-13 12:53:17,526 INFO     Training average negative_sample_loss at step 40500: 0.030943
2025-12-13 12:53:17,526 INFO     Training average loss at step 40500: 0.212390
2025-12-13 12:53:22,838 INFO     Training average regularization at step 40600: 0.186092
2025-12-13 12:53:22,839 INFO     Training average positive_sample_loss at step 40600: 0.018577
2025-12-13 12:53:22,839 INFO     Training average negative_sample_loss at step 40600: 0.032952
2025-12-13 12:53:22,839 INFO     Training average loss at step 40600: 0.211856
2025-12-13 12:53:28,119 INFO     Training average regularization at step 40700: 0.185845
2025-12-13 12:53:28,120 INFO     Training average positive_sample_loss at step 40700: 0.019275
2025-12-13 12:53:28,120 INFO     Training average negative_sample_loss at step 40700: 0.028937
2025-12-13 12:53:28,120 INFO     Training average loss at step 40700: 0.209950
2025-12-13 12:53:33,433 INFO     Training average regularization at step 40800: 0.185638
2025-12-13 12:53:33,433 INFO     Training average positive_sample_loss at step 40800: 0.022132
2025-12-13 12:53:33,433 INFO     Training average negative_sample_loss at step 40800: 0.026797
2025-12-13 12:53:33,433 INFO     Training average loss at step 40800: 0.210103
2025-12-13 12:53:38,803 INFO     Training average regularization at step 40900: 0.185462
2025-12-13 12:53:38,803 INFO     Training average positive_sample_loss at step 40900: 0.024196
2025-12-13 12:53:38,803 INFO     Training average negative_sample_loss at step 40900: 0.031040
2025-12-13 12:53:38,803 INFO     Training average loss at step 40900: 0.213080
2025-12-13 12:53:44,208 INFO     Training average regularization at step 41000: 0.185307
2025-12-13 12:53:44,209 INFO     Training average positive_sample_loss at step 41000: 0.023602
2025-12-13 12:53:44,209 INFO     Training average negative_sample_loss at step 41000: 0.031203
2025-12-13 12:53:44,209 INFO     Training average loss at step 41000: 0.212709
2025-12-13 12:53:49,652 INFO     Training average regularization at step 41100: 0.185168
2025-12-13 12:53:49,652 INFO     Training average positive_sample_loss at step 41100: 0.019868
2025-12-13 12:53:49,653 INFO     Training average negative_sample_loss at step 41100: 0.031043
2025-12-13 12:53:49,653 INFO     Training average loss at step 41100: 0.210624
2025-12-13 12:53:54,878 INFO     Training average regularization at step 41200: 0.185043
2025-12-13 12:53:54,878 INFO     Training average positive_sample_loss at step 41200: 0.022539
2025-12-13 12:53:54,878 INFO     Training average negative_sample_loss at step 41200: 0.030048
2025-12-13 12:53:54,878 INFO     Training average loss at step 41200: 0.211336
2025-12-13 12:54:00,213 INFO     Training average regularization at step 41300: 0.184929
2025-12-13 12:54:00,213 INFO     Training average positive_sample_loss at step 41300: 0.022594
2025-12-13 12:54:00,213 INFO     Training average negative_sample_loss at step 41300: 0.024562
2025-12-13 12:54:00,213 INFO     Training average loss at step 41300: 0.208507
2025-12-13 12:54:05,707 INFO     Training average regularization at step 41400: 0.184823
2025-12-13 12:54:05,708 INFO     Training average positive_sample_loss at step 41400: 0.024403
2025-12-13 12:54:05,708 INFO     Training average negative_sample_loss at step 41400: 0.030127
2025-12-13 12:54:05,708 INFO     Training average loss at step 41400: 0.212088
2025-12-13 12:54:10,856 INFO     Training average regularization at step 41500: 0.184724
2025-12-13 12:54:10,856 INFO     Training average positive_sample_loss at step 41500: 0.022639
2025-12-13 12:54:10,856 INFO     Training average negative_sample_loss at step 41500: 0.026500
2025-12-13 12:54:10,856 INFO     Training average loss at step 41500: 0.209293
2025-12-13 12:54:16,091 INFO     Training average regularization at step 41600: 0.184631
2025-12-13 12:54:16,092 INFO     Training average positive_sample_loss at step 41600: 0.018206
2025-12-13 12:54:16,092 INFO     Training average negative_sample_loss at step 41600: 0.031563
2025-12-13 12:54:16,092 INFO     Training average loss at step 41600: 0.209515
2025-12-13 12:54:21,201 INFO     Training average regularization at step 41700: 0.184542
2025-12-13 12:54:21,202 INFO     Training average positive_sample_loss at step 41700: 0.024187
2025-12-13 12:54:21,202 INFO     Training average negative_sample_loss at step 41700: 0.030257
2025-12-13 12:54:21,202 INFO     Training average loss at step 41700: 0.211764
2025-12-13 12:54:26,174 INFO     Training average regularization at step 41800: 0.184459
2025-12-13 12:54:26,174 INFO     Training average positive_sample_loss at step 41800: 0.021008
2025-12-13 12:54:26,174 INFO     Training average negative_sample_loss at step 41800: 0.028885
2025-12-13 12:54:26,174 INFO     Training average loss at step 41800: 0.209405
2025-12-13 12:54:31,273 INFO     Training average regularization at step 41900: 0.184379
2025-12-13 12:54:31,274 INFO     Training average positive_sample_loss at step 41900: 0.022321
2025-12-13 12:54:31,274 INFO     Training average negative_sample_loss at step 41900: 0.030219
2025-12-13 12:54:31,274 INFO     Training average loss at step 41900: 0.210649
2025-12-13 12:54:36,284 INFO     Training average regularization at step 42000: 0.184303
2025-12-13 12:54:36,285 INFO     Training average positive_sample_loss at step 42000: 0.024309
2025-12-13 12:54:36,285 INFO     Training average negative_sample_loss at step 42000: 0.029333
2025-12-13 12:54:36,285 INFO     Training average loss at step 42000: 0.211124
2025-12-13 12:54:41,417 INFO     Training average regularization at step 42100: 0.184228
2025-12-13 12:54:41,417 INFO     Training average positive_sample_loss at step 42100: 0.020961
2025-12-13 12:54:41,417 INFO     Training average negative_sample_loss at step 42100: 0.027187
2025-12-13 12:54:41,417 INFO     Training average loss at step 42100: 0.208302
2025-12-13 12:54:46,404 INFO     Training average regularization at step 42200: 0.184155
2025-12-13 12:54:46,404 INFO     Training average positive_sample_loss at step 42200: 0.022068
2025-12-13 12:54:46,404 INFO     Training average negative_sample_loss at step 42200: 0.033951
2025-12-13 12:54:46,404 INFO     Training average loss at step 42200: 0.212164
2025-12-13 12:54:51,394 INFO     Training average regularization at step 42300: 0.184085
2025-12-13 12:54:51,394 INFO     Training average positive_sample_loss at step 42300: 0.024649
2025-12-13 12:54:51,394 INFO     Training average negative_sample_loss at step 42300: 0.030301
2025-12-13 12:54:51,394 INFO     Training average loss at step 42300: 0.211560
2025-12-13 12:54:56,702 INFO     Training average regularization at step 42400: 0.184018
2025-12-13 12:54:56,703 INFO     Training average positive_sample_loss at step 42400: 0.018121
2025-12-13 12:54:56,703 INFO     Training average negative_sample_loss at step 42400: 0.026949
2025-12-13 12:54:56,703 INFO     Training average loss at step 42400: 0.206553
2025-12-13 12:55:01,992 INFO     Training average regularization at step 42500: 0.183952
2025-12-13 12:55:01,992 INFO     Training average positive_sample_loss at step 42500: 0.021093
2025-12-13 12:55:01,993 INFO     Training average negative_sample_loss at step 42500: 0.034991
2025-12-13 12:55:01,993 INFO     Training average loss at step 42500: 0.211994
2025-12-13 12:55:07,291 INFO     Training average regularization at step 42600: 0.183888
2025-12-13 12:55:07,292 INFO     Training average positive_sample_loss at step 42600: 0.022467
2025-12-13 12:55:07,292 INFO     Training average negative_sample_loss at step 42600: 0.025401
2025-12-13 12:55:07,292 INFO     Training average loss at step 42600: 0.207822
2025-12-13 12:55:12,493 INFO     Training average regularization at step 42700: 0.183826
2025-12-13 12:55:12,493 INFO     Training average positive_sample_loss at step 42700: 0.019969
2025-12-13 12:55:12,493 INFO     Training average negative_sample_loss at step 42700: 0.019854
2025-12-13 12:55:12,493 INFO     Training average loss at step 42700: 0.203737
2025-12-13 12:55:17,695 INFO     Training average regularization at step 42800: 0.183764
2025-12-13 12:55:17,695 INFO     Training average positive_sample_loss at step 42800: 0.019367
2025-12-13 12:55:17,695 INFO     Training average negative_sample_loss at step 42800: 0.027772
2025-12-13 12:55:17,695 INFO     Training average loss at step 42800: 0.207333
2025-12-13 12:55:22,810 INFO     Training average regularization at step 42900: 0.183702
2025-12-13 12:55:22,811 INFO     Training average positive_sample_loss at step 42900: 0.017342
2025-12-13 12:55:22,811 INFO     Training average negative_sample_loss at step 42900: 0.025191
2025-12-13 12:55:22,811 INFO     Training average loss at step 42900: 0.204968
2025-12-13 12:55:28,128 INFO     Training average regularization at step 43000: 0.183640
2025-12-13 12:55:28,129 INFO     Training average positive_sample_loss at step 43000: 0.019540
2025-12-13 12:55:28,129 INFO     Training average negative_sample_loss at step 43000: 0.029130
2025-12-13 12:55:28,129 INFO     Training average loss at step 43000: 0.207975
2025-12-13 12:55:33,477 INFO     Training average regularization at step 43100: 0.183579
2025-12-13 12:55:33,477 INFO     Training average positive_sample_loss at step 43100: 0.020215
2025-12-13 12:55:33,477 INFO     Training average negative_sample_loss at step 43100: 0.028036
2025-12-13 12:55:33,478 INFO     Training average loss at step 43100: 0.207705
2025-12-13 12:55:38,831 INFO     Training average regularization at step 43200: 0.183519
2025-12-13 12:55:38,831 INFO     Training average positive_sample_loss at step 43200: 0.021241
2025-12-13 12:55:38,831 INFO     Training average negative_sample_loss at step 43200: 0.028672
2025-12-13 12:55:38,831 INFO     Training average loss at step 43200: 0.208476
2025-12-13 12:55:44,190 INFO     Training average regularization at step 43300: 0.183460
2025-12-13 12:55:44,190 INFO     Training average positive_sample_loss at step 43300: 0.018444
2025-12-13 12:55:44,190 INFO     Training average negative_sample_loss at step 43300: 0.031102
2025-12-13 12:55:44,190 INFO     Training average loss at step 43300: 0.208233
2025-12-13 12:55:49,379 INFO     Training average regularization at step 43400: 0.183403
2025-12-13 12:55:49,379 INFO     Training average positive_sample_loss at step 43400: 0.019130
2025-12-13 12:55:49,379 INFO     Training average negative_sample_loss at step 43400: 0.032503
2025-12-13 12:55:49,379 INFO     Training average loss at step 43400: 0.209219
2025-12-13 12:55:55,724 INFO     Training average regularization at step 43500: 0.183347
2025-12-13 12:55:55,725 INFO     Training average positive_sample_loss at step 43500: 0.019346
2025-12-13 12:55:55,725 INFO     Training average negative_sample_loss at step 43500: 0.030008
2025-12-13 12:55:55,725 INFO     Training average loss at step 43500: 0.208024
2025-12-13 12:56:00,994 INFO     Training average regularization at step 43600: 0.183288
2025-12-13 12:56:00,995 INFO     Training average positive_sample_loss at step 43600: 0.015029
2025-12-13 12:56:00,995 INFO     Training average negative_sample_loss at step 43600: 0.027168
2025-12-13 12:56:00,995 INFO     Training average loss at step 43600: 0.204386
2025-12-13 12:56:06,292 INFO     Training average regularization at step 43700: 0.183226
2025-12-13 12:56:06,292 INFO     Training average positive_sample_loss at step 43700: 0.014499
2025-12-13 12:56:06,292 INFO     Training average negative_sample_loss at step 43700: 0.024869
2025-12-13 12:56:06,292 INFO     Training average loss at step 43700: 0.202910
2025-12-13 12:56:11,527 INFO     Training average regularization at step 43800: 0.183166
2025-12-13 12:56:11,527 INFO     Training average positive_sample_loss at step 43800: 0.014407
2025-12-13 12:56:11,527 INFO     Training average negative_sample_loss at step 43800: 0.024487
2025-12-13 12:56:11,527 INFO     Training average loss at step 43800: 0.202612
2025-12-13 12:56:16,799 INFO     Training average regularization at step 43900: 0.183105
2025-12-13 12:56:16,799 INFO     Training average positive_sample_loss at step 43900: 0.014473
2025-12-13 12:56:16,799 INFO     Training average negative_sample_loss at step 43900: 0.028526
2025-12-13 12:56:16,799 INFO     Training average loss at step 43900: 0.204605
2025-12-13 12:56:22,008 INFO     Training average regularization at step 44000: 0.183047
2025-12-13 12:56:22,008 INFO     Training average positive_sample_loss at step 44000: 0.012650
2025-12-13 12:56:22,009 INFO     Training average negative_sample_loss at step 44000: 0.029664
2025-12-13 12:56:22,009 INFO     Training average loss at step 44000: 0.204204
2025-12-13 12:56:27,089 INFO     Training average regularization at step 44100: 0.182989
2025-12-13 12:56:27,090 INFO     Training average positive_sample_loss at step 44100: 0.014531
2025-12-13 12:56:27,090 INFO     Training average negative_sample_loss at step 44100: 0.028139
2025-12-13 12:56:27,090 INFO     Training average loss at step 44100: 0.204323
2025-12-13 12:56:32,361 INFO     Training average regularization at step 44200: 0.182931
2025-12-13 12:56:32,362 INFO     Training average positive_sample_loss at step 44200: 0.017407
2025-12-13 12:56:32,362 INFO     Training average negative_sample_loss at step 44200: 0.026362
2025-12-13 12:56:32,362 INFO     Training average loss at step 44200: 0.204816
2025-12-13 12:56:37,686 INFO     Training average regularization at step 44300: 0.182876
2025-12-13 12:56:37,686 INFO     Training average positive_sample_loss at step 44300: 0.016037
2025-12-13 12:56:37,686 INFO     Training average negative_sample_loss at step 44300: 0.031232
2025-12-13 12:56:37,686 INFO     Training average loss at step 44300: 0.206510
2025-12-13 12:56:43,195 INFO     Training average regularization at step 44400: 0.182821
2025-12-13 12:56:43,195 INFO     Training average positive_sample_loss at step 44400: 0.014023
2025-12-13 12:56:43,195 INFO     Training average negative_sample_loss at step 44400: 0.024701
2025-12-13 12:56:43,195 INFO     Training average loss at step 44400: 0.202183
2025-12-13 12:56:48,536 INFO     Training average regularization at step 44500: 0.182766
2025-12-13 12:56:48,537 INFO     Training average positive_sample_loss at step 44500: 0.014341
2025-12-13 12:56:48,537 INFO     Training average negative_sample_loss at step 44500: 0.024287
2025-12-13 12:56:48,537 INFO     Training average loss at step 44500: 0.202080
2025-12-13 12:56:53,927 INFO     Training average regularization at step 44600: 0.182712
2025-12-13 12:56:53,927 INFO     Training average positive_sample_loss at step 44600: 0.015726
2025-12-13 12:56:53,927 INFO     Training average negative_sample_loss at step 44600: 0.024060
2025-12-13 12:56:53,927 INFO     Training average loss at step 44600: 0.202604
2025-12-13 12:56:59,176 INFO     Training average regularization at step 44700: 0.182658
2025-12-13 12:56:59,176 INFO     Training average positive_sample_loss at step 44700: 0.014349
2025-12-13 12:56:59,176 INFO     Training average negative_sample_loss at step 44700: 0.026778
2025-12-13 12:56:59,176 INFO     Training average loss at step 44700: 0.203221
2025-12-13 12:57:04,511 INFO     Training average regularization at step 44800: 0.182603
2025-12-13 12:57:04,511 INFO     Training average positive_sample_loss at step 44800: 0.013683
2025-12-13 12:57:04,511 INFO     Training average negative_sample_loss at step 44800: 0.025798
2025-12-13 12:57:04,511 INFO     Training average loss at step 44800: 0.202343
2025-12-13 12:57:09,922 INFO     Training average regularization at step 44900: 0.182551
2025-12-13 12:57:09,922 INFO     Training average positive_sample_loss at step 44900: 0.015475
2025-12-13 12:57:09,922 INFO     Training average negative_sample_loss at step 44900: 0.028169
2025-12-13 12:57:09,922 INFO     Training average loss at step 44900: 0.204373
2025-12-13 12:57:15,143 INFO     Training average regularization at step 45000: 0.182500
2025-12-13 12:57:15,143 INFO     Training average positive_sample_loss at step 45000: 0.014598
2025-12-13 12:57:15,143 INFO     Training average negative_sample_loss at step 45000: 0.022884
2025-12-13 12:57:15,143 INFO     Training average loss at step 45000: 0.201241
2025-12-13 12:57:20,323 INFO     Training average regularization at step 45100: 0.182448
2025-12-13 12:57:20,324 INFO     Training average positive_sample_loss at step 45100: 0.014300
2025-12-13 12:57:20,324 INFO     Training average negative_sample_loss at step 45100: 0.027427
2025-12-13 12:57:20,324 INFO     Training average loss at step 45100: 0.203312
2025-12-13 12:57:25,521 INFO     Training average regularization at step 45200: 0.182397
2025-12-13 12:57:25,521 INFO     Training average positive_sample_loss at step 45200: 0.015134
2025-12-13 12:57:25,522 INFO     Training average negative_sample_loss at step 45200: 0.025097
2025-12-13 12:57:25,522 INFO     Training average loss at step 45200: 0.202512
2025-12-13 12:57:30,892 INFO     Training average regularization at step 45300: 0.182346
2025-12-13 12:57:30,893 INFO     Training average positive_sample_loss at step 45300: 0.014217
2025-12-13 12:57:30,893 INFO     Training average negative_sample_loss at step 45300: 0.029445
2025-12-13 12:57:30,893 INFO     Training average loss at step 45300: 0.204177
2025-12-13 12:57:36,176 INFO     Training average regularization at step 45400: 0.182295
2025-12-13 12:57:36,177 INFO     Training average positive_sample_loss at step 45400: 0.014153
2025-12-13 12:57:36,177 INFO     Training average negative_sample_loss at step 45400: 0.024771
2025-12-13 12:57:36,177 INFO     Training average loss at step 45400: 0.201756
2025-12-13 12:57:41,400 INFO     Training average regularization at step 45500: 0.182245
2025-12-13 12:57:41,400 INFO     Training average positive_sample_loss at step 45500: 0.013319
2025-12-13 12:57:41,400 INFO     Training average negative_sample_loss at step 45500: 0.026270
2025-12-13 12:57:41,400 INFO     Training average loss at step 45500: 0.202039
2025-12-13 12:57:46,758 INFO     Training average regularization at step 45600: 0.182194
2025-12-13 12:57:46,758 INFO     Training average positive_sample_loss at step 45600: 0.016909
2025-12-13 12:57:46,758 INFO     Training average negative_sample_loss at step 45600: 0.026103
2025-12-13 12:57:46,758 INFO     Training average loss at step 45600: 0.203701
2025-12-13 12:57:51,946 INFO     Training average regularization at step 45700: 0.182146
2025-12-13 12:57:51,946 INFO     Training average positive_sample_loss at step 45700: 0.013738
2025-12-13 12:57:51,946 INFO     Training average negative_sample_loss at step 45700: 0.023059
2025-12-13 12:57:51,946 INFO     Training average loss at step 45700: 0.200544
2025-12-13 12:57:57,079 INFO     Training average regularization at step 45800: 0.182096
2025-12-13 12:57:57,079 INFO     Training average positive_sample_loss at step 45800: 0.013359
2025-12-13 12:57:57,079 INFO     Training average negative_sample_loss at step 45800: 0.024188
2025-12-13 12:57:57,079 INFO     Training average loss at step 45800: 0.200870
2025-12-13 12:58:02,440 INFO     Training average regularization at step 45900: 0.182047
2025-12-13 12:58:02,441 INFO     Training average positive_sample_loss at step 45900: 0.014539
2025-12-13 12:58:02,441 INFO     Training average negative_sample_loss at step 45900: 0.026873
2025-12-13 12:58:02,441 INFO     Training average loss at step 45900: 0.202753
2025-12-13 12:58:07,576 INFO     Training average regularization at step 46000: 0.181999
2025-12-13 12:58:07,576 INFO     Training average positive_sample_loss at step 46000: 0.012893
2025-12-13 12:58:07,576 INFO     Training average negative_sample_loss at step 46000: 0.026424
2025-12-13 12:58:07,576 INFO     Training average loss at step 46000: 0.201657
2025-12-13 12:58:12,785 INFO     Training average regularization at step 46100: 0.181948
2025-12-13 12:58:12,785 INFO     Training average positive_sample_loss at step 46100: 0.014642
2025-12-13 12:58:12,785 INFO     Training average negative_sample_loss at step 46100: 0.027618
2025-12-13 12:58:12,785 INFO     Training average loss at step 46100: 0.203078
2025-12-13 12:58:18,157 INFO     Training average regularization at step 46200: 0.181900
2025-12-13 12:58:18,157 INFO     Training average positive_sample_loss at step 46200: 0.014599
2025-12-13 12:58:18,157 INFO     Training average negative_sample_loss at step 46200: 0.023556
2025-12-13 12:58:18,157 INFO     Training average loss at step 46200: 0.200977
2025-12-13 12:58:23,518 INFO     Training average regularization at step 46300: 0.181851
2025-12-13 12:58:23,519 INFO     Training average positive_sample_loss at step 46300: 0.015079
2025-12-13 12:58:23,519 INFO     Training average negative_sample_loss at step 46300: 0.025329
2025-12-13 12:58:23,519 INFO     Training average loss at step 46300: 0.202055
2025-12-13 12:58:28,918 INFO     Training average regularization at step 46400: 0.181803
2025-12-13 12:58:28,920 INFO     Training average positive_sample_loss at step 46400: 0.014181
2025-12-13 12:58:28,920 INFO     Training average negative_sample_loss at step 46400: 0.025627
2025-12-13 12:58:28,920 INFO     Training average loss at step 46400: 0.201707
2025-12-13 12:58:34,278 INFO     Training average regularization at step 46500: 0.181755
2025-12-13 12:58:34,278 INFO     Training average positive_sample_loss at step 46500: 0.012750
2025-12-13 12:58:34,278 INFO     Training average negative_sample_loss at step 46500: 0.025538
2025-12-13 12:58:34,278 INFO     Training average loss at step 46500: 0.200899
2025-12-13 12:58:39,522 INFO     Training average regularization at step 46600: 0.181706
2025-12-13 12:58:39,522 INFO     Training average positive_sample_loss at step 46600: 0.013894
2025-12-13 12:58:39,522 INFO     Training average negative_sample_loss at step 46600: 0.022021
2025-12-13 12:58:39,522 INFO     Training average loss at step 46600: 0.199663
2025-12-13 12:58:44,818 INFO     Training average regularization at step 46700: 0.181658
2025-12-13 12:58:44,818 INFO     Training average positive_sample_loss at step 46700: 0.014546
2025-12-13 12:58:44,818 INFO     Training average negative_sample_loss at step 46700: 0.022781
2025-12-13 12:58:44,818 INFO     Training average loss at step 46700: 0.200321
2025-12-13 12:58:50,124 INFO     Training average regularization at step 46800: 0.181609
2025-12-13 12:58:50,125 INFO     Training average positive_sample_loss at step 46800: 0.014793
2025-12-13 12:58:50,125 INFO     Training average negative_sample_loss at step 46800: 0.024897
2025-12-13 12:58:50,125 INFO     Training average loss at step 46800: 0.201454
2025-12-13 12:58:55,469 INFO     Training average regularization at step 46900: 0.181561
2025-12-13 12:58:55,469 INFO     Training average positive_sample_loss at step 46900: 0.015069
2025-12-13 12:58:55,469 INFO     Training average negative_sample_loss at step 46900: 0.024322
2025-12-13 12:58:55,469 INFO     Training average loss at step 46900: 0.201256
2025-12-13 12:59:00,540 INFO     Training average regularization at step 47000: 0.181513
2025-12-13 12:59:00,540 INFO     Training average positive_sample_loss at step 47000: 0.013662
2025-12-13 12:59:00,540 INFO     Training average negative_sample_loss at step 47000: 0.020871
2025-12-13 12:59:00,540 INFO     Training average loss at step 47000: 0.198779
2025-12-13 12:59:05,607 INFO     Training average regularization at step 47100: 0.181465
2025-12-13 12:59:05,607 INFO     Training average positive_sample_loss at step 47100: 0.013295
2025-12-13 12:59:05,607 INFO     Training average negative_sample_loss at step 47100: 0.023025
2025-12-13 12:59:05,607 INFO     Training average loss at step 47100: 0.199625
2025-12-13 12:59:10,684 INFO     Training average regularization at step 47200: 0.181417
2025-12-13 12:59:10,685 INFO     Training average positive_sample_loss at step 47200: 0.012839
2025-12-13 12:59:10,685 INFO     Training average negative_sample_loss at step 47200: 0.022906
2025-12-13 12:59:10,685 INFO     Training average loss at step 47200: 0.199289
2025-12-13 12:59:15,567 INFO     Training average regularization at step 47300: 0.181368
2025-12-13 12:59:15,568 INFO     Training average positive_sample_loss at step 47300: 0.012287
2025-12-13 12:59:15,568 INFO     Training average negative_sample_loss at step 47300: 0.026179
2025-12-13 12:59:15,568 INFO     Training average loss at step 47300: 0.200601
2025-12-13 12:59:20,448 INFO     Training average regularization at step 47400: 0.181319
2025-12-13 12:59:20,449 INFO     Training average positive_sample_loss at step 47400: 0.014030
2025-12-13 12:59:20,449 INFO     Training average negative_sample_loss at step 47400: 0.023119
2025-12-13 12:59:20,449 INFO     Training average loss at step 47400: 0.199894
2025-12-13 12:59:25,387 INFO     Training average regularization at step 47500: 0.181271
2025-12-13 12:59:25,388 INFO     Training average positive_sample_loss at step 47500: 0.014066
2025-12-13 12:59:25,388 INFO     Training average negative_sample_loss at step 47500: 0.023083
2025-12-13 12:59:25,388 INFO     Training average loss at step 47500: 0.199845
2025-12-13 12:59:30,352 INFO     Training average regularization at step 47600: 0.181222
2025-12-13 12:59:30,353 INFO     Training average positive_sample_loss at step 47600: 0.012449
2025-12-13 12:59:30,353 INFO     Training average negative_sample_loss at step 47600: 0.020348
2025-12-13 12:59:30,353 INFO     Training average loss at step 47600: 0.197620
2025-12-13 12:59:35,314 INFO     Training average regularization at step 47700: 0.181172
2025-12-13 12:59:35,314 INFO     Training average positive_sample_loss at step 47700: 0.011982
2025-12-13 12:59:35,314 INFO     Training average negative_sample_loss at step 47700: 0.026986
2025-12-13 12:59:35,314 INFO     Training average loss at step 47700: 0.200656
2025-12-13 12:59:40,285 INFO     Training average regularization at step 47800: 0.181121
2025-12-13 12:59:40,285 INFO     Training average positive_sample_loss at step 47800: 0.015013
2025-12-13 12:59:40,285 INFO     Training average negative_sample_loss at step 47800: 0.026473
2025-12-13 12:59:40,285 INFO     Training average loss at step 47800: 0.201864
2025-12-13 12:59:45,697 INFO     Training average regularization at step 47900: 0.181071
2025-12-13 12:59:45,697 INFO     Training average positive_sample_loss at step 47900: 0.013599
2025-12-13 12:59:45,697 INFO     Training average negative_sample_loss at step 47900: 0.022860
2025-12-13 12:59:45,697 INFO     Training average loss at step 47900: 0.199301
2025-12-13 12:59:50,845 INFO     Training average regularization at step 48000: 0.181021
2025-12-13 12:59:50,846 INFO     Training average positive_sample_loss at step 48000: 0.014238
2025-12-13 12:59:50,846 INFO     Training average negative_sample_loss at step 48000: 0.027503
2025-12-13 12:59:50,846 INFO     Training average loss at step 48000: 0.201892
2025-12-13 12:59:56,022 INFO     Training average regularization at step 48100: 0.180973
2025-12-13 12:59:56,022 INFO     Training average positive_sample_loss at step 48100: 0.013607
2025-12-13 12:59:56,022 INFO     Training average negative_sample_loss at step 48100: 0.024230
2025-12-13 12:59:56,023 INFO     Training average loss at step 48100: 0.199892
2025-12-13 13:00:01,377 INFO     Training average regularization at step 48200: 0.180924
2025-12-13 13:00:01,378 INFO     Training average positive_sample_loss at step 48200: 0.013003
2025-12-13 13:00:01,378 INFO     Training average negative_sample_loss at step 48200: 0.021632
2025-12-13 13:00:01,378 INFO     Training average loss at step 48200: 0.198242
2025-12-13 13:00:07,084 INFO     Training average regularization at step 48300: 0.180875
2025-12-13 13:00:07,084 INFO     Training average positive_sample_loss at step 48300: 0.011943
2025-12-13 13:00:07,084 INFO     Training average negative_sample_loss at step 48300: 0.025388
2025-12-13 13:00:07,084 INFO     Training average loss at step 48300: 0.199540
2025-12-13 13:00:13,555 INFO     Training average regularization at step 48400: 0.180824
2025-12-13 13:00:13,556 INFO     Training average positive_sample_loss at step 48400: 0.011798
2025-12-13 13:00:13,556 INFO     Training average negative_sample_loss at step 48400: 0.025335
2025-12-13 13:00:13,556 INFO     Training average loss at step 48400: 0.199391
2025-12-13 13:00:19,055 INFO     Training average regularization at step 48500: 0.180771
2025-12-13 13:00:19,056 INFO     Training average positive_sample_loss at step 48500: 0.010480
2025-12-13 13:00:19,057 INFO     Training average negative_sample_loss at step 48500: 0.024837
2025-12-13 13:00:19,057 INFO     Training average loss at step 48500: 0.198429
2025-12-13 13:00:24,384 INFO     Training average regularization at step 48600: 0.180717
2025-12-13 13:00:24,384 INFO     Training average positive_sample_loss at step 48600: 0.012212
2025-12-13 13:00:24,384 INFO     Training average negative_sample_loss at step 48600: 0.024981
2025-12-13 13:00:24,384 INFO     Training average loss at step 48600: 0.199314
2025-12-13 13:00:29,765 INFO     Training average regularization at step 48700: 0.180665
2025-12-13 13:00:29,766 INFO     Training average positive_sample_loss at step 48700: 0.011041
2025-12-13 13:00:29,766 INFO     Training average negative_sample_loss at step 48700: 0.024815
2025-12-13 13:00:29,766 INFO     Training average loss at step 48700: 0.198594
2025-12-13 13:00:35,184 INFO     Training average regularization at step 48800: 0.180613
2025-12-13 13:00:35,185 INFO     Training average positive_sample_loss at step 48800: 0.012737
2025-12-13 13:00:35,185 INFO     Training average negative_sample_loss at step 48800: 0.022816
2025-12-13 13:00:35,185 INFO     Training average loss at step 48800: 0.198390
2025-12-13 13:00:40,532 INFO     Training average regularization at step 48900: 0.180562
2025-12-13 13:00:40,532 INFO     Training average positive_sample_loss at step 48900: 0.012467
2025-12-13 13:00:40,532 INFO     Training average negative_sample_loss at step 48900: 0.021743
2025-12-13 13:00:40,532 INFO     Training average loss at step 48900: 0.197667
2025-12-13 13:00:45,891 INFO     Training average regularization at step 49000: 0.180511
2025-12-13 13:00:45,891 INFO     Training average positive_sample_loss at step 49000: 0.011990
2025-12-13 13:00:45,891 INFO     Training average negative_sample_loss at step 49000: 0.024612
2025-12-13 13:00:45,891 INFO     Training average loss at step 49000: 0.198811
2025-12-13 13:00:51,163 INFO     Training average regularization at step 49100: 0.180459
2025-12-13 13:00:51,163 INFO     Training average positive_sample_loss at step 49100: 0.011053
2025-12-13 13:00:51,163 INFO     Training average negative_sample_loss at step 49100: 0.022836
2025-12-13 13:00:51,163 INFO     Training average loss at step 49100: 0.197403
2025-12-13 13:00:56,423 INFO     Training average regularization at step 49200: 0.180407
2025-12-13 13:00:56,424 INFO     Training average positive_sample_loss at step 49200: 0.013383
2025-12-13 13:00:56,424 INFO     Training average negative_sample_loss at step 49200: 0.026901
2025-12-13 13:00:56,424 INFO     Training average loss at step 49200: 0.200549
2025-12-13 13:01:01,847 INFO     Training average regularization at step 49300: 0.180355
2025-12-13 13:01:01,848 INFO     Training average positive_sample_loss at step 49300: 0.013726
2025-12-13 13:01:01,848 INFO     Training average negative_sample_loss at step 49300: 0.026359
2025-12-13 13:01:01,848 INFO     Training average loss at step 49300: 0.200397
2025-12-13 13:01:07,344 INFO     Training average regularization at step 49400: 0.180304
2025-12-13 13:01:07,344 INFO     Training average positive_sample_loss at step 49400: 0.011795
2025-12-13 13:01:07,344 INFO     Training average negative_sample_loss at step 49400: 0.025474
2025-12-13 13:01:07,344 INFO     Training average loss at step 49400: 0.198938
2025-12-13 13:01:12,640 INFO     Training average regularization at step 49500: 0.180253
2025-12-13 13:01:12,640 INFO     Training average positive_sample_loss at step 49500: 0.010931
2025-12-13 13:01:12,640 INFO     Training average negative_sample_loss at step 49500: 0.020122
2025-12-13 13:01:12,640 INFO     Training average loss at step 49500: 0.195780
2025-12-13 13:01:17,977 INFO     Training average regularization at step 49600: 0.180201
2025-12-13 13:01:17,977 INFO     Training average positive_sample_loss at step 49600: 0.011477
2025-12-13 13:01:17,977 INFO     Training average negative_sample_loss at step 49600: 0.025027
2025-12-13 13:01:17,977 INFO     Training average loss at step 49600: 0.198453
2025-12-13 13:01:23,349 INFO     Training average regularization at step 49700: 0.180149
2025-12-13 13:01:23,349 INFO     Training average positive_sample_loss at step 49700: 0.010720
2025-12-13 13:01:23,349 INFO     Training average negative_sample_loss at step 49700: 0.021363
2025-12-13 13:01:23,349 INFO     Training average loss at step 49700: 0.196191
2025-12-13 13:01:28,610 INFO     Training average regularization at step 49800: 0.180098
2025-12-13 13:01:28,610 INFO     Training average positive_sample_loss at step 49800: 0.011346
2025-12-13 13:01:28,610 INFO     Training average negative_sample_loss at step 49800: 0.028920
2025-12-13 13:01:28,610 INFO     Training average loss at step 49800: 0.200231
2025-12-13 13:01:33,861 INFO     Training average regularization at step 49900: 0.180047
2025-12-13 13:01:33,862 INFO     Training average positive_sample_loss at step 49900: 0.012330
2025-12-13 13:01:33,862 INFO     Training average negative_sample_loss at step 49900: 0.019949
2025-12-13 13:01:33,862 INFO     Training average loss at step 49900: 0.196187
2025-12-13 13:01:38,980 INFO     Training average regularization at step 50000: 0.179997
2025-12-13 13:01:38,980 INFO     Training average positive_sample_loss at step 50000: 0.010815
2025-12-13 13:01:38,980 INFO     Training average negative_sample_loss at step 50000: 0.024923
2025-12-13 13:01:38,980 INFO     Training average loss at step 50000: 0.197866
2025-12-13 13:01:38,981 INFO     Evaluating on Valid Dataset...
2025-12-13 13:01:39,663 INFO     Evaluating the model... (0/50000)
2025-12-13 13:01:44,470 INFO     Evaluating the model... (500/50000)
2025-12-13 13:01:50,590 INFO     Evaluating the model... (1000/50000)
2025-12-13 13:01:55,115 INFO     Evaluating the model... (1500/50000)
2025-12-13 13:01:59,930 INFO     Evaluating the model... (2000/50000)
2025-12-13 13:02:04,622 INFO     Evaluating the model... (2500/50000)
2025-12-13 13:02:09,230 INFO     Evaluating the model... (3000/50000)
2025-12-13 13:02:14,417 INFO     Evaluating the model... (3500/50000)
2025-12-13 13:02:18,719 INFO     Evaluating the model... (4000/50000)
2025-12-13 13:02:23,270 INFO     Evaluating the model... (4500/50000)
2025-12-13 13:02:27,701 INFO     Evaluating the model... (5000/50000)
2025-12-13 13:02:32,460 INFO     Evaluating the model... (5500/50000)
2025-12-13 13:02:37,908 INFO     Evaluating the model... (6000/50000)
2025-12-13 13:02:42,487 INFO     Evaluating the model... (6500/50000)
2025-12-13 13:02:47,011 INFO     Evaluating the model... (7000/50000)
2025-12-13 13:02:51,595 INFO     Evaluating the model... (7500/50000)
2025-12-13 13:02:56,233 INFO     Evaluating the model... (8000/50000)
2025-12-13 13:03:01,429 INFO     Evaluating the model... (8500/50000)
2025-12-13 13:03:05,959 INFO     Evaluating the model... (9000/50000)
2025-12-13 13:03:10,384 INFO     Evaluating the model... (9500/50000)
2025-12-13 13:03:14,976 INFO     Evaluating the model... (10000/50000)
2025-12-13 13:03:19,653 INFO     Evaluating the model... (10500/50000)
2025-12-13 13:03:24,953 INFO     Evaluating the model... (11000/50000)
2025-12-13 13:03:29,295 INFO     Evaluating the model... (11500/50000)
2025-12-13 13:03:33,740 INFO     Evaluating the model... (12000/50000)
2025-12-13 13:03:38,349 INFO     Evaluating the model... (12500/50000)
2025-12-13 13:03:43,157 INFO     Evaluating the model... (13000/50000)
2025-12-13 13:03:48,609 INFO     Evaluating the model... (13500/50000)
2025-12-13 13:03:53,382 INFO     Evaluating the model... (14000/50000)
2025-12-13 13:03:58,114 INFO     Evaluating the model... (14500/50000)
2025-12-13 13:04:02,854 INFO     Evaluating the model... (15000/50000)
2025-12-13 13:04:08,807 INFO     Evaluating the model... (15500/50000)
2025-12-13 13:04:13,491 INFO     Evaluating the model... (16000/50000)
2025-12-13 13:04:18,163 INFO     Evaluating the model... (16500/50000)
2025-12-13 13:04:22,818 INFO     Evaluating the model... (17000/50000)
2025-12-13 13:04:27,320 INFO     Evaluating the model... (17500/50000)
2025-12-13 13:04:32,884 INFO     Evaluating the model... (18000/50000)
2025-12-13 13:04:37,568 INFO     Evaluating the model... (18500/50000)
2025-12-13 13:04:42,054 INFO     Evaluating the model... (19000/50000)
2025-12-13 13:04:46,496 INFO     Evaluating the model... (19500/50000)
2025-12-13 13:04:51,121 INFO     Evaluating the model... (20000/50000)
2025-12-13 13:04:57,050 INFO     Evaluating the model... (20500/50000)
2025-12-13 13:05:01,482 INFO     Evaluating the model... (21000/50000)
2025-12-13 13:05:05,914 INFO     Evaluating the model... (21500/50000)
2025-12-13 13:05:10,465 INFO     Evaluating the model... (22000/50000)
2025-12-13 13:05:14,800 INFO     Evaluating the model... (22500/50000)
2025-12-13 13:05:20,508 INFO     Evaluating the model... (23000/50000)
2025-12-13 13:05:24,857 INFO     Evaluating the model... (23500/50000)
2025-12-13 13:05:29,241 INFO     Evaluating the model... (24000/50000)
2025-12-13 13:05:33,781 INFO     Evaluating the model... (24500/50000)
2025-12-13 13:05:38,692 INFO     Evaluating the model... (25000/50000)
2025-12-13 13:05:44,311 INFO     Evaluating the model... (25500/50000)
2025-12-13 13:05:48,679 INFO     Evaluating the model... (26000/50000)
2025-12-13 13:05:52,970 INFO     Evaluating the model... (26500/50000)
2025-12-13 13:05:57,473 INFO     Evaluating the model... (27000/50000)
2025-12-13 13:06:01,966 INFO     Evaluating the model... (27500/50000)
2025-12-13 13:06:07,033 INFO     Evaluating the model... (28000/50000)
2025-12-13 13:06:11,465 INFO     Evaluating the model... (28500/50000)
2025-12-13 13:06:15,828 INFO     Evaluating the model... (29000/50000)
2025-12-13 13:06:20,326 INFO     Evaluating the model... (29500/50000)
2025-12-13 13:06:24,641 INFO     Evaluating the model... (30000/50000)
2025-12-13 13:06:29,923 INFO     Evaluating the model... (30500/50000)
2025-12-13 13:06:34,315 INFO     Evaluating the model... (31000/50000)
2025-12-13 13:06:38,848 INFO     Evaluating the model... (31500/50000)
2025-12-13 13:06:43,540 INFO     Evaluating the model... (32000/50000)
2025-12-13 13:06:48,240 INFO     Evaluating the model... (32500/50000)
2025-12-13 13:06:53,714 INFO     Evaluating the model... (33000/50000)
2025-12-13 13:06:58,239 INFO     Evaluating the model... (33500/50000)
2025-12-13 13:07:02,844 INFO     Evaluating the model... (34000/50000)
2025-12-13 13:07:07,300 INFO     Evaluating the model... (34500/50000)
2025-12-13 13:07:11,808 INFO     Evaluating the model... (35000/50000)
2025-12-13 13:07:17,031 INFO     Evaluating the model... (35500/50000)
2025-12-13 13:07:21,697 INFO     Evaluating the model... (36000/50000)
2025-12-13 13:07:26,379 INFO     Evaluating the model... (36500/50000)
2025-12-13 13:07:31,144 INFO     Evaluating the model... (37000/50000)
2025-12-13 13:07:35,940 INFO     Evaluating the model... (37500/50000)
2025-12-13 13:07:41,432 INFO     Evaluating the model... (38000/50000)
2025-12-13 13:07:46,055 INFO     Evaluating the model... (38500/50000)
2025-12-13 13:07:50,659 INFO     Evaluating the model... (39000/50000)
2025-12-13 13:07:55,189 INFO     Evaluating the model... (39500/50000)
2025-12-13 13:07:59,880 INFO     Evaluating the model... (40000/50000)
2025-12-13 13:08:05,567 INFO     Evaluating the model... (40500/50000)
2025-12-13 13:08:10,324 INFO     Evaluating the model... (41000/50000)
2025-12-13 13:08:14,868 INFO     Evaluating the model... (41500/50000)
2025-12-13 13:08:19,320 INFO     Evaluating the model... (42000/50000)
2025-12-13 13:08:24,836 INFO     Evaluating the model... (42500/50000)
2025-12-13 13:08:29,604 INFO     Evaluating the model... (43000/50000)
2025-12-13 13:08:34,179 INFO     Evaluating the model... (43500/50000)
2025-12-13 13:08:38,535 INFO     Evaluating the model... (44000/50000)
2025-12-13 13:08:43,219 INFO     Evaluating the model... (44500/50000)
2025-12-13 13:08:49,205 INFO     Evaluating the model... (45000/50000)
2025-12-13 13:08:53,829 INFO     Evaluating the model... (45500/50000)
2025-12-13 13:08:58,440 INFO     Evaluating the model... (46000/50000)
2025-12-13 13:09:03,243 INFO     Evaluating the model... (46500/50000)
2025-12-13 13:09:07,878 INFO     Evaluating the model... (47000/50000)
2025-12-13 13:09:13,570 INFO     Evaluating the model... (47500/50000)
2025-12-13 13:09:18,162 INFO     Evaluating the model... (48000/50000)
2025-12-13 13:09:22,737 INFO     Evaluating the model... (48500/50000)
2025-12-13 13:09:27,402 INFO     Evaluating the model... (49000/50000)
2025-12-13 13:09:31,998 INFO     Evaluating the model... (49500/50000)
2025-12-13 13:09:38,574 INFO     Valid MRR at step 50000: 0.720847
2025-12-13 13:09:38,574 INFO     Valid MR at step 50000: 264.997880
2025-12-13 13:09:38,575 INFO     Valid HITS@1 at step 50000: 0.655040
2025-12-13 13:09:38,575 INFO     Valid HITS@3 at step 50000: 0.765650
2025-12-13 13:09:38,575 INFO     Valid HITS@10 at step 50000: 0.835100
2025-12-13 13:09:40,260 INFO     Evaluating on Test Dataset...
2025-12-13 13:09:41,322 INFO     Evaluating the model... (0/59072)
2025-12-13 13:09:46,125 INFO     Evaluating the model... (500/59072)
2025-12-13 13:09:51,111 INFO     Evaluating the model... (1000/59072)
2025-12-13 13:09:55,806 INFO     Evaluating the model... (1500/59072)
2025-12-13 13:10:00,815 INFO     Evaluating the model... (2000/59072)
2025-12-13 13:10:06,888 INFO     Evaluating the model... (2500/59072)
2025-12-13 13:10:11,637 INFO     Evaluating the model... (3000/59072)
2025-12-13 13:10:16,397 INFO     Evaluating the model... (3500/59072)
2025-12-13 13:10:21,138 INFO     Evaluating the model... (4000/59072)
2025-12-13 13:10:25,891 INFO     Evaluating the model... (4500/59072)
2025-12-13 13:10:31,496 INFO     Evaluating the model... (5000/59072)
2025-12-13 13:10:36,178 INFO     Evaluating the model... (5500/59072)
2025-12-13 13:10:40,766 INFO     Evaluating the model... (6000/59072)
2025-12-13 13:10:45,500 INFO     Evaluating the model... (6500/59072)
2025-12-13 13:10:50,356 INFO     Evaluating the model... (7000/59072)
2025-12-13 13:10:56,053 INFO     Evaluating the model... (7500/59072)
2025-12-13 13:11:00,483 INFO     Evaluating the model... (8000/59072)
2025-12-13 13:11:04,936 INFO     Evaluating the model... (8500/59072)
2025-12-13 13:11:09,628 INFO     Evaluating the model... (9000/59072)
2025-12-13 13:11:14,427 INFO     Evaluating the model... (9500/59072)
2025-12-13 13:11:20,053 INFO     Evaluating the model... (10000/59072)
2025-12-13 13:11:24,467 INFO     Evaluating the model... (10500/59072)
2025-12-13 13:11:28,932 INFO     Evaluating the model... (11000/59072)
2025-12-13 13:11:33,449 INFO     Evaluating the model... (11500/59072)
2025-12-13 13:11:37,902 INFO     Evaluating the model... (12000/59072)
2025-12-13 13:11:43,632 INFO     Evaluating the model... (12500/59072)
2025-12-13 13:11:48,204 INFO     Evaluating the model... (13000/59072)
2025-12-13 13:11:52,807 INFO     Evaluating the model... (13500/59072)
2025-12-13 13:11:57,312 INFO     Evaluating the model... (14000/59072)
2025-12-13 13:12:01,902 INFO     Evaluating the model... (14500/59072)
2025-12-13 13:12:07,996 INFO     Evaluating the model... (15000/59072)
2025-12-13 13:12:12,651 INFO     Evaluating the model... (15500/59072)
2025-12-13 13:12:17,188 INFO     Evaluating the model... (16000/59072)
2025-12-13 13:12:21,695 INFO     Evaluating the model... (16500/59072)
2025-12-13 13:12:26,051 INFO     Evaluating the model... (17000/59072)
2025-12-13 13:12:31,831 INFO     Evaluating the model... (17500/59072)
2025-12-13 13:12:36,098 INFO     Evaluating the model... (18000/59072)
2025-12-13 13:12:40,509 INFO     Evaluating the model... (18500/59072)
2025-12-13 13:12:45,026 INFO     Evaluating the model... (19000/59072)
2025-12-13 13:12:49,820 INFO     Evaluating the model... (19500/59072)
2025-12-13 13:12:55,020 INFO     Evaluating the model... (20000/59072)
2025-12-13 13:12:59,474 INFO     Evaluating the model... (20500/59072)
2025-12-13 13:13:04,158 INFO     Evaluating the model... (21000/59072)
2025-12-13 13:13:08,691 INFO     Evaluating the model... (21500/59072)
2025-12-13 13:13:14,444 INFO     Evaluating the model... (22000/59072)
2025-12-13 13:13:19,040 INFO     Evaluating the model... (22500/59072)
2025-12-13 13:13:23,580 INFO     Evaluating the model... (23000/59072)
2025-12-13 13:13:28,060 INFO     Evaluating the model... (23500/59072)
2025-12-13 13:13:32,432 INFO     Evaluating the model... (24000/59072)
2025-12-13 13:13:38,162 INFO     Evaluating the model... (24500/59072)
2025-12-13 13:13:42,786 INFO     Evaluating the model... (25000/59072)
2025-12-13 13:13:47,294 INFO     Evaluating the model... (25500/59072)
2025-12-13 13:13:51,785 INFO     Evaluating the model... (26000/59072)
2025-12-13 13:13:56,388 INFO     Evaluating the model... (26500/59072)
2025-12-13 13:14:02,090 INFO     Evaluating the model... (27000/59072)
2025-12-13 13:14:06,684 INFO     Evaluating the model... (27500/59072)
2025-12-13 13:14:11,099 INFO     Evaluating the model... (28000/59072)
2025-12-13 13:14:15,550 INFO     Evaluating the model... (28500/59072)
2025-12-13 13:14:19,947 INFO     Evaluating the model... (29000/59072)
2025-12-13 13:14:25,499 INFO     Evaluating the model... (29500/59072)
2025-12-13 13:14:30,471 INFO     Evaluating the model... (30000/59072)
2025-12-13 13:14:35,011 INFO     Evaluating the model... (30500/59072)
2025-12-13 13:14:39,568 INFO     Evaluating the model... (31000/59072)
2025-12-13 13:14:44,339 INFO     Evaluating the model... (31500/59072)
2025-12-13 13:14:50,260 INFO     Evaluating the model... (32000/59072)
2025-12-13 13:14:55,011 INFO     Evaluating the model... (32500/59072)
2025-12-13 13:14:59,619 INFO     Evaluating the model... (33000/59072)
2025-12-13 13:15:04,380 INFO     Evaluating the model... (33500/59072)
2025-12-13 13:15:09,418 INFO     Evaluating the model... (34000/59072)
2025-12-13 13:15:13,893 INFO     Evaluating the model... (34500/59072)
2025-12-13 13:15:18,353 INFO     Evaluating the model... (35000/59072)
2025-12-13 13:15:22,918 INFO     Evaluating the model... (35500/59072)
2025-12-13 13:15:27,573 INFO     Evaluating the model... (36000/59072)
2025-12-13 13:15:33,096 INFO     Evaluating the model... (36500/59072)
2025-12-13 13:15:37,664 INFO     Evaluating the model... (37000/59072)
2025-12-13 13:15:41,987 INFO     Evaluating the model... (37500/59072)
2025-12-13 13:15:46,754 INFO     Evaluating the model... (38000/59072)
2025-12-13 13:15:51,288 INFO     Evaluating the model... (38500/59072)
2025-12-13 13:15:56,895 INFO     Evaluating the model... (39000/59072)
2025-12-13 13:16:01,440 INFO     Evaluating the model... (39500/59072)
2025-12-13 13:16:05,811 INFO     Evaluating the model... (40000/59072)
2025-12-13 13:16:10,184 INFO     Evaluating the model... (40500/59072)
2025-12-13 13:16:14,400 INFO     Evaluating the model... (41000/59072)
2025-12-13 13:16:20,178 INFO     Evaluating the model... (41500/59072)
2025-12-13 13:16:24,464 INFO     Evaluating the model... (42000/59072)
2025-12-13 13:16:28,879 INFO     Evaluating the model... (42500/59072)
2025-12-13 13:16:33,358 INFO     Evaluating the model... (43000/59072)
2025-12-13 13:16:37,525 INFO     Evaluating the model... (43500/59072)
2025-12-13 13:16:43,277 INFO     Evaluating the model... (44000/59072)
2025-12-13 13:16:47,780 INFO     Evaluating the model... (44500/59072)
2025-12-13 13:16:52,156 INFO     Evaluating the model... (45000/59072)
2025-12-13 13:16:56,447 INFO     Evaluating the model... (45500/59072)
2025-12-13 13:17:00,731 INFO     Evaluating the model... (46000/59072)
2025-12-13 13:17:06,257 INFO     Evaluating the model... (46500/59072)
2025-12-13 13:17:10,616 INFO     Evaluating the model... (47000/59072)
2025-12-13 13:17:15,064 INFO     Evaluating the model... (47500/59072)
2025-12-13 13:17:19,294 INFO     Evaluating the model... (48000/59072)
2025-12-13 13:17:23,609 INFO     Evaluating the model... (48500/59072)
2025-12-13 13:17:29,041 INFO     Evaluating the model... (49000/59072)
2025-12-13 13:17:33,060 INFO     Evaluating the model... (49500/59072)
2025-12-13 13:17:37,306 INFO     Evaluating the model... (50000/59072)
2025-12-13 13:17:41,617 INFO     Evaluating the model... (50500/59072)
2025-12-13 13:17:45,875 INFO     Evaluating the model... (51000/59072)
2025-12-13 13:17:51,324 INFO     Evaluating the model... (51500/59072)
2025-12-13 13:17:55,760 INFO     Evaluating the model... (52000/59072)
2025-12-13 13:18:00,007 INFO     Evaluating the model... (52500/59072)
2025-12-13 13:18:04,427 INFO     Evaluating the model... (53000/59072)
2025-12-13 13:18:09,951 INFO     Evaluating the model... (53500/59072)
2025-12-13 13:18:14,325 INFO     Evaluating the model... (54000/59072)
2025-12-13 13:18:18,729 INFO     Evaluating the model... (54500/59072)
2025-12-13 13:18:23,232 INFO     Evaluating the model... (55000/59072)
2025-12-13 13:18:27,759 INFO     Evaluating the model... (55500/59072)
2025-12-13 13:18:33,258 INFO     Evaluating the model... (56000/59072)
2025-12-13 13:18:37,519 INFO     Evaluating the model... (56500/59072)
2025-12-13 13:18:41,806 INFO     Evaluating the model... (57000/59072)
2025-12-13 13:18:46,080 INFO     Evaluating the model... (57500/59072)
2025-12-13 13:18:50,506 INFO     Evaluating the model... (58000/59072)
2025-12-13 13:18:56,367 INFO     Evaluating the model... (58500/59072)
2025-12-13 13:19:00,589 INFO     Evaluating the model... (59000/59072)
2025-12-13 13:19:01,484 INFO     Test MRR at step 50000: 0.715053
2025-12-13 13:19:01,484 INFO     Test MR at step 50000: 267.852449
2025-12-13 13:19:01,484 INFO     Test HITS@1 at step 50000: 0.648059
2025-12-13 13:19:01,484 INFO     Test HITS@3 at step 50000: 0.760568
2025-12-13 13:19:01,484 INFO     Test HITS@10 at step 50000: 0.831567
2025-12-13 13:19:06,869 INFO     Training average regularization at step 50100: 0.179947
2025-12-13 13:19:06,874 INFO     Training average positive_sample_loss at step 50100: 0.012293
2025-12-13 13:19:06,874 INFO     Training average negative_sample_loss at step 50100: 0.024020
2025-12-13 13:19:06,874 INFO     Training average loss at step 50100: 0.198103
2025-12-13 13:19:12,285 INFO     Training average regularization at step 50200: 0.179896
2025-12-13 13:19:12,286 INFO     Training average positive_sample_loss at step 50200: 0.012446
2025-12-13 13:19:12,286 INFO     Training average negative_sample_loss at step 50200: 0.027061
2025-12-13 13:19:12,286 INFO     Training average loss at step 50200: 0.199650
2025-12-13 13:19:17,700 INFO     Training average regularization at step 50300: 0.179847
2025-12-13 13:19:17,700 INFO     Training average positive_sample_loss at step 50300: 0.012436
2025-12-13 13:19:17,700 INFO     Training average negative_sample_loss at step 50300: 0.021475
2025-12-13 13:19:17,700 INFO     Training average loss at step 50300: 0.196803
2025-12-13 13:19:22,957 INFO     Training average regularization at step 50400: 0.179797
2025-12-13 13:19:22,957 INFO     Training average positive_sample_loss at step 50400: 0.011947
2025-12-13 13:19:22,957 INFO     Training average negative_sample_loss at step 50400: 0.030119
2025-12-13 13:19:22,957 INFO     Training average loss at step 50400: 0.200830
2025-12-13 13:19:28,199 INFO     Training average regularization at step 50500: 0.179747
2025-12-13 13:19:28,200 INFO     Training average positive_sample_loss at step 50500: 0.012236
2025-12-13 13:19:28,200 INFO     Training average negative_sample_loss at step 50500: 0.021703
2025-12-13 13:19:28,200 INFO     Training average loss at step 50500: 0.196717
2025-12-13 13:19:33,546 INFO     Training average regularization at step 50600: 0.179698
2025-12-13 13:19:33,546 INFO     Training average positive_sample_loss at step 50600: 0.012927
2025-12-13 13:19:33,546 INFO     Training average negative_sample_loss at step 50600: 0.021188
2025-12-13 13:19:33,546 INFO     Training average loss at step 50600: 0.196755
2025-12-13 13:19:38,930 INFO     Training average regularization at step 50700: 0.179648
2025-12-13 13:19:38,930 INFO     Training average positive_sample_loss at step 50700: 0.011565
2025-12-13 13:19:38,930 INFO     Training average negative_sample_loss at step 50700: 0.025358
2025-12-13 13:19:38,930 INFO     Training average loss at step 50700: 0.198110
2025-12-13 13:19:44,294 INFO     Training average regularization at step 50800: 0.179597
2025-12-13 13:19:44,295 INFO     Training average positive_sample_loss at step 50800: 0.010964
2025-12-13 13:19:44,295 INFO     Training average negative_sample_loss at step 50800: 0.022517
2025-12-13 13:19:44,295 INFO     Training average loss at step 50800: 0.196338
2025-12-13 13:19:49,684 INFO     Training average regularization at step 50900: 0.179547
2025-12-13 13:19:49,684 INFO     Training average positive_sample_loss at step 50900: 0.011427
2025-12-13 13:19:49,684 INFO     Training average negative_sample_loss at step 50900: 0.019096
2025-12-13 13:19:49,684 INFO     Training average loss at step 50900: 0.194809
2025-12-13 13:19:54,920 INFO     Training average regularization at step 51000: 0.179497
2025-12-13 13:19:54,925 INFO     Training average positive_sample_loss at step 51000: 0.011282
2025-12-13 13:19:54,925 INFO     Training average negative_sample_loss at step 51000: 0.026074
2025-12-13 13:19:54,925 INFO     Training average loss at step 51000: 0.198175
2025-12-13 13:20:00,164 INFO     Training average regularization at step 51100: 0.179448
2025-12-13 13:20:00,165 INFO     Training average positive_sample_loss at step 51100: 0.012481
2025-12-13 13:20:00,165 INFO     Training average negative_sample_loss at step 51100: 0.024061
2025-12-13 13:20:00,165 INFO     Training average loss at step 51100: 0.197719
2025-12-13 13:20:05,372 INFO     Training average regularization at step 51200: 0.179399
2025-12-13 13:20:05,373 INFO     Training average positive_sample_loss at step 51200: 0.011183
2025-12-13 13:20:05,373 INFO     Training average negative_sample_loss at step 51200: 0.021114
2025-12-13 13:20:05,373 INFO     Training average loss at step 51200: 0.195548
2025-12-13 13:20:10,543 INFO     Training average regularization at step 51300: 0.179349
2025-12-13 13:20:10,544 INFO     Training average positive_sample_loss at step 51300: 0.011343
2025-12-13 13:20:10,544 INFO     Training average negative_sample_loss at step 51300: 0.023319
2025-12-13 13:20:10,544 INFO     Training average loss at step 51300: 0.196680
2025-12-13 13:20:15,848 INFO     Training average regularization at step 51400: 0.179299
2025-12-13 13:20:15,848 INFO     Training average positive_sample_loss at step 51400: 0.010756
2025-12-13 13:20:15,848 INFO     Training average negative_sample_loss at step 51400: 0.023498
2025-12-13 13:20:15,848 INFO     Training average loss at step 51400: 0.196426
2025-12-13 13:20:21,142 INFO     Training average regularization at step 51500: 0.179249
2025-12-13 13:20:21,144 INFO     Training average positive_sample_loss at step 51500: 0.011746
2025-12-13 13:20:21,144 INFO     Training average negative_sample_loss at step 51500: 0.021586
2025-12-13 13:20:21,144 INFO     Training average loss at step 51500: 0.195915
2025-12-13 13:20:26,416 INFO     Training average regularization at step 51600: 0.179199
2025-12-13 13:20:26,416 INFO     Training average positive_sample_loss at step 51600: 0.011113
2025-12-13 13:20:26,416 INFO     Training average negative_sample_loss at step 51600: 0.022764
2025-12-13 13:20:26,416 INFO     Training average loss at step 51600: 0.196137
2025-12-13 13:20:31,788 INFO     Training average regularization at step 51700: 0.179148
2025-12-13 13:20:31,789 INFO     Training average positive_sample_loss at step 51700: 0.011591
2025-12-13 13:20:31,789 INFO     Training average negative_sample_loss at step 51700: 0.027769
2025-12-13 13:20:31,789 INFO     Training average loss at step 51700: 0.198828
2025-12-13 13:20:37,164 INFO     Training average regularization at step 51800: 0.179098
2025-12-13 13:20:37,165 INFO     Training average positive_sample_loss at step 51800: 0.011325
2025-12-13 13:20:37,165 INFO     Training average negative_sample_loss at step 51800: 0.026511
2025-12-13 13:20:37,165 INFO     Training average loss at step 51800: 0.198017
2025-12-13 13:20:42,559 INFO     Training average regularization at step 51900: 0.179049
2025-12-13 13:20:42,559 INFO     Training average positive_sample_loss at step 51900: 0.010369
2025-12-13 13:20:42,559 INFO     Training average negative_sample_loss at step 51900: 0.022843
2025-12-13 13:20:42,559 INFO     Training average loss at step 51900: 0.195655
2025-12-13 13:20:47,830 INFO     Training average regularization at step 52000: 0.178999
2025-12-13 13:20:47,830 INFO     Training average positive_sample_loss at step 52000: 0.011950
2025-12-13 13:20:47,831 INFO     Training average negative_sample_loss at step 52000: 0.026925
2025-12-13 13:20:47,831 INFO     Training average loss at step 52000: 0.198436
2025-12-13 13:20:53,068 INFO     Training average regularization at step 52100: 0.178950
2025-12-13 13:20:53,069 INFO     Training average positive_sample_loss at step 52100: 0.012241
2025-12-13 13:20:53,069 INFO     Training average negative_sample_loss at step 52100: 0.025394
2025-12-13 13:20:53,069 INFO     Training average loss at step 52100: 0.197768
2025-12-13 13:20:58,287 INFO     Training average regularization at step 52200: 0.178902
2025-12-13 13:20:58,287 INFO     Training average positive_sample_loss at step 52200: 0.010879
2025-12-13 13:20:58,287 INFO     Training average negative_sample_loss at step 52200: 0.027646
2025-12-13 13:20:58,287 INFO     Training average loss at step 52200: 0.198164
2025-12-13 13:21:03,606 INFO     Training average regularization at step 52300: 0.178854
2025-12-13 13:21:03,606 INFO     Training average positive_sample_loss at step 52300: 0.012714
2025-12-13 13:21:03,606 INFO     Training average negative_sample_loss at step 52300: 0.021035
2025-12-13 13:21:03,606 INFO     Training average loss at step 52300: 0.195728
2025-12-13 13:21:08,911 INFO     Training average regularization at step 52400: 0.178805
2025-12-13 13:21:08,911 INFO     Training average positive_sample_loss at step 52400: 0.011239
2025-12-13 13:21:08,911 INFO     Training average negative_sample_loss at step 52400: 0.022960
2025-12-13 13:21:08,911 INFO     Training average loss at step 52400: 0.195905
2025-12-13 13:21:14,074 INFO     Training average regularization at step 52500: 0.178756
2025-12-13 13:21:14,074 INFO     Training average positive_sample_loss at step 52500: 0.011830
2025-12-13 13:21:14,074 INFO     Training average negative_sample_loss at step 52500: 0.022432
2025-12-13 13:21:14,074 INFO     Training average loss at step 52500: 0.195886
2025-12-13 13:21:19,193 INFO     Training average regularization at step 52600: 0.178706
2025-12-13 13:21:19,194 INFO     Training average positive_sample_loss at step 52600: 0.011797
2025-12-13 13:21:19,194 INFO     Training average negative_sample_loss at step 52600: 0.021089
2025-12-13 13:21:19,194 INFO     Training average loss at step 52600: 0.195149
2025-12-13 13:21:24,325 INFO     Training average regularization at step 52700: 0.178656
2025-12-13 13:21:24,326 INFO     Training average positive_sample_loss at step 52700: 0.010784
2025-12-13 13:21:24,326 INFO     Training average negative_sample_loss at step 52700: 0.022433
2025-12-13 13:21:24,326 INFO     Training average loss at step 52700: 0.195264
2025-12-13 13:21:29,450 INFO     Training average regularization at step 52800: 0.178606
2025-12-13 13:21:29,450 INFO     Training average positive_sample_loss at step 52800: 0.009633
2025-12-13 13:21:29,450 INFO     Training average negative_sample_loss at step 52800: 0.024253
2025-12-13 13:21:29,450 INFO     Training average loss at step 52800: 0.195548
2025-12-13 13:21:34,629 INFO     Training average regularization at step 52900: 0.178555
2025-12-13 13:21:34,629 INFO     Training average positive_sample_loss at step 52900: 0.010985
2025-12-13 13:21:34,629 INFO     Training average negative_sample_loss at step 52900: 0.024216
2025-12-13 13:21:34,629 INFO     Training average loss at step 52900: 0.196156
2025-12-13 13:21:39,866 INFO     Training average regularization at step 53000: 0.178505
2025-12-13 13:21:39,866 INFO     Training average positive_sample_loss at step 53000: 0.010871
2025-12-13 13:21:39,866 INFO     Training average negative_sample_loss at step 53000: 0.022678
2025-12-13 13:21:39,866 INFO     Training average loss at step 53000: 0.195280
2025-12-13 13:21:45,168 INFO     Training average regularization at step 53100: 0.178455
2025-12-13 13:21:45,168 INFO     Training average positive_sample_loss at step 53100: 0.012673
2025-12-13 13:21:45,168 INFO     Training average negative_sample_loss at step 53100: 0.024560
2025-12-13 13:21:45,168 INFO     Training average loss at step 53100: 0.197071
2025-12-13 13:21:51,393 INFO     Training average regularization at step 53200: 0.178405
2025-12-13 13:21:51,393 INFO     Training average positive_sample_loss at step 53200: 0.010781
2025-12-13 13:21:51,394 INFO     Training average negative_sample_loss at step 53200: 0.024467
2025-12-13 13:21:51,394 INFO     Training average loss at step 53200: 0.196029
2025-12-13 13:21:56,445 INFO     Training average regularization at step 53300: 0.178351
2025-12-13 13:21:56,445 INFO     Training average positive_sample_loss at step 53300: 0.010539
2025-12-13 13:21:56,445 INFO     Training average negative_sample_loss at step 53300: 0.024018
2025-12-13 13:21:56,445 INFO     Training average loss at step 53300: 0.195629
2025-12-13 13:22:01,479 INFO     Training average regularization at step 53400: 0.178298
2025-12-13 13:22:01,480 INFO     Training average positive_sample_loss at step 53400: 0.010075
2025-12-13 13:22:01,480 INFO     Training average negative_sample_loss at step 53400: 0.025343
2025-12-13 13:22:01,480 INFO     Training average loss at step 53400: 0.196007
2025-12-13 13:22:06,483 INFO     Training average regularization at step 53500: 0.178245
2025-12-13 13:22:06,484 INFO     Training average positive_sample_loss at step 53500: 0.010053
2025-12-13 13:22:06,484 INFO     Training average negative_sample_loss at step 53500: 0.020239
2025-12-13 13:22:06,484 INFO     Training average loss at step 53500: 0.193391
2025-12-13 13:22:11,555 INFO     Training average regularization at step 53600: 0.178193
2025-12-13 13:22:11,555 INFO     Training average positive_sample_loss at step 53600: 0.010032
2025-12-13 13:22:11,555 INFO     Training average negative_sample_loss at step 53600: 0.021059
2025-12-13 13:22:11,555 INFO     Training average loss at step 53600: 0.193738
2025-12-13 13:22:16,917 INFO     Training average regularization at step 53700: 0.178140
2025-12-13 13:22:16,918 INFO     Training average positive_sample_loss at step 53700: 0.009840
2025-12-13 13:22:16,918 INFO     Training average negative_sample_loss at step 53700: 0.022376
2025-12-13 13:22:16,918 INFO     Training average loss at step 53700: 0.194248
2025-12-13 13:22:22,160 INFO     Training average regularization at step 53800: 0.178087
2025-12-13 13:22:22,161 INFO     Training average positive_sample_loss at step 53800: 0.010564
2025-12-13 13:22:22,161 INFO     Training average negative_sample_loss at step 53800: 0.024115
2025-12-13 13:22:22,161 INFO     Training average loss at step 53800: 0.195427
2025-12-13 13:22:27,392 INFO     Training average regularization at step 53900: 0.178035
2025-12-13 13:22:27,392 INFO     Training average positive_sample_loss at step 53900: 0.012080
2025-12-13 13:22:27,392 INFO     Training average negative_sample_loss at step 53900: 0.021141
2025-12-13 13:22:27,392 INFO     Training average loss at step 53900: 0.194646
2025-12-13 13:22:32,605 INFO     Training average regularization at step 54000: 0.177982
2025-12-13 13:22:32,605 INFO     Training average positive_sample_loss at step 54000: 0.009207
2025-12-13 13:22:32,605 INFO     Training average negative_sample_loss at step 54000: 0.024108
2025-12-13 13:22:32,605 INFO     Training average loss at step 54000: 0.194640
2025-12-13 13:22:37,827 INFO     Training average regularization at step 54100: 0.177929
2025-12-13 13:22:37,827 INFO     Training average positive_sample_loss at step 54100: 0.010395
2025-12-13 13:22:37,827 INFO     Training average negative_sample_loss at step 54100: 0.023335
2025-12-13 13:22:37,827 INFO     Training average loss at step 54100: 0.194794
2025-12-13 13:22:43,149 INFO     Training average regularization at step 54200: 0.177877
2025-12-13 13:22:43,149 INFO     Training average positive_sample_loss at step 54200: 0.009893
2025-12-13 13:22:43,150 INFO     Training average negative_sample_loss at step 54200: 0.022493
2025-12-13 13:22:43,150 INFO     Training average loss at step 54200: 0.194070
2025-12-13 13:22:48,458 INFO     Training average regularization at step 54300: 0.177825
2025-12-13 13:22:48,459 INFO     Training average positive_sample_loss at step 54300: 0.011270
2025-12-13 13:22:48,459 INFO     Training average negative_sample_loss at step 54300: 0.023722
2025-12-13 13:22:48,459 INFO     Training average loss at step 54300: 0.195321
2025-12-13 13:22:53,721 INFO     Training average regularization at step 54400: 0.177773
2025-12-13 13:22:53,721 INFO     Training average positive_sample_loss at step 54400: 0.010488
2025-12-13 13:22:53,722 INFO     Training average negative_sample_loss at step 54400: 0.024538
2025-12-13 13:22:53,722 INFO     Training average loss at step 54400: 0.195287
2025-12-13 13:22:59,080 INFO     Training average regularization at step 54500: 0.177721
2025-12-13 13:22:59,080 INFO     Training average positive_sample_loss at step 54500: 0.010116
2025-12-13 13:22:59,080 INFO     Training average negative_sample_loss at step 54500: 0.020584
2025-12-13 13:22:59,080 INFO     Training average loss at step 54500: 0.193071
2025-12-13 13:23:04,376 INFO     Training average regularization at step 54600: 0.177670
2025-12-13 13:23:04,376 INFO     Training average positive_sample_loss at step 54600: 0.010423
2025-12-13 13:23:04,377 INFO     Training average negative_sample_loss at step 54600: 0.025580
2025-12-13 13:23:04,377 INFO     Training average loss at step 54600: 0.195671
2025-12-13 13:23:09,686 INFO     Training average regularization at step 54700: 0.177618
2025-12-13 13:23:09,686 INFO     Training average positive_sample_loss at step 54700: 0.010722
2025-12-13 13:23:09,686 INFO     Training average negative_sample_loss at step 54700: 0.023602
2025-12-13 13:23:09,686 INFO     Training average loss at step 54700: 0.194780
2025-12-13 13:23:14,803 INFO     Training average regularization at step 54800: 0.177567
2025-12-13 13:23:14,803 INFO     Training average positive_sample_loss at step 54800: 0.009481
2025-12-13 13:23:14,803 INFO     Training average negative_sample_loss at step 54800: 0.025090
2025-12-13 13:23:14,803 INFO     Training average loss at step 54800: 0.194852
2025-12-13 13:23:19,865 INFO     Training average regularization at step 54900: 0.177516
2025-12-13 13:23:19,865 INFO     Training average positive_sample_loss at step 54900: 0.010833
2025-12-13 13:23:19,865 INFO     Training average negative_sample_loss at step 54900: 0.021477
2025-12-13 13:23:19,865 INFO     Training average loss at step 54900: 0.193671
2025-12-13 13:23:24,932 INFO     Training average regularization at step 55000: 0.177465
2025-12-13 13:23:24,933 INFO     Training average positive_sample_loss at step 55000: 0.010020
2025-12-13 13:23:24,933 INFO     Training average negative_sample_loss at step 55000: 0.024339
2025-12-13 13:23:24,933 INFO     Training average loss at step 55000: 0.194645
2025-12-13 13:23:30,042 INFO     Training average regularization at step 55100: 0.177414
2025-12-13 13:23:30,042 INFO     Training average positive_sample_loss at step 55100: 0.010160
2025-12-13 13:23:30,042 INFO     Training average negative_sample_loss at step 55100: 0.020388
2025-12-13 13:23:30,042 INFO     Training average loss at step 55100: 0.192688
2025-12-13 13:23:35,191 INFO     Training average regularization at step 55200: 0.177363
2025-12-13 13:23:35,191 INFO     Training average positive_sample_loss at step 55200: 0.009348
2025-12-13 13:23:35,191 INFO     Training average negative_sample_loss at step 55200: 0.024822
2025-12-13 13:23:35,191 INFO     Training average loss at step 55200: 0.194448
2025-12-13 13:23:40,503 INFO     Training average regularization at step 55300: 0.177312
2025-12-13 13:23:40,503 INFO     Training average positive_sample_loss at step 55300: 0.009975
2025-12-13 13:23:40,503 INFO     Training average negative_sample_loss at step 55300: 0.024401
2025-12-13 13:23:40,503 INFO     Training average loss at step 55300: 0.194500
2025-12-13 13:23:45,775 INFO     Training average regularization at step 55400: 0.177261
2025-12-13 13:23:45,775 INFO     Training average positive_sample_loss at step 55400: 0.009579
2025-12-13 13:23:45,775 INFO     Training average negative_sample_loss at step 55400: 0.020944
2025-12-13 13:23:45,775 INFO     Training average loss at step 55400: 0.192523
2025-12-13 13:23:51,095 INFO     Training average regularization at step 55500: 0.177210
2025-12-13 13:23:51,095 INFO     Training average positive_sample_loss at step 55500: 0.010733
2025-12-13 13:23:51,095 INFO     Training average negative_sample_loss at step 55500: 0.021596
2025-12-13 13:23:51,095 INFO     Training average loss at step 55500: 0.193374
2025-12-13 13:23:56,353 INFO     Training average regularization at step 55600: 0.177159
2025-12-13 13:23:56,353 INFO     Training average positive_sample_loss at step 55600: 0.009716
2025-12-13 13:23:56,353 INFO     Training average negative_sample_loss at step 55600: 0.020149
2025-12-13 13:23:56,353 INFO     Training average loss at step 55600: 0.192091
2025-12-13 13:24:01,703 INFO     Training average regularization at step 55700: 0.177107
2025-12-13 13:24:01,703 INFO     Training average positive_sample_loss at step 55700: 0.010521
2025-12-13 13:24:01,703 INFO     Training average negative_sample_loss at step 55700: 0.020966
2025-12-13 13:24:01,703 INFO     Training average loss at step 55700: 0.192851
2025-12-13 13:24:07,023 INFO     Training average regularization at step 55800: 0.177056
2025-12-13 13:24:07,023 INFO     Training average positive_sample_loss at step 55800: 0.010083
2025-12-13 13:24:07,023 INFO     Training average negative_sample_loss at step 55800: 0.023477
2025-12-13 13:24:07,023 INFO     Training average loss at step 55800: 0.193836
2025-12-13 13:24:12,379 INFO     Training average regularization at step 55900: 0.177006
2025-12-13 13:24:12,379 INFO     Training average positive_sample_loss at step 55900: 0.011443
2025-12-13 13:24:12,379 INFO     Training average negative_sample_loss at step 55900: 0.020744
2025-12-13 13:24:12,379 INFO     Training average loss at step 55900: 0.193099
2025-12-13 13:24:17,610 INFO     Training average regularization at step 56000: 0.176956
2025-12-13 13:24:17,610 INFO     Training average positive_sample_loss at step 56000: 0.011264
2025-12-13 13:24:17,610 INFO     Training average negative_sample_loss at step 56000: 0.019350
2025-12-13 13:24:17,610 INFO     Training average loss at step 56000: 0.192262
2025-12-13 13:24:22,861 INFO     Training average regularization at step 56100: 0.176905
2025-12-13 13:24:22,861 INFO     Training average positive_sample_loss at step 56100: 0.010571
2025-12-13 13:24:22,861 INFO     Training average negative_sample_loss at step 56100: 0.022079
2025-12-13 13:24:22,861 INFO     Training average loss at step 56100: 0.193230
2025-12-13 13:24:28,155 INFO     Training average regularization at step 56200: 0.176855
2025-12-13 13:24:28,155 INFO     Training average positive_sample_loss at step 56200: 0.009962
2025-12-13 13:24:28,156 INFO     Training average negative_sample_loss at step 56200: 0.019671
2025-12-13 13:24:28,156 INFO     Training average loss at step 56200: 0.191671
2025-12-13 13:24:33,459 INFO     Training average regularization at step 56300: 0.176804
2025-12-13 13:24:33,460 INFO     Training average positive_sample_loss at step 56300: 0.010831
2025-12-13 13:24:33,460 INFO     Training average negative_sample_loss at step 56300: 0.024711
2025-12-13 13:24:33,460 INFO     Training average loss at step 56300: 0.194575
2025-12-13 13:24:38,738 INFO     Training average regularization at step 56400: 0.176755
2025-12-13 13:24:38,738 INFO     Training average positive_sample_loss at step 56400: 0.009883
2025-12-13 13:24:38,738 INFO     Training average negative_sample_loss at step 56400: 0.022117
2025-12-13 13:24:38,738 INFO     Training average loss at step 56400: 0.192755
2025-12-13 13:24:44,042 INFO     Training average regularization at step 56500: 0.176706
2025-12-13 13:24:44,042 INFO     Training average positive_sample_loss at step 56500: 0.010142
2025-12-13 13:24:44,042 INFO     Training average negative_sample_loss at step 56500: 0.022870
2025-12-13 13:24:44,042 INFO     Training average loss at step 56500: 0.193212
2025-12-13 13:24:49,270 INFO     Training average regularization at step 56600: 0.176657
2025-12-13 13:24:49,271 INFO     Training average positive_sample_loss at step 56600: 0.009221
2025-12-13 13:24:49,271 INFO     Training average negative_sample_loss at step 56600: 0.023958
2025-12-13 13:24:49,271 INFO     Training average loss at step 56600: 0.193246
2025-12-13 13:24:54,660 INFO     Training average regularization at step 56700: 0.176609
2025-12-13 13:24:54,661 INFO     Training average positive_sample_loss at step 56700: 0.009032
2025-12-13 13:24:54,661 INFO     Training average negative_sample_loss at step 56700: 0.019320
2025-12-13 13:24:54,661 INFO     Training average loss at step 56700: 0.190785
2025-12-13 13:24:59,797 INFO     Training average regularization at step 56800: 0.176560
2025-12-13 13:24:59,797 INFO     Training average positive_sample_loss at step 56800: 0.009746
2025-12-13 13:24:59,797 INFO     Training average negative_sample_loss at step 56800: 0.025539
2025-12-13 13:24:59,797 INFO     Training average loss at step 56800: 0.194203
2025-12-13 13:25:05,090 INFO     Training average regularization at step 56900: 0.176511
2025-12-13 13:25:05,090 INFO     Training average positive_sample_loss at step 56900: 0.010079
2025-12-13 13:25:05,090 INFO     Training average negative_sample_loss at step 56900: 0.023160
2025-12-13 13:25:05,090 INFO     Training average loss at step 56900: 0.193130
2025-12-13 13:25:10,402 INFO     Training average regularization at step 57000: 0.176462
2025-12-13 13:25:10,402 INFO     Training average positive_sample_loss at step 57000: 0.009996
2025-12-13 13:25:10,402 INFO     Training average negative_sample_loss at step 57000: 0.023557
2025-12-13 13:25:10,402 INFO     Training average loss at step 57000: 0.193239
2025-12-13 13:25:15,605 INFO     Training average regularization at step 57100: 0.176413
2025-12-13 13:25:15,605 INFO     Training average positive_sample_loss at step 57100: 0.009519
2025-12-13 13:25:15,605 INFO     Training average negative_sample_loss at step 57100: 0.022723
2025-12-13 13:25:15,605 INFO     Training average loss at step 57100: 0.192534
2025-12-13 13:25:20,832 INFO     Training average regularization at step 57200: 0.176364
2025-12-13 13:25:20,833 INFO     Training average positive_sample_loss at step 57200: 0.009902
2025-12-13 13:25:20,833 INFO     Training average negative_sample_loss at step 57200: 0.022962
2025-12-13 13:25:20,833 INFO     Training average loss at step 57200: 0.192796
2025-12-13 13:25:26,091 INFO     Training average regularization at step 57300: 0.176316
2025-12-13 13:25:26,092 INFO     Training average positive_sample_loss at step 57300: 0.009698
2025-12-13 13:25:26,092 INFO     Training average negative_sample_loss at step 57300: 0.022159
2025-12-13 13:25:26,092 INFO     Training average loss at step 57300: 0.192244
2025-12-13 13:25:31,256 INFO     Training average regularization at step 57400: 0.176267
2025-12-13 13:25:31,256 INFO     Training average positive_sample_loss at step 57400: 0.010130
2025-12-13 13:25:31,256 INFO     Training average negative_sample_loss at step 57400: 0.021407
2025-12-13 13:25:31,256 INFO     Training average loss at step 57400: 0.192036
2025-12-13 13:25:36,388 INFO     Training average regularization at step 57500: 0.176219
2025-12-13 13:25:36,388 INFO     Training average positive_sample_loss at step 57500: 0.010350
2025-12-13 13:25:36,388 INFO     Training average negative_sample_loss at step 57500: 0.021360
2025-12-13 13:25:36,388 INFO     Training average loss at step 57500: 0.192073
2025-12-13 13:25:41,643 INFO     Training average regularization at step 57600: 0.176170
2025-12-13 13:25:41,643 INFO     Training average positive_sample_loss at step 57600: 0.010215
2025-12-13 13:25:41,643 INFO     Training average negative_sample_loss at step 57600: 0.022374
2025-12-13 13:25:41,643 INFO     Training average loss at step 57600: 0.192465
2025-12-13 13:25:46,960 INFO     Training average regularization at step 57700: 0.176120
2025-12-13 13:25:46,961 INFO     Training average positive_sample_loss at step 57700: 0.009323
2025-12-13 13:25:46,961 INFO     Training average negative_sample_loss at step 57700: 0.019173
2025-12-13 13:25:46,961 INFO     Training average loss at step 57700: 0.190369
2025-12-13 13:25:52,187 INFO     Training average regularization at step 57800: 0.176069
2025-12-13 13:25:52,187 INFO     Training average positive_sample_loss at step 57800: 0.008811
2025-12-13 13:25:52,187 INFO     Training average negative_sample_loss at step 57800: 0.025625
2025-12-13 13:25:52,187 INFO     Training average loss at step 57800: 0.193288
2025-12-13 13:25:57,435 INFO     Training average regularization at step 57900: 0.176020
2025-12-13 13:25:57,435 INFO     Training average positive_sample_loss at step 57900: 0.009279
2025-12-13 13:25:57,436 INFO     Training average negative_sample_loss at step 57900: 0.024687
2025-12-13 13:25:57,436 INFO     Training average loss at step 57900: 0.193003
2025-12-13 13:26:03,617 INFO     Training average regularization at step 58000: 0.175971
2025-12-13 13:26:03,617 INFO     Training average positive_sample_loss at step 58000: 0.009918
2025-12-13 13:26:03,617 INFO     Training average negative_sample_loss at step 58000: 0.022667
2025-12-13 13:26:03,617 INFO     Training average loss at step 58000: 0.192263
2025-12-13 13:26:09,019 INFO     Training average regularization at step 58100: 0.175919
2025-12-13 13:26:09,020 INFO     Training average positive_sample_loss at step 58100: 0.008224
2025-12-13 13:26:09,020 INFO     Training average negative_sample_loss at step 58100: 0.020684
2025-12-13 13:26:09,020 INFO     Training average loss at step 58100: 0.190373
2025-12-13 13:26:14,342 INFO     Training average regularization at step 58200: 0.175865
2025-12-13 13:26:14,342 INFO     Training average positive_sample_loss at step 58200: 0.008339
2025-12-13 13:26:14,342 INFO     Training average negative_sample_loss at step 58200: 0.022193
2025-12-13 13:26:14,342 INFO     Training average loss at step 58200: 0.191131
2025-12-13 13:26:19,637 INFO     Training average regularization at step 58300: 0.175812
2025-12-13 13:26:19,637 INFO     Training average positive_sample_loss at step 58300: 0.008685
2025-12-13 13:26:19,637 INFO     Training average negative_sample_loss at step 58300: 0.022837
2025-12-13 13:26:19,637 INFO     Training average loss at step 58300: 0.191573
2025-12-13 13:26:24,969 INFO     Training average regularization at step 58400: 0.175759
2025-12-13 13:26:24,969 INFO     Training average positive_sample_loss at step 58400: 0.009806
2025-12-13 13:26:24,970 INFO     Training average negative_sample_loss at step 58400: 0.022814
2025-12-13 13:26:24,970 INFO     Training average loss at step 58400: 0.192069
2025-12-13 13:26:30,291 INFO     Training average regularization at step 58500: 0.175706
2025-12-13 13:26:30,291 INFO     Training average positive_sample_loss at step 58500: 0.009352
2025-12-13 13:26:30,291 INFO     Training average negative_sample_loss at step 58500: 0.025598
2025-12-13 13:26:30,291 INFO     Training average loss at step 58500: 0.193182
2025-12-13 13:26:35,641 INFO     Training average regularization at step 58600: 0.175655
2025-12-13 13:26:35,641 INFO     Training average positive_sample_loss at step 58600: 0.009021
2025-12-13 13:26:35,641 INFO     Training average negative_sample_loss at step 58600: 0.022385
2025-12-13 13:26:35,641 INFO     Training average loss at step 58600: 0.191358
2025-12-13 13:26:40,915 INFO     Training average regularization at step 58700: 0.175604
2025-12-13 13:26:40,915 INFO     Training average positive_sample_loss at step 58700: 0.009259
2025-12-13 13:26:40,915 INFO     Training average negative_sample_loss at step 58700: 0.022275
2025-12-13 13:26:40,915 INFO     Training average loss at step 58700: 0.191371
2025-12-13 13:26:46,199 INFO     Training average regularization at step 58800: 0.175553
2025-12-13 13:26:46,199 INFO     Training average positive_sample_loss at step 58800: 0.009296
2025-12-13 13:26:46,199 INFO     Training average negative_sample_loss at step 58800: 0.021047
2025-12-13 13:26:46,199 INFO     Training average loss at step 58800: 0.190724
2025-12-13 13:26:51,499 INFO     Training average regularization at step 58900: 0.175501
2025-12-13 13:26:51,500 INFO     Training average positive_sample_loss at step 58900: 0.008835
2025-12-13 13:26:51,500 INFO     Training average negative_sample_loss at step 58900: 0.023488
2025-12-13 13:26:51,500 INFO     Training average loss at step 58900: 0.191663
2025-12-13 13:26:56,829 INFO     Training average regularization at step 59000: 0.175449
2025-12-13 13:26:56,829 INFO     Training average positive_sample_loss at step 59000: 0.009599
2025-12-13 13:26:56,829 INFO     Training average negative_sample_loss at step 59000: 0.019442
2025-12-13 13:26:56,829 INFO     Training average loss at step 59000: 0.189970
2025-12-13 13:27:02,134 INFO     Training average regularization at step 59100: 0.175397
2025-12-13 13:27:02,134 INFO     Training average positive_sample_loss at step 59100: 0.008786
2025-12-13 13:27:02,134 INFO     Training average negative_sample_loss at step 59100: 0.020122
2025-12-13 13:27:02,134 INFO     Training average loss at step 59100: 0.189851
2025-12-13 13:27:07,559 INFO     Training average regularization at step 59200: 0.175344
2025-12-13 13:27:07,559 INFO     Training average positive_sample_loss at step 59200: 0.008584
2025-12-13 13:27:07,560 INFO     Training average negative_sample_loss at step 59200: 0.019961
2025-12-13 13:27:07,560 INFO     Training average loss at step 59200: 0.189616
2025-12-13 13:27:12,945 INFO     Training average regularization at step 59300: 0.175291
2025-12-13 13:27:12,946 INFO     Training average positive_sample_loss at step 59300: 0.008801
2025-12-13 13:27:12,946 INFO     Training average negative_sample_loss at step 59300: 0.022370
2025-12-13 13:27:12,946 INFO     Training average loss at step 59300: 0.190876
2025-12-13 13:27:18,252 INFO     Training average regularization at step 59400: 0.175237
2025-12-13 13:27:18,252 INFO     Training average positive_sample_loss at step 59400: 0.008757
2025-12-13 13:27:18,252 INFO     Training average negative_sample_loss at step 59400: 0.023789
2025-12-13 13:27:18,252 INFO     Training average loss at step 59400: 0.191510
2025-12-13 13:27:23,583 INFO     Training average regularization at step 59500: 0.175185
2025-12-13 13:27:23,583 INFO     Training average positive_sample_loss at step 59500: 0.009802
2025-12-13 13:27:23,583 INFO     Training average negative_sample_loss at step 59500: 0.022763
2025-12-13 13:27:23,583 INFO     Training average loss at step 59500: 0.191468
2025-12-13 13:27:28,837 INFO     Training average regularization at step 59600: 0.175133
2025-12-13 13:27:28,837 INFO     Training average positive_sample_loss at step 59600: 0.008689
2025-12-13 13:27:28,837 INFO     Training average negative_sample_loss at step 59600: 0.020573
2025-12-13 13:27:28,837 INFO     Training average loss at step 59600: 0.189764
2025-12-13 13:27:34,227 INFO     Training average regularization at step 59700: 0.175081
2025-12-13 13:27:34,227 INFO     Training average positive_sample_loss at step 59700: 0.008508
2025-12-13 13:27:34,227 INFO     Training average negative_sample_loss at step 59700: 0.020403
2025-12-13 13:27:34,227 INFO     Training average loss at step 59700: 0.189536
2025-12-13 13:27:39,463 INFO     Training average regularization at step 59800: 0.175029
2025-12-13 13:27:39,463 INFO     Training average positive_sample_loss at step 59800: 0.008219
2025-12-13 13:27:39,464 INFO     Training average negative_sample_loss at step 59800: 0.016507
2025-12-13 13:27:39,464 INFO     Training average loss at step 59800: 0.187393
2025-12-13 13:27:44,836 INFO     Training average regularization at step 59900: 0.174977
2025-12-13 13:27:44,836 INFO     Training average positive_sample_loss at step 59900: 0.008605
2025-12-13 13:27:44,836 INFO     Training average negative_sample_loss at step 59900: 0.021870
2025-12-13 13:27:44,836 INFO     Training average loss at step 59900: 0.190215
2025-12-13 13:27:51,565 INFO     Training average regularization at step 60000: 0.174925
2025-12-13 13:27:51,566 INFO     Training average positive_sample_loss at step 60000: 0.010006
2025-12-13 13:27:51,566 INFO     Training average negative_sample_loss at step 60000: 0.025028
2025-12-13 13:27:51,566 INFO     Training average loss at step 60000: 0.192442
2025-12-13 13:27:51,566 INFO     Evaluating on Valid Dataset...
2025-12-13 13:27:52,271 INFO     Evaluating the model... (0/50000)
2025-12-13 13:27:57,041 INFO     Evaluating the model... (500/50000)
2025-12-13 13:28:01,496 INFO     Evaluating the model... (1000/50000)
2025-12-13 13:28:06,553 INFO     Evaluating the model... (1500/50000)
2025-12-13 13:28:11,063 INFO     Evaluating the model... (2000/50000)
2025-12-13 13:28:15,422 INFO     Evaluating the model... (2500/50000)
2025-12-13 13:28:19,918 INFO     Evaluating the model... (3000/50000)
2025-12-13 13:28:24,111 INFO     Evaluating the model... (3500/50000)
2025-12-13 13:28:29,074 INFO     Evaluating the model... (4000/50000)
2025-12-13 13:28:33,614 INFO     Evaluating the model... (4500/50000)
2025-12-13 13:28:37,985 INFO     Evaluating the model... (5000/50000)
2025-12-13 13:28:42,386 INFO     Evaluating the model... (5500/50000)
2025-12-13 13:28:46,794 INFO     Evaluating the model... (6000/50000)
2025-12-13 13:28:51,758 INFO     Evaluating the model... (6500/50000)
2025-12-13 13:28:55,951 INFO     Evaluating the model... (7000/50000)
2025-12-13 13:29:00,222 INFO     Evaluating the model... (7500/50000)
2025-12-13 13:29:04,601 INFO     Evaluating the model... (8000/50000)
2025-12-13 13:29:08,986 INFO     Evaluating the model... (8500/50000)
2025-12-13 13:29:13,892 INFO     Evaluating the model... (9000/50000)
2025-12-13 13:29:18,392 INFO     Evaluating the model... (9500/50000)
2025-12-13 13:29:22,816 INFO     Evaluating the model... (10000/50000)
2025-12-13 13:29:27,200 INFO     Evaluating the model... (10500/50000)
2025-12-13 13:29:31,827 INFO     Evaluating the model... (11000/50000)
2025-12-13 13:29:37,222 INFO     Evaluating the model... (11500/50000)
2025-12-13 13:29:41,578 INFO     Evaluating the model... (12000/50000)
2025-12-13 13:29:45,925 INFO     Evaluating the model... (12500/50000)
2025-12-13 13:29:50,338 INFO     Evaluating the model... (13000/50000)
2025-12-13 13:29:54,805 INFO     Evaluating the model... (13500/50000)
2025-12-13 13:30:00,264 INFO     Evaluating the model... (14000/50000)
2025-12-13 13:30:04,851 INFO     Evaluating the model... (14500/50000)
2025-12-13 13:30:09,341 INFO     Evaluating the model... (15000/50000)
2025-12-13 13:30:13,840 INFO     Evaluating the model... (15500/50000)
2025-12-13 13:30:18,363 INFO     Evaluating the model... (16000/50000)
2025-12-13 13:30:23,995 INFO     Evaluating the model... (16500/50000)
2025-12-13 13:30:28,369 INFO     Evaluating the model... (17000/50000)
2025-12-13 13:30:32,734 INFO     Evaluating the model... (17500/50000)
2025-12-13 13:30:37,306 INFO     Evaluating the model... (18000/50000)
2025-12-13 13:30:42,612 INFO     Evaluating the model... (18500/50000)
2025-12-13 13:30:47,705 INFO     Evaluating the model... (19000/50000)
2025-12-13 13:30:52,400 INFO     Evaluating the model... (19500/50000)
2025-12-13 13:30:57,106 INFO     Evaluating the model... (20000/50000)
2025-12-13 13:31:01,854 INFO     Evaluating the model... (20500/50000)
2025-12-13 13:31:08,220 INFO     Evaluating the model... (21000/50000)
2025-12-13 13:31:12,901 INFO     Evaluating the model... (21500/50000)
2025-12-13 13:31:17,372 INFO     Evaluating the model... (22000/50000)
2025-12-13 13:31:21,962 INFO     Evaluating the model... (22500/50000)
2025-12-13 13:31:26,433 INFO     Evaluating the model... (23000/50000)
2025-12-13 13:31:32,344 INFO     Evaluating the model... (23500/50000)
2025-12-13 13:31:37,032 INFO     Evaluating the model... (24000/50000)
2025-12-13 13:31:41,949 INFO     Evaluating the model... (24500/50000)
2025-12-13 13:31:47,133 INFO     Evaluating the model... (25000/50000)
2025-12-13 13:31:51,716 INFO     Evaluating the model... (25500/50000)
2025-12-13 13:31:57,401 INFO     Evaluating the model... (26000/50000)
2025-12-13 13:32:02,333 INFO     Evaluating the model... (26500/50000)
2025-12-13 13:32:07,278 INFO     Evaluating the model... (27000/50000)
2025-12-13 13:32:12,050 INFO     Evaluating the model... (27500/50000)
2025-12-13 13:32:16,663 INFO     Evaluating the model... (28000/50000)
2025-12-13 13:32:21,847 INFO     Evaluating the model... (28500/50000)
2025-12-13 13:32:26,375 INFO     Evaluating the model... (29000/50000)
2025-12-13 13:32:31,073 INFO     Evaluating the model... (29500/50000)
2025-12-13 13:32:35,825 INFO     Evaluating the model... (30000/50000)
2025-12-13 13:32:40,269 INFO     Evaluating the model... (30500/50000)
2025-12-13 13:32:45,636 INFO     Evaluating the model... (31000/50000)
2025-12-13 13:32:50,209 INFO     Evaluating the model... (31500/50000)
2025-12-13 13:32:54,647 INFO     Evaluating the model... (32000/50000)
2025-12-13 13:32:59,333 INFO     Evaluating the model... (32500/50000)
2025-12-13 13:33:04,184 INFO     Evaluating the model... (33000/50000)
2025-12-13 13:33:09,368 INFO     Evaluating the model... (33500/50000)
2025-12-13 13:33:13,798 INFO     Evaluating the model... (34000/50000)
2025-12-13 13:33:18,544 INFO     Evaluating the model... (34500/50000)
2025-12-13 13:33:23,138 INFO     Evaluating the model... (35000/50000)
2025-12-13 13:33:27,859 INFO     Evaluating the model... (35500/50000)
2025-12-13 13:33:33,396 INFO     Evaluating the model... (36000/50000)
2025-12-13 13:33:38,080 INFO     Evaluating the model... (36500/50000)
2025-12-13 13:33:42,828 INFO     Evaluating the model... (37000/50000)
2025-12-13 13:33:47,322 INFO     Evaluating the model... (37500/50000)
2025-12-13 13:33:51,978 INFO     Evaluating the model... (38000/50000)
2025-12-13 13:33:57,543 INFO     Evaluating the model... (38500/50000)
2025-12-13 13:34:02,227 INFO     Evaluating the model... (39000/50000)
2025-12-13 13:34:06,757 INFO     Evaluating the model... (39500/50000)
2025-12-13 13:34:11,359 INFO     Evaluating the model... (40000/50000)
2025-12-13 13:34:15,804 INFO     Evaluating the model... (40500/50000)
2025-12-13 13:34:21,617 INFO     Evaluating the model... (41000/50000)
2025-12-13 13:34:26,401 INFO     Evaluating the model... (41500/50000)
2025-12-13 13:34:31,209 INFO     Evaluating the model... (42000/50000)
2025-12-13 13:34:35,861 INFO     Evaluating the model... (42500/50000)
2025-12-13 13:34:40,523 INFO     Evaluating the model... (43000/50000)
2025-12-13 13:34:46,273 INFO     Evaluating the model... (43500/50000)
2025-12-13 13:34:50,891 INFO     Evaluating the model... (44000/50000)
2025-12-13 13:34:55,625 INFO     Evaluating the model... (44500/50000)
2025-12-13 13:35:00,105 INFO     Evaluating the model... (45000/50000)
2025-12-13 13:35:04,844 INFO     Evaluating the model... (45500/50000)
2025-12-13 13:35:10,452 INFO     Evaluating the model... (46000/50000)
2025-12-13 13:35:14,861 INFO     Evaluating the model... (46500/50000)
2025-12-13 13:35:19,433 INFO     Evaluating the model... (47000/50000)
2025-12-13 13:35:23,653 INFO     Evaluating the model... (47500/50000)
2025-12-13 13:35:29,228 INFO     Evaluating the model... (48000/50000)
2025-12-13 13:35:33,837 INFO     Evaluating the model... (48500/50000)
2025-12-13 13:35:38,261 INFO     Evaluating the model... (49000/50000)
2025-12-13 13:35:42,625 INFO     Evaluating the model... (49500/50000)
2025-12-13 13:35:47,356 INFO     Valid MRR at step 60000: 0.726854
2025-12-13 13:35:47,356 INFO     Valid MR at step 60000: 260.305010
2025-12-13 13:35:47,356 INFO     Valid HITS@1 at step 60000: 0.661790
2025-12-13 13:35:47,356 INFO     Valid HITS@3 at step 60000: 0.772330
2025-12-13 13:35:47,356 INFO     Valid HITS@10 at step 60000: 0.839350
2025-12-13 13:35:48,781 INFO     Evaluating on Test Dataset...
2025-12-13 13:35:49,379 INFO     Evaluating the model... (0/59072)
2025-12-13 13:35:54,282 INFO     Evaluating the model... (500/59072)
2025-12-13 13:36:00,164 INFO     Evaluating the model... (1000/59072)
2025-12-13 13:36:04,984 INFO     Evaluating the model... (1500/59072)
2025-12-13 13:36:09,598 INFO     Evaluating the model... (2000/59072)
2025-12-13 13:36:14,401 INFO     Evaluating the model... (2500/59072)
2025-12-13 13:36:19,859 INFO     Evaluating the model... (3000/59072)
2025-12-13 13:36:24,479 INFO     Evaluating the model... (3500/59072)
2025-12-13 13:36:29,034 INFO     Evaluating the model... (4000/59072)
2025-12-13 13:36:33,853 INFO     Evaluating the model... (4500/59072)
2025-12-13 13:36:38,364 INFO     Evaluating the model... (5000/59072)
2025-12-13 13:36:44,074 INFO     Evaluating the model... (5500/59072)
2025-12-13 13:36:48,875 INFO     Evaluating the model... (6000/59072)
2025-12-13 13:36:53,526 INFO     Evaluating the model... (6500/59072)
2025-12-13 13:36:58,090 INFO     Evaluating the model... (7000/59072)
2025-12-13 13:37:02,862 INFO     Evaluating the model... (7500/59072)
2025-12-13 13:37:08,665 INFO     Evaluating the model... (8000/59072)
2025-12-13 13:37:13,529 INFO     Evaluating the model... (8500/59072)
2025-12-13 13:37:18,000 INFO     Evaluating the model... (9000/59072)
2025-12-13 13:37:22,562 INFO     Evaluating the model... (9500/59072)
2025-12-13 13:37:27,347 INFO     Evaluating the model... (10000/59072)
2025-12-13 13:37:32,531 INFO     Evaluating the model... (10500/59072)
2025-12-13 13:37:37,120 INFO     Evaluating the model... (11000/59072)
2025-12-13 13:37:42,014 INFO     Evaluating the model... (11500/59072)
2025-12-13 13:37:46,968 INFO     Evaluating the model... (12000/59072)
2025-12-13 13:37:51,587 INFO     Evaluating the model... (12500/59072)
2025-12-13 13:37:56,581 INFO     Evaluating the model... (13000/59072)
2025-12-13 13:38:01,095 INFO     Evaluating the model... (13500/59072)
2025-12-13 13:38:05,842 INFO     Evaluating the model... (14000/59072)
2025-12-13 13:38:10,325 INFO     Evaluating the model... (14500/59072)
2025-12-13 13:38:14,645 INFO     Evaluating the model... (15000/59072)
2025-12-13 13:38:20,152 INFO     Evaluating the model... (15500/59072)
2025-12-13 13:38:24,535 INFO     Evaluating the model... (16000/59072)
2025-12-13 13:38:28,871 INFO     Evaluating the model... (16500/59072)
2025-12-13 13:38:33,317 INFO     Evaluating the model... (17000/59072)
2025-12-13 13:38:37,661 INFO     Evaluating the model... (17500/59072)
2025-12-13 13:38:43,042 INFO     Evaluating the model... (18000/59072)
2025-12-13 13:38:47,669 INFO     Evaluating the model... (18500/59072)
2025-12-13 13:38:52,390 INFO     Evaluating the model... (19000/59072)
2025-12-13 13:38:57,247 INFO     Evaluating the model... (19500/59072)
2025-12-13 13:39:02,201 INFO     Evaluating the model... (20000/59072)
2025-12-13 13:39:08,252 INFO     Evaluating the model... (20500/59072)
2025-12-13 13:39:12,893 INFO     Evaluating the model... (21000/59072)
2025-12-13 13:39:17,461 INFO     Evaluating the model... (21500/59072)
2025-12-13 13:39:22,050 INFO     Evaluating the model... (22000/59072)
2025-12-13 13:39:27,088 INFO     Evaluating the model... (22500/59072)
2025-12-13 13:39:32,939 INFO     Evaluating the model... (23000/59072)
2025-12-13 13:39:37,300 INFO     Evaluating the model... (23500/59072)
2025-12-13 13:39:42,028 INFO     Evaluating the model... (24000/59072)
2025-12-13 13:39:46,471 INFO     Evaluating the model... (24500/59072)
2025-12-13 13:39:52,840 INFO     Evaluating the model... (25000/59072)
2025-12-13 13:39:57,408 INFO     Evaluating the model... (25500/59072)
2025-12-13 13:40:02,012 INFO     Evaluating the model... (26000/59072)
2025-12-13 13:40:06,550 INFO     Evaluating the model... (26500/59072)
2025-12-13 13:40:11,046 INFO     Evaluating the model... (27000/59072)
2025-12-13 13:40:17,338 INFO     Evaluating the model... (27500/59072)
2025-12-13 13:40:21,887 INFO     Evaluating the model... (28000/59072)
2025-12-13 13:40:26,595 INFO     Evaluating the model... (28500/59072)
2025-12-13 13:40:31,188 INFO     Evaluating the model... (29000/59072)
2025-12-13 13:40:35,711 INFO     Evaluating the model... (29500/59072)
2025-12-13 13:40:41,292 INFO     Evaluating the model... (30000/59072)
2025-12-13 13:40:45,856 INFO     Evaluating the model... (30500/59072)
2025-12-13 13:40:50,201 INFO     Evaluating the model... (31000/59072)
2025-12-13 13:40:54,699 INFO     Evaluating the model... (31500/59072)
2025-12-13 13:40:59,096 INFO     Evaluating the model... (32000/59072)
2025-12-13 13:41:04,159 INFO     Evaluating the model... (32500/59072)
2025-12-13 13:41:08,472 INFO     Evaluating the model... (33000/59072)
2025-12-13 13:41:12,857 INFO     Evaluating the model... (33500/59072)
2025-12-13 13:41:17,399 INFO     Evaluating the model... (34000/59072)
2025-12-13 13:41:22,659 INFO     Evaluating the model... (34500/59072)
2025-12-13 13:41:27,166 INFO     Evaluating the model... (35000/59072)
2025-12-13 13:41:31,328 INFO     Evaluating the model... (35500/59072)
2025-12-13 13:41:35,649 INFO     Evaluating the model... (36000/59072)
2025-12-13 13:41:39,822 INFO     Evaluating the model... (36500/59072)
2025-12-13 13:41:44,856 INFO     Evaluating the model... (37000/59072)
2025-12-13 13:41:48,940 INFO     Evaluating the model... (37500/59072)
2025-12-13 13:41:53,409 INFO     Evaluating the model... (38000/59072)
2025-12-13 13:41:57,779 INFO     Evaluating the model... (38500/59072)
2025-12-13 13:42:02,077 INFO     Evaluating the model... (39000/59072)
2025-12-13 13:42:06,910 INFO     Evaluating the model... (39500/59072)
2025-12-13 13:42:11,445 INFO     Evaluating the model... (40000/59072)
2025-12-13 13:42:15,933 INFO     Evaluating the model... (40500/59072)
2025-12-13 13:42:20,167 INFO     Evaluating the model... (41000/59072)
2025-12-13 13:42:24,283 INFO     Evaluating the model... (41500/59072)
2025-12-13 13:42:28,951 INFO     Evaluating the model... (42000/59072)
2025-12-13 13:42:33,041 INFO     Evaluating the model... (42500/59072)
2025-12-13 13:42:37,114 INFO     Evaluating the model... (43000/59072)
2025-12-13 13:42:41,201 INFO     Evaluating the model... (43500/59072)
2025-12-13 13:42:45,250 INFO     Evaluating the model... (44000/59072)
2025-12-13 13:42:50,353 INFO     Evaluating the model... (44500/59072)
2025-12-13 13:42:54,526 INFO     Evaluating the model... (45000/59072)
2025-12-13 13:42:58,780 INFO     Evaluating the model... (45500/59072)
2025-12-13 13:43:03,081 INFO     Evaluating the model... (46000/59072)
2025-12-13 13:43:07,320 INFO     Evaluating the model... (46500/59072)
2025-12-13 13:43:12,316 INFO     Evaluating the model... (47000/59072)
2025-12-13 13:43:16,538 INFO     Evaluating the model... (47500/59072)
2025-12-13 13:43:20,785 INFO     Evaluating the model... (48000/59072)
2025-12-13 13:43:25,131 INFO     Evaluating the model... (48500/59072)
2025-12-13 13:43:29,335 INFO     Evaluating the model... (49000/59072)
2025-12-13 13:43:33,935 INFO     Evaluating the model... (49500/59072)
2025-12-13 13:43:37,944 INFO     Evaluating the model... (50000/59072)
2025-12-13 13:43:42,253 INFO     Evaluating the model... (50500/59072)
2025-12-13 13:43:46,602 INFO     Evaluating the model... (51000/59072)
2025-12-13 13:43:50,705 INFO     Evaluating the model... (51500/59072)
2025-12-13 13:43:55,648 INFO     Evaluating the model... (52000/59072)
2025-12-13 13:44:00,172 INFO     Evaluating the model... (52500/59072)
2025-12-13 13:44:04,518 INFO     Evaluating the model... (53000/59072)
2025-12-13 13:44:08,664 INFO     Evaluating the model... (53500/59072)
2025-12-13 13:44:13,031 INFO     Evaluating the model... (54000/59072)
2025-12-13 13:44:17,689 INFO     Evaluating the model... (54500/59072)
2025-12-13 13:44:22,184 INFO     Evaluating the model... (55000/59072)
2025-12-13 13:44:26,772 INFO     Evaluating the model... (55500/59072)
2025-12-13 13:44:31,150 INFO     Evaluating the model... (56000/59072)
2025-12-13 13:44:36,239 INFO     Evaluating the model... (56500/59072)
2025-12-13 13:44:40,778 INFO     Evaluating the model... (57000/59072)
2025-12-13 13:44:44,947 INFO     Evaluating the model... (57500/59072)
2025-12-13 13:44:49,493 INFO     Evaluating the model... (58000/59072)
2025-12-13 13:44:54,144 INFO     Evaluating the model... (58500/59072)
2025-12-13 13:44:59,272 INFO     Evaluating the model... (59000/59072)
2025-12-13 13:45:00,171 INFO     Test MRR at step 60000: 0.721540
2025-12-13 13:45:00,171 INFO     Test MR at step 60000: 263.688883
2025-12-13 13:45:00,171 INFO     Test HITS@1 at step 60000: 0.655618
2025-12-13 13:45:00,171 INFO     Test HITS@3 at step 60000: 0.766281
2025-12-13 13:45:00,171 INFO     Test HITS@10 at step 60000: 0.836104
2025-12-13 13:45:05,515 INFO     Training average regularization at step 60100: 0.174873
2025-12-13 13:45:05,515 INFO     Training average positive_sample_loss at step 60100: 0.008701
2025-12-13 13:45:05,515 INFO     Training average negative_sample_loss at step 60100: 0.025731
2025-12-13 13:45:05,516 INFO     Training average loss at step 60100: 0.192089
2025-12-13 13:45:10,908 INFO     Training average regularization at step 60200: 0.174821
2025-12-13 13:45:10,908 INFO     Training average positive_sample_loss at step 60200: 0.009192
2025-12-13 13:45:10,908 INFO     Training average negative_sample_loss at step 60200: 0.024503
2025-12-13 13:45:10,908 INFO     Training average loss at step 60200: 0.191669
2025-12-13 13:45:16,284 INFO     Training average regularization at step 60300: 0.174771
2025-12-13 13:45:16,284 INFO     Training average positive_sample_loss at step 60300: 0.010135
2025-12-13 13:45:16,284 INFO     Training average negative_sample_loss at step 60300: 0.020395
2025-12-13 13:45:16,284 INFO     Training average loss at step 60300: 0.190035
2025-12-13 13:45:21,565 INFO     Training average regularization at step 60400: 0.174720
2025-12-13 13:45:21,565 INFO     Training average positive_sample_loss at step 60400: 0.009464
2025-12-13 13:45:21,565 INFO     Training average negative_sample_loss at step 60400: 0.020139
2025-12-13 13:45:21,565 INFO     Training average loss at step 60400: 0.189521
2025-12-13 13:45:26,769 INFO     Training average regularization at step 60500: 0.174669
2025-12-13 13:45:26,770 INFO     Training average positive_sample_loss at step 60500: 0.009377
2025-12-13 13:45:26,770 INFO     Training average negative_sample_loss at step 60500: 0.021306
2025-12-13 13:45:26,770 INFO     Training average loss at step 60500: 0.190011
2025-12-13 13:45:32,064 INFO     Training average regularization at step 60600: 0.174618
2025-12-13 13:45:32,064 INFO     Training average positive_sample_loss at step 60600: 0.008940
2025-12-13 13:45:32,064 INFO     Training average negative_sample_loss at step 60600: 0.022544
2025-12-13 13:45:32,064 INFO     Training average loss at step 60600: 0.190361
2025-12-13 13:45:37,241 INFO     Training average regularization at step 60700: 0.174567
2025-12-13 13:45:37,241 INFO     Training average positive_sample_loss at step 60700: 0.009244
2025-12-13 13:45:37,241 INFO     Training average negative_sample_loss at step 60700: 0.020018
2025-12-13 13:45:37,241 INFO     Training average loss at step 60700: 0.189198
2025-12-13 13:45:42,573 INFO     Training average regularization at step 60800: 0.174516
2025-12-13 13:45:42,573 INFO     Training average positive_sample_loss at step 60800: 0.008474
2025-12-13 13:45:42,573 INFO     Training average negative_sample_loss at step 60800: 0.027636
2025-12-13 13:45:42,573 INFO     Training average loss at step 60800: 0.192572
2025-12-13 13:45:47,888 INFO     Training average regularization at step 60900: 0.174467
2025-12-13 13:45:47,888 INFO     Training average positive_sample_loss at step 60900: 0.010216
2025-12-13 13:45:47,888 INFO     Training average negative_sample_loss at step 60900: 0.024298
2025-12-13 13:45:47,888 INFO     Training average loss at step 60900: 0.191724
2025-12-13 13:45:53,152 INFO     Training average regularization at step 61000: 0.174419
2025-12-13 13:45:53,152 INFO     Training average positive_sample_loss at step 61000: 0.009348
2025-12-13 13:45:53,152 INFO     Training average negative_sample_loss at step 61000: 0.019075
2025-12-13 13:45:53,152 INFO     Training average loss at step 61000: 0.188630
2025-12-13 13:45:58,396 INFO     Training average regularization at step 61100: 0.174370
2025-12-13 13:45:58,396 INFO     Training average positive_sample_loss at step 61100: 0.008637
2025-12-13 13:45:58,396 INFO     Training average negative_sample_loss at step 61100: 0.025324
2025-12-13 13:45:58,396 INFO     Training average loss at step 61100: 0.191351
2025-12-13 13:46:03,537 INFO     Training average regularization at step 61200: 0.174322
2025-12-13 13:46:03,538 INFO     Training average positive_sample_loss at step 61200: 0.009440
2025-12-13 13:46:03,538 INFO     Training average negative_sample_loss at step 61200: 0.022968
2025-12-13 13:46:03,538 INFO     Training average loss at step 61200: 0.190526
2025-12-13 13:46:08,847 INFO     Training average regularization at step 61300: 0.174274
2025-12-13 13:46:08,848 INFO     Training average positive_sample_loss at step 61300: 0.009170
2025-12-13 13:46:08,848 INFO     Training average negative_sample_loss at step 61300: 0.022346
2025-12-13 13:46:08,848 INFO     Training average loss at step 61300: 0.190032
2025-12-13 13:46:14,126 INFO     Training average regularization at step 61400: 0.174226
2025-12-13 13:46:14,126 INFO     Training average positive_sample_loss at step 61400: 0.010752
2025-12-13 13:46:14,126 INFO     Training average negative_sample_loss at step 61400: 0.023763
2025-12-13 13:46:14,126 INFO     Training average loss at step 61400: 0.191483
2025-12-13 13:46:19,411 INFO     Training average regularization at step 61500: 0.174179
2025-12-13 13:46:19,411 INFO     Training average positive_sample_loss at step 61500: 0.009434
2025-12-13 13:46:19,411 INFO     Training average negative_sample_loss at step 61500: 0.021083
2025-12-13 13:46:19,411 INFO     Training average loss at step 61500: 0.189437
2025-12-13 13:46:24,675 INFO     Training average regularization at step 61600: 0.174131
2025-12-13 13:46:24,675 INFO     Training average positive_sample_loss at step 61600: 0.009312
2025-12-13 13:46:24,675 INFO     Training average negative_sample_loss at step 61600: 0.026040
2025-12-13 13:46:24,675 INFO     Training average loss at step 61600: 0.191807
2025-12-13 13:46:29,971 INFO     Training average regularization at step 61700: 0.174085
2025-12-13 13:46:29,971 INFO     Training average positive_sample_loss at step 61700: 0.010068
2025-12-13 13:46:29,971 INFO     Training average negative_sample_loss at step 61700: 0.021277
2025-12-13 13:46:29,971 INFO     Training average loss at step 61700: 0.189757
2025-12-13 13:46:35,192 INFO     Training average regularization at step 61800: 0.174038
2025-12-13 13:46:35,192 INFO     Training average positive_sample_loss at step 61800: 0.009385
2025-12-13 13:46:35,192 INFO     Training average negative_sample_loss at step 61800: 0.025378
2025-12-13 13:46:35,192 INFO     Training average loss at step 61800: 0.191420
2025-12-13 13:46:40,451 INFO     Training average regularization at step 61900: 0.173992
2025-12-13 13:46:40,451 INFO     Training average positive_sample_loss at step 61900: 0.010478
2025-12-13 13:46:40,452 INFO     Training average negative_sample_loss at step 61900: 0.022279
2025-12-13 13:46:40,452 INFO     Training average loss at step 61900: 0.190371
2025-12-13 13:46:45,596 INFO     Training average regularization at step 62000: 0.173947
2025-12-13 13:46:45,596 INFO     Training average positive_sample_loss at step 62000: 0.009555
2025-12-13 13:46:45,596 INFO     Training average negative_sample_loss at step 62000: 0.017694
2025-12-13 13:46:45,596 INFO     Training average loss at step 62000: 0.187572
2025-12-13 13:46:50,899 INFO     Training average regularization at step 62100: 0.173901
2025-12-13 13:46:50,899 INFO     Training average positive_sample_loss at step 62100: 0.008740
2025-12-13 13:46:50,899 INFO     Training average negative_sample_loss at step 62100: 0.023281
2025-12-13 13:46:50,899 INFO     Training average loss at step 62100: 0.189911
2025-12-13 13:46:56,151 INFO     Training average regularization at step 62200: 0.173855
2025-12-13 13:46:56,151 INFO     Training average positive_sample_loss at step 62200: 0.010084
2025-12-13 13:46:56,151 INFO     Training average negative_sample_loss at step 62200: 0.022432
2025-12-13 13:46:56,151 INFO     Training average loss at step 62200: 0.190113
2025-12-13 13:47:01,383 INFO     Training average regularization at step 62300: 0.173809
2025-12-13 13:47:01,384 INFO     Training average positive_sample_loss at step 62300: 0.009378
2025-12-13 13:47:01,384 INFO     Training average negative_sample_loss at step 62300: 0.026591
2025-12-13 13:47:01,384 INFO     Training average loss at step 62300: 0.191793
2025-12-13 13:47:06,622 INFO     Training average regularization at step 62400: 0.173763
2025-12-13 13:47:06,623 INFO     Training average positive_sample_loss at step 62400: 0.009653
2025-12-13 13:47:06,623 INFO     Training average negative_sample_loss at step 62400: 0.023191
2025-12-13 13:47:06,623 INFO     Training average loss at step 62400: 0.190185
2025-12-13 13:47:12,015 INFO     Training average regularization at step 62500: 0.173718
2025-12-13 13:47:12,016 INFO     Training average positive_sample_loss at step 62500: 0.008916
2025-12-13 13:47:12,016 INFO     Training average negative_sample_loss at step 62500: 0.022560
2025-12-13 13:47:12,016 INFO     Training average loss at step 62500: 0.189456
2025-12-13 13:47:17,236 INFO     Training average regularization at step 62600: 0.173671
2025-12-13 13:47:17,236 INFO     Training average positive_sample_loss at step 62600: 0.010659
2025-12-13 13:47:17,236 INFO     Training average negative_sample_loss at step 62600: 0.022162
2025-12-13 13:47:17,236 INFO     Training average loss at step 62600: 0.190082
2025-12-13 13:47:22,440 INFO     Training average regularization at step 62700: 0.173625
2025-12-13 13:47:22,440 INFO     Training average positive_sample_loss at step 62700: 0.009550
2025-12-13 13:47:22,440 INFO     Training average negative_sample_loss at step 62700: 0.023029
2025-12-13 13:47:22,440 INFO     Training average loss at step 62700: 0.189915
2025-12-13 13:47:27,701 INFO     Training average regularization at step 62800: 0.173580
2025-12-13 13:47:27,701 INFO     Training average positive_sample_loss at step 62800: 0.008509
2025-12-13 13:47:27,701 INFO     Training average negative_sample_loss at step 62800: 0.022314
2025-12-13 13:47:27,701 INFO     Training average loss at step 62800: 0.188991
2025-12-13 13:47:33,777 INFO     Training average regularization at step 62900: 0.173532
2025-12-13 13:47:33,777 INFO     Training average positive_sample_loss at step 62900: 0.009183
2025-12-13 13:47:33,777 INFO     Training average negative_sample_loss at step 62900: 0.029196
2025-12-13 13:47:33,777 INFO     Training average loss at step 62900: 0.192722
2025-12-13 13:47:38,685 INFO     Training average regularization at step 63000: 0.173481
2025-12-13 13:47:38,685 INFO     Training average positive_sample_loss at step 63000: 0.009061
2025-12-13 13:47:38,685 INFO     Training average negative_sample_loss at step 63000: 0.020715
2025-12-13 13:47:38,685 INFO     Training average loss at step 63000: 0.188369
2025-12-13 13:47:43,885 INFO     Training average regularization at step 63100: 0.173432
2025-12-13 13:47:43,885 INFO     Training average positive_sample_loss at step 63100: 0.007640
2025-12-13 13:47:43,885 INFO     Training average negative_sample_loss at step 63100: 0.016902
2025-12-13 13:47:43,885 INFO     Training average loss at step 63100: 0.185703
2025-12-13 13:47:49,201 INFO     Training average regularization at step 63200: 0.173382
2025-12-13 13:47:49,201 INFO     Training average positive_sample_loss at step 63200: 0.008213
2025-12-13 13:47:49,201 INFO     Training average negative_sample_loss at step 63200: 0.023125
2025-12-13 13:47:49,201 INFO     Training average loss at step 63200: 0.189050
2025-12-13 13:47:54,543 INFO     Training average regularization at step 63300: 0.173331
2025-12-13 13:47:54,543 INFO     Training average positive_sample_loss at step 63300: 0.008458
2025-12-13 13:47:54,543 INFO     Training average negative_sample_loss at step 63300: 0.021397
2025-12-13 13:47:54,543 INFO     Training average loss at step 63300: 0.188259
2025-12-13 13:47:59,768 INFO     Training average regularization at step 63400: 0.173281
2025-12-13 13:47:59,768 INFO     Training average positive_sample_loss at step 63400: 0.008234
2025-12-13 13:47:59,768 INFO     Training average negative_sample_loss at step 63400: 0.022567
2025-12-13 13:47:59,768 INFO     Training average loss at step 63400: 0.188681
2025-12-13 13:48:05,069 INFO     Training average regularization at step 63500: 0.173231
2025-12-13 13:48:05,069 INFO     Training average positive_sample_loss at step 63500: 0.008084
2025-12-13 13:48:05,069 INFO     Training average negative_sample_loss at step 63500: 0.020698
2025-12-13 13:48:05,069 INFO     Training average loss at step 63500: 0.187622
2025-12-13 13:48:10,346 INFO     Training average regularization at step 63600: 0.173181
2025-12-13 13:48:10,347 INFO     Training average positive_sample_loss at step 63600: 0.007850
2025-12-13 13:48:10,347 INFO     Training average negative_sample_loss at step 63600: 0.018021
2025-12-13 13:48:10,347 INFO     Training average loss at step 63600: 0.186117
2025-12-13 13:48:15,511 INFO     Training average regularization at step 63700: 0.173132
2025-12-13 13:48:15,511 INFO     Training average positive_sample_loss at step 63700: 0.008212
2025-12-13 13:48:15,511 INFO     Training average negative_sample_loss at step 63700: 0.021149
2025-12-13 13:48:15,511 INFO     Training average loss at step 63700: 0.187812
2025-12-13 13:48:20,792 INFO     Training average regularization at step 63800: 0.173082
2025-12-13 13:48:20,792 INFO     Training average positive_sample_loss at step 63800: 0.008294
2025-12-13 13:48:20,792 INFO     Training average negative_sample_loss at step 63800: 0.024145
2025-12-13 13:48:20,792 INFO     Training average loss at step 63800: 0.189302
2025-12-13 13:48:25,975 INFO     Training average regularization at step 63900: 0.173032
2025-12-13 13:48:25,975 INFO     Training average positive_sample_loss at step 63900: 0.008875
2025-12-13 13:48:25,975 INFO     Training average negative_sample_loss at step 63900: 0.024669
2025-12-13 13:48:25,975 INFO     Training average loss at step 63900: 0.189804
2025-12-13 13:48:31,185 INFO     Training average regularization at step 64000: 0.172984
2025-12-13 13:48:31,185 INFO     Training average positive_sample_loss at step 64000: 0.009031
2025-12-13 13:48:31,185 INFO     Training average negative_sample_loss at step 64000: 0.021549
2025-12-13 13:48:31,185 INFO     Training average loss at step 64000: 0.188274
2025-12-13 13:48:36,396 INFO     Training average regularization at step 64100: 0.172936
2025-12-13 13:48:36,396 INFO     Training average positive_sample_loss at step 64100: 0.009185
2025-12-13 13:48:36,397 INFO     Training average negative_sample_loss at step 64100: 0.023342
2025-12-13 13:48:36,397 INFO     Training average loss at step 64100: 0.189200
2025-12-13 13:48:41,702 INFO     Training average regularization at step 64200: 0.172888
2025-12-13 13:48:41,703 INFO     Training average positive_sample_loss at step 64200: 0.008470
2025-12-13 13:48:41,703 INFO     Training average negative_sample_loss at step 64200: 0.020109
2025-12-13 13:48:41,703 INFO     Training average loss at step 64200: 0.187178
2025-12-13 13:48:47,073 INFO     Training average regularization at step 64300: 0.172839
2025-12-13 13:48:47,073 INFO     Training average positive_sample_loss at step 64300: 0.008936
2025-12-13 13:48:47,073 INFO     Training average negative_sample_loss at step 64300: 0.021678
2025-12-13 13:48:47,073 INFO     Training average loss at step 64300: 0.188146
2025-12-13 13:48:52,410 INFO     Training average regularization at step 64400: 0.172791
2025-12-13 13:48:52,411 INFO     Training average positive_sample_loss at step 64400: 0.008163
2025-12-13 13:48:52,411 INFO     Training average negative_sample_loss at step 64400: 0.021359
2025-12-13 13:48:52,411 INFO     Training average loss at step 64400: 0.187552
2025-12-13 13:48:57,689 INFO     Training average regularization at step 64500: 0.172743
2025-12-13 13:48:57,690 INFO     Training average positive_sample_loss at step 64500: 0.008633
2025-12-13 13:48:57,690 INFO     Training average negative_sample_loss at step 64500: 0.017450
2025-12-13 13:48:57,690 INFO     Training average loss at step 64500: 0.185784
2025-12-13 13:49:02,989 INFO     Training average regularization at step 64600: 0.172694
2025-12-13 13:49:02,989 INFO     Training average positive_sample_loss at step 64600: 0.008539
2025-12-13 13:49:02,989 INFO     Training average negative_sample_loss at step 64600: 0.021007
2025-12-13 13:49:02,989 INFO     Training average loss at step 64600: 0.187467
2025-12-13 13:49:08,291 INFO     Training average regularization at step 64700: 0.172645
2025-12-13 13:49:08,291 INFO     Training average positive_sample_loss at step 64700: 0.009853
2025-12-13 13:49:08,291 INFO     Training average negative_sample_loss at step 64700: 0.021389
2025-12-13 13:49:08,291 INFO     Training average loss at step 64700: 0.188266
2025-12-13 13:49:13,523 INFO     Training average regularization at step 64800: 0.172595
2025-12-13 13:49:13,523 INFO     Training average positive_sample_loss at step 64800: 0.008398
2025-12-13 13:49:13,523 INFO     Training average negative_sample_loss at step 64800: 0.024501
2025-12-13 13:49:13,523 INFO     Training average loss at step 64800: 0.189045
2025-12-13 13:49:18,758 INFO     Training average regularization at step 64900: 0.172547
2025-12-13 13:49:18,758 INFO     Training average positive_sample_loss at step 64900: 0.009177
2025-12-13 13:49:18,758 INFO     Training average negative_sample_loss at step 64900: 0.025255
2025-12-13 13:49:18,758 INFO     Training average loss at step 64900: 0.189763
2025-12-13 13:49:23,992 INFO     Training average regularization at step 65000: 0.172498
2025-12-13 13:49:23,992 INFO     Training average positive_sample_loss at step 65000: 0.008648
2025-12-13 13:49:23,992 INFO     Training average negative_sample_loss at step 65000: 0.024004
2025-12-13 13:49:23,993 INFO     Training average loss at step 65000: 0.188824
2025-12-13 13:49:29,189 INFO     Training average regularization at step 65100: 0.172450
2025-12-13 13:49:29,189 INFO     Training average positive_sample_loss at step 65100: 0.008621
2025-12-13 13:49:29,189 INFO     Training average negative_sample_loss at step 65100: 0.024653
2025-12-13 13:49:29,189 INFO     Training average loss at step 65100: 0.189087
2025-12-13 13:49:34,406 INFO     Training average regularization at step 65200: 0.172402
2025-12-13 13:49:34,406 INFO     Training average positive_sample_loss at step 65200: 0.008865
2025-12-13 13:49:34,406 INFO     Training average negative_sample_loss at step 65200: 0.023851
2025-12-13 13:49:34,406 INFO     Training average loss at step 65200: 0.188760
2025-12-13 13:49:39,612 INFO     Training average regularization at step 65300: 0.172355
2025-12-13 13:49:39,613 INFO     Training average positive_sample_loss at step 65300: 0.008348
2025-12-13 13:49:39,613 INFO     Training average negative_sample_loss at step 65300: 0.024865
2025-12-13 13:49:39,613 INFO     Training average loss at step 65300: 0.188961
2025-12-13 13:49:44,566 INFO     Training average regularization at step 65400: 0.172307
2025-12-13 13:49:44,566 INFO     Training average positive_sample_loss at step 65400: 0.008560
2025-12-13 13:49:44,566 INFO     Training average negative_sample_loss at step 65400: 0.021261
2025-12-13 13:49:44,566 INFO     Training average loss at step 65400: 0.187217
2025-12-13 13:49:49,784 INFO     Training average regularization at step 65500: 0.172260
2025-12-13 13:49:49,784 INFO     Training average positive_sample_loss at step 65500: 0.009147
2025-12-13 13:49:49,784 INFO     Training average negative_sample_loss at step 65500: 0.024172
2025-12-13 13:49:49,784 INFO     Training average loss at step 65500: 0.188919
2025-12-13 13:49:54,966 INFO     Training average regularization at step 65600: 0.172212
2025-12-13 13:49:54,966 INFO     Training average positive_sample_loss at step 65600: 0.008726
2025-12-13 13:49:54,966 INFO     Training average negative_sample_loss at step 65600: 0.019447
2025-12-13 13:49:54,966 INFO     Training average loss at step 65600: 0.186299
2025-12-13 13:50:00,240 INFO     Training average regularization at step 65700: 0.172166
2025-12-13 13:50:00,241 INFO     Training average positive_sample_loss at step 65700: 0.009122
2025-12-13 13:50:00,241 INFO     Training average negative_sample_loss at step 65700: 0.021355
2025-12-13 13:50:00,241 INFO     Training average loss at step 65700: 0.187404
2025-12-13 13:50:05,474 INFO     Training average regularization at step 65800: 0.172117
2025-12-13 13:50:05,474 INFO     Training average positive_sample_loss at step 65800: 0.008184
2025-12-13 13:50:05,474 INFO     Training average negative_sample_loss at step 65800: 0.020359
2025-12-13 13:50:05,474 INFO     Training average loss at step 65800: 0.186389
2025-12-13 13:50:10,795 INFO     Training average regularization at step 65900: 0.172070
2025-12-13 13:50:10,796 INFO     Training average positive_sample_loss at step 65900: 0.008524
2025-12-13 13:50:10,796 INFO     Training average negative_sample_loss at step 65900: 0.017733
2025-12-13 13:50:10,796 INFO     Training average loss at step 65900: 0.185199
2025-12-13 13:50:15,844 INFO     Training average regularization at step 66000: 0.172023
2025-12-13 13:50:15,844 INFO     Training average positive_sample_loss at step 66000: 0.008597
2025-12-13 13:50:15,844 INFO     Training average negative_sample_loss at step 66000: 0.020925
2025-12-13 13:50:15,844 INFO     Training average loss at step 66000: 0.186784
2025-12-13 13:50:21,041 INFO     Training average regularization at step 66100: 0.171975
2025-12-13 13:50:21,041 INFO     Training average positive_sample_loss at step 66100: 0.008773
2025-12-13 13:50:21,041 INFO     Training average negative_sample_loss at step 66100: 0.019908
2025-12-13 13:50:21,041 INFO     Training average loss at step 66100: 0.186316
2025-12-13 13:50:26,336 INFO     Training average regularization at step 66200: 0.171928
2025-12-13 13:50:26,336 INFO     Training average positive_sample_loss at step 66200: 0.008360
2025-12-13 13:50:26,336 INFO     Training average negative_sample_loss at step 66200: 0.022822
2025-12-13 13:50:26,336 INFO     Training average loss at step 66200: 0.187519
2025-12-13 13:50:31,580 INFO     Training average regularization at step 66300: 0.171882
2025-12-13 13:50:31,580 INFO     Training average positive_sample_loss at step 66300: 0.007971
2025-12-13 13:50:31,580 INFO     Training average negative_sample_loss at step 66300: 0.021606
2025-12-13 13:50:31,580 INFO     Training average loss at step 66300: 0.186670
2025-12-13 13:50:36,696 INFO     Training average regularization at step 66400: 0.171834
2025-12-13 13:50:36,696 INFO     Training average positive_sample_loss at step 66400: 0.008920
2025-12-13 13:50:36,696 INFO     Training average negative_sample_loss at step 66400: 0.018737
2025-12-13 13:50:36,697 INFO     Training average loss at step 66400: 0.185663
2025-12-13 13:50:41,885 INFO     Training average regularization at step 66500: 0.171786
2025-12-13 13:50:41,886 INFO     Training average positive_sample_loss at step 66500: 0.008730
2025-12-13 13:50:41,886 INFO     Training average negative_sample_loss at step 66500: 0.022507
2025-12-13 13:50:41,886 INFO     Training average loss at step 66500: 0.187405
2025-12-13 13:50:47,092 INFO     Training average regularization at step 66600: 0.171740
2025-12-13 13:50:47,092 INFO     Training average positive_sample_loss at step 66600: 0.009923
2025-12-13 13:50:47,092 INFO     Training average negative_sample_loss at step 66600: 0.019562
2025-12-13 13:50:47,092 INFO     Training average loss at step 66600: 0.186483
2025-12-13 13:50:52,311 INFO     Training average regularization at step 66700: 0.171693
2025-12-13 13:50:52,311 INFO     Training average positive_sample_loss at step 66700: 0.008500
2025-12-13 13:50:52,311 INFO     Training average negative_sample_loss at step 66700: 0.026083
2025-12-13 13:50:52,311 INFO     Training average loss at step 66700: 0.188984
2025-12-13 13:50:57,514 INFO     Training average regularization at step 66800: 0.171647
2025-12-13 13:50:57,514 INFO     Training average positive_sample_loss at step 66800: 0.009149
2025-12-13 13:50:57,514 INFO     Training average negative_sample_loss at step 66800: 0.027474
2025-12-13 13:50:57,514 INFO     Training average loss at step 66800: 0.189958
2025-12-13 13:51:02,775 INFO     Training average regularization at step 66900: 0.171601
2025-12-13 13:51:02,775 INFO     Training average positive_sample_loss at step 66900: 0.008990
2025-12-13 13:51:02,775 INFO     Training average negative_sample_loss at step 66900: 0.023251
2025-12-13 13:51:02,775 INFO     Training average loss at step 66900: 0.187722
2025-12-13 13:51:08,140 INFO     Training average regularization at step 67000: 0.171556
2025-12-13 13:51:08,141 INFO     Training average positive_sample_loss at step 67000: 0.008778
2025-12-13 13:51:08,141 INFO     Training average negative_sample_loss at step 67000: 0.017099
2025-12-13 13:51:08,141 INFO     Training average loss at step 67000: 0.184495
2025-12-13 13:51:13,452 INFO     Training average regularization at step 67100: 0.171511
2025-12-13 13:51:13,452 INFO     Training average positive_sample_loss at step 67100: 0.009209
2025-12-13 13:51:13,452 INFO     Training average negative_sample_loss at step 67100: 0.021783
2025-12-13 13:51:13,452 INFO     Training average loss at step 67100: 0.187006
2025-12-13 13:51:18,731 INFO     Training average regularization at step 67200: 0.171465
2025-12-13 13:51:18,732 INFO     Training average positive_sample_loss at step 67200: 0.008536
2025-12-13 13:51:18,732 INFO     Training average negative_sample_loss at step 67200: 0.020720
2025-12-13 13:51:18,732 INFO     Training average loss at step 67200: 0.186093
2025-12-13 13:51:23,872 INFO     Training average regularization at step 67300: 0.171419
2025-12-13 13:51:23,873 INFO     Training average positive_sample_loss at step 67300: 0.008723
2025-12-13 13:51:23,873 INFO     Training average negative_sample_loss at step 67300: 0.022056
2025-12-13 13:51:23,873 INFO     Training average loss at step 67300: 0.186809
2025-12-13 13:51:28,987 INFO     Training average regularization at step 67400: 0.171373
2025-12-13 13:51:28,988 INFO     Training average positive_sample_loss at step 67400: 0.008172
2025-12-13 13:51:28,988 INFO     Training average negative_sample_loss at step 67400: 0.021759
2025-12-13 13:51:28,988 INFO     Training average loss at step 67400: 0.186338
2025-12-13 13:51:34,097 INFO     Training average regularization at step 67500: 0.171327
2025-12-13 13:51:34,097 INFO     Training average positive_sample_loss at step 67500: 0.008620
2025-12-13 13:51:34,097 INFO     Training average negative_sample_loss at step 67500: 0.025679
2025-12-13 13:51:34,097 INFO     Training average loss at step 67500: 0.188476
2025-12-13 13:51:39,302 INFO     Training average regularization at step 67600: 0.171281
2025-12-13 13:51:39,303 INFO     Training average positive_sample_loss at step 67600: 0.009369
2025-12-13 13:51:39,303 INFO     Training average negative_sample_loss at step 67600: 0.022082
2025-12-13 13:51:39,303 INFO     Training average loss at step 67600: 0.187006
2025-12-13 13:51:45,982 INFO     Training average regularization at step 67700: 0.171234
2025-12-13 13:51:45,982 INFO     Training average positive_sample_loss at step 67700: 0.007544
2025-12-13 13:51:45,983 INFO     Training average negative_sample_loss at step 67700: 0.019623
2025-12-13 13:51:45,983 INFO     Training average loss at step 67700: 0.184817
2025-12-13 13:51:51,238 INFO     Training average regularization at step 67800: 0.171182
2025-12-13 13:51:51,238 INFO     Training average positive_sample_loss at step 67800: 0.006997
2025-12-13 13:51:51,238 INFO     Training average negative_sample_loss at step 67800: 0.023689
2025-12-13 13:51:51,238 INFO     Training average loss at step 67800: 0.186525
2025-12-13 13:51:56,627 INFO     Training average regularization at step 67900: 0.171130
2025-12-13 13:51:56,628 INFO     Training average positive_sample_loss at step 67900: 0.007335
2025-12-13 13:51:56,628 INFO     Training average negative_sample_loss at step 67900: 0.017844
2025-12-13 13:51:56,628 INFO     Training average loss at step 67900: 0.183719
2025-12-13 13:52:02,060 INFO     Training average regularization at step 68000: 0.171079
2025-12-13 13:52:02,060 INFO     Training average positive_sample_loss at step 68000: 0.008006
2025-12-13 13:52:02,060 INFO     Training average negative_sample_loss at step 68000: 0.019081
2025-12-13 13:52:02,060 INFO     Training average loss at step 68000: 0.184623
2025-12-13 13:52:07,374 INFO     Training average regularization at step 68100: 0.171028
2025-12-13 13:52:07,374 INFO     Training average positive_sample_loss at step 68100: 0.007772
2025-12-13 13:52:07,374 INFO     Training average negative_sample_loss at step 68100: 0.021519
2025-12-13 13:52:07,374 INFO     Training average loss at step 68100: 0.185674
2025-12-13 13:52:12,607 INFO     Training average regularization at step 68200: 0.170976
2025-12-13 13:52:12,607 INFO     Training average positive_sample_loss at step 68200: 0.007437
2025-12-13 13:52:12,607 INFO     Training average negative_sample_loss at step 68200: 0.028698
2025-12-13 13:52:12,607 INFO     Training average loss at step 68200: 0.189044
2025-12-13 13:52:17,919 INFO     Training average regularization at step 68300: 0.170925
2025-12-13 13:52:17,920 INFO     Training average positive_sample_loss at step 68300: 0.007348
2025-12-13 13:52:17,920 INFO     Training average negative_sample_loss at step 68300: 0.021730
2025-12-13 13:52:17,920 INFO     Training average loss at step 68300: 0.185464
2025-12-13 13:52:23,252 INFO     Training average regularization at step 68400: 0.170876
2025-12-13 13:52:23,252 INFO     Training average positive_sample_loss at step 68400: 0.007811
2025-12-13 13:52:23,252 INFO     Training average negative_sample_loss at step 68400: 0.019627
2025-12-13 13:52:23,252 INFO     Training average loss at step 68400: 0.184595
2025-12-13 13:52:28,539 INFO     Training average regularization at step 68500: 0.170827
2025-12-13 13:52:28,554 INFO     Training average positive_sample_loss at step 68500: 0.008256
2025-12-13 13:52:28,554 INFO     Training average negative_sample_loss at step 68500: 0.020471
2025-12-13 13:52:28,554 INFO     Training average loss at step 68500: 0.185190
2025-12-13 13:52:33,844 INFO     Training average regularization at step 68600: 0.170779
2025-12-13 13:52:33,845 INFO     Training average positive_sample_loss at step 68600: 0.008354
2025-12-13 13:52:33,845 INFO     Training average negative_sample_loss at step 68600: 0.025238
2025-12-13 13:52:33,845 INFO     Training average loss at step 68600: 0.187575
2025-12-13 13:52:39,187 INFO     Training average regularization at step 68700: 0.170731
2025-12-13 13:52:39,188 INFO     Training average positive_sample_loss at step 68700: 0.008172
2025-12-13 13:52:39,188 INFO     Training average negative_sample_loss at step 68700: 0.021723
2025-12-13 13:52:39,188 INFO     Training average loss at step 68700: 0.185678
2025-12-13 13:52:44,602 INFO     Training average regularization at step 68800: 0.170683
2025-12-13 13:52:44,603 INFO     Training average positive_sample_loss at step 68800: 0.008440
2025-12-13 13:52:44,603 INFO     Training average negative_sample_loss at step 68800: 0.018102
2025-12-13 13:52:44,603 INFO     Training average loss at step 68800: 0.183955
2025-12-13 13:52:50,058 INFO     Training average regularization at step 68900: 0.170634
2025-12-13 13:52:50,058 INFO     Training average positive_sample_loss at step 68900: 0.007526
2025-12-13 13:52:50,058 INFO     Training average negative_sample_loss at step 68900: 0.021855
2025-12-13 13:52:50,058 INFO     Training average loss at step 68900: 0.185325
2025-12-13 13:52:55,292 INFO     Training average regularization at step 69000: 0.170585
2025-12-13 13:52:55,292 INFO     Training average positive_sample_loss at step 69000: 0.007731
2025-12-13 13:52:55,292 INFO     Training average negative_sample_loss at step 69000: 0.019631
2025-12-13 13:52:55,293 INFO     Training average loss at step 69000: 0.184266
2025-12-13 13:53:00,523 INFO     Training average regularization at step 69100: 0.170537
2025-12-13 13:53:00,527 INFO     Training average positive_sample_loss at step 69100: 0.009017
2025-12-13 13:53:00,527 INFO     Training average negative_sample_loss at step 69100: 0.020089
2025-12-13 13:53:00,527 INFO     Training average loss at step 69100: 0.185090
2025-12-13 13:53:05,813 INFO     Training average regularization at step 69200: 0.170487
2025-12-13 13:53:05,813 INFO     Training average positive_sample_loss at step 69200: 0.008373
2025-12-13 13:53:05,813 INFO     Training average negative_sample_loss at step 69200: 0.024360
2025-12-13 13:53:05,813 INFO     Training average loss at step 69200: 0.186854
2025-12-13 13:53:11,075 INFO     Training average regularization at step 69300: 0.170438
2025-12-13 13:53:11,075 INFO     Training average positive_sample_loss at step 69300: 0.008683
2025-12-13 13:53:11,075 INFO     Training average negative_sample_loss at step 69300: 0.022055
2025-12-13 13:53:11,075 INFO     Training average loss at step 69300: 0.185807
2025-12-13 13:53:16,382 INFO     Training average regularization at step 69400: 0.170389
2025-12-13 13:53:16,383 INFO     Training average positive_sample_loss at step 69400: 0.008361
2025-12-13 13:53:16,383 INFO     Training average negative_sample_loss at step 69400: 0.024940
2025-12-13 13:53:16,383 INFO     Training average loss at step 69400: 0.187039
2025-12-13 13:53:21,781 INFO     Training average regularization at step 69500: 0.170341
2025-12-13 13:53:21,781 INFO     Training average positive_sample_loss at step 69500: 0.008164
2025-12-13 13:53:21,781 INFO     Training average negative_sample_loss at step 69500: 0.018105
2025-12-13 13:53:21,782 INFO     Training average loss at step 69500: 0.183475
2025-12-13 13:53:27,201 INFO     Training average regularization at step 69600: 0.170293
2025-12-13 13:53:27,201 INFO     Training average positive_sample_loss at step 69600: 0.008181
2025-12-13 13:53:27,201 INFO     Training average negative_sample_loss at step 69600: 0.025004
2025-12-13 13:53:27,201 INFO     Training average loss at step 69600: 0.186885
2025-12-13 13:53:32,475 INFO     Training average regularization at step 69700: 0.170245
2025-12-13 13:53:32,476 INFO     Training average positive_sample_loss at step 69700: 0.007773
2025-12-13 13:53:32,476 INFO     Training average negative_sample_loss at step 69700: 0.020236
2025-12-13 13:53:32,476 INFO     Training average loss at step 69700: 0.184250
2025-12-13 13:53:37,865 INFO     Training average regularization at step 69800: 0.170196
2025-12-13 13:53:37,865 INFO     Training average positive_sample_loss at step 69800: 0.007977
2025-12-13 13:53:37,865 INFO     Training average negative_sample_loss at step 69800: 0.021228
2025-12-13 13:53:37,865 INFO     Training average loss at step 69800: 0.184799
2025-12-13 13:53:43,208 INFO     Training average regularization at step 69900: 0.170147
2025-12-13 13:53:43,208 INFO     Training average positive_sample_loss at step 69900: 0.008276
2025-12-13 13:53:43,208 INFO     Training average negative_sample_loss at step 69900: 0.021809
2025-12-13 13:53:43,208 INFO     Training average loss at step 69900: 0.185190
2025-12-13 13:53:48,601 INFO     Training average regularization at step 70000: 0.170099
2025-12-13 13:53:48,601 INFO     Training average positive_sample_loss at step 70000: 0.007703
2025-12-13 13:53:48,602 INFO     Training average negative_sample_loss at step 70000: 0.022472
2025-12-13 13:53:48,602 INFO     Training average loss at step 70000: 0.185187
2025-12-13 13:53:48,602 INFO     Evaluating on Valid Dataset...
2025-12-13 13:53:49,275 INFO     Evaluating the model... (0/50000)
2025-12-13 13:53:53,766 INFO     Evaluating the model... (500/50000)
2025-12-13 13:53:58,048 INFO     Evaluating the model... (1000/50000)
2025-12-13 13:54:02,248 INFO     Evaluating the model... (1500/50000)
2025-12-13 13:54:07,765 INFO     Evaluating the model... (2000/50000)
2025-12-13 13:54:12,286 INFO     Evaluating the model... (2500/50000)
2025-12-13 13:54:16,573 INFO     Evaluating the model... (3000/50000)
2025-12-13 13:54:20,945 INFO     Evaluating the model... (3500/50000)
2025-12-13 13:54:25,388 INFO     Evaluating the model... (4000/50000)
2025-12-13 13:54:30,649 INFO     Evaluating the model... (4500/50000)
2025-12-13 13:54:34,898 INFO     Evaluating the model... (5000/50000)
2025-12-13 13:54:39,227 INFO     Evaluating the model... (5500/50000)
2025-12-13 13:54:43,572 INFO     Evaluating the model... (6000/50000)
2025-12-13 13:54:47,771 INFO     Evaluating the model... (6500/50000)
2025-12-13 13:54:52,500 INFO     Evaluating the model... (7000/50000)
2025-12-13 13:54:56,635 INFO     Evaluating the model... (7500/50000)
2025-12-13 13:55:00,789 INFO     Evaluating the model... (8000/50000)
2025-12-13 13:55:05,136 INFO     Evaluating the model... (8500/50000)
2025-12-13 13:55:09,787 INFO     Evaluating the model... (9000/50000)
2025-12-13 13:55:14,665 INFO     Evaluating the model... (9500/50000)
2025-12-13 13:55:18,964 INFO     Evaluating the model... (10000/50000)
2025-12-13 13:55:23,292 INFO     Evaluating the model... (10500/50000)
2025-12-13 13:55:27,526 INFO     Evaluating the model... (11000/50000)
2025-12-13 13:55:31,681 INFO     Evaluating the model... (11500/50000)
2025-12-13 13:55:36,793 INFO     Evaluating the model... (12000/50000)
2025-12-13 13:55:41,206 INFO     Evaluating the model... (12500/50000)
2025-12-13 13:55:45,494 INFO     Evaluating the model... (13000/50000)
2025-12-13 13:55:49,708 INFO     Evaluating the model... (13500/50000)
2025-12-13 13:55:53,955 INFO     Evaluating the model... (14000/50000)
2025-12-13 13:55:58,971 INFO     Evaluating the model... (14500/50000)
2025-12-13 13:56:03,219 INFO     Evaluating the model... (15000/50000)
2025-12-13 13:56:07,482 INFO     Evaluating the model... (15500/50000)
2025-12-13 13:56:11,679 INFO     Evaluating the model... (16000/50000)
2025-12-13 13:56:16,054 INFO     Evaluating the model... (16500/50000)
2025-12-13 13:56:21,126 INFO     Evaluating the model... (17000/50000)
2025-12-13 13:56:25,300 INFO     Evaluating the model... (17500/50000)
2025-12-13 13:56:29,434 INFO     Evaluating the model... (18000/50000)
2025-12-13 13:56:33,775 INFO     Evaluating the model... (18500/50000)
2025-12-13 13:56:38,095 INFO     Evaluating the model... (19000/50000)
2025-12-13 13:56:43,433 INFO     Evaluating the model... (19500/50000)
2025-12-13 13:56:47,744 INFO     Evaluating the model... (20000/50000)
2025-12-13 13:56:52,071 INFO     Evaluating the model... (20500/50000)
2025-12-13 13:56:56,543 INFO     Evaluating the model... (21000/50000)
2025-12-13 13:57:01,083 INFO     Evaluating the model... (21500/50000)
2025-12-13 13:57:05,869 INFO     Evaluating the model... (22000/50000)
2025-12-13 13:57:10,132 INFO     Evaluating the model... (22500/50000)
2025-12-13 13:57:14,407 INFO     Evaluating the model... (23000/50000)
2025-12-13 13:57:18,604 INFO     Evaluating the model... (23500/50000)
2025-12-13 13:57:23,519 INFO     Evaluating the model... (24000/50000)
2025-12-13 13:57:27,793 INFO     Evaluating the model... (24500/50000)
2025-12-13 13:57:32,580 INFO     Evaluating the model... (25000/50000)
2025-12-13 13:57:37,169 INFO     Evaluating the model... (25500/50000)
2025-12-13 13:57:41,546 INFO     Evaluating the model... (26000/50000)
2025-12-13 13:57:45,879 INFO     Evaluating the model... (26500/50000)
2025-12-13 13:57:51,181 INFO     Evaluating the model... (27000/50000)
2025-12-13 13:57:55,760 INFO     Evaluating the model... (27500/50000)
2025-12-13 13:58:00,372 INFO     Evaluating the model... (28000/50000)
2025-12-13 13:58:04,806 INFO     Evaluating the model... (28500/50000)
2025-12-13 13:58:09,621 INFO     Evaluating the model... (29000/50000)
2025-12-13 13:58:13,996 INFO     Evaluating the model... (29500/50000)
2025-12-13 13:58:18,127 INFO     Evaluating the model... (30000/50000)
2025-12-13 13:58:22,236 INFO     Evaluating the model... (30500/50000)
2025-12-13 13:58:26,487 INFO     Evaluating the model... (31000/50000)
2025-12-13 13:58:31,256 INFO     Evaluating the model... (31500/50000)
2025-12-13 13:58:35,537 INFO     Evaluating the model... (32000/50000)
2025-12-13 13:58:39,868 INFO     Evaluating the model... (32500/50000)
2025-12-13 13:58:44,393 INFO     Evaluating the model... (33000/50000)
2025-12-13 13:58:48,936 INFO     Evaluating the model... (33500/50000)
2025-12-13 13:58:54,136 INFO     Evaluating the model... (34000/50000)
2025-12-13 13:58:58,560 INFO     Evaluating the model... (34500/50000)
2025-12-13 13:59:02,903 INFO     Evaluating the model... (35000/50000)
2025-12-13 13:59:07,163 INFO     Evaluating the model... (35500/50000)
2025-12-13 13:59:11,348 INFO     Evaluating the model... (36000/50000)
2025-12-13 13:59:16,060 INFO     Evaluating the model... (36500/50000)
2025-12-13 13:59:20,181 INFO     Evaluating the model... (37000/50000)
2025-12-13 13:59:24,249 INFO     Evaluating the model... (37500/50000)
2025-12-13 13:59:28,433 INFO     Evaluating the model... (38000/50000)
2025-12-13 13:59:32,605 INFO     Evaluating the model... (38500/50000)
2025-12-13 13:59:37,637 INFO     Evaluating the model... (39000/50000)
2025-12-13 13:59:41,750 INFO     Evaluating the model... (39500/50000)
2025-12-13 13:59:45,830 INFO     Evaluating the model... (40000/50000)
2025-12-13 13:59:50,112 INFO     Evaluating the model... (40500/50000)
2025-12-13 13:59:54,241 INFO     Evaluating the model... (41000/50000)
2025-12-13 13:59:59,381 INFO     Evaluating the model... (41500/50000)
2025-12-13 14:00:03,666 INFO     Evaluating the model... (42000/50000)
2025-12-13 14:00:07,821 INFO     Evaluating the model... (42500/50000)
2025-12-13 14:00:11,996 INFO     Evaluating the model... (43000/50000)
2025-12-13 14:00:16,254 INFO     Evaluating the model... (43500/50000)
2025-12-13 14:00:21,346 INFO     Evaluating the model... (44000/50000)
2025-12-13 14:00:25,496 INFO     Evaluating the model... (44500/50000)
2025-12-13 14:00:29,533 INFO     Evaluating the model... (45000/50000)
2025-12-13 14:00:33,569 INFO     Evaluating the model... (45500/50000)
2025-12-13 14:00:37,635 INFO     Evaluating the model... (46000/50000)
2025-12-13 14:00:42,771 INFO     Evaluating the model... (46500/50000)
2025-12-13 14:00:47,015 INFO     Evaluating the model... (47000/50000)
2025-12-13 14:00:51,199 INFO     Evaluating the model... (47500/50000)
2025-12-13 14:00:55,495 INFO     Evaluating the model... (48000/50000)
2025-12-13 14:01:00,137 INFO     Evaluating the model... (48500/50000)
2025-12-13 14:01:05,273 INFO     Evaluating the model... (49000/50000)
2025-12-13 14:01:09,400 INFO     Evaluating the model... (49500/50000)
2025-12-13 14:01:13,958 INFO     Valid MRR at step 70000: 0.729101
2025-12-13 14:01:13,959 INFO     Valid MR at step 70000: 257.756380
2025-12-13 14:01:13,959 INFO     Valid HITS@1 at step 70000: 0.664050
2025-12-13 14:01:13,959 INFO     Valid HITS@3 at step 70000: 0.773950
2025-12-13 14:01:13,959 INFO     Valid HITS@10 at step 70000: 0.841360
2025-12-13 14:01:15,464 INFO     Evaluating on Test Dataset...
2025-12-13 14:01:16,037 INFO     Evaluating the model... (0/59072)
2025-12-13 14:01:20,622 INFO     Evaluating the model... (500/59072)
2025-12-13 14:01:24,974 INFO     Evaluating the model... (1000/59072)
2025-12-13 14:01:30,473 INFO     Evaluating the model... (1500/59072)
2025-12-13 14:01:34,795 INFO     Evaluating the model... (2000/59072)
2025-12-13 14:01:39,180 INFO     Evaluating the model... (2500/59072)
2025-12-13 14:01:43,520 INFO     Evaluating the model... (3000/59072)
2025-12-13 14:01:47,810 INFO     Evaluating the model... (3500/59072)
2025-12-13 14:01:52,611 INFO     Evaluating the model... (4000/59072)
2025-12-13 14:01:56,840 INFO     Evaluating the model... (4500/59072)
2025-12-13 14:02:01,245 INFO     Evaluating the model... (5000/59072)
2025-12-13 14:02:05,642 INFO     Evaluating the model... (5500/59072)
2025-12-13 14:02:10,025 INFO     Evaluating the model... (6000/59072)
2025-12-13 14:02:15,087 INFO     Evaluating the model... (6500/59072)
2025-12-13 14:02:19,511 INFO     Evaluating the model... (7000/59072)
2025-12-13 14:02:24,053 INFO     Evaluating the model... (7500/59072)
2025-12-13 14:02:28,567 INFO     Evaluating the model... (8000/59072)
2025-12-13 14:02:33,490 INFO     Evaluating the model... (8500/59072)
2025-12-13 14:02:37,683 INFO     Evaluating the model... (9000/59072)
2025-12-13 14:02:42,047 INFO     Evaluating the model... (9500/59072)
2025-12-13 14:02:46,454 INFO     Evaluating the model... (10000/59072)
2025-12-13 14:02:51,016 INFO     Evaluating the model... (10500/59072)
2025-12-13 14:02:56,216 INFO     Evaluating the model... (11000/59072)
2025-12-13 14:03:00,612 INFO     Evaluating the model... (11500/59072)
2025-12-13 14:03:04,971 INFO     Evaluating the model... (12000/59072)
2025-12-13 14:03:09,307 INFO     Evaluating the model... (12500/59072)
2025-12-13 14:03:13,837 INFO     Evaluating the model... (13000/59072)
2025-12-13 14:03:19,349 INFO     Evaluating the model... (13500/59072)
2025-12-13 14:03:23,786 INFO     Evaluating the model... (14000/59072)
2025-12-13 14:03:27,939 INFO     Evaluating the model... (14500/59072)
2025-12-13 14:03:32,188 INFO     Evaluating the model... (15000/59072)
2025-12-13 14:03:36,619 INFO     Evaluating the model... (15500/59072)
2025-12-13 14:03:41,866 INFO     Evaluating the model... (16000/59072)
2025-12-13 14:03:46,522 INFO     Evaluating the model... (16500/59072)
2025-12-13 14:03:50,842 INFO     Evaluating the model... (17000/59072)
2025-12-13 14:03:55,104 INFO     Evaluating the model... (17500/59072)
2025-12-13 14:03:59,472 INFO     Evaluating the model... (18000/59072)
2025-12-13 14:04:05,047 INFO     Evaluating the model... (18500/59072)
2025-12-13 14:04:09,465 INFO     Evaluating the model... (19000/59072)
2025-12-13 14:04:13,733 INFO     Evaluating the model... (19500/59072)
2025-12-13 14:04:17,989 INFO     Evaluating the model... (20000/59072)
2025-12-13 14:04:22,231 INFO     Evaluating the model... (20500/59072)
2025-12-13 14:04:27,668 INFO     Evaluating the model... (21000/59072)
2025-12-13 14:04:32,007 INFO     Evaluating the model... (21500/59072)
2025-12-13 14:04:36,245 INFO     Evaluating the model... (22000/59072)
2025-12-13 14:04:40,357 INFO     Evaluating the model... (22500/59072)
2025-12-13 14:04:44,573 INFO     Evaluating the model... (23000/59072)
2025-12-13 14:04:49,962 INFO     Evaluating the model... (23500/59072)
2025-12-13 14:04:54,035 INFO     Evaluating the model... (24000/59072)
2025-12-13 14:04:58,261 INFO     Evaluating the model... (24500/59072)
2025-12-13 14:05:02,644 INFO     Evaluating the model... (25000/59072)
2025-12-13 14:05:06,926 INFO     Evaluating the model... (25500/59072)
2025-12-13 14:05:12,324 INFO     Evaluating the model... (26000/59072)
2025-12-13 14:05:16,479 INFO     Evaluating the model... (26500/59072)
2025-12-13 14:05:20,645 INFO     Evaluating the model... (27000/59072)
2025-12-13 14:05:25,163 INFO     Evaluating the model... (27500/59072)
2025-12-13 14:05:30,135 INFO     Evaluating the model... (28000/59072)
2025-12-13 14:05:34,781 INFO     Evaluating the model... (28500/59072)
2025-12-13 14:05:39,032 INFO     Evaluating the model... (29000/59072)
2025-12-13 14:05:43,277 INFO     Evaluating the model... (29500/59072)
2025-12-13 14:05:48,344 INFO     Evaluating the model... (30000/59072)
2025-12-13 14:05:53,913 INFO     Evaluating the model... (30500/59072)
2025-12-13 14:05:58,350 INFO     Evaluating the model... (31000/59072)
2025-12-13 14:06:02,753 INFO     Evaluating the model... (31500/59072)
2025-12-13 14:06:07,084 INFO     Evaluating the model... (32000/59072)
2025-12-13 14:06:11,620 INFO     Evaluating the model... (32500/59072)
2025-12-13 14:06:16,814 INFO     Evaluating the model... (33000/59072)
2025-12-13 14:06:21,271 INFO     Evaluating the model... (33500/59072)
2025-12-13 14:06:25,550 INFO     Evaluating the model... (34000/59072)
2025-12-13 14:06:29,976 INFO     Evaluating the model... (34500/59072)
2025-12-13 14:06:34,300 INFO     Evaluating the model... (35000/59072)
2025-12-13 14:06:39,443 INFO     Evaluating the model... (35500/59072)
2025-12-13 14:06:43,746 INFO     Evaluating the model... (36000/59072)
2025-12-13 14:06:47,963 INFO     Evaluating the model... (36500/59072)
2025-12-13 14:06:52,343 INFO     Evaluating the model... (37000/59072)
2025-12-13 14:06:56,961 INFO     Evaluating the model... (37500/59072)
2025-12-13 14:07:01,969 INFO     Evaluating the model... (38000/59072)
2025-12-13 14:07:06,492 INFO     Evaluating the model... (38500/59072)
2025-12-13 14:07:11,267 INFO     Evaluating the model... (39000/59072)
2025-12-13 14:07:15,662 INFO     Evaluating the model... (39500/59072)
2025-12-13 14:07:20,863 INFO     Evaluating the model... (40000/59072)
2025-12-13 14:07:25,561 INFO     Evaluating the model... (40500/59072)
2025-12-13 14:07:30,176 INFO     Evaluating the model... (41000/59072)
2025-12-13 14:07:34,718 INFO     Evaluating the model... (41500/59072)
2025-12-13 14:07:39,361 INFO     Evaluating the model... (42000/59072)
2025-12-13 14:07:44,672 INFO     Evaluating the model... (42500/59072)
2025-12-13 14:07:49,343 INFO     Evaluating the model... (43000/59072)
2025-12-13 14:07:54,188 INFO     Evaluating the model... (43500/59072)
2025-12-13 14:07:58,949 INFO     Evaluating the model... (44000/59072)
2025-12-13 14:08:03,678 INFO     Evaluating the model... (44500/59072)
2025-12-13 14:08:09,134 INFO     Evaluating the model... (45000/59072)
2025-12-13 14:08:13,870 INFO     Evaluating the model... (45500/59072)
2025-12-13 14:08:18,495 INFO     Evaluating the model... (46000/59072)
2025-12-13 14:08:23,141 INFO     Evaluating the model... (46500/59072)
2025-12-13 14:08:27,745 INFO     Evaluating the model... (47000/59072)
2025-12-13 14:08:33,492 INFO     Evaluating the model... (47500/59072)
2025-12-13 14:08:38,253 INFO     Evaluating the model... (48000/59072)
2025-12-13 14:08:42,931 INFO     Evaluating the model... (48500/59072)
2025-12-13 14:08:47,571 INFO     Evaluating the model... (49000/59072)
2025-12-13 14:08:52,416 INFO     Evaluating the model... (49500/59072)
2025-12-13 14:08:58,331 INFO     Evaluating the model... (50000/59072)
2025-12-13 14:09:03,086 INFO     Evaluating the model... (50500/59072)
2025-12-13 14:09:07,963 INFO     Evaluating the model... (51000/59072)
2025-12-13 14:09:12,526 INFO     Evaluating the model... (51500/59072)
2025-12-13 14:09:17,174 INFO     Evaluating the model... (52000/59072)
2025-12-13 14:09:23,257 INFO     Evaluating the model... (52500/59072)
2025-12-13 14:09:27,901 INFO     Evaluating the model... (53000/59072)
2025-12-13 14:09:32,421 INFO     Evaluating the model... (53500/59072)
2025-12-13 14:09:36,763 INFO     Evaluating the model... (54000/59072)
2025-12-13 14:09:41,078 INFO     Evaluating the model... (54500/59072)
2025-12-13 14:09:46,881 INFO     Evaluating the model... (55000/59072)
2025-12-13 14:09:51,433 INFO     Evaluating the model... (55500/59072)
2025-12-13 14:09:55,572 INFO     Evaluating the model... (56000/59072)
2025-12-13 14:09:59,697 INFO     Evaluating the model... (56500/59072)
2025-12-13 14:10:03,867 INFO     Evaluating the model... (57000/59072)
2025-12-13 14:10:09,337 INFO     Evaluating the model... (57500/59072)
2025-12-13 14:10:13,556 INFO     Evaluating the model... (58000/59072)
2025-12-13 14:10:17,856 INFO     Evaluating the model... (58500/59072)
2025-12-13 14:10:21,994 INFO     Evaluating the model... (59000/59072)
2025-12-13 14:10:22,822 INFO     Test MRR at step 70000: 0.723744
2025-12-13 14:10:22,822 INFO     Test MR at step 70000: 260.734218
2025-12-13 14:10:22,822 INFO     Test HITS@1 at step 70000: 0.658140
2025-12-13 14:10:22,822 INFO     Test HITS@3 at step 70000: 0.768964
2025-12-13 14:10:22,822 INFO     Test HITS@10 at step 70000: 0.837628
2025-12-13 14:10:28,108 INFO     Training average regularization at step 70100: 0.170051
2025-12-13 14:10:28,109 INFO     Training average positive_sample_loss at step 70100: 0.007776
2025-12-13 14:10:28,109 INFO     Training average negative_sample_loss at step 70100: 0.024728
2025-12-13 14:10:28,109 INFO     Training average loss at step 70100: 0.186303
2025-12-13 14:10:33,398 INFO     Training average regularization at step 70200: 0.170004
2025-12-13 14:10:33,398 INFO     Training average positive_sample_loss at step 70200: 0.007899
2025-12-13 14:10:33,398 INFO     Training average negative_sample_loss at step 70200: 0.019077
2025-12-13 14:10:33,398 INFO     Training average loss at step 70200: 0.183492
2025-12-13 14:10:38,765 INFO     Training average regularization at step 70300: 0.169957
2025-12-13 14:10:38,765 INFO     Training average positive_sample_loss at step 70300: 0.008953
2025-12-13 14:10:38,765 INFO     Training average negative_sample_loss at step 70300: 0.024027
2025-12-13 14:10:38,765 INFO     Training average loss at step 70300: 0.186447
2025-12-13 14:10:44,106 INFO     Training average regularization at step 70400: 0.169911
2025-12-13 14:10:44,107 INFO     Training average positive_sample_loss at step 70400: 0.007808
2025-12-13 14:10:44,107 INFO     Training average negative_sample_loss at step 70400: 0.023329
2025-12-13 14:10:44,107 INFO     Training average loss at step 70400: 0.185479
2025-12-13 14:10:49,327 INFO     Training average regularization at step 70500: 0.169865
2025-12-13 14:10:49,327 INFO     Training average positive_sample_loss at step 70500: 0.009398
2025-12-13 14:10:49,327 INFO     Training average negative_sample_loss at step 70500: 0.022391
2025-12-13 14:10:49,327 INFO     Training average loss at step 70500: 0.185759
2025-12-13 14:10:54,593 INFO     Training average regularization at step 70600: 0.169818
2025-12-13 14:10:54,593 INFO     Training average positive_sample_loss at step 70600: 0.008125
2025-12-13 14:10:54,593 INFO     Training average negative_sample_loss at step 70600: 0.023056
2025-12-13 14:10:54,593 INFO     Training average loss at step 70600: 0.185409
2025-12-13 14:10:59,886 INFO     Training average regularization at step 70700: 0.169772
2025-12-13 14:10:59,886 INFO     Training average positive_sample_loss at step 70700: 0.008252
2025-12-13 14:10:59,886 INFO     Training average negative_sample_loss at step 70700: 0.026107
2025-12-13 14:10:59,886 INFO     Training average loss at step 70700: 0.186952
2025-12-13 14:11:05,137 INFO     Training average regularization at step 70800: 0.169726
2025-12-13 14:11:05,137 INFO     Training average positive_sample_loss at step 70800: 0.008169
2025-12-13 14:11:05,137 INFO     Training average negative_sample_loss at step 70800: 0.021148
2025-12-13 14:11:05,137 INFO     Training average loss at step 70800: 0.184385
2025-12-13 14:11:10,384 INFO     Training average regularization at step 70900: 0.169680
2025-12-13 14:11:10,384 INFO     Training average positive_sample_loss at step 70900: 0.008013
2025-12-13 14:11:10,384 INFO     Training average negative_sample_loss at step 70900: 0.022545
2025-12-13 14:11:10,384 INFO     Training average loss at step 70900: 0.184959
2025-12-13 14:11:15,551 INFO     Training average regularization at step 71000: 0.169633
2025-12-13 14:11:15,552 INFO     Training average positive_sample_loss at step 71000: 0.008211
2025-12-13 14:11:15,552 INFO     Training average negative_sample_loss at step 71000: 0.019784
2025-12-13 14:11:15,552 INFO     Training average loss at step 71000: 0.183631
2025-12-13 14:11:20,729 INFO     Training average regularization at step 71100: 0.169587
2025-12-13 14:11:20,729 INFO     Training average positive_sample_loss at step 71100: 0.007882
2025-12-13 14:11:20,729 INFO     Training average negative_sample_loss at step 71100: 0.021187
2025-12-13 14:11:20,729 INFO     Training average loss at step 71100: 0.184122
2025-12-13 14:11:25,960 INFO     Training average regularization at step 71200: 0.169542
2025-12-13 14:11:25,960 INFO     Training average positive_sample_loss at step 71200: 0.008018
2025-12-13 14:11:25,960 INFO     Training average negative_sample_loss at step 71200: 0.018931
2025-12-13 14:11:25,960 INFO     Training average loss at step 71200: 0.183016
2025-12-13 14:11:31,176 INFO     Training average regularization at step 71300: 0.169495
2025-12-13 14:11:31,177 INFO     Training average positive_sample_loss at step 71300: 0.008291
2025-12-13 14:11:31,177 INFO     Training average negative_sample_loss at step 71300: 0.020854
2025-12-13 14:11:31,177 INFO     Training average loss at step 71300: 0.184068
2025-12-13 14:11:36,351 INFO     Training average regularization at step 71400: 0.169449
2025-12-13 14:11:36,351 INFO     Training average positive_sample_loss at step 71400: 0.009722
2025-12-13 14:11:36,351 INFO     Training average negative_sample_loss at step 71400: 0.025592
2025-12-13 14:11:36,351 INFO     Training average loss at step 71400: 0.187107
2025-12-13 14:11:41,607 INFO     Training average regularization at step 71500: 0.169404
2025-12-13 14:11:41,607 INFO     Training average positive_sample_loss at step 71500: 0.008396
2025-12-13 14:11:41,608 INFO     Training average negative_sample_loss at step 71500: 0.025490
2025-12-13 14:11:41,608 INFO     Training average loss at step 71500: 0.186348
2025-12-13 14:11:46,923 INFO     Training average regularization at step 71600: 0.169360
2025-12-13 14:11:46,923 INFO     Training average positive_sample_loss at step 71600: 0.008381
2025-12-13 14:11:46,923 INFO     Training average negative_sample_loss at step 71600: 0.020187
2025-12-13 14:11:46,923 INFO     Training average loss at step 71600: 0.183644
2025-12-13 14:11:52,239 INFO     Training average regularization at step 71700: 0.169315
2025-12-13 14:11:52,239 INFO     Training average positive_sample_loss at step 71700: 0.007520
2025-12-13 14:11:52,239 INFO     Training average negative_sample_loss at step 71700: 0.021288
2025-12-13 14:11:52,239 INFO     Training average loss at step 71700: 0.183719
2025-12-13 14:11:57,569 INFO     Training average regularization at step 71800: 0.169269
2025-12-13 14:11:57,569 INFO     Training average positive_sample_loss at step 71800: 0.008048
2025-12-13 14:11:57,569 INFO     Training average negative_sample_loss at step 71800: 0.022245
2025-12-13 14:11:57,569 INFO     Training average loss at step 71800: 0.184415
2025-12-13 14:12:02,903 INFO     Training average regularization at step 71900: 0.169224
2025-12-13 14:12:02,904 INFO     Training average positive_sample_loss at step 71900: 0.008444
2025-12-13 14:12:02,904 INFO     Training average negative_sample_loss at step 71900: 0.025910
2025-12-13 14:12:02,904 INFO     Training average loss at step 71900: 0.186402
2025-12-13 14:12:08,244 INFO     Training average regularization at step 72000: 0.169180
2025-12-13 14:12:08,244 INFO     Training average positive_sample_loss at step 72000: 0.008265
2025-12-13 14:12:08,244 INFO     Training average negative_sample_loss at step 72000: 0.019247
2025-12-13 14:12:08,244 INFO     Training average loss at step 72000: 0.182936
2025-12-13 14:12:13,511 INFO     Training average regularization at step 72100: 0.169136
2025-12-13 14:12:13,512 INFO     Training average positive_sample_loss at step 72100: 0.009742
2025-12-13 14:12:13,512 INFO     Training average negative_sample_loss at step 72100: 0.024354
2025-12-13 14:12:13,512 INFO     Training average loss at step 72100: 0.186184
2025-12-13 14:12:18,807 INFO     Training average regularization at step 72200: 0.169092
2025-12-13 14:12:18,807 INFO     Training average positive_sample_loss at step 72200: 0.008170
2025-12-13 14:12:18,807 INFO     Training average negative_sample_loss at step 72200: 0.019762
2025-12-13 14:12:18,807 INFO     Training average loss at step 72200: 0.183058
2025-12-13 14:12:23,865 INFO     Training average regularization at step 72300: 0.169047
2025-12-13 14:12:23,865 INFO     Training average positive_sample_loss at step 72300: 0.008100
2025-12-13 14:12:23,865 INFO     Training average negative_sample_loss at step 72300: 0.023094
2025-12-13 14:12:23,865 INFO     Training average loss at step 72300: 0.184644
2025-12-13 14:12:29,018 INFO     Training average regularization at step 72400: 0.169003
2025-12-13 14:12:29,019 INFO     Training average positive_sample_loss at step 72400: 0.009899
2025-12-13 14:12:29,019 INFO     Training average negative_sample_loss at step 72400: 0.021323
2025-12-13 14:12:29,019 INFO     Training average loss at step 72400: 0.184613
2025-12-13 14:12:35,302 INFO     Training average regularization at step 72500: 0.168957
2025-12-13 14:12:35,303 INFO     Training average positive_sample_loss at step 72500: 0.007739
2025-12-13 14:12:35,306 INFO     Training average negative_sample_loss at step 72500: 0.023082
2025-12-13 14:12:35,306 INFO     Training average loss at step 72500: 0.184368
2025-12-13 14:12:40,589 INFO     Training average regularization at step 72600: 0.168909
2025-12-13 14:12:40,590 INFO     Training average positive_sample_loss at step 72600: 0.007155
2025-12-13 14:12:40,590 INFO     Training average negative_sample_loss at step 72600: 0.019787
2025-12-13 14:12:40,590 INFO     Training average loss at step 72600: 0.182380
2025-12-13 14:12:45,742 INFO     Training average regularization at step 72700: 0.168859
2025-12-13 14:12:45,742 INFO     Training average positive_sample_loss at step 72700: 0.007868
2025-12-13 14:12:45,742 INFO     Training average negative_sample_loss at step 72700: 0.019658
2025-12-13 14:12:45,742 INFO     Training average loss at step 72700: 0.182622
2025-12-13 14:12:51,019 INFO     Training average regularization at step 72800: 0.168810
2025-12-13 14:12:51,019 INFO     Training average positive_sample_loss at step 72800: 0.007248
2025-12-13 14:12:51,019 INFO     Training average negative_sample_loss at step 72800: 0.017010
2025-12-13 14:12:51,019 INFO     Training average loss at step 72800: 0.180939
2025-12-13 14:12:56,366 INFO     Training average regularization at step 72900: 0.168762
2025-12-13 14:12:56,366 INFO     Training average positive_sample_loss at step 72900: 0.007286
2025-12-13 14:12:56,366 INFO     Training average negative_sample_loss at step 72900: 0.021189
2025-12-13 14:12:56,366 INFO     Training average loss at step 72900: 0.183000
2025-12-13 14:13:01,563 INFO     Training average regularization at step 73000: 0.168712
2025-12-13 14:13:01,564 INFO     Training average positive_sample_loss at step 73000: 0.007171
2025-12-13 14:13:01,564 INFO     Training average negative_sample_loss at step 73000: 0.023752
2025-12-13 14:13:01,564 INFO     Training average loss at step 73000: 0.184174
2025-12-13 14:13:06,864 INFO     Training average regularization at step 73100: 0.168663
2025-12-13 14:13:06,864 INFO     Training average positive_sample_loss at step 73100: 0.007674
2025-12-13 14:13:06,864 INFO     Training average negative_sample_loss at step 73100: 0.019398
2025-12-13 14:13:06,864 INFO     Training average loss at step 73100: 0.182199
2025-12-13 14:13:12,102 INFO     Training average regularization at step 73200: 0.168615
2025-12-13 14:13:12,102 INFO     Training average positive_sample_loss at step 73200: 0.008394
2025-12-13 14:13:12,103 INFO     Training average negative_sample_loss at step 73200: 0.021660
2025-12-13 14:13:12,103 INFO     Training average loss at step 73200: 0.183642
2025-12-13 14:13:17,295 INFO     Training average regularization at step 73300: 0.168567
2025-12-13 14:13:17,295 INFO     Training average positive_sample_loss at step 73300: 0.007189
2025-12-13 14:13:17,295 INFO     Training average negative_sample_loss at step 73300: 0.018105
2025-12-13 14:13:17,295 INFO     Training average loss at step 73300: 0.181214
2025-12-13 14:13:22,512 INFO     Training average regularization at step 73400: 0.168520
2025-12-13 14:13:22,512 INFO     Training average positive_sample_loss at step 73400: 0.007826
2025-12-13 14:13:22,512 INFO     Training average negative_sample_loss at step 73400: 0.014737
2025-12-13 14:13:22,512 INFO     Training average loss at step 73400: 0.179801
2025-12-13 14:13:27,695 INFO     Training average regularization at step 73500: 0.168470
2025-12-13 14:13:27,695 INFO     Training average positive_sample_loss at step 73500: 0.008107
2025-12-13 14:13:27,695 INFO     Training average negative_sample_loss at step 73500: 0.022744
2025-12-13 14:13:27,696 INFO     Training average loss at step 73500: 0.183896
2025-12-13 14:13:32,932 INFO     Training average regularization at step 73600: 0.168420
2025-12-13 14:13:32,932 INFO     Training average positive_sample_loss at step 73600: 0.007966
2025-12-13 14:13:32,933 INFO     Training average negative_sample_loss at step 73600: 0.022511
2025-12-13 14:13:32,933 INFO     Training average loss at step 73600: 0.183659
2025-12-13 14:13:38,292 INFO     Training average regularization at step 73700: 0.168370
2025-12-13 14:13:38,292 INFO     Training average positive_sample_loss at step 73700: 0.007490
2025-12-13 14:13:38,292 INFO     Training average negative_sample_loss at step 73700: 0.023297
2025-12-13 14:13:38,292 INFO     Training average loss at step 73700: 0.183764
2025-12-13 14:13:43,405 INFO     Training average regularization at step 73800: 0.168321
2025-12-13 14:13:43,406 INFO     Training average positive_sample_loss at step 73800: 0.007361
2025-12-13 14:13:43,406 INFO     Training average negative_sample_loss at step 73800: 0.024100
2025-12-13 14:13:43,406 INFO     Training average loss at step 73800: 0.184052
2025-12-13 14:13:48,696 INFO     Training average regularization at step 73900: 0.168273
2025-12-13 14:13:48,696 INFO     Training average positive_sample_loss at step 73900: 0.007752
2025-12-13 14:13:48,696 INFO     Training average negative_sample_loss at step 73900: 0.019749
2025-12-13 14:13:48,696 INFO     Training average loss at step 73900: 0.182023
2025-12-13 14:13:53,933 INFO     Training average regularization at step 74000: 0.168224
2025-12-13 14:13:53,933 INFO     Training average positive_sample_loss at step 74000: 0.007489
2025-12-13 14:13:53,933 INFO     Training average negative_sample_loss at step 74000: 0.017655
2025-12-13 14:13:53,933 INFO     Training average loss at step 74000: 0.180797
2025-12-13 14:13:59,213 INFO     Training average regularization at step 74100: 0.168176
2025-12-13 14:13:59,213 INFO     Training average positive_sample_loss at step 74100: 0.007301
2025-12-13 14:13:59,213 INFO     Training average negative_sample_loss at step 74100: 0.020875
2025-12-13 14:13:59,213 INFO     Training average loss at step 74100: 0.182264
2025-12-13 14:14:04,482 INFO     Training average regularization at step 74200: 0.168128
2025-12-13 14:14:04,482 INFO     Training average positive_sample_loss at step 74200: 0.007173
2025-12-13 14:14:04,482 INFO     Training average negative_sample_loss at step 74200: 0.020195
2025-12-13 14:14:04,482 INFO     Training average loss at step 74200: 0.181812
2025-12-13 14:14:09,732 INFO     Training average regularization at step 74300: 0.168080
2025-12-13 14:14:09,732 INFO     Training average positive_sample_loss at step 74300: 0.007740
2025-12-13 14:14:09,732 INFO     Training average negative_sample_loss at step 74300: 0.018839
2025-12-13 14:14:09,732 INFO     Training average loss at step 74300: 0.181369
2025-12-13 14:14:14,832 INFO     Training average regularization at step 74400: 0.168031
2025-12-13 14:14:14,833 INFO     Training average positive_sample_loss at step 74400: 0.007894
2025-12-13 14:14:14,833 INFO     Training average negative_sample_loss at step 74400: 0.019711
2025-12-13 14:14:14,833 INFO     Training average loss at step 74400: 0.181834
2025-12-13 14:14:19,799 INFO     Training average regularization at step 74500: 0.167984
2025-12-13 14:14:19,800 INFO     Training average positive_sample_loss at step 74500: 0.007583
2025-12-13 14:14:19,800 INFO     Training average negative_sample_loss at step 74500: 0.023778
2025-12-13 14:14:19,800 INFO     Training average loss at step 74500: 0.183665
2025-12-13 14:14:24,835 INFO     Training average regularization at step 74600: 0.167937
2025-12-13 14:14:24,835 INFO     Training average positive_sample_loss at step 74600: 0.007631
2025-12-13 14:14:24,835 INFO     Training average negative_sample_loss at step 74600: 0.022486
2025-12-13 14:14:24,835 INFO     Training average loss at step 74600: 0.182996
2025-12-13 14:14:29,931 INFO     Training average regularization at step 74700: 0.167890
2025-12-13 14:14:29,931 INFO     Training average positive_sample_loss at step 74700: 0.008525
2025-12-13 14:14:29,931 INFO     Training average negative_sample_loss at step 74700: 0.024151
2025-12-13 14:14:29,931 INFO     Training average loss at step 74700: 0.184228
2025-12-13 14:14:34,992 INFO     Training average regularization at step 74800: 0.167845
2025-12-13 14:14:34,993 INFO     Training average positive_sample_loss at step 74800: 0.007808
2025-12-13 14:14:34,993 INFO     Training average negative_sample_loss at step 74800: 0.021381
2025-12-13 14:14:34,993 INFO     Training average loss at step 74800: 0.182439
2025-12-13 14:14:40,084 INFO     Training average regularization at step 74900: 0.167800
2025-12-13 14:14:40,084 INFO     Training average positive_sample_loss at step 74900: 0.007958
2025-12-13 14:14:40,084 INFO     Training average negative_sample_loss at step 74900: 0.018634
2025-12-13 14:14:40,084 INFO     Training average loss at step 74900: 0.181096
2025-12-13 14:14:45,163 INFO     Training average regularization at step 75000: 0.167755
2025-12-13 14:14:45,164 INFO     Training average positive_sample_loss at step 75000: 0.007914
2025-12-13 14:14:45,164 INFO     Training average negative_sample_loss at step 75000: 0.018832
2025-12-13 14:14:45,164 INFO     Training average loss at step 75000: 0.181128
2025-12-13 14:14:50,265 INFO     Training average regularization at step 75100: 0.167709
2025-12-13 14:14:50,265 INFO     Training average positive_sample_loss at step 75100: 0.007419
2025-12-13 14:14:50,265 INFO     Training average negative_sample_loss at step 75100: 0.022768
2025-12-13 14:14:50,266 INFO     Training average loss at step 75100: 0.182802
2025-12-13 14:14:55,333 INFO     Training average regularization at step 75200: 0.167662
2025-12-13 14:14:55,333 INFO     Training average positive_sample_loss at step 75200: 0.007628
2025-12-13 14:14:55,333 INFO     Training average negative_sample_loss at step 75200: 0.026419
2025-12-13 14:14:55,333 INFO     Training average loss at step 75200: 0.184686
2025-12-13 14:15:00,410 INFO     Training average regularization at step 75300: 0.167617
2025-12-13 14:15:00,411 INFO     Training average positive_sample_loss at step 75300: 0.008208
2025-12-13 14:15:00,411 INFO     Training average negative_sample_loss at step 75300: 0.018925
2025-12-13 14:15:00,411 INFO     Training average loss at step 75300: 0.181184
2025-12-13 14:15:05,450 INFO     Training average regularization at step 75400: 0.167572
2025-12-13 14:15:05,452 INFO     Training average positive_sample_loss at step 75400: 0.007431
2025-12-13 14:15:05,452 INFO     Training average negative_sample_loss at step 75400: 0.023212
2025-12-13 14:15:05,452 INFO     Training average loss at step 75400: 0.182893
2025-12-13 14:15:10,534 INFO     Training average regularization at step 75500: 0.167527
2025-12-13 14:15:10,534 INFO     Training average positive_sample_loss at step 75500: 0.007667
2025-12-13 14:15:10,534 INFO     Training average negative_sample_loss at step 75500: 0.022447
2025-12-13 14:15:10,534 INFO     Training average loss at step 75500: 0.182583
2025-12-13 14:15:15,611 INFO     Training average regularization at step 75600: 0.167483
2025-12-13 14:15:15,611 INFO     Training average positive_sample_loss at step 75600: 0.008105
2025-12-13 14:15:15,611 INFO     Training average negative_sample_loss at step 75600: 0.020136
2025-12-13 14:15:15,611 INFO     Training average loss at step 75600: 0.181604
2025-12-13 14:15:20,688 INFO     Training average regularization at step 75700: 0.167439
2025-12-13 14:15:20,688 INFO     Training average positive_sample_loss at step 75700: 0.007993
2025-12-13 14:15:20,688 INFO     Training average negative_sample_loss at step 75700: 0.023250
2025-12-13 14:15:20,688 INFO     Training average loss at step 75700: 0.183060
2025-12-13 14:15:25,794 INFO     Training average regularization at step 75800: 0.167394
2025-12-13 14:15:25,794 INFO     Training average positive_sample_loss at step 75800: 0.008897
2025-12-13 14:15:25,794 INFO     Training average negative_sample_loss at step 75800: 0.017952
2025-12-13 14:15:25,794 INFO     Training average loss at step 75800: 0.180818
2025-12-13 14:15:30,885 INFO     Training average regularization at step 75900: 0.167350
2025-12-13 14:15:30,886 INFO     Training average positive_sample_loss at step 75900: 0.007381
2025-12-13 14:15:30,886 INFO     Training average negative_sample_loss at step 75900: 0.021179
2025-12-13 14:15:30,886 INFO     Training average loss at step 75900: 0.181630
2025-12-13 14:15:36,036 INFO     Training average regularization at step 76000: 0.167304
2025-12-13 14:15:36,037 INFO     Training average positive_sample_loss at step 76000: 0.007482
2025-12-13 14:15:36,037 INFO     Training average negative_sample_loss at step 76000: 0.021856
2025-12-13 14:15:36,037 INFO     Training average loss at step 76000: 0.181974
2025-12-13 14:15:41,236 INFO     Training average regularization at step 76100: 0.167258
2025-12-13 14:15:41,239 INFO     Training average positive_sample_loss at step 76100: 0.007486
2025-12-13 14:15:41,239 INFO     Training average negative_sample_loss at step 76100: 0.020425
2025-12-13 14:15:41,239 INFO     Training average loss at step 76100: 0.181214
2025-12-13 14:15:46,516 INFO     Training average regularization at step 76200: 0.167213
2025-12-13 14:15:46,516 INFO     Training average positive_sample_loss at step 76200: 0.007636
2025-12-13 14:15:46,516 INFO     Training average negative_sample_loss at step 76200: 0.023042
2025-12-13 14:15:46,516 INFO     Training average loss at step 76200: 0.182552
2025-12-13 14:15:51,886 INFO     Training average regularization at step 76300: 0.167168
2025-12-13 14:15:51,886 INFO     Training average positive_sample_loss at step 76300: 0.008066
2025-12-13 14:15:51,886 INFO     Training average negative_sample_loss at step 76300: 0.022033
2025-12-13 14:15:51,886 INFO     Training average loss at step 76300: 0.182218
2025-12-13 14:15:57,171 INFO     Training average regularization at step 76400: 0.167126
2025-12-13 14:15:57,172 INFO     Training average positive_sample_loss at step 76400: 0.008582
2025-12-13 14:15:57,172 INFO     Training average negative_sample_loss at step 76400: 0.025275
2025-12-13 14:15:57,172 INFO     Training average loss at step 76400: 0.184054
2025-12-13 14:16:02,455 INFO     Training average regularization at step 76500: 0.167086
2025-12-13 14:16:02,455 INFO     Training average positive_sample_loss at step 76500: 0.008085
2025-12-13 14:16:02,455 INFO     Training average negative_sample_loss at step 76500: 0.021379
2025-12-13 14:16:02,455 INFO     Training average loss at step 76500: 0.181818
2025-12-13 14:16:07,712 INFO     Training average regularization at step 76600: 0.167044
2025-12-13 14:16:07,712 INFO     Training average positive_sample_loss at step 76600: 0.008356
2025-12-13 14:16:07,712 INFO     Training average negative_sample_loss at step 76600: 0.020485
2025-12-13 14:16:07,712 INFO     Training average loss at step 76600: 0.181464
2025-12-13 14:16:12,981 INFO     Training average regularization at step 76700: 0.167001
2025-12-13 14:16:12,982 INFO     Training average positive_sample_loss at step 76700: 0.008555
2025-12-13 14:16:12,982 INFO     Training average negative_sample_loss at step 76700: 0.022832
2025-12-13 14:16:12,982 INFO     Training average loss at step 76700: 0.182695
2025-12-13 14:16:18,322 INFO     Training average regularization at step 76800: 0.166957
2025-12-13 14:16:18,322 INFO     Training average positive_sample_loss at step 76800: 0.007698
2025-12-13 14:16:18,322 INFO     Training average negative_sample_loss at step 76800: 0.017906
2025-12-13 14:16:18,322 INFO     Training average loss at step 76800: 0.179759
2025-12-13 14:16:23,561 INFO     Training average regularization at step 76900: 0.166913
2025-12-13 14:16:23,561 INFO     Training average positive_sample_loss at step 76900: 0.007895
2025-12-13 14:16:23,561 INFO     Training average negative_sample_loss at step 76900: 0.017432
2025-12-13 14:16:23,561 INFO     Training average loss at step 76900: 0.179577
2025-12-13 14:16:28,777 INFO     Training average regularization at step 77000: 0.166868
2025-12-13 14:16:28,777 INFO     Training average positive_sample_loss at step 77000: 0.007864
2025-12-13 14:16:28,777 INFO     Training average negative_sample_loss at step 77000: 0.024739
2025-12-13 14:16:28,777 INFO     Training average loss at step 77000: 0.183169
2025-12-13 14:16:33,982 INFO     Training average regularization at step 77100: 0.166824
2025-12-13 14:16:33,983 INFO     Training average positive_sample_loss at step 77100: 0.007403
2025-12-13 14:16:33,983 INFO     Training average negative_sample_loss at step 77100: 0.020312
2025-12-13 14:16:33,983 INFO     Training average loss at step 77100: 0.180681
2025-12-13 14:16:39,257 INFO     Training average regularization at step 77200: 0.166779
2025-12-13 14:16:39,257 INFO     Training average positive_sample_loss at step 77200: 0.007357
2025-12-13 14:16:39,257 INFO     Training average negative_sample_loss at step 77200: 0.019722
2025-12-13 14:16:39,257 INFO     Training average loss at step 77200: 0.180318
2025-12-13 14:16:44,582 INFO     Training average regularization at step 77300: 0.166733
2025-12-13 14:16:44,582 INFO     Training average positive_sample_loss at step 77300: 0.008229
2025-12-13 14:16:44,582 INFO     Training average negative_sample_loss at step 77300: 0.025494
2025-12-13 14:16:44,582 INFO     Training average loss at step 77300: 0.183595
2025-12-13 14:16:50,744 INFO     Training average regularization at step 77400: 0.166686
2025-12-13 14:16:50,745 INFO     Training average positive_sample_loss at step 77400: 0.007745
2025-12-13 14:16:50,745 INFO     Training average negative_sample_loss at step 77400: 0.018289
2025-12-13 14:16:50,745 INFO     Training average loss at step 77400: 0.179703
2025-12-13 14:16:56,026 INFO     Training average regularization at step 77500: 0.166636
2025-12-13 14:16:56,026 INFO     Training average positive_sample_loss at step 77500: 0.006218
2025-12-13 14:16:56,026 INFO     Training average negative_sample_loss at step 77500: 0.020176
2025-12-13 14:16:56,026 INFO     Training average loss at step 77500: 0.179833
2025-12-13 14:17:01,224 INFO     Training average regularization at step 77600: 0.166586
2025-12-13 14:17:01,228 INFO     Training average positive_sample_loss at step 77600: 0.006645
2025-12-13 14:17:01,228 INFO     Training average negative_sample_loss at step 77600: 0.021903
2025-12-13 14:17:01,228 INFO     Training average loss at step 77600: 0.180860
2025-12-13 14:17:06,454 INFO     Training average regularization at step 77700: 0.166536
2025-12-13 14:17:06,455 INFO     Training average positive_sample_loss at step 77700: 0.006912
2025-12-13 14:17:06,455 INFO     Training average negative_sample_loss at step 77700: 0.019373
2025-12-13 14:17:06,455 INFO     Training average loss at step 77700: 0.179678
2025-12-13 14:17:11,856 INFO     Training average regularization at step 77800: 0.166487
2025-12-13 14:17:11,857 INFO     Training average positive_sample_loss at step 77800: 0.006746
2025-12-13 14:17:11,857 INFO     Training average negative_sample_loss at step 77800: 0.021174
2025-12-13 14:17:11,857 INFO     Training average loss at step 77800: 0.180447
2025-12-13 14:17:17,155 INFO     Training average regularization at step 77900: 0.166439
2025-12-13 14:17:17,155 INFO     Training average positive_sample_loss at step 77900: 0.006958
2025-12-13 14:17:17,156 INFO     Training average negative_sample_loss at step 77900: 0.021311
2025-12-13 14:17:17,156 INFO     Training average loss at step 77900: 0.180574
2025-12-13 14:17:22,400 INFO     Training average regularization at step 78000: 0.166391
2025-12-13 14:17:22,400 INFO     Training average positive_sample_loss at step 78000: 0.007018
2025-12-13 14:17:22,400 INFO     Training average negative_sample_loss at step 78000: 0.018796
2025-12-13 14:17:22,400 INFO     Training average loss at step 78000: 0.179298
2025-12-13 14:17:27,635 INFO     Training average regularization at step 78100: 0.166343
2025-12-13 14:17:27,636 INFO     Training average positive_sample_loss at step 78100: 0.006894
2025-12-13 14:17:27,636 INFO     Training average negative_sample_loss at step 78100: 0.022247
2025-12-13 14:17:27,636 INFO     Training average loss at step 78100: 0.180914
2025-12-13 14:17:32,977 INFO     Training average regularization at step 78200: 0.166296
2025-12-13 14:17:32,978 INFO     Training average positive_sample_loss at step 78200: 0.007324
2025-12-13 14:17:32,978 INFO     Training average negative_sample_loss at step 78200: 0.021727
2025-12-13 14:17:32,978 INFO     Training average loss at step 78200: 0.180821
2025-12-13 14:17:38,248 INFO     Training average regularization at step 78300: 0.166248
2025-12-13 14:17:38,248 INFO     Training average positive_sample_loss at step 78300: 0.006928
2025-12-13 14:17:38,248 INFO     Training average negative_sample_loss at step 78300: 0.018778
2025-12-13 14:17:38,248 INFO     Training average loss at step 78300: 0.179101
2025-12-13 14:17:43,549 INFO     Training average regularization at step 78400: 0.166200
2025-12-13 14:17:43,549 INFO     Training average positive_sample_loss at step 78400: 0.007503
2025-12-13 14:17:43,549 INFO     Training average negative_sample_loss at step 78400: 0.020580
2025-12-13 14:17:43,549 INFO     Training average loss at step 78400: 0.180241
2025-12-13 14:17:48,847 INFO     Training average regularization at step 78500: 0.166152
2025-12-13 14:17:48,847 INFO     Training average positive_sample_loss at step 78500: 0.007394
2025-12-13 14:17:48,847 INFO     Training average negative_sample_loss at step 78500: 0.024817
2025-12-13 14:17:48,847 INFO     Training average loss at step 78500: 0.182257
2025-12-13 14:17:54,143 INFO     Training average regularization at step 78600: 0.166106
2025-12-13 14:17:54,144 INFO     Training average positive_sample_loss at step 78600: 0.007490
2025-12-13 14:17:54,144 INFO     Training average negative_sample_loss at step 78600: 0.020716
2025-12-13 14:17:54,144 INFO     Training average loss at step 78600: 0.180210
2025-12-13 14:17:59,436 INFO     Training average regularization at step 78700: 0.166061
2025-12-13 14:17:59,436 INFO     Training average positive_sample_loss at step 78700: 0.007234
2025-12-13 14:17:59,436 INFO     Training average negative_sample_loss at step 78700: 0.019822
2025-12-13 14:17:59,436 INFO     Training average loss at step 78700: 0.179589
2025-12-13 14:18:04,749 INFO     Training average regularization at step 78800: 0.166016
2025-12-13 14:18:04,749 INFO     Training average positive_sample_loss at step 78800: 0.007948
2025-12-13 14:18:04,749 INFO     Training average negative_sample_loss at step 78800: 0.021435
2025-12-13 14:18:04,749 INFO     Training average loss at step 78800: 0.180708
2025-12-13 14:18:10,089 INFO     Training average regularization at step 78900: 0.165971
2025-12-13 14:18:10,089 INFO     Training average positive_sample_loss at step 78900: 0.007764
2025-12-13 14:18:10,089 INFO     Training average negative_sample_loss at step 78900: 0.017309
2025-12-13 14:18:10,089 INFO     Training average loss at step 78900: 0.178507
2025-12-13 14:18:15,441 INFO     Training average regularization at step 79000: 0.165926
2025-12-13 14:18:15,441 INFO     Training average positive_sample_loss at step 79000: 0.007387
2025-12-13 14:18:15,442 INFO     Training average negative_sample_loss at step 79000: 0.019026
2025-12-13 14:18:15,442 INFO     Training average loss at step 79000: 0.179133
2025-12-13 14:18:20,663 INFO     Training average regularization at step 79100: 0.165880
2025-12-13 14:18:20,663 INFO     Training average positive_sample_loss at step 79100: 0.007415
2025-12-13 14:18:20,663 INFO     Training average negative_sample_loss at step 79100: 0.023837
2025-12-13 14:18:20,663 INFO     Training average loss at step 79100: 0.181506
2025-12-13 14:18:25,923 INFO     Training average regularization at step 79200: 0.165835
2025-12-13 14:18:25,923 INFO     Training average positive_sample_loss at step 79200: 0.007597
2025-12-13 14:18:25,923 INFO     Training average negative_sample_loss at step 79200: 0.021526
2025-12-13 14:18:25,923 INFO     Training average loss at step 79200: 0.180396
2025-12-13 14:18:31,152 INFO     Training average regularization at step 79300: 0.165790
2025-12-13 14:18:31,152 INFO     Training average positive_sample_loss at step 79300: 0.007361
2025-12-13 14:18:31,153 INFO     Training average negative_sample_loss at step 79300: 0.023031
2025-12-13 14:18:31,153 INFO     Training average loss at step 79300: 0.180986
2025-12-13 14:18:36,429 INFO     Training average regularization at step 79400: 0.165745
2025-12-13 14:18:36,429 INFO     Training average positive_sample_loss at step 79400: 0.007517
2025-12-13 14:18:36,429 INFO     Training average negative_sample_loss at step 79400: 0.020799
2025-12-13 14:18:36,429 INFO     Training average loss at step 79400: 0.179903
2025-12-13 14:18:41,592 INFO     Training average regularization at step 79500: 0.165700
2025-12-13 14:18:41,593 INFO     Training average positive_sample_loss at step 79500: 0.008113
2025-12-13 14:18:41,593 INFO     Training average negative_sample_loss at step 79500: 0.019873
2025-12-13 14:18:41,593 INFO     Training average loss at step 79500: 0.179694
2025-12-13 14:18:46,573 INFO     Training average regularization at step 79600: 0.165657
2025-12-13 14:18:46,573 INFO     Training average positive_sample_loss at step 79600: 0.007424
2025-12-13 14:18:46,573 INFO     Training average negative_sample_loss at step 79600: 0.021356
2025-12-13 14:18:46,574 INFO     Training average loss at step 79600: 0.180047
2025-12-13 14:18:51,468 INFO     Training average regularization at step 79700: 0.165612
2025-12-13 14:18:51,468 INFO     Training average positive_sample_loss at step 79700: 0.007817
2025-12-13 14:18:51,468 INFO     Training average negative_sample_loss at step 79700: 0.021398
2025-12-13 14:18:51,468 INFO     Training average loss at step 79700: 0.180220
2025-12-13 14:18:56,669 INFO     Training average regularization at step 79800: 0.165569
2025-12-13 14:18:56,670 INFO     Training average positive_sample_loss at step 79800: 0.007968
2025-12-13 14:18:56,670 INFO     Training average negative_sample_loss at step 79800: 0.020996
2025-12-13 14:18:56,670 INFO     Training average loss at step 79800: 0.180052
2025-12-13 14:19:01,993 INFO     Training average regularization at step 79900: 0.165528
2025-12-13 14:19:01,993 INFO     Training average positive_sample_loss at step 79900: 0.008332
2025-12-13 14:19:01,993 INFO     Training average negative_sample_loss at step 79900: 0.021672
2025-12-13 14:19:01,993 INFO     Training average loss at step 79900: 0.180530
2025-12-13 14:19:07,271 INFO     Change learning_rate to 0.000003 at step 80000
2025-12-13 14:19:08,110 INFO     Training average regularization at step 80000: 0.165486
2025-12-13 14:19:08,110 INFO     Training average positive_sample_loss at step 80000: 0.007446
2025-12-13 14:19:08,111 INFO     Training average negative_sample_loss at step 80000: 0.026156
2025-12-13 14:19:08,111 INFO     Training average loss at step 80000: 0.182287
2025-12-13 14:19:08,111 INFO     Evaluating on Valid Dataset...
2025-12-13 14:19:08,808 INFO     Evaluating the model... (0/50000)
2025-12-13 14:19:14,001 INFO     Evaluating the model... (500/50000)
2025-12-13 14:19:18,328 INFO     Evaluating the model... (1000/50000)
2025-12-13 14:19:22,874 INFO     Evaluating the model... (1500/50000)
2025-12-13 14:19:27,235 INFO     Evaluating the model... (2000/50000)
2025-12-13 14:19:31,640 INFO     Evaluating the model... (2500/50000)
2025-12-13 14:19:36,400 INFO     Evaluating the model... (3000/50000)
2025-12-13 14:19:40,537 INFO     Evaluating the model... (3500/50000)
2025-12-13 14:19:44,718 INFO     Evaluating the model... (4000/50000)
2025-12-13 14:19:49,108 INFO     Evaluating the model... (4500/50000)
2025-12-13 14:19:54,099 INFO     Evaluating the model... (5000/50000)
2025-12-13 14:19:58,464 INFO     Evaluating the model... (5500/50000)
2025-12-13 14:20:03,044 INFO     Evaluating the model... (6000/50000)
2025-12-13 14:20:07,236 INFO     Evaluating the model... (6500/50000)
2025-12-13 14:20:11,501 INFO     Evaluating the model... (7000/50000)
2025-12-13 14:20:16,517 INFO     Evaluating the model... (7500/50000)
2025-12-13 14:20:20,942 INFO     Evaluating the model... (8000/50000)
2025-12-13 14:20:25,174 INFO     Evaluating the model... (8500/50000)
2025-12-13 14:20:29,614 INFO     Evaluating the model... (9000/50000)
2025-12-13 14:20:33,900 INFO     Evaluating the model... (9500/50000)
2025-12-13 14:20:38,798 INFO     Evaluating the model... (10000/50000)
2025-12-13 14:20:43,274 INFO     Evaluating the model... (10500/50000)
2025-12-13 14:20:47,583 INFO     Evaluating the model... (11000/50000)
2025-12-13 14:20:51,814 INFO     Evaluating the model... (11500/50000)
2025-12-13 14:20:56,231 INFO     Evaluating the model... (12000/50000)
2025-12-13 14:21:01,270 INFO     Evaluating the model... (12500/50000)
2025-12-13 14:21:05,433 INFO     Evaluating the model... (13000/50000)
2025-12-13 14:21:09,654 INFO     Evaluating the model... (13500/50000)
2025-12-13 14:21:13,995 INFO     Evaluating the model... (14000/50000)
2025-12-13 14:21:18,460 INFO     Evaluating the model... (14500/50000)
2025-12-13 14:21:23,765 INFO     Evaluating the model... (15000/50000)
2025-12-13 14:21:27,993 INFO     Evaluating the model... (15500/50000)
2025-12-13 14:21:32,470 INFO     Evaluating the model... (16000/50000)
2025-12-13 14:21:36,816 INFO     Evaluating the model... (16500/50000)
2025-12-13 14:21:41,416 INFO     Evaluating the model... (17000/50000)
2025-12-13 14:21:46,366 INFO     Evaluating the model... (17500/50000)
2025-12-13 14:21:50,797 INFO     Evaluating the model... (18000/50000)
2025-12-13 14:21:55,072 INFO     Evaluating the model... (18500/50000)
2025-12-13 14:21:59,576 INFO     Evaluating the model... (19000/50000)
2025-12-13 14:22:04,018 INFO     Evaluating the model... (19500/50000)
2025-12-13 14:22:09,246 INFO     Evaluating the model... (20000/50000)
2025-12-13 14:22:13,563 INFO     Evaluating the model... (20500/50000)
2025-12-13 14:22:17,933 INFO     Evaluating the model... (21000/50000)
2025-12-13 14:22:22,253 INFO     Evaluating the model... (21500/50000)
2025-12-13 14:22:26,542 INFO     Evaluating the model... (22000/50000)
2025-12-13 14:22:31,932 INFO     Evaluating the model... (22500/50000)
2025-12-13 14:22:36,127 INFO     Evaluating the model... (23000/50000)
2025-12-13 14:22:40,385 INFO     Evaluating the model... (23500/50000)
2025-12-13 14:22:44,575 INFO     Evaluating the model... (24000/50000)
2025-12-13 14:22:49,922 INFO     Evaluating the model... (24500/50000)
2025-12-13 14:22:54,919 INFO     Evaluating the model... (25000/50000)
2025-12-13 14:22:59,338 INFO     Evaluating the model... (25500/50000)
2025-12-13 14:23:03,783 INFO     Evaluating the model... (26000/50000)
2025-12-13 14:23:08,132 INFO     Evaluating the model... (26500/50000)
2025-12-13 14:23:12,496 INFO     Evaluating the model... (27000/50000)
2025-12-13 14:23:17,578 INFO     Evaluating the model... (27500/50000)
2025-12-13 14:23:21,818 INFO     Evaluating the model... (28000/50000)
2025-12-13 14:23:25,997 INFO     Evaluating the model... (28500/50000)
2025-12-13 14:23:30,394 INFO     Evaluating the model... (29000/50000)
2025-12-13 14:23:34,554 INFO     Evaluating the model... (29500/50000)
2025-12-13 14:23:39,265 INFO     Evaluating the model... (30000/50000)
2025-12-13 14:23:43,449 INFO     Evaluating the model... (30500/50000)
2025-12-13 14:23:47,421 INFO     Evaluating the model... (31000/50000)
2025-12-13 14:23:51,405 INFO     Evaluating the model... (31500/50000)
2025-12-13 14:23:55,905 INFO     Evaluating the model... (32000/50000)
2025-12-13 14:24:00,037 INFO     Evaluating the model... (32500/50000)
2025-12-13 14:24:04,008 INFO     Evaluating the model... (33000/50000)
2025-12-13 14:24:08,050 INFO     Evaluating the model... (33500/50000)
2025-12-13 14:24:12,175 INFO     Evaluating the model... (34000/50000)
2025-12-13 14:24:16,475 INFO     Evaluating the model... (34500/50000)
2025-12-13 14:24:20,457 INFO     Evaluating the model... (35000/50000)
2025-12-13 14:24:24,478 INFO     Evaluating the model... (35500/50000)
2025-12-13 14:24:28,618 INFO     Evaluating the model... (36000/50000)
2025-12-13 14:24:32,843 INFO     Evaluating the model... (36500/50000)
2025-12-13 14:24:37,758 INFO     Evaluating the model... (37000/50000)
2025-12-13 14:24:42,189 INFO     Evaluating the model... (37500/50000)
2025-12-13 14:24:46,331 INFO     Evaluating the model... (38000/50000)
2025-12-13 14:24:50,460 INFO     Evaluating the model... (38500/50000)
2025-12-13 14:24:54,588 INFO     Evaluating the model... (39000/50000)
2025-12-13 14:24:59,600 INFO     Evaluating the model... (39500/50000)
2025-12-13 14:25:03,681 INFO     Evaluating the model... (40000/50000)
2025-12-13 14:25:08,168 INFO     Evaluating the model... (40500/50000)
2025-12-13 14:25:12,259 INFO     Evaluating the model... (41000/50000)
2025-12-13 14:25:16,319 INFO     Evaluating the model... (41500/50000)
2025-12-13 14:25:21,391 INFO     Evaluating the model... (42000/50000)
2025-12-13 14:25:25,842 INFO     Evaluating the model... (42500/50000)
2025-12-13 14:25:30,110 INFO     Evaluating the model... (43000/50000)
2025-12-13 14:25:34,365 INFO     Evaluating the model... (43500/50000)
2025-12-13 14:25:38,751 INFO     Evaluating the model... (44000/50000)
2025-12-13 14:25:44,226 INFO     Evaluating the model... (44500/50000)
2025-12-13 14:25:48,495 INFO     Evaluating the model... (45000/50000)
2025-12-13 14:25:52,784 INFO     Evaluating the model... (45500/50000)
2025-12-13 14:25:57,049 INFO     Evaluating the model... (46000/50000)
2025-12-13 14:26:01,300 INFO     Evaluating the model... (46500/50000)
2025-12-13 14:26:06,929 INFO     Evaluating the model... (47000/50000)
2025-12-13 14:26:11,074 INFO     Evaluating the model... (47500/50000)
2025-12-13 14:26:15,245 INFO     Evaluating the model... (48000/50000)
2025-12-13 14:26:19,398 INFO     Evaluating the model... (48500/50000)
2025-12-13 14:26:23,490 INFO     Evaluating the model... (49000/50000)
2025-12-13 14:26:28,739 INFO     Evaluating the model... (49500/50000)
2025-12-13 14:26:32,908 INFO     Valid MRR at step 80000: 0.731567
2025-12-13 14:26:32,909 INFO     Valid MR at step 80000: 255.536620
2025-12-13 14:26:32,909 INFO     Valid HITS@1 at step 80000: 0.666800
2025-12-13 14:26:32,909 INFO     Valid HITS@3 at step 80000: 0.777110
2025-12-13 14:26:32,909 INFO     Valid HITS@10 at step 80000: 0.842250
2025-12-13 14:26:34,317 INFO     Evaluating on Test Dataset...
2025-12-13 14:26:34,968 INFO     Evaluating the model... (0/59072)
2025-12-13 14:26:39,582 INFO     Evaluating the model... (500/59072)
2025-12-13 14:26:44,043 INFO     Evaluating the model... (1000/59072)
2025-12-13 14:26:48,501 INFO     Evaluating the model... (1500/59072)
2025-12-13 14:26:54,330 INFO     Evaluating the model... (2000/59072)
2025-12-13 14:26:59,044 INFO     Evaluating the model... (2500/59072)
2025-12-13 14:27:03,367 INFO     Evaluating the model... (3000/59072)
2025-12-13 14:27:07,958 INFO     Evaluating the model... (3500/59072)
2025-12-13 14:27:12,573 INFO     Evaluating the model... (4000/59072)
2025-12-13 14:27:17,923 INFO     Evaluating the model... (4500/59072)
2025-12-13 14:27:22,302 INFO     Evaluating the model... (5000/59072)
2025-12-13 14:27:26,655 INFO     Evaluating the model... (5500/59072)
2025-12-13 14:27:31,059 INFO     Evaluating the model... (6000/59072)
2025-12-13 14:27:35,462 INFO     Evaluating the model... (6500/59072)
2025-12-13 14:27:40,518 INFO     Evaluating the model... (7000/59072)
2025-12-13 14:27:44,948 INFO     Evaluating the model... (7500/59072)
2025-12-13 14:27:49,427 INFO     Evaluating the model... (8000/59072)
2025-12-13 14:27:53,699 INFO     Evaluating the model... (8500/59072)
2025-12-13 14:27:58,307 INFO     Evaluating the model... (9000/59072)
2025-12-13 14:28:03,716 INFO     Evaluating the model... (9500/59072)
2025-12-13 14:28:08,155 INFO     Evaluating the model... (10000/59072)
2025-12-13 14:28:12,712 INFO     Evaluating the model... (10500/59072)
2025-12-13 14:28:17,016 INFO     Evaluating the model... (11000/59072)
2025-12-13 14:28:22,243 INFO     Evaluating the model... (11500/59072)
2025-12-13 14:28:26,744 INFO     Evaluating the model... (12000/59072)
2025-12-13 14:28:31,033 INFO     Evaluating the model... (12500/59072)
2025-12-13 14:28:35,254 INFO     Evaluating the model... (13000/59072)
2025-12-13 14:28:39,407 INFO     Evaluating the model... (13500/59072)
2025-12-13 14:28:44,864 INFO     Evaluating the model... (14000/59072)
2025-12-13 14:28:49,239 INFO     Evaluating the model... (14500/59072)
2025-12-13 14:28:53,462 INFO     Evaluating the model... (15000/59072)
2025-12-13 14:28:57,812 INFO     Evaluating the model... (15500/59072)
2025-12-13 14:29:02,174 INFO     Evaluating the model... (16000/59072)
2025-12-13 14:29:07,619 INFO     Evaluating the model... (16500/59072)
2025-12-13 14:29:11,801 INFO     Evaluating the model... (17000/59072)
2025-12-13 14:29:15,926 INFO     Evaluating the model... (17500/59072)
2025-12-13 14:29:20,140 INFO     Evaluating the model... (18000/59072)
2025-12-13 14:29:24,586 INFO     Evaluating the model... (18500/59072)
2025-12-13 14:29:29,749 INFO     Evaluating the model... (19000/59072)
2025-12-13 14:29:33,895 INFO     Evaluating the model... (19500/59072)
2025-12-13 14:29:38,032 INFO     Evaluating the model... (20000/59072)
2025-12-13 14:29:42,276 INFO     Evaluating the model... (20500/59072)
2025-12-13 14:29:46,595 INFO     Evaluating the model... (21000/59072)
2025-12-13 14:29:52,211 INFO     Evaluating the model... (21500/59072)
2025-12-13 14:29:56,643 INFO     Evaluating the model... (22000/59072)
2025-12-13 14:30:00,991 INFO     Evaluating the model... (22500/59072)
2025-12-13 14:30:05,324 INFO     Evaluating the model... (23000/59072)
2025-12-13 14:30:09,637 INFO     Evaluating the model... (23500/59072)
2025-12-13 14:30:15,000 INFO     Evaluating the model... (24000/59072)
2025-12-13 14:30:19,170 INFO     Evaluating the model... (24500/59072)
2025-12-13 14:30:23,468 INFO     Evaluating the model... (25000/59072)
2025-12-13 14:30:27,568 INFO     Evaluating the model... (25500/59072)
2025-12-13 14:30:31,743 INFO     Evaluating the model... (26000/59072)
2025-12-13 14:30:37,476 INFO     Evaluating the model... (26500/59072)
2025-12-13 14:30:41,596 INFO     Evaluating the model... (27000/59072)
2025-12-13 14:30:45,775 INFO     Evaluating the model... (27500/59072)
2025-12-13 14:30:50,309 INFO     Evaluating the model... (28000/59072)
2025-12-13 14:30:54,566 INFO     Evaluating the model... (28500/59072)
2025-12-13 14:31:00,487 INFO     Evaluating the model... (29000/59072)
2025-12-13 14:31:04,876 INFO     Evaluating the model... (29500/59072)
2025-12-13 14:31:09,647 INFO     Evaluating the model... (30000/59072)
2025-12-13 14:31:13,869 INFO     Evaluating the model... (30500/59072)
2025-12-13 14:31:19,079 INFO     Evaluating the model... (31000/59072)
2025-12-13 14:31:23,209 INFO     Evaluating the model... (31500/59072)
2025-12-13 14:31:27,377 INFO     Evaluating the model... (32000/59072)
2025-12-13 14:31:31,714 INFO     Evaluating the model... (32500/59072)
2025-12-13 14:31:35,921 INFO     Evaluating the model... (33000/59072)
2025-12-13 14:31:40,991 INFO     Evaluating the model... (33500/59072)
2025-12-13 14:31:45,218 INFO     Evaluating the model... (34000/59072)
2025-12-13 14:31:49,323 INFO     Evaluating the model... (34500/59072)
2025-12-13 14:31:53,424 INFO     Evaluating the model... (35000/59072)
2025-12-13 14:31:57,580 INFO     Evaluating the model... (35500/59072)
2025-12-13 14:32:02,582 INFO     Evaluating the model... (36000/59072)
2025-12-13 14:32:06,741 INFO     Evaluating the model... (36500/59072)
2025-12-13 14:32:10,842 INFO     Evaluating the model... (37000/59072)
2025-12-13 14:32:14,903 INFO     Evaluating the model... (37500/59072)
2025-12-13 14:32:18,938 INFO     Evaluating the model... (38000/59072)
2025-12-13 14:32:23,659 INFO     Evaluating the model... (38500/59072)
2025-12-13 14:32:27,710 INFO     Evaluating the model... (39000/59072)
2025-12-13 14:32:31,661 INFO     Evaluating the model... (39500/59072)
2025-12-13 14:32:35,645 INFO     Evaluating the model... (40000/59072)
2025-12-13 14:32:39,685 INFO     Evaluating the model... (40500/59072)
2025-12-13 14:32:44,631 INFO     Evaluating the model... (41000/59072)
2025-12-13 14:32:48,897 INFO     Evaluating the model... (41500/59072)
2025-12-13 14:32:52,988 INFO     Evaluating the model... (42000/59072)
2025-12-13 14:32:57,268 INFO     Evaluating the model... (42500/59072)
2025-12-13 14:33:02,548 INFO     Evaluating the model... (43000/59072)
2025-12-13 14:33:06,980 INFO     Evaluating the model... (43500/59072)
2025-12-13 14:33:11,347 INFO     Evaluating the model... (44000/59072)
2025-12-13 14:33:15,516 INFO     Evaluating the model... (44500/59072)
2025-12-13 14:33:19,603 INFO     Evaluating the model... (45000/59072)
2025-12-13 14:33:24,762 INFO     Evaluating the model... (45500/59072)
2025-12-13 14:33:29,031 INFO     Evaluating the model... (46000/59072)
2025-12-13 14:33:33,117 INFO     Evaluating the model... (46500/59072)
2025-12-13 14:33:37,429 INFO     Evaluating the model... (47000/59072)
2025-12-13 14:33:41,538 INFO     Evaluating the model... (47500/59072)
2025-12-13 14:33:46,598 INFO     Evaluating the model... (48000/59072)
2025-12-13 14:33:50,785 INFO     Evaluating the model... (48500/59072)
2025-12-13 14:33:55,149 INFO     Evaluating the model... (49000/59072)
2025-12-13 14:33:59,321 INFO     Evaluating the model... (49500/59072)
2025-12-13 14:34:03,605 INFO     Evaluating the model... (50000/59072)
2025-12-13 14:34:08,904 INFO     Evaluating the model... (50500/59072)
2025-12-13 14:34:12,908 INFO     Evaluating the model... (51000/59072)
2025-12-13 14:34:16,942 INFO     Evaluating the model... (51500/59072)
2025-12-13 14:34:20,953 INFO     Evaluating the model... (52000/59072)
2025-12-13 14:34:25,129 INFO     Evaluating the model... (52500/59072)
2025-12-13 14:34:30,116 INFO     Evaluating the model... (53000/59072)
2025-12-13 14:34:34,232 INFO     Evaluating the model... (53500/59072)
2025-12-13 14:34:38,503 INFO     Evaluating the model... (54000/59072)
2025-12-13 14:34:42,824 INFO     Evaluating the model... (54500/59072)
2025-12-13 14:34:47,242 INFO     Evaluating the model... (55000/59072)
2025-12-13 14:34:52,282 INFO     Evaluating the model... (55500/59072)
2025-12-13 14:34:56,412 INFO     Evaluating the model... (56000/59072)
2025-12-13 14:35:00,704 INFO     Evaluating the model... (56500/59072)
2025-12-13 14:35:04,988 INFO     Evaluating the model... (57000/59072)
2025-12-13 14:35:09,038 INFO     Evaluating the model... (57500/59072)
2025-12-13 14:35:14,097 INFO     Evaluating the model... (58000/59072)
2025-12-13 14:35:18,118 INFO     Evaluating the model... (58500/59072)
2025-12-13 14:35:22,401 INFO     Evaluating the model... (59000/59072)
2025-12-13 14:35:23,249 INFO     Test MRR at step 80000: 0.725939
2025-12-13 14:35:23,250 INFO     Test MR at step 80000: 258.396658
2025-12-13 14:35:23,250 INFO     Test HITS@1 at step 80000: 0.660569
2025-12-13 14:35:23,250 INFO     Test HITS@3 at step 80000: 0.771682
2025-12-13 14:35:23,250 INFO     Test HITS@10 at step 80000: 0.838135
2025-12-13 14:35:28,574 INFO     Training average regularization at step 80100: 0.165359
2025-12-13 14:35:28,574 INFO     Training average positive_sample_loss at step 80100: 0.008368
2025-12-13 14:35:28,574 INFO     Training average negative_sample_loss at step 80100: 0.020654
2025-12-13 14:35:28,574 INFO     Training average loss at step 80100: 0.179871
2025-12-13 14:35:33,831 INFO     Training average regularization at step 80200: 0.165235
2025-12-13 14:35:33,831 INFO     Training average positive_sample_loss at step 80200: 0.008365
2025-12-13 14:35:33,831 INFO     Training average negative_sample_loss at step 80200: 0.021891
2025-12-13 14:35:33,831 INFO     Training average loss at step 80200: 0.180363
2025-12-13 14:35:39,054 INFO     Training average regularization at step 80300: 0.165165
2025-12-13 14:35:39,054 INFO     Training average positive_sample_loss at step 80300: 0.008293
2025-12-13 14:35:39,054 INFO     Training average negative_sample_loss at step 80300: 0.021191
2025-12-13 14:35:39,054 INFO     Training average loss at step 80300: 0.179907
2025-12-13 14:35:44,323 INFO     Training average regularization at step 80400: 0.165118
2025-12-13 14:35:44,323 INFO     Training average positive_sample_loss at step 80400: 0.008613
2025-12-13 14:35:44,323 INFO     Training average negative_sample_loss at step 80400: 0.021906
2025-12-13 14:35:44,323 INFO     Training average loss at step 80400: 0.180378
2025-12-13 14:35:49,562 INFO     Training average regularization at step 80500: 0.165084
2025-12-13 14:35:49,562 INFO     Training average positive_sample_loss at step 80500: 0.008060
2025-12-13 14:35:49,562 INFO     Training average negative_sample_loss at step 80500: 0.021692
2025-12-13 14:35:49,562 INFO     Training average loss at step 80500: 0.179960
2025-12-13 14:35:54,772 INFO     Training average regularization at step 80600: 0.165057
2025-12-13 14:35:54,772 INFO     Training average positive_sample_loss at step 80600: 0.008168
2025-12-13 14:35:54,772 INFO     Training average negative_sample_loss at step 80600: 0.020858
2025-12-13 14:35:54,772 INFO     Training average loss at step 80600: 0.179570
2025-12-13 14:36:00,095 INFO     Training average regularization at step 80700: 0.165036
2025-12-13 14:36:00,096 INFO     Training average positive_sample_loss at step 80700: 0.009091
2025-12-13 14:36:00,096 INFO     Training average negative_sample_loss at step 80700: 0.018541
2025-12-13 14:36:00,096 INFO     Training average loss at step 80700: 0.178852
2025-12-13 14:36:05,490 INFO     Training average regularization at step 80800: 0.165018
2025-12-13 14:36:05,490 INFO     Training average positive_sample_loss at step 80800: 0.008190
2025-12-13 14:36:05,490 INFO     Training average negative_sample_loss at step 80800: 0.021469
2025-12-13 14:36:05,490 INFO     Training average loss at step 80800: 0.179848
2025-12-13 14:36:10,802 INFO     Training average regularization at step 80900: 0.165003
2025-12-13 14:36:10,802 INFO     Training average positive_sample_loss at step 80900: 0.008123
2025-12-13 14:36:10,802 INFO     Training average negative_sample_loss at step 80900: 0.022206
2025-12-13 14:36:10,802 INFO     Training average loss at step 80900: 0.180167
2025-12-13 14:36:16,054 INFO     Training average regularization at step 81000: 0.164989
2025-12-13 14:36:16,054 INFO     Training average positive_sample_loss at step 81000: 0.007926
2025-12-13 14:36:16,054 INFO     Training average negative_sample_loss at step 81000: 0.022495
2025-12-13 14:36:16,054 INFO     Training average loss at step 81000: 0.180199
2025-12-13 14:36:21,296 INFO     Training average regularization at step 81100: 0.164976
2025-12-13 14:36:21,296 INFO     Training average positive_sample_loss at step 81100: 0.008934
2025-12-13 14:36:21,296 INFO     Training average negative_sample_loss at step 81100: 0.021637
2025-12-13 14:36:21,296 INFO     Training average loss at step 81100: 0.180262
2025-12-13 14:36:26,528 INFO     Training average regularization at step 81200: 0.164965
2025-12-13 14:36:26,528 INFO     Training average positive_sample_loss at step 81200: 0.008538
2025-12-13 14:36:26,529 INFO     Training average negative_sample_loss at step 81200: 0.018460
2025-12-13 14:36:26,529 INFO     Training average loss at step 81200: 0.178464
2025-12-13 14:36:31,788 INFO     Training average regularization at step 81300: 0.164955
2025-12-13 14:36:31,788 INFO     Training average positive_sample_loss at step 81300: 0.008630
2025-12-13 14:36:31,788 INFO     Training average negative_sample_loss at step 81300: 0.019095
2025-12-13 14:36:31,788 INFO     Training average loss at step 81300: 0.178817
2025-12-13 14:36:36,935 INFO     Training average regularization at step 81400: 0.164945
2025-12-13 14:36:36,935 INFO     Training average positive_sample_loss at step 81400: 0.007808
2025-12-13 14:36:36,935 INFO     Training average negative_sample_loss at step 81400: 0.020066
2025-12-13 14:36:36,935 INFO     Training average loss at step 81400: 0.178882
2025-12-13 14:36:42,197 INFO     Training average regularization at step 81500: 0.164936
2025-12-13 14:36:42,197 INFO     Training average positive_sample_loss at step 81500: 0.008442
2025-12-13 14:36:42,197 INFO     Training average negative_sample_loss at step 81500: 0.021258
2025-12-13 14:36:42,197 INFO     Training average loss at step 81500: 0.179786
2025-12-13 14:36:47,516 INFO     Training average regularization at step 81600: 0.164928
2025-12-13 14:36:47,516 INFO     Training average positive_sample_loss at step 81600: 0.007819
2025-12-13 14:36:47,516 INFO     Training average negative_sample_loss at step 81600: 0.018585
2025-12-13 14:36:47,516 INFO     Training average loss at step 81600: 0.178130
2025-12-13 14:36:52,807 INFO     Training average regularization at step 81700: 0.164920
2025-12-13 14:36:52,808 INFO     Training average positive_sample_loss at step 81700: 0.008032
2025-12-13 14:36:52,808 INFO     Training average negative_sample_loss at step 81700: 0.021096
2025-12-13 14:36:52,808 INFO     Training average loss at step 81700: 0.179484
2025-12-13 14:36:58,095 INFO     Training average regularization at step 81800: 0.164912
2025-12-13 14:36:58,095 INFO     Training average positive_sample_loss at step 81800: 0.007733
2025-12-13 14:36:58,095 INFO     Training average negative_sample_loss at step 81800: 0.021771
2025-12-13 14:36:58,095 INFO     Training average loss at step 81800: 0.179664
2025-12-13 14:37:03,435 INFO     Training average regularization at step 81900: 0.164905
2025-12-13 14:37:03,436 INFO     Training average positive_sample_loss at step 81900: 0.008264
2025-12-13 14:37:03,436 INFO     Training average negative_sample_loss at step 81900: 0.019816
2025-12-13 14:37:03,436 INFO     Training average loss at step 81900: 0.178945
2025-12-13 14:37:08,708 INFO     Training average regularization at step 82000: 0.164898
2025-12-13 14:37:08,708 INFO     Training average positive_sample_loss at step 82000: 0.008312
2025-12-13 14:37:08,708 INFO     Training average negative_sample_loss at step 82000: 0.020754
2025-12-13 14:37:08,708 INFO     Training average loss at step 82000: 0.179431
2025-12-13 14:37:14,116 INFO     Training average regularization at step 82100: 0.164891
2025-12-13 14:37:14,116 INFO     Training average positive_sample_loss at step 82100: 0.007839
2025-12-13 14:37:14,116 INFO     Training average negative_sample_loss at step 82100: 0.015718
2025-12-13 14:37:14,116 INFO     Training average loss at step 82100: 0.176669
2025-12-13 14:37:20,408 INFO     Training average regularization at step 82200: 0.164885
2025-12-13 14:37:20,408 INFO     Training average positive_sample_loss at step 82200: 0.007443
2025-12-13 14:37:20,408 INFO     Training average negative_sample_loss at step 82200: 0.020947
2025-12-13 14:37:20,408 INFO     Training average loss at step 82200: 0.179079
2025-12-13 14:37:25,760 INFO     Training average regularization at step 82300: 0.164878
2025-12-13 14:37:25,760 INFO     Training average positive_sample_loss at step 82300: 0.007513
2025-12-13 14:37:25,760 INFO     Training average negative_sample_loss at step 82300: 0.024932
2025-12-13 14:37:25,760 INFO     Training average loss at step 82300: 0.181100
2025-12-13 14:37:30,994 INFO     Training average regularization at step 82400: 0.164871
2025-12-13 14:37:30,994 INFO     Training average positive_sample_loss at step 82400: 0.007448
2025-12-13 14:37:30,994 INFO     Training average negative_sample_loss at step 82400: 0.022341
2025-12-13 14:37:30,994 INFO     Training average loss at step 82400: 0.179766
2025-12-13 14:37:36,246 INFO     Training average regularization at step 82500: 0.164865
2025-12-13 14:37:36,246 INFO     Training average positive_sample_loss at step 82500: 0.007374
2025-12-13 14:37:36,246 INFO     Training average negative_sample_loss at step 82500: 0.024280
2025-12-13 14:37:36,246 INFO     Training average loss at step 82500: 0.180691
2025-12-13 14:37:41,554 INFO     Training average regularization at step 82600: 0.164858
2025-12-13 14:37:41,554 INFO     Training average positive_sample_loss at step 82600: 0.007117
2025-12-13 14:37:41,554 INFO     Training average negative_sample_loss at step 82600: 0.024743
2025-12-13 14:37:41,554 INFO     Training average loss at step 82600: 0.180789
2025-12-13 14:37:46,786 INFO     Training average regularization at step 82700: 0.164852
2025-12-13 14:37:46,786 INFO     Training average positive_sample_loss at step 82700: 0.007844
2025-12-13 14:37:46,786 INFO     Training average negative_sample_loss at step 82700: 0.026852
2025-12-13 14:37:46,786 INFO     Training average loss at step 82700: 0.182200
2025-12-13 14:37:52,155 INFO     Training average regularization at step 82800: 0.164846
2025-12-13 14:37:52,155 INFO     Training average positive_sample_loss at step 82800: 0.007587
2025-12-13 14:37:52,155 INFO     Training average negative_sample_loss at step 82800: 0.019789
2025-12-13 14:37:52,156 INFO     Training average loss at step 82800: 0.178534
2025-12-13 14:37:57,508 INFO     Training average regularization at step 82900: 0.164840
2025-12-13 14:37:57,508 INFO     Training average positive_sample_loss at step 82900: 0.007668
2025-12-13 14:37:57,508 INFO     Training average negative_sample_loss at step 82900: 0.018536
2025-12-13 14:37:57,508 INFO     Training average loss at step 82900: 0.177942
2025-12-13 14:38:02,881 INFO     Training average regularization at step 83000: 0.164834
2025-12-13 14:38:02,881 INFO     Training average positive_sample_loss at step 83000: 0.007237
2025-12-13 14:38:02,881 INFO     Training average negative_sample_loss at step 83000: 0.022059
2025-12-13 14:38:02,881 INFO     Training average loss at step 83000: 0.179482
2025-12-13 14:38:08,240 INFO     Training average regularization at step 83100: 0.164828
2025-12-13 14:38:08,241 INFO     Training average positive_sample_loss at step 83100: 0.007390
2025-12-13 14:38:08,241 INFO     Training average negative_sample_loss at step 83100: 0.022262
2025-12-13 14:38:08,241 INFO     Training average loss at step 83100: 0.179654
2025-12-13 14:38:13,520 INFO     Training average regularization at step 83200: 0.164822
2025-12-13 14:38:13,521 INFO     Training average positive_sample_loss at step 83200: 0.007725
2025-12-13 14:38:13,521 INFO     Training average negative_sample_loss at step 83200: 0.020802
2025-12-13 14:38:13,521 INFO     Training average loss at step 83200: 0.179085
2025-12-13 14:38:18,788 INFO     Training average regularization at step 83300: 0.164817
2025-12-13 14:38:18,789 INFO     Training average positive_sample_loss at step 83300: 0.007154
2025-12-13 14:38:18,789 INFO     Training average negative_sample_loss at step 83300: 0.021725
2025-12-13 14:38:18,789 INFO     Training average loss at step 83300: 0.179256
2025-12-13 14:38:23,969 INFO     Training average regularization at step 83400: 0.164811
2025-12-13 14:38:23,969 INFO     Training average positive_sample_loss at step 83400: 0.007363
2025-12-13 14:38:23,969 INFO     Training average negative_sample_loss at step 83400: 0.025485
2025-12-13 14:38:23,969 INFO     Training average loss at step 83400: 0.181235
2025-12-13 14:38:29,118 INFO     Training average regularization at step 83500: 0.164806
2025-12-13 14:38:29,119 INFO     Training average positive_sample_loss at step 83500: 0.007120
2025-12-13 14:38:29,119 INFO     Training average negative_sample_loss at step 83500: 0.019459
2025-12-13 14:38:29,119 INFO     Training average loss at step 83500: 0.178095
2025-12-13 14:38:34,226 INFO     Training average regularization at step 83600: 0.164800
2025-12-13 14:38:34,226 INFO     Training average positive_sample_loss at step 83600: 0.007066
2025-12-13 14:38:34,226 INFO     Training average negative_sample_loss at step 83600: 0.022383
2025-12-13 14:38:34,226 INFO     Training average loss at step 83600: 0.179524
2025-12-13 14:38:39,274 INFO     Training average regularization at step 83700: 0.164795
2025-12-13 14:38:39,274 INFO     Training average positive_sample_loss at step 83700: 0.007642
2025-12-13 14:38:39,274 INFO     Training average negative_sample_loss at step 83700: 0.023979
2025-12-13 14:38:39,274 INFO     Training average loss at step 83700: 0.180605
2025-12-13 14:38:44,377 INFO     Training average regularization at step 83800: 0.164789
2025-12-13 14:38:44,378 INFO     Training average positive_sample_loss at step 83800: 0.007907
2025-12-13 14:38:44,378 INFO     Training average negative_sample_loss at step 83800: 0.022305
2025-12-13 14:38:44,378 INFO     Training average loss at step 83800: 0.179895
2025-12-13 14:38:49,350 INFO     Training average regularization at step 83900: 0.164784
2025-12-13 14:38:49,351 INFO     Training average positive_sample_loss at step 83900: 0.007707
2025-12-13 14:38:49,351 INFO     Training average negative_sample_loss at step 83900: 0.019558
2025-12-13 14:38:49,351 INFO     Training average loss at step 83900: 0.178417
2025-12-13 14:38:54,382 INFO     Training average regularization at step 84000: 0.164779
2025-12-13 14:38:54,383 INFO     Training average positive_sample_loss at step 84000: 0.008560
2025-12-13 14:38:54,383 INFO     Training average negative_sample_loss at step 84000: 0.022956
2025-12-13 14:38:54,383 INFO     Training average loss at step 84000: 0.180537
2025-12-13 14:38:59,388 INFO     Training average regularization at step 84100: 0.164774
2025-12-13 14:38:59,389 INFO     Training average positive_sample_loss at step 84100: 0.008203
2025-12-13 14:38:59,389 INFO     Training average negative_sample_loss at step 84100: 0.021251
2025-12-13 14:38:59,389 INFO     Training average loss at step 84100: 0.179501
2025-12-13 14:39:04,369 INFO     Training average regularization at step 84200: 0.164769
2025-12-13 14:39:04,370 INFO     Training average positive_sample_loss at step 84200: 0.007324
2025-12-13 14:39:04,370 INFO     Training average negative_sample_loss at step 84200: 0.021930
2025-12-13 14:39:04,370 INFO     Training average loss at step 84200: 0.179396
2025-12-13 14:39:09,347 INFO     Training average regularization at step 84300: 0.164764
2025-12-13 14:39:09,347 INFO     Training average positive_sample_loss at step 84300: 0.008113
2025-12-13 14:39:09,347 INFO     Training average negative_sample_loss at step 84300: 0.022059
2025-12-13 14:39:09,347 INFO     Training average loss at step 84300: 0.179850
2025-12-13 14:39:14,365 INFO     Training average regularization at step 84400: 0.164759
2025-12-13 14:39:14,365 INFO     Training average positive_sample_loss at step 84400: 0.007478
2025-12-13 14:39:14,365 INFO     Training average negative_sample_loss at step 84400: 0.019913
2025-12-13 14:39:14,365 INFO     Training average loss at step 84400: 0.178455
2025-12-13 14:39:19,342 INFO     Training average regularization at step 84500: 0.164755
2025-12-13 14:39:19,345 INFO     Training average positive_sample_loss at step 84500: 0.007567
2025-12-13 14:39:19,345 INFO     Training average negative_sample_loss at step 84500: 0.018453
2025-12-13 14:39:19,345 INFO     Training average loss at step 84500: 0.177764
2025-12-13 14:39:24,435 INFO     Training average regularization at step 84600: 0.164750
2025-12-13 14:39:24,436 INFO     Training average positive_sample_loss at step 84600: 0.007070
2025-12-13 14:39:24,436 INFO     Training average negative_sample_loss at step 84600: 0.020965
2025-12-13 14:39:24,436 INFO     Training average loss at step 84600: 0.178767
2025-12-13 14:39:29,726 INFO     Training average regularization at step 84700: 0.164745
2025-12-13 14:39:29,727 INFO     Training average positive_sample_loss at step 84700: 0.007486
2025-12-13 14:39:29,727 INFO     Training average negative_sample_loss at step 84700: 0.018942
2025-12-13 14:39:29,727 INFO     Training average loss at step 84700: 0.177959
2025-12-13 14:39:34,987 INFO     Training average regularization at step 84800: 0.164740
2025-12-13 14:39:34,987 INFO     Training average positive_sample_loss at step 84800: 0.007845
2025-12-13 14:39:34,987 INFO     Training average negative_sample_loss at step 84800: 0.020471
2025-12-13 14:39:34,987 INFO     Training average loss at step 84800: 0.178898
2025-12-13 14:39:40,291 INFO     Training average regularization at step 84900: 0.164736
2025-12-13 14:39:40,291 INFO     Training average positive_sample_loss at step 84900: 0.007542
2025-12-13 14:39:40,291 INFO     Training average negative_sample_loss at step 84900: 0.025127
2025-12-13 14:39:40,291 INFO     Training average loss at step 84900: 0.181070
2025-12-13 14:39:45,613 INFO     Training average regularization at step 85000: 0.164731
2025-12-13 14:39:45,613 INFO     Training average positive_sample_loss at step 85000: 0.007163
2025-12-13 14:39:45,613 INFO     Training average negative_sample_loss at step 85000: 0.022823
2025-12-13 14:39:45,613 INFO     Training average loss at step 85000: 0.179724
2025-12-13 14:39:50,901 INFO     Training average regularization at step 85100: 0.164727
2025-12-13 14:39:50,901 INFO     Training average positive_sample_loss at step 85100: 0.009450
2025-12-13 14:39:50,901 INFO     Training average negative_sample_loss at step 85100: 0.020497
2025-12-13 14:39:50,901 INFO     Training average loss at step 85100: 0.179700
2025-12-13 14:39:56,176 INFO     Training average regularization at step 85200: 0.164722
2025-12-13 14:39:56,176 INFO     Training average positive_sample_loss at step 85200: 0.007333
2025-12-13 14:39:56,176 INFO     Training average negative_sample_loss at step 85200: 0.021155
2025-12-13 14:39:56,176 INFO     Training average loss at step 85200: 0.178966
2025-12-13 14:40:01,460 INFO     Training average regularization at step 85300: 0.164718
2025-12-13 14:40:01,460 INFO     Training average positive_sample_loss at step 85300: 0.007153
2025-12-13 14:40:01,460 INFO     Training average negative_sample_loss at step 85300: 0.021328
2025-12-13 14:40:01,460 INFO     Training average loss at step 85300: 0.178958
2025-12-13 14:40:06,787 INFO     Training average regularization at step 85400: 0.164713
2025-12-13 14:40:06,788 INFO     Training average positive_sample_loss at step 85400: 0.007483
2025-12-13 14:40:06,788 INFO     Training average negative_sample_loss at step 85400: 0.021076
2025-12-13 14:40:06,788 INFO     Training average loss at step 85400: 0.178993
2025-12-13 14:40:12,041 INFO     Training average regularization at step 85500: 0.164709
2025-12-13 14:40:12,041 INFO     Training average positive_sample_loss at step 85500: 0.007588
2025-12-13 14:40:12,041 INFO     Training average negative_sample_loss at step 85500: 0.017149
2025-12-13 14:40:12,041 INFO     Training average loss at step 85500: 0.177077
2025-12-13 14:40:17,305 INFO     Training average regularization at step 85600: 0.164704
2025-12-13 14:40:17,305 INFO     Training average positive_sample_loss at step 85600: 0.007963
2025-12-13 14:40:17,305 INFO     Training average negative_sample_loss at step 85600: 0.022622
2025-12-13 14:40:17,305 INFO     Training average loss at step 85600: 0.179997
2025-12-13 14:40:22,472 INFO     Training average regularization at step 85700: 0.164700
2025-12-13 14:40:22,473 INFO     Training average positive_sample_loss at step 85700: 0.007138
2025-12-13 14:40:22,473 INFO     Training average negative_sample_loss at step 85700: 0.019472
2025-12-13 14:40:22,473 INFO     Training average loss at step 85700: 0.178005
2025-12-13 14:40:27,712 INFO     Training average regularization at step 85800: 0.164696
2025-12-13 14:40:27,712 INFO     Training average positive_sample_loss at step 85800: 0.007721
2025-12-13 14:40:27,712 INFO     Training average negative_sample_loss at step 85800: 0.017601
2025-12-13 14:40:27,712 INFO     Training average loss at step 85800: 0.177356
2025-12-13 14:40:33,040 INFO     Training average regularization at step 85900: 0.164691
2025-12-13 14:40:33,040 INFO     Training average positive_sample_loss at step 85900: 0.007299
2025-12-13 14:40:33,040 INFO     Training average negative_sample_loss at step 85900: 0.019083
2025-12-13 14:40:33,040 INFO     Training average loss at step 85900: 0.177882
2025-12-13 14:40:38,338 INFO     Training average regularization at step 86000: 0.164687
2025-12-13 14:40:38,338 INFO     Training average positive_sample_loss at step 86000: 0.007389
2025-12-13 14:40:38,338 INFO     Training average negative_sample_loss at step 86000: 0.023431
2025-12-13 14:40:38,338 INFO     Training average loss at step 86000: 0.180097
2025-12-13 14:40:43,580 INFO     Training average regularization at step 86100: 0.164682
2025-12-13 14:40:43,580 INFO     Training average positive_sample_loss at step 86100: 0.007370
2025-12-13 14:40:43,580 INFO     Training average negative_sample_loss at step 86100: 0.018591
2025-12-13 14:40:43,580 INFO     Training average loss at step 86100: 0.177663
2025-12-13 14:40:48,909 INFO     Training average regularization at step 86200: 0.164678
2025-12-13 14:40:48,910 INFO     Training average positive_sample_loss at step 86200: 0.007517
2025-12-13 14:40:48,910 INFO     Training average negative_sample_loss at step 86200: 0.020573
2025-12-13 14:40:48,910 INFO     Training average loss at step 86200: 0.178723
2025-12-13 14:40:54,211 INFO     Training average regularization at step 86300: 0.164674
2025-12-13 14:40:54,211 INFO     Training average positive_sample_loss at step 86300: 0.007139
2025-12-13 14:40:54,211 INFO     Training average negative_sample_loss at step 86300: 0.020585
2025-12-13 14:40:54,211 INFO     Training average loss at step 86300: 0.178536
2025-12-13 14:40:59,540 INFO     Training average regularization at step 86400: 0.164670
2025-12-13 14:40:59,540 INFO     Training average positive_sample_loss at step 86400: 0.008224
2025-12-13 14:40:59,540 INFO     Training average negative_sample_loss at step 86400: 0.021233
2025-12-13 14:40:59,540 INFO     Training average loss at step 86400: 0.179398
2025-12-13 14:41:04,868 INFO     Training average regularization at step 86500: 0.164665
2025-12-13 14:41:04,868 INFO     Training average positive_sample_loss at step 86500: 0.007632
2025-12-13 14:41:04,868 INFO     Training average negative_sample_loss at step 86500: 0.025169
2025-12-13 14:41:04,868 INFO     Training average loss at step 86500: 0.181066
2025-12-13 14:41:10,175 INFO     Training average regularization at step 86600: 0.164661
2025-12-13 14:41:10,175 INFO     Training average positive_sample_loss at step 86600: 0.008798
2025-12-13 14:41:10,175 INFO     Training average negative_sample_loss at step 86600: 0.018287
2025-12-13 14:41:10,175 INFO     Training average loss at step 86600: 0.178204
2025-12-13 14:41:15,418 INFO     Training average regularization at step 86700: 0.164657
2025-12-13 14:41:15,418 INFO     Training average positive_sample_loss at step 86700: 0.007214
2025-12-13 14:41:15,418 INFO     Training average negative_sample_loss at step 86700: 0.022134
2025-12-13 14:41:15,418 INFO     Training average loss at step 86700: 0.179331
2025-12-13 14:41:20,660 INFO     Training average regularization at step 86800: 0.164653
2025-12-13 14:41:20,660 INFO     Training average positive_sample_loss at step 86800: 0.007519
2025-12-13 14:41:20,660 INFO     Training average negative_sample_loss at step 86800: 0.020251
2025-12-13 14:41:20,660 INFO     Training average loss at step 86800: 0.178538
2025-12-13 14:41:25,899 INFO     Training average regularization at step 86900: 0.164649
2025-12-13 14:41:25,899 INFO     Training average positive_sample_loss at step 86900: 0.007122
2025-12-13 14:41:25,899 INFO     Training average negative_sample_loss at step 86900: 0.021570
2025-12-13 14:41:25,900 INFO     Training average loss at step 86900: 0.178995
2025-12-13 14:41:32,179 INFO     Training average regularization at step 87000: 0.164645
2025-12-13 14:41:32,179 INFO     Training average positive_sample_loss at step 87000: 0.007878
2025-12-13 14:41:32,179 INFO     Training average negative_sample_loss at step 87000: 0.022461
2025-12-13 14:41:32,179 INFO     Training average loss at step 87000: 0.179814
2025-12-13 14:41:37,331 INFO     Training average regularization at step 87100: 0.164640
2025-12-13 14:41:37,331 INFO     Training average positive_sample_loss at step 87100: 0.007707
2025-12-13 14:41:37,331 INFO     Training average negative_sample_loss at step 87100: 0.022888
2025-12-13 14:41:37,331 INFO     Training average loss at step 87100: 0.179938
2025-12-13 14:41:42,551 INFO     Training average regularization at step 87200: 0.164636
2025-12-13 14:41:42,551 INFO     Training average positive_sample_loss at step 87200: 0.008146
2025-12-13 14:41:42,551 INFO     Training average negative_sample_loss at step 87200: 0.017467
2025-12-13 14:41:42,551 INFO     Training average loss at step 87200: 0.177442
2025-12-13 14:41:47,897 INFO     Training average regularization at step 87300: 0.164632
2025-12-13 14:41:47,897 INFO     Training average positive_sample_loss at step 87300: 0.007434
2025-12-13 14:41:47,897 INFO     Training average negative_sample_loss at step 87300: 0.018472
2025-12-13 14:41:47,897 INFO     Training average loss at step 87300: 0.177585
2025-12-13 14:41:53,306 INFO     Training average regularization at step 87400: 0.164628
2025-12-13 14:41:53,307 INFO     Training average positive_sample_loss at step 87400: 0.007455
2025-12-13 14:41:53,307 INFO     Training average negative_sample_loss at step 87400: 0.019108
2025-12-13 14:41:53,307 INFO     Training average loss at step 87400: 0.177909
2025-12-13 14:41:58,634 INFO     Training average regularization at step 87500: 0.164623
2025-12-13 14:41:58,635 INFO     Training average positive_sample_loss at step 87500: 0.008202
2025-12-13 14:41:58,635 INFO     Training average negative_sample_loss at step 87500: 0.022838
2025-12-13 14:41:58,635 INFO     Training average loss at step 87500: 0.180144
2025-12-13 14:42:03,945 INFO     Training average regularization at step 87600: 0.164619
2025-12-13 14:42:03,946 INFO     Training average positive_sample_loss at step 87600: 0.007352
2025-12-13 14:42:03,946 INFO     Training average negative_sample_loss at step 87600: 0.019171
2025-12-13 14:42:03,946 INFO     Training average loss at step 87600: 0.177881
2025-12-13 14:42:09,243 INFO     Training average regularization at step 87700: 0.164614
2025-12-13 14:42:09,243 INFO     Training average positive_sample_loss at step 87700: 0.007602
2025-12-13 14:42:09,244 INFO     Training average negative_sample_loss at step 87700: 0.022279
2025-12-13 14:42:09,244 INFO     Training average loss at step 87700: 0.179555
2025-12-13 14:42:14,488 INFO     Training average regularization at step 87800: 0.164610
2025-12-13 14:42:14,489 INFO     Training average positive_sample_loss at step 87800: 0.008065
2025-12-13 14:42:14,489 INFO     Training average negative_sample_loss at step 87800: 0.020646
2025-12-13 14:42:14,489 INFO     Training average loss at step 87800: 0.178965
2025-12-13 14:42:19,774 INFO     Training average regularization at step 87900: 0.164606
2025-12-13 14:42:19,775 INFO     Training average positive_sample_loss at step 87900: 0.007105
2025-12-13 14:42:19,775 INFO     Training average negative_sample_loss at step 87900: 0.022297
2025-12-13 14:42:19,775 INFO     Training average loss at step 87900: 0.179307
2025-12-13 14:42:25,041 INFO     Training average regularization at step 88000: 0.164601
2025-12-13 14:42:25,041 INFO     Training average positive_sample_loss at step 88000: 0.007767
2025-12-13 14:42:25,041 INFO     Training average negative_sample_loss at step 88000: 0.023055
2025-12-13 14:42:25,041 INFO     Training average loss at step 88000: 0.180012
2025-12-13 14:42:30,290 INFO     Training average regularization at step 88100: 0.164597
2025-12-13 14:42:30,291 INFO     Training average positive_sample_loss at step 88100: 0.007517
2025-12-13 14:42:30,291 INFO     Training average negative_sample_loss at step 88100: 0.022393
2025-12-13 14:42:30,291 INFO     Training average loss at step 88100: 0.179552
2025-12-13 14:42:35,539 INFO     Training average regularization at step 88200: 0.164592
2025-12-13 14:42:35,540 INFO     Training average positive_sample_loss at step 88200: 0.007533
2025-12-13 14:42:35,540 INFO     Training average negative_sample_loss at step 88200: 0.021582
2025-12-13 14:42:35,540 INFO     Training average loss at step 88200: 0.179150
2025-12-13 14:42:40,788 INFO     Training average regularization at step 88300: 0.164588
2025-12-13 14:42:40,789 INFO     Training average positive_sample_loss at step 88300: 0.006846
2025-12-13 14:42:40,789 INFO     Training average negative_sample_loss at step 88300: 0.023673
2025-12-13 14:42:40,789 INFO     Training average loss at step 88300: 0.179847
2025-12-13 14:42:46,119 INFO     Training average regularization at step 88400: 0.164584
2025-12-13 14:42:46,119 INFO     Training average positive_sample_loss at step 88400: 0.008228
2025-12-13 14:42:46,119 INFO     Training average negative_sample_loss at step 88400: 0.016708
2025-12-13 14:42:46,119 INFO     Training average loss at step 88400: 0.177052
2025-12-13 14:42:51,449 INFO     Training average regularization at step 88500: 0.164580
2025-12-13 14:42:51,449 INFO     Training average positive_sample_loss at step 88500: 0.008056
2025-12-13 14:42:51,449 INFO     Training average negative_sample_loss at step 88500: 0.019581
2025-12-13 14:42:51,449 INFO     Training average loss at step 88500: 0.178398
2025-12-13 14:42:56,781 INFO     Training average regularization at step 88600: 0.164575
2025-12-13 14:42:56,781 INFO     Training average positive_sample_loss at step 88600: 0.007471
2025-12-13 14:42:56,781 INFO     Training average negative_sample_loss at step 88600: 0.023457
2025-12-13 14:42:56,781 INFO     Training average loss at step 88600: 0.180039
2025-12-13 14:43:02,133 INFO     Training average regularization at step 88700: 0.164571
2025-12-13 14:43:02,133 INFO     Training average positive_sample_loss at step 88700: 0.007125
2025-12-13 14:43:02,133 INFO     Training average negative_sample_loss at step 88700: 0.023994
2025-12-13 14:43:02,133 INFO     Training average loss at step 88700: 0.180131
2025-12-13 14:43:07,374 INFO     Training average regularization at step 88800: 0.164567
2025-12-13 14:43:07,374 INFO     Training average positive_sample_loss at step 88800: 0.007947
2025-12-13 14:43:07,374 INFO     Training average negative_sample_loss at step 88800: 0.019363
2025-12-13 14:43:07,374 INFO     Training average loss at step 88800: 0.178221
2025-12-13 14:43:12,617 INFO     Training average regularization at step 88900: 0.164562
2025-12-13 14:43:12,618 INFO     Training average positive_sample_loss at step 88900: 0.007384
2025-12-13 14:43:12,618 INFO     Training average negative_sample_loss at step 88900: 0.019588
2025-12-13 14:43:12,618 INFO     Training average loss at step 88900: 0.178048
2025-12-13 14:43:17,864 INFO     Training average regularization at step 89000: 0.164558
2025-12-13 14:43:17,864 INFO     Training average positive_sample_loss at step 89000: 0.007181
2025-12-13 14:43:17,864 INFO     Training average negative_sample_loss at step 89000: 0.021839
2025-12-13 14:43:17,864 INFO     Training average loss at step 89000: 0.179068
2025-12-13 14:43:22,973 INFO     Training average regularization at step 89100: 0.164554
2025-12-13 14:43:22,974 INFO     Training average positive_sample_loss at step 89100: 0.007601
2025-12-13 14:43:22,974 INFO     Training average negative_sample_loss at step 89100: 0.021987
2025-12-13 14:43:22,974 INFO     Training average loss at step 89100: 0.179348
2025-12-13 14:43:27,791 INFO     Training average regularization at step 89200: 0.164550
2025-12-13 14:43:27,791 INFO     Training average positive_sample_loss at step 89200: 0.007299
2025-12-13 14:43:27,792 INFO     Training average negative_sample_loss at step 89200: 0.021502
2025-12-13 14:43:27,792 INFO     Training average loss at step 89200: 0.178950
2025-12-13 14:43:33,034 INFO     Training average regularization at step 89300: 0.164546
2025-12-13 14:43:33,034 INFO     Training average positive_sample_loss at step 89300: 0.007329
2025-12-13 14:43:33,034 INFO     Training average negative_sample_loss at step 89300: 0.017247
2025-12-13 14:43:33,034 INFO     Training average loss at step 89300: 0.176834
2025-12-13 14:43:38,275 INFO     Training average regularization at step 89400: 0.164542
2025-12-13 14:43:38,275 INFO     Training average positive_sample_loss at step 89400: 0.007199
2025-12-13 14:43:38,275 INFO     Training average negative_sample_loss at step 89400: 0.019906
2025-12-13 14:43:38,275 INFO     Training average loss at step 89400: 0.178094
2025-12-13 14:43:43,591 INFO     Training average regularization at step 89500: 0.164537
2025-12-13 14:43:43,592 INFO     Training average positive_sample_loss at step 89500: 0.007193
2025-12-13 14:43:43,592 INFO     Training average negative_sample_loss at step 89500: 0.022394
2025-12-13 14:43:43,592 INFO     Training average loss at step 89500: 0.179331
2025-12-13 14:43:48,918 INFO     Training average regularization at step 89600: 0.164533
2025-12-13 14:43:48,918 INFO     Training average positive_sample_loss at step 89600: 0.007815
2025-12-13 14:43:48,918 INFO     Training average negative_sample_loss at step 89600: 0.023008
2025-12-13 14:43:48,918 INFO     Training average loss at step 89600: 0.179945
2025-12-13 14:43:54,215 INFO     Training average regularization at step 89700: 0.164529
2025-12-13 14:43:54,215 INFO     Training average positive_sample_loss at step 89700: 0.007876
2025-12-13 14:43:54,215 INFO     Training average negative_sample_loss at step 89700: 0.024695
2025-12-13 14:43:54,215 INFO     Training average loss at step 89700: 0.180814
2025-12-13 14:43:59,467 INFO     Training average regularization at step 89800: 0.164525
2025-12-13 14:43:59,467 INFO     Training average positive_sample_loss at step 89800: 0.006833
2025-12-13 14:43:59,467 INFO     Training average negative_sample_loss at step 89800: 0.020805
2025-12-13 14:43:59,467 INFO     Training average loss at step 89800: 0.178344
2025-12-13 14:44:04,742 INFO     Training average regularization at step 89900: 0.164521
2025-12-13 14:44:04,742 INFO     Training average positive_sample_loss at step 89900: 0.008319
2025-12-13 14:44:04,742 INFO     Training average negative_sample_loss at step 89900: 0.021341
2025-12-13 14:44:04,742 INFO     Training average loss at step 89900: 0.179350
2025-12-13 14:44:10,054 INFO     Training average regularization at step 90000: 0.164516
2025-12-13 14:44:10,056 INFO     Training average positive_sample_loss at step 90000: 0.007611
2025-12-13 14:44:10,056 INFO     Training average negative_sample_loss at step 90000: 0.016992
2025-12-13 14:44:10,056 INFO     Training average loss at step 90000: 0.176818
2025-12-13 14:44:10,056 INFO     Evaluating on Valid Dataset...
2025-12-13 14:44:10,752 INFO     Evaluating the model... (0/50000)
2025-12-13 14:44:15,376 INFO     Evaluating the model... (500/50000)
2025-12-13 14:44:21,037 INFO     Evaluating the model... (1000/50000)
2025-12-13 14:44:25,680 INFO     Evaluating the model... (1500/50000)
2025-12-13 14:44:29,935 INFO     Evaluating the model... (2000/50000)
2025-12-13 14:44:34,328 INFO     Evaluating the model... (2500/50000)
2025-12-13 14:44:38,872 INFO     Evaluating the model... (3000/50000)
2025-12-13 14:44:44,566 INFO     Evaluating the model... (3500/50000)
2025-12-13 14:44:49,149 INFO     Evaluating the model... (4000/50000)
2025-12-13 14:44:54,214 INFO     Evaluating the model... (4500/50000)
2025-12-13 14:44:58,878 INFO     Evaluating the model... (5000/50000)
2025-12-13 14:45:03,355 INFO     Evaluating the model... (5500/50000)
2025-12-13 14:45:08,460 INFO     Evaluating the model... (6000/50000)
2025-12-13 14:45:12,820 INFO     Evaluating the model... (6500/50000)
2025-12-13 14:45:17,395 INFO     Evaluating the model... (7000/50000)
2025-12-13 14:45:22,282 INFO     Evaluating the model... (7500/50000)
2025-12-13 14:45:27,861 INFO     Evaluating the model... (8000/50000)
2025-12-13 14:45:32,290 INFO     Evaluating the model... (8500/50000)
2025-12-13 14:45:36,876 INFO     Evaluating the model... (9000/50000)
2025-12-13 14:45:41,752 INFO     Evaluating the model... (9500/50000)
2025-12-13 14:45:46,533 INFO     Evaluating the model... (10000/50000)
2025-12-13 14:45:51,813 INFO     Evaluating the model... (10500/50000)
2025-12-13 14:45:56,426 INFO     Evaluating the model... (11000/50000)
2025-12-13 14:46:00,894 INFO     Evaluating the model... (11500/50000)
2025-12-13 14:46:05,405 INFO     Evaluating the model... (12000/50000)
2025-12-13 14:46:09,974 INFO     Evaluating the model... (12500/50000)
2025-12-13 14:46:15,483 INFO     Evaluating the model... (13000/50000)
2025-12-13 14:46:20,104 INFO     Evaluating the model... (13500/50000)
2025-12-13 14:46:24,655 INFO     Evaluating the model... (14000/50000)
2025-12-13 14:46:29,426 INFO     Evaluating the model... (14500/50000)
2025-12-13 14:46:34,307 INFO     Evaluating the model... (15000/50000)
2025-12-13 14:46:39,945 INFO     Evaluating the model... (15500/50000)
2025-12-13 14:46:44,595 INFO     Evaluating the model... (16000/50000)
2025-12-13 14:46:49,546 INFO     Evaluating the model... (16500/50000)
2025-12-13 14:46:54,403 INFO     Evaluating the model... (17000/50000)
2025-12-13 14:46:58,950 INFO     Evaluating the model... (17500/50000)
2025-12-13 14:47:05,036 INFO     Evaluating the model... (18000/50000)
2025-12-13 14:47:09,961 INFO     Evaluating the model... (18500/50000)
2025-12-13 14:47:14,561 INFO     Evaluating the model... (19000/50000)
2025-12-13 14:47:19,150 INFO     Evaluating the model... (19500/50000)
2025-12-13 14:47:23,912 INFO     Evaluating the model... (20000/50000)
2025-12-13 14:47:29,999 INFO     Evaluating the model... (20500/50000)
2025-12-13 14:47:34,233 INFO     Evaluating the model... (21000/50000)
2025-12-13 14:47:38,418 INFO     Evaluating the model... (21500/50000)
2025-12-13 14:47:42,540 INFO     Evaluating the model... (22000/50000)
2025-12-13 14:47:46,723 INFO     Evaluating the model... (22500/50000)
2025-12-13 14:47:52,202 INFO     Evaluating the model... (23000/50000)
2025-12-13 14:47:56,383 INFO     Evaluating the model... (23500/50000)
2025-12-13 14:48:00,736 INFO     Evaluating the model... (24000/50000)
2025-12-13 14:48:04,968 INFO     Evaluating the model... (24500/50000)
2025-12-13 14:48:09,666 INFO     Evaluating the model... (25000/50000)
2025-12-13 14:48:15,005 INFO     Evaluating the model... (25500/50000)
2025-12-13 14:48:19,441 INFO     Evaluating the model... (26000/50000)
2025-12-13 14:48:23,756 INFO     Evaluating the model... (26500/50000)
2025-12-13 14:48:28,199 INFO     Evaluating the model... (27000/50000)
2025-12-13 14:48:32,738 INFO     Evaluating the model... (27500/50000)
2025-12-13 14:48:37,764 INFO     Evaluating the model... (28000/50000)
2025-12-13 14:48:42,176 INFO     Evaluating the model... (28500/50000)
2025-12-13 14:48:46,806 INFO     Evaluating the model... (29000/50000)
2025-12-13 14:48:51,303 INFO     Evaluating the model... (29500/50000)
2025-12-13 14:48:55,743 INFO     Evaluating the model... (30000/50000)
2025-12-13 14:49:01,284 INFO     Evaluating the model... (30500/50000)
2025-12-13 14:49:06,506 INFO     Evaluating the model... (31000/50000)
2025-12-13 14:49:11,252 INFO     Evaluating the model... (31500/50000)
2025-12-13 14:49:16,973 INFO     Evaluating the model... (32000/50000)
2025-12-13 14:49:22,561 INFO     Evaluating the model... (32500/50000)
2025-12-13 14:49:28,537 INFO     Evaluating the model... (33000/50000)
2025-12-13 14:49:33,873 INFO     Evaluating the model... (33500/50000)
2025-12-13 14:49:39,621 INFO     Evaluating the model... (34000/50000)
2025-12-13 14:49:44,235 INFO     Evaluating the model... (34500/50000)
2025-12-13 14:49:49,251 INFO     Evaluating the model... (35000/50000)
2025-12-13 14:49:54,589 INFO     Evaluating the model... (35500/50000)
2025-12-13 14:49:59,915 INFO     Evaluating the model... (36000/50000)
2025-12-13 14:50:05,163 INFO     Evaluating the model... (36500/50000)
2025-12-13 14:50:11,410 INFO     Evaluating the model... (37000/50000)
2025-12-13 14:50:17,992 INFO     Evaluating the model... (37500/50000)
2025-12-13 14:50:22,647 INFO     Evaluating the model... (38000/50000)
2025-12-13 14:50:28,861 INFO     Evaluating the model... (38500/50000)
2025-12-13 14:50:34,953 INFO     Evaluating the model... (39000/50000)
2025-12-13 14:50:39,659 INFO     Evaluating the model... (39500/50000)
2025-12-13 14:50:46,244 INFO     Evaluating the model... (40000/50000)
2025-12-13 14:50:51,638 INFO     Evaluating the model... (40500/50000)
2025-12-13 14:50:56,114 INFO     Evaluating the model... (41000/50000)
2025-12-13 14:51:01,295 INFO     Evaluating the model... (41500/50000)
2025-12-13 14:51:07,818 INFO     Evaluating the model... (42000/50000)
2025-12-13 14:51:14,309 INFO     Evaluating the model... (42500/50000)
2025-12-13 14:51:19,786 INFO     Evaluating the model... (43000/50000)
2025-12-13 14:51:24,823 INFO     Evaluating the model... (43500/50000)
2025-12-13 14:51:29,409 INFO     Evaluating the model... (44000/50000)
2025-12-13 14:51:33,776 INFO     Evaluating the model... (44500/50000)
2025-12-13 14:51:39,352 INFO     Evaluating the model... (45000/50000)
2025-12-13 14:51:44,160 INFO     Evaluating the model... (45500/50000)
2025-12-13 14:51:48,760 INFO     Evaluating the model... (46000/50000)
2025-12-13 14:51:53,664 INFO     Evaluating the model... (46500/50000)
2025-12-13 14:51:59,063 INFO     Evaluating the model... (47000/50000)
2025-12-13 14:52:05,377 INFO     Evaluating the model... (47500/50000)
2025-12-13 14:52:10,320 INFO     Evaluating the model... (48000/50000)
2025-12-13 14:52:16,770 INFO     Evaluating the model... (48500/50000)
2025-12-13 14:52:22,154 INFO     Evaluating the model... (49000/50000)
2025-12-13 14:52:27,597 INFO     Evaluating the model... (49500/50000)
2025-12-13 14:52:36,109 INFO     Valid MRR at step 90000: 0.733445
2025-12-13 14:52:36,109 INFO     Valid MR at step 90000: 255.456410
2025-12-13 14:52:36,109 INFO     Valid HITS@1 at step 90000: 0.669000
2025-12-13 14:52:36,109 INFO     Valid HITS@3 at step 90000: 0.779050
2025-12-13 14:52:36,109 INFO     Valid HITS@10 at step 90000: 0.843400
2025-12-13 14:52:38,000 INFO     Evaluating on Test Dataset...
2025-12-13 14:52:38,698 INFO     Evaluating the model... (0/59072)
2025-12-13 14:52:43,336 INFO     Evaluating the model... (500/59072)
2025-12-13 14:52:48,664 INFO     Evaluating the model... (1000/59072)
2025-12-13 14:52:54,109 INFO     Evaluating the model... (1500/59072)
2025-12-13 14:52:59,138 INFO     Evaluating the model... (2000/59072)
2025-12-13 14:53:05,061 INFO     Evaluating the model... (2500/59072)
2025-12-13 14:53:11,405 INFO     Evaluating the model... (3000/59072)
2025-12-13 14:53:17,295 INFO     Evaluating the model... (3500/59072)
2025-12-13 14:53:22,323 INFO     Evaluating the model... (4000/59072)
2025-12-13 14:53:28,756 INFO     Evaluating the model... (4500/59072)
2025-12-13 14:53:35,449 INFO     Evaluating the model... (5000/59072)
2025-12-13 14:53:40,529 INFO     Evaluating the model... (5500/59072)
2025-12-13 14:53:46,225 INFO     Evaluating the model... (6000/59072)
2025-12-13 14:53:51,316 INFO     Evaluating the model... (6500/59072)
2025-12-13 14:53:56,153 INFO     Evaluating the model... (7000/59072)
2025-12-13 14:54:02,888 INFO     Evaluating the model... (7500/59072)
2025-12-13 14:54:08,308 INFO     Evaluating the model... (8000/59072)
2025-12-13 14:54:13,260 INFO     Evaluating the model... (8500/59072)
2025-12-13 14:54:18,414 INFO     Evaluating the model... (9000/59072)
2025-12-13 14:54:22,989 INFO     Evaluating the model... (9500/59072)
2025-12-13 14:54:28,220 INFO     Evaluating the model... (10000/59072)
2025-12-13 14:54:32,918 INFO     Evaluating the model... (10500/59072)
2025-12-13 14:54:37,633 INFO     Evaluating the model... (11000/59072)
2025-12-13 14:54:42,700 INFO     Evaluating the model... (11500/59072)
2025-12-13 14:54:47,324 INFO     Evaluating the model... (12000/59072)
2025-12-13 14:54:53,444 INFO     Evaluating the model... (12500/59072)
2025-12-13 14:54:59,133 INFO     Evaluating the model... (13000/59072)
2025-12-13 14:55:04,097 INFO     Evaluating the model... (13500/59072)
2025-12-13 14:55:09,164 INFO     Evaluating the model... (14000/59072)
2025-12-13 14:55:16,203 INFO     Evaluating the model... (14500/59072)
2025-12-13 14:55:20,922 INFO     Evaluating the model... (15000/59072)
2025-12-13 14:55:26,186 INFO     Evaluating the model... (15500/59072)
2025-12-13 14:55:32,505 INFO     Evaluating the model... (16000/59072)
2025-12-13 14:55:37,705 INFO     Evaluating the model... (16500/59072)
2025-12-13 14:55:43,576 INFO     Evaluating the model... (17000/59072)
2025-12-13 14:55:48,802 INFO     Evaluating the model... (17500/59072)
2025-12-13 14:55:53,900 INFO     Evaluating the model... (18000/59072)
2025-12-13 14:55:58,423 INFO     Evaluating the model... (18500/59072)
2025-12-13 14:56:04,740 INFO     Evaluating the model... (19000/59072)
2025-12-13 14:56:11,876 INFO     Evaluating the model... (19500/59072)
2025-12-13 14:56:16,471 INFO     Evaluating the model... (20000/59072)
2025-12-13 14:56:22,507 INFO     Evaluating the model... (20500/59072)
2025-12-13 14:56:28,302 INFO     Evaluating the model... (21000/59072)
2025-12-13 14:56:33,014 INFO     Evaluating the model... (21500/59072)
2025-12-13 14:56:39,367 INFO     Evaluating the model... (22000/59072)
2025-12-13 14:56:44,622 INFO     Evaluating the model... (22500/59072)
2025-12-13 14:56:49,132 INFO     Evaluating the model... (23000/59072)
2025-12-13 14:56:53,966 INFO     Evaluating the model... (23500/59072)
2025-12-13 14:56:59,901 INFO     Evaluating the model... (24000/59072)
2025-12-13 14:57:05,766 INFO     Evaluating the model... (24500/59072)
2025-12-13 14:57:10,336 INFO     Evaluating the model... (25000/59072)
2025-12-13 14:57:14,925 INFO     Evaluating the model... (25500/59072)
2025-12-13 14:57:19,964 INFO     Evaluating the model... (26000/59072)
2025-12-13 14:57:25,088 INFO     Evaluating the model... (26500/59072)
2025-12-13 14:57:31,585 INFO     Evaluating the model... (27000/59072)
2025-12-13 14:57:37,901 INFO     Evaluating the model... (27500/59072)
2025-12-13 14:57:42,521 INFO     Evaluating the model... (28000/59072)
2025-12-13 14:57:47,383 INFO     Evaluating the model... (28500/59072)
2025-12-13 14:57:53,066 INFO     Evaluating the model... (29000/59072)
2025-12-13 14:57:59,167 INFO     Evaluating the model... (29500/59072)
2025-12-13 14:58:05,141 INFO     Evaluating the model... (30000/59072)
2025-12-13 14:58:11,130 INFO     Evaluating the model... (30500/59072)
2025-12-13 14:58:16,556 INFO     Evaluating the model... (31000/59072)
2025-12-13 14:58:23,070 INFO     Evaluating the model... (31500/59072)
2025-12-13 14:58:29,251 INFO     Evaluating the model... (32000/59072)
2025-12-13 14:58:34,831 INFO     Evaluating the model... (32500/59072)
2025-12-13 14:58:39,673 INFO     Evaluating the model... (33000/59072)
2025-12-13 14:58:45,098 INFO     Evaluating the model... (33500/59072)
2025-12-13 14:58:50,545 INFO     Evaluating the model... (34000/59072)
2025-12-13 14:58:55,187 INFO     Evaluating the model... (34500/59072)
2025-12-13 14:59:00,679 INFO     Evaluating the model... (35000/59072)
2025-12-13 14:59:06,615 INFO     Evaluating the model... (35500/59072)
2025-12-13 14:59:11,800 INFO     Evaluating the model... (36000/59072)
2025-12-13 14:59:18,813 INFO     Evaluating the model... (36500/59072)
2025-12-13 14:59:24,986 INFO     Evaluating the model... (37000/59072)
2025-12-13 14:59:29,774 INFO     Evaluating the model... (37500/59072)
2025-12-13 14:59:35,837 INFO     Evaluating the model... (38000/59072)
2025-12-13 14:59:40,856 INFO     Evaluating the model... (38500/59072)
2025-12-13 14:59:46,707 INFO     Evaluating the model... (39000/59072)
2025-12-13 14:59:51,358 INFO     Evaluating the model... (39500/59072)
2025-12-13 14:59:56,193 INFO     Evaluating the model... (40000/59072)
2025-12-13 15:00:01,332 INFO     Evaluating the model... (40500/59072)
2025-12-13 15:00:06,086 INFO     Evaluating the model... (41000/59072)
2025-12-13 15:00:13,076 INFO     Evaluating the model... (41500/59072)
2025-12-13 15:00:19,054 INFO     Evaluating the model... (42000/59072)
2025-12-13 15:00:23,545 INFO     Evaluating the model... (42500/59072)
2025-12-13 15:00:29,465 INFO     Evaluating the model... (43000/59072)
2025-12-13 15:00:36,232 INFO     Evaluating the model... (43500/59072)
2025-12-13 15:00:41,337 INFO     Evaluating the model... (44000/59072)
2025-12-13 15:00:46,484 INFO     Evaluating the model... (44500/59072)
2025-12-13 15:00:51,932 INFO     Evaluating the model... (45000/59072)
2025-12-13 15:00:56,624 INFO     Evaluating the model... (45500/59072)
2025-12-13 15:01:02,322 INFO     Evaluating the model... (46000/59072)
2025-12-13 15:01:07,144 INFO     Evaluating the model... (46500/59072)
2025-12-13 15:01:12,292 INFO     Evaluating the model... (47000/59072)
2025-12-13 15:01:16,936 INFO     Evaluating the model... (47500/59072)
2025-12-13 15:01:22,971 INFO     Evaluating the model... (48000/59072)
2025-12-13 15:01:29,927 INFO     Evaluating the model... (48500/59072)
2025-12-13 15:01:34,638 INFO     Evaluating the model... (49000/59072)
2025-12-13 15:01:40,320 INFO     Evaluating the model... (49500/59072)
2025-12-13 15:01:45,681 INFO     Evaluating the model... (50000/59072)
2025-12-13 15:01:50,222 INFO     Evaluating the model... (50500/59072)
2025-12-13 15:01:56,675 INFO     Evaluating the model... (51000/59072)
2025-12-13 15:02:02,825 INFO     Evaluating the model... (51500/59072)
2025-12-13 15:02:07,722 INFO     Evaluating the model... (52000/59072)
2025-12-13 15:02:12,560 INFO     Evaluating the model... (52500/59072)
2025-12-13 15:02:17,261 INFO     Evaluating the model... (53000/59072)
2025-12-13 15:02:23,222 INFO     Evaluating the model... (53500/59072)
2025-12-13 15:02:27,843 INFO     Evaluating the model... (54000/59072)
2025-12-13 15:02:34,106 INFO     Evaluating the model... (54500/59072)
2025-12-13 15:02:39,425 INFO     Evaluating the model... (55000/59072)
2025-12-13 15:02:43,889 INFO     Evaluating the model... (55500/59072)
2025-12-13 15:02:50,863 INFO     Evaluating the model... (56000/59072)
2025-12-13 15:02:56,009 INFO     Evaluating the model... (56500/59072)
2025-12-13 15:03:00,774 INFO     Evaluating the model... (57000/59072)
2025-12-13 15:03:05,969 INFO     Evaluating the model... (57500/59072)
2025-12-13 15:03:10,957 INFO     Evaluating the model... (58000/59072)
2025-12-13 15:03:17,215 INFO     Evaluating the model... (58500/59072)
2025-12-13 15:03:23,103 INFO     Evaluating the model... (59000/59072)
2025-12-13 15:03:24,429 INFO     Test MRR at step 90000: 0.727612
2025-12-13 15:03:24,429 INFO     Test MR at step 90000: 258.255785
2025-12-13 15:03:24,429 INFO     Test HITS@1 at step 90000: 0.662212
2025-12-13 15:03:24,429 INFO     Test HITS@3 at step 90000: 0.773713
2025-12-13 15:03:24,429 INFO     Test HITS@10 at step 90000: 0.839287
2025-12-13 15:03:29,622 INFO     Training average regularization at step 90100: 0.164512
2025-12-13 15:03:29,627 INFO     Training average positive_sample_loss at step 90100: 0.007838
2025-12-13 15:03:29,627 INFO     Training average negative_sample_loss at step 90100: 0.019507
2025-12-13 15:03:29,627 INFO     Training average loss at step 90100: 0.178185
2025-12-13 15:03:34,595 INFO     Training average regularization at step 90200: 0.164508
2025-12-13 15:03:34,595 INFO     Training average positive_sample_loss at step 90200: 0.006955
2025-12-13 15:03:34,595 INFO     Training average negative_sample_loss at step 90200: 0.022171
2025-12-13 15:03:34,595 INFO     Training average loss at step 90200: 0.179071
2025-12-13 15:03:39,712 INFO     Training average regularization at step 90300: 0.164504
2025-12-13 15:03:39,713 INFO     Training average positive_sample_loss at step 90300: 0.007446
2025-12-13 15:03:39,713 INFO     Training average negative_sample_loss at step 90300: 0.021698
2025-12-13 15:03:39,713 INFO     Training average loss at step 90300: 0.179076
2025-12-13 15:03:44,837 INFO     Training average regularization at step 90400: 0.164500
2025-12-13 15:03:44,838 INFO     Training average positive_sample_loss at step 90400: 0.007192
2025-12-13 15:03:44,838 INFO     Training average negative_sample_loss at step 90400: 0.020372
2025-12-13 15:03:44,838 INFO     Training average loss at step 90400: 0.178282
2025-12-13 15:03:49,696 INFO     Training average regularization at step 90500: 0.164496
2025-12-13 15:03:49,696 INFO     Training average positive_sample_loss at step 90500: 0.007462
2025-12-13 15:03:49,696 INFO     Training average negative_sample_loss at step 90500: 0.022165
2025-12-13 15:03:49,696 INFO     Training average loss at step 90500: 0.179310
2025-12-13 15:03:54,584 INFO     Training average regularization at step 90600: 0.164492
2025-12-13 15:03:54,585 INFO     Training average positive_sample_loss at step 90600: 0.007706
2025-12-13 15:03:54,585 INFO     Training average negative_sample_loss at step 90600: 0.020131
2025-12-13 15:03:54,585 INFO     Training average loss at step 90600: 0.178411
2025-12-13 15:03:59,961 INFO     Training average regularization at step 90700: 0.164488
2025-12-13 15:03:59,961 INFO     Training average positive_sample_loss at step 90700: 0.007411
2025-12-13 15:03:59,961 INFO     Training average negative_sample_loss at step 90700: 0.019915
2025-12-13 15:03:59,961 INFO     Training average loss at step 90700: 0.178151
2025-12-13 15:04:05,212 INFO     Training average regularization at step 90800: 0.164484
2025-12-13 15:04:05,213 INFO     Training average positive_sample_loss at step 90800: 0.007445
2025-12-13 15:04:05,213 INFO     Training average negative_sample_loss at step 90800: 0.024168
2025-12-13 15:04:05,213 INFO     Training average loss at step 90800: 0.180291
2025-12-13 15:04:10,117 INFO     Training average regularization at step 90900: 0.164480
2025-12-13 15:04:10,117 INFO     Training average positive_sample_loss at step 90900: 0.007702
2025-12-13 15:04:10,117 INFO     Training average negative_sample_loss at step 90900: 0.021930
2025-12-13 15:04:10,117 INFO     Training average loss at step 90900: 0.179296
2025-12-13 15:04:15,568 INFO     Training average regularization at step 91000: 0.164476
2025-12-13 15:04:15,568 INFO     Training average positive_sample_loss at step 91000: 0.008834
2025-12-13 15:04:15,568 INFO     Training average negative_sample_loss at step 91000: 0.022083
2025-12-13 15:04:15,568 INFO     Training average loss at step 91000: 0.179935
2025-12-13 15:04:20,866 INFO     Training average regularization at step 91100: 0.164472
2025-12-13 15:04:20,869 INFO     Training average positive_sample_loss at step 91100: 0.007460
2025-12-13 15:04:20,869 INFO     Training average negative_sample_loss at step 91100: 0.023635
2025-12-13 15:04:20,869 INFO     Training average loss at step 91100: 0.180020
2025-12-13 15:04:25,732 INFO     Training average regularization at step 91200: 0.164468
2025-12-13 15:04:25,732 INFO     Training average positive_sample_loss at step 91200: 0.007562
2025-12-13 15:04:25,732 INFO     Training average negative_sample_loss at step 91200: 0.017670
2025-12-13 15:04:25,732 INFO     Training average loss at step 91200: 0.177084
2025-12-13 15:04:31,172 INFO     Training average regularization at step 91300: 0.164464
2025-12-13 15:04:31,173 INFO     Training average positive_sample_loss at step 91300: 0.007536
2025-12-13 15:04:31,173 INFO     Training average negative_sample_loss at step 91300: 0.020105
2025-12-13 15:04:31,174 INFO     Training average loss at step 91300: 0.178285
2025-12-13 15:04:36,262 INFO     Training average regularization at step 91400: 0.164460
2025-12-13 15:04:36,262 INFO     Training average positive_sample_loss at step 91400: 0.007925
2025-12-13 15:04:36,263 INFO     Training average negative_sample_loss at step 91400: 0.019449
2025-12-13 15:04:36,263 INFO     Training average loss at step 91400: 0.178147
2025-12-13 15:04:41,254 INFO     Training average regularization at step 91500: 0.164457
2025-12-13 15:04:41,255 INFO     Training average positive_sample_loss at step 91500: 0.007745
2025-12-13 15:04:41,255 INFO     Training average negative_sample_loss at step 91500: 0.023718
2025-12-13 15:04:41,255 INFO     Training average loss at step 91500: 0.180188
2025-12-13 15:04:46,182 INFO     Training average regularization at step 91600: 0.164453
2025-12-13 15:04:46,183 INFO     Training average positive_sample_loss at step 91600: 0.007559
2025-12-13 15:04:46,183 INFO     Training average negative_sample_loss at step 91600: 0.024147
2025-12-13 15:04:46,183 INFO     Training average loss at step 91600: 0.180305
2025-12-13 15:04:51,217 INFO     Training average regularization at step 91700: 0.164449
2025-12-13 15:04:51,218 INFO     Training average positive_sample_loss at step 91700: 0.008140
2025-12-13 15:04:51,218 INFO     Training average negative_sample_loss at step 91700: 0.017548
2025-12-13 15:04:51,218 INFO     Training average loss at step 91700: 0.177293
2025-12-13 15:04:56,344 INFO     Training average regularization at step 91800: 0.164445
2025-12-13 15:04:56,344 INFO     Training average positive_sample_loss at step 91800: 0.007993
2025-12-13 15:04:56,344 INFO     Training average negative_sample_loss at step 91800: 0.024094
2025-12-13 15:04:56,344 INFO     Training average loss at step 91800: 0.180488
2025-12-13 15:05:02,239 INFO     Training average regularization at step 91900: 0.164441
2025-12-13 15:05:02,240 INFO     Training average positive_sample_loss at step 91900: 0.007478
2025-12-13 15:05:02,240 INFO     Training average negative_sample_loss at step 91900: 0.022858
2025-12-13 15:05:02,240 INFO     Training average loss at step 91900: 0.179609
2025-12-13 15:05:07,504 INFO     Training average regularization at step 92000: 0.164436
2025-12-13 15:05:07,505 INFO     Training average positive_sample_loss at step 92000: 0.007326
2025-12-13 15:05:07,505 INFO     Training average negative_sample_loss at step 92000: 0.026546
2025-12-13 15:05:07,505 INFO     Training average loss at step 92000: 0.181372
2025-12-13 15:05:12,685 INFO     Training average regularization at step 92100: 0.164432
2025-12-13 15:05:12,687 INFO     Training average positive_sample_loss at step 92100: 0.007499
2025-12-13 15:05:12,687 INFO     Training average negative_sample_loss at step 92100: 0.022924
2025-12-13 15:05:12,687 INFO     Training average loss at step 92100: 0.179644
2025-12-13 15:05:17,575 INFO     Training average regularization at step 92200: 0.164428
2025-12-13 15:05:17,575 INFO     Training average positive_sample_loss at step 92200: 0.007316
2025-12-13 15:05:17,576 INFO     Training average negative_sample_loss at step 92200: 0.020686
2025-12-13 15:05:17,576 INFO     Training average loss at step 92200: 0.178429
2025-12-13 15:05:22,614 INFO     Training average regularization at step 92300: 0.164424
2025-12-13 15:05:22,615 INFO     Training average positive_sample_loss at step 92300: 0.007075
2025-12-13 15:05:22,615 INFO     Training average negative_sample_loss at step 92300: 0.020857
2025-12-13 15:05:22,615 INFO     Training average loss at step 92300: 0.178390
2025-12-13 15:05:27,726 INFO     Training average regularization at step 92400: 0.164420
2025-12-13 15:05:27,726 INFO     Training average positive_sample_loss at step 92400: 0.007205
2025-12-13 15:05:27,726 INFO     Training average negative_sample_loss at step 92400: 0.018991
2025-12-13 15:05:27,726 INFO     Training average loss at step 92400: 0.177518
2025-12-13 15:05:32,653 INFO     Training average regularization at step 92500: 0.164416
2025-12-13 15:05:32,653 INFO     Training average positive_sample_loss at step 92500: 0.007533
2025-12-13 15:05:32,653 INFO     Training average negative_sample_loss at step 92500: 0.018987
2025-12-13 15:05:32,653 INFO     Training average loss at step 92500: 0.177676
2025-12-13 15:05:37,582 INFO     Training average regularization at step 92600: 0.164411
2025-12-13 15:05:37,582 INFO     Training average positive_sample_loss at step 92600: 0.007215
2025-12-13 15:05:37,582 INFO     Training average negative_sample_loss at step 92600: 0.019532
2025-12-13 15:05:37,582 INFO     Training average loss at step 92600: 0.177785
2025-12-13 15:05:42,614 INFO     Training average regularization at step 92700: 0.164407
2025-12-13 15:05:42,614 INFO     Training average positive_sample_loss at step 92700: 0.008193
2025-12-13 15:05:42,614 INFO     Training average negative_sample_loss at step 92700: 0.017248
2025-12-13 15:05:42,614 INFO     Training average loss at step 92700: 0.177128
2025-12-13 15:05:47,617 INFO     Training average regularization at step 92800: 0.164403
2025-12-13 15:05:47,617 INFO     Training average positive_sample_loss at step 92800: 0.007430
2025-12-13 15:05:47,617 INFO     Training average negative_sample_loss at step 92800: 0.019767
2025-12-13 15:05:47,617 INFO     Training average loss at step 92800: 0.178002
2025-12-13 15:05:52,446 INFO     Training average regularization at step 92900: 0.164399
2025-12-13 15:05:52,446 INFO     Training average positive_sample_loss at step 92900: 0.007595
2025-12-13 15:05:52,446 INFO     Training average negative_sample_loss at step 92900: 0.023367
2025-12-13 15:05:52,446 INFO     Training average loss at step 92900: 0.179880
2025-12-13 15:05:57,648 INFO     Training average regularization at step 93000: 0.164394
2025-12-13 15:05:57,648 INFO     Training average positive_sample_loss at step 93000: 0.006954
2025-12-13 15:05:57,648 INFO     Training average negative_sample_loss at step 93000: 0.019156
2025-12-13 15:05:57,648 INFO     Training average loss at step 93000: 0.177449
2025-12-13 15:06:02,904 INFO     Training average regularization at step 93100: 0.164390
2025-12-13 15:06:02,905 INFO     Training average positive_sample_loss at step 93100: 0.007178
2025-12-13 15:06:02,905 INFO     Training average negative_sample_loss at step 93100: 0.022737
2025-12-13 15:06:02,905 INFO     Training average loss at step 93100: 0.179348
2025-12-13 15:06:07,698 INFO     Training average regularization at step 93200: 0.164386
2025-12-13 15:06:07,698 INFO     Training average positive_sample_loss at step 93200: 0.007546
2025-12-13 15:06:07,698 INFO     Training average negative_sample_loss at step 93200: 0.024920
2025-12-13 15:06:07,698 INFO     Training average loss at step 93200: 0.180619
2025-12-13 15:06:12,894 INFO     Training average regularization at step 93300: 0.164382
2025-12-13 15:06:12,894 INFO     Training average positive_sample_loss at step 93300: 0.007965
2025-12-13 15:06:12,894 INFO     Training average negative_sample_loss at step 93300: 0.019815
2025-12-13 15:06:12,894 INFO     Training average loss at step 93300: 0.178272
2025-12-13 15:06:18,251 INFO     Training average regularization at step 93400: 0.164377
2025-12-13 15:06:18,251 INFO     Training average positive_sample_loss at step 93400: 0.007270
2025-12-13 15:06:18,251 INFO     Training average negative_sample_loss at step 93400: 0.021645
2025-12-13 15:06:18,251 INFO     Training average loss at step 93400: 0.178835
2025-12-13 15:06:23,221 INFO     Training average regularization at step 93500: 0.164373
2025-12-13 15:06:23,221 INFO     Training average positive_sample_loss at step 93500: 0.007887
2025-12-13 15:06:23,221 INFO     Training average negative_sample_loss at step 93500: 0.018730
2025-12-13 15:06:23,222 INFO     Training average loss at step 93500: 0.177682
2025-12-13 15:06:28,079 INFO     Training average regularization at step 93600: 0.164369
2025-12-13 15:06:28,079 INFO     Training average positive_sample_loss at step 93600: 0.007193
2025-12-13 15:06:28,079 INFO     Training average negative_sample_loss at step 93600: 0.018611
2025-12-13 15:06:28,079 INFO     Training average loss at step 93600: 0.177271
2025-12-13 15:06:33,429 INFO     Training average regularization at step 93700: 0.164365
2025-12-13 15:06:33,434 INFO     Training average positive_sample_loss at step 93700: 0.008009
2025-12-13 15:06:33,434 INFO     Training average negative_sample_loss at step 93700: 0.021783
2025-12-13 15:06:33,434 INFO     Training average loss at step 93700: 0.179261
2025-12-13 15:06:38,617 INFO     Training average regularization at step 93800: 0.164360
2025-12-13 15:06:38,617 INFO     Training average positive_sample_loss at step 93800: 0.008029
2025-12-13 15:06:38,617 INFO     Training average negative_sample_loss at step 93800: 0.022496
2025-12-13 15:06:38,617 INFO     Training average loss at step 93800: 0.179623
2025-12-13 15:06:43,402 INFO     Training average regularization at step 93900: 0.164356
2025-12-13 15:06:43,403 INFO     Training average positive_sample_loss at step 93900: 0.007458
2025-12-13 15:06:43,403 INFO     Training average negative_sample_loss at step 93900: 0.019384
2025-12-13 15:06:43,403 INFO     Training average loss at step 93900: 0.177777
2025-12-13 15:06:48,331 INFO     Training average regularization at step 94000: 0.164352
2025-12-13 15:06:48,331 INFO     Training average positive_sample_loss at step 94000: 0.007075
2025-12-13 15:06:48,331 INFO     Training average negative_sample_loss at step 94000: 0.017438
2025-12-13 15:06:48,331 INFO     Training average loss at step 94000: 0.176608
2025-12-13 15:06:53,184 INFO     Training average regularization at step 94100: 0.164348
2025-12-13 15:06:53,185 INFO     Training average positive_sample_loss at step 94100: 0.007097
2025-12-13 15:06:53,185 INFO     Training average negative_sample_loss at step 94100: 0.020201
2025-12-13 15:06:53,185 INFO     Training average loss at step 94100: 0.177997
2025-12-13 15:06:58,088 INFO     Training average regularization at step 94200: 0.164344
2025-12-13 15:06:58,088 INFO     Training average positive_sample_loss at step 94200: 0.007634
2025-12-13 15:06:58,088 INFO     Training average negative_sample_loss at step 94200: 0.017748
2025-12-13 15:06:58,088 INFO     Training average loss at step 94200: 0.177035
2025-12-13 15:07:03,003 INFO     Training average regularization at step 94300: 0.164339
2025-12-13 15:07:03,004 INFO     Training average positive_sample_loss at step 94300: 0.007492
2025-12-13 15:07:03,004 INFO     Training average negative_sample_loss at step 94300: 0.021496
2025-12-13 15:07:03,004 INFO     Training average loss at step 94300: 0.178834
2025-12-13 15:07:08,358 INFO     Training average regularization at step 94400: 0.164335
2025-12-13 15:07:08,358 INFO     Training average positive_sample_loss at step 94400: 0.008337
2025-12-13 15:07:08,358 INFO     Training average negative_sample_loss at step 94400: 0.019659
2025-12-13 15:07:08,358 INFO     Training average loss at step 94400: 0.178333
2025-12-13 15:07:13,433 INFO     Training average regularization at step 94500: 0.164331
2025-12-13 15:07:13,433 INFO     Training average positive_sample_loss at step 94500: 0.007971
2025-12-13 15:07:13,433 INFO     Training average negative_sample_loss at step 94500: 0.018602
2025-12-13 15:07:13,433 INFO     Training average loss at step 94500: 0.177618
2025-12-13 15:07:18,330 INFO     Training average regularization at step 94600: 0.164327
2025-12-13 15:07:18,331 INFO     Training average positive_sample_loss at step 94600: 0.006897
2025-12-13 15:07:18,331 INFO     Training average negative_sample_loss at step 94600: 0.016595
2025-12-13 15:07:18,331 INFO     Training average loss at step 94600: 0.176073
2025-12-13 15:07:23,465 INFO     Training average regularization at step 94700: 0.164323
2025-12-13 15:07:23,469 INFO     Training average positive_sample_loss at step 94700: 0.007467
2025-12-13 15:07:23,469 INFO     Training average negative_sample_loss at step 94700: 0.017527
2025-12-13 15:07:23,469 INFO     Training average loss at step 94700: 0.176820
2025-12-13 15:07:28,537 INFO     Training average regularization at step 94800: 0.164319
2025-12-13 15:07:28,538 INFO     Training average positive_sample_loss at step 94800: 0.008589
2025-12-13 15:07:28,538 INFO     Training average negative_sample_loss at step 94800: 0.020761
2025-12-13 15:07:28,538 INFO     Training average loss at step 94800: 0.178994
2025-12-13 15:07:33,390 INFO     Training average regularization at step 94900: 0.164314
2025-12-13 15:07:33,391 INFO     Training average positive_sample_loss at step 94900: 0.007353
2025-12-13 15:07:33,391 INFO     Training average negative_sample_loss at step 94900: 0.016243
2025-12-13 15:07:33,391 INFO     Training average loss at step 94900: 0.176113
2025-12-13 15:07:38,376 INFO     Training average regularization at step 95000: 0.164310
2025-12-13 15:07:38,376 INFO     Training average positive_sample_loss at step 95000: 0.007019
2025-12-13 15:07:38,376 INFO     Training average negative_sample_loss at step 95000: 0.022350
2025-12-13 15:07:38,376 INFO     Training average loss at step 95000: 0.178994
2025-12-13 15:07:43,517 INFO     Training average regularization at step 95100: 0.164306
2025-12-13 15:07:43,517 INFO     Training average positive_sample_loss at step 95100: 0.007057
2025-12-13 15:07:43,517 INFO     Training average negative_sample_loss at step 95100: 0.022566
2025-12-13 15:07:43,517 INFO     Training average loss at step 95100: 0.179118
2025-12-13 15:07:48,359 INFO     Training average regularization at step 95200: 0.164302
2025-12-13 15:07:48,359 INFO     Training average positive_sample_loss at step 95200: 0.007806
2025-12-13 15:07:48,359 INFO     Training average negative_sample_loss at step 95200: 0.021661
2025-12-13 15:07:48,359 INFO     Training average loss at step 95200: 0.179035
2025-12-13 15:07:53,199 INFO     Training average regularization at step 95300: 0.164298
2025-12-13 15:07:53,199 INFO     Training average positive_sample_loss at step 95300: 0.007311
2025-12-13 15:07:53,199 INFO     Training average negative_sample_loss at step 95300: 0.021561
2025-12-13 15:07:53,199 INFO     Training average loss at step 95300: 0.178734
2025-12-13 15:07:58,268 INFO     Training average regularization at step 95400: 0.164294
2025-12-13 15:07:58,268 INFO     Training average positive_sample_loss at step 95400: 0.006899
2025-12-13 15:07:58,268 INFO     Training average negative_sample_loss at step 95400: 0.018045
2025-12-13 15:07:58,268 INFO     Training average loss at step 95400: 0.176766
2025-12-13 15:08:03,287 INFO     Training average regularization at step 95500: 0.164290
2025-12-13 15:08:03,287 INFO     Training average positive_sample_loss at step 95500: 0.008317
2025-12-13 15:08:03,287 INFO     Training average negative_sample_loss at step 95500: 0.022188
2025-12-13 15:08:03,287 INFO     Training average loss at step 95500: 0.179542
2025-12-13 15:08:08,124 INFO     Training average regularization at step 95600: 0.164285
2025-12-13 15:08:08,124 INFO     Training average positive_sample_loss at step 95600: 0.007429
2025-12-13 15:08:08,124 INFO     Training average negative_sample_loss at step 95600: 0.021205
2025-12-13 15:08:08,124 INFO     Training average loss at step 95600: 0.178602
2025-12-13 15:08:13,316 INFO     Training average regularization at step 95700: 0.164281
2025-12-13 15:08:13,316 INFO     Training average positive_sample_loss at step 95700: 0.007242
2025-12-13 15:08:13,316 INFO     Training average negative_sample_loss at step 95700: 0.019031
2025-12-13 15:08:13,317 INFO     Training average loss at step 95700: 0.177418
2025-12-13 15:08:18,591 INFO     Training average regularization at step 95800: 0.164277
2025-12-13 15:08:18,592 INFO     Training average positive_sample_loss at step 95800: 0.007779
2025-12-13 15:08:18,592 INFO     Training average negative_sample_loss at step 95800: 0.020743
2025-12-13 15:08:18,592 INFO     Training average loss at step 95800: 0.178538
2025-12-13 15:08:23,416 INFO     Training average regularization at step 95900: 0.164273
2025-12-13 15:08:23,417 INFO     Training average positive_sample_loss at step 95900: 0.007128
2025-12-13 15:08:23,417 INFO     Training average negative_sample_loss at step 95900: 0.019632
2025-12-13 15:08:23,417 INFO     Training average loss at step 95900: 0.177653
2025-12-13 15:08:28,426 INFO     Training average regularization at step 96000: 0.164269
2025-12-13 15:08:28,427 INFO     Training average positive_sample_loss at step 96000: 0.007441
2025-12-13 15:08:28,427 INFO     Training average negative_sample_loss at step 96000: 0.020470
2025-12-13 15:08:28,427 INFO     Training average loss at step 96000: 0.178224
2025-12-13 15:08:33,745 INFO     Training average regularization at step 96100: 0.164265
2025-12-13 15:08:33,757 INFO     Training average positive_sample_loss at step 96100: 0.008105
2025-12-13 15:08:33,757 INFO     Training average negative_sample_loss at step 96100: 0.022583
2025-12-13 15:08:33,757 INFO     Training average loss at step 96100: 0.179609
2025-12-13 15:08:38,756 INFO     Training average regularization at step 96200: 0.164261
2025-12-13 15:08:38,756 INFO     Training average positive_sample_loss at step 96200: 0.007050
2025-12-13 15:08:38,756 INFO     Training average negative_sample_loss at step 96200: 0.019596
2025-12-13 15:08:38,756 INFO     Training average loss at step 96200: 0.177584
2025-12-13 15:08:43,618 INFO     Training average regularization at step 96300: 0.164256
2025-12-13 15:08:43,618 INFO     Training average positive_sample_loss at step 96300: 0.007678
2025-12-13 15:08:43,619 INFO     Training average negative_sample_loss at step 96300: 0.021831
2025-12-13 15:08:43,619 INFO     Training average loss at step 96300: 0.179011
2025-12-13 15:08:48,789 INFO     Training average regularization at step 96400: 0.164252
2025-12-13 15:08:48,789 INFO     Training average positive_sample_loss at step 96400: 0.007407
2025-12-13 15:08:48,789 INFO     Training average negative_sample_loss at step 96400: 0.022599
2025-12-13 15:08:48,789 INFO     Training average loss at step 96400: 0.179256
2025-12-13 15:08:53,826 INFO     Training average regularization at step 96500: 0.164248
2025-12-13 15:08:53,826 INFO     Training average positive_sample_loss at step 96500: 0.008081
2025-12-13 15:08:53,826 INFO     Training average negative_sample_loss at step 96500: 0.022432
2025-12-13 15:08:53,826 INFO     Training average loss at step 96500: 0.179505
2025-12-13 15:08:58,656 INFO     Training average regularization at step 96600: 0.164244
2025-12-13 15:08:58,656 INFO     Training average positive_sample_loss at step 96600: 0.007145
2025-12-13 15:08:58,656 INFO     Training average negative_sample_loss at step 96600: 0.021628
2025-12-13 15:08:58,656 INFO     Training average loss at step 96600: 0.178631
2025-12-13 15:09:04,897 INFO     Training average regularization at step 96700: 0.164240
2025-12-13 15:09:04,899 INFO     Training average positive_sample_loss at step 96700: 0.007367
2025-12-13 15:09:04,899 INFO     Training average negative_sample_loss at step 96700: 0.021833
2025-12-13 15:09:04,899 INFO     Training average loss at step 96700: 0.178840
2025-12-13 15:09:09,855 INFO     Training average regularization at step 96800: 0.164236
2025-12-13 15:09:09,855 INFO     Training average positive_sample_loss at step 96800: 0.007143
2025-12-13 15:09:09,855 INFO     Training average negative_sample_loss at step 96800: 0.024281
2025-12-13 15:09:09,855 INFO     Training average loss at step 96800: 0.179948
2025-12-13 15:09:14,741 INFO     Training average regularization at step 96900: 0.164232
2025-12-13 15:09:14,741 INFO     Training average positive_sample_loss at step 96900: 0.007370
2025-12-13 15:09:14,741 INFO     Training average negative_sample_loss at step 96900: 0.026154
2025-12-13 15:09:14,741 INFO     Training average loss at step 96900: 0.180993
2025-12-13 15:09:19,805 INFO     Training average regularization at step 97000: 0.164227
2025-12-13 15:09:19,805 INFO     Training average positive_sample_loss at step 97000: 0.007169
2025-12-13 15:09:19,805 INFO     Training average negative_sample_loss at step 97000: 0.023777
2025-12-13 15:09:19,805 INFO     Training average loss at step 97000: 0.179700
2025-12-13 15:09:24,836 INFO     Training average regularization at step 97100: 0.164223
2025-12-13 15:09:24,839 INFO     Training average positive_sample_loss at step 97100: 0.007264
2025-12-13 15:09:24,839 INFO     Training average negative_sample_loss at step 97100: 0.018218
2025-12-13 15:09:24,839 INFO     Training average loss at step 97100: 0.176964
2025-12-13 15:09:29,738 INFO     Training average regularization at step 97200: 0.164219
2025-12-13 15:09:29,738 INFO     Training average positive_sample_loss at step 97200: 0.007184
2025-12-13 15:09:29,738 INFO     Training average negative_sample_loss at step 97200: 0.020967
2025-12-13 15:09:29,738 INFO     Training average loss at step 97200: 0.178294
2025-12-13 15:09:34,674 INFO     Training average regularization at step 97300: 0.164215
2025-12-13 15:09:34,674 INFO     Training average positive_sample_loss at step 97300: 0.006841
2025-12-13 15:09:34,674 INFO     Training average negative_sample_loss at step 97300: 0.019950
2025-12-13 15:09:34,674 INFO     Training average loss at step 97300: 0.177610
2025-12-13 15:09:39,701 INFO     Training average regularization at step 97400: 0.164210
2025-12-13 15:09:39,701 INFO     Training average positive_sample_loss at step 97400: 0.007591
2025-12-13 15:09:39,701 INFO     Training average negative_sample_loss at step 97400: 0.023794
2025-12-13 15:09:39,701 INFO     Training average loss at step 97400: 0.179903
2025-12-13 15:09:44,660 INFO     Training average regularization at step 97500: 0.164206
2025-12-13 15:09:44,660 INFO     Training average positive_sample_loss at step 97500: 0.006926
2025-12-13 15:09:44,660 INFO     Training average negative_sample_loss at step 97500: 0.017949
2025-12-13 15:09:44,660 INFO     Training average loss at step 97500: 0.176644
2025-12-13 15:09:49,496 INFO     Training average regularization at step 97600: 0.164202
2025-12-13 15:09:49,497 INFO     Training average positive_sample_loss at step 97600: 0.007048
2025-12-13 15:09:49,497 INFO     Training average negative_sample_loss at step 97600: 0.016899
2025-12-13 15:09:49,497 INFO     Training average loss at step 97600: 0.176175
2025-12-13 15:09:54,624 INFO     Training average regularization at step 97700: 0.164197
2025-12-13 15:09:54,624 INFO     Training average positive_sample_loss at step 97700: 0.007328
2025-12-13 15:09:54,624 INFO     Training average negative_sample_loss at step 97700: 0.025199
2025-12-13 15:09:54,624 INFO     Training average loss at step 97700: 0.180461
2025-12-13 15:09:59,739 INFO     Training average regularization at step 97800: 0.164193
2025-12-13 15:09:59,739 INFO     Training average positive_sample_loss at step 97800: 0.007842
2025-12-13 15:09:59,739 INFO     Training average negative_sample_loss at step 97800: 0.020908
2025-12-13 15:09:59,739 INFO     Training average loss at step 97800: 0.178568
2025-12-13 15:10:04,561 INFO     Training average regularization at step 97900: 0.164189
2025-12-13 15:10:04,561 INFO     Training average positive_sample_loss at step 97900: 0.007204
2025-12-13 15:10:04,561 INFO     Training average negative_sample_loss at step 97900: 0.022391
2025-12-13 15:10:04,561 INFO     Training average loss at step 97900: 0.178986
2025-12-13 15:10:09,598 INFO     Training average regularization at step 98000: 0.164184
2025-12-13 15:10:09,598 INFO     Training average positive_sample_loss at step 98000: 0.007165
2025-12-13 15:10:09,598 INFO     Training average negative_sample_loss at step 98000: 0.020281
2025-12-13 15:10:09,598 INFO     Training average loss at step 98000: 0.177908
2025-12-13 15:10:15,028 INFO     Training average regularization at step 98100: 0.164180
2025-12-13 15:10:15,029 INFO     Training average positive_sample_loss at step 98100: 0.007590
2025-12-13 15:10:15,029 INFO     Training average negative_sample_loss at step 98100: 0.024414
2025-12-13 15:10:15,029 INFO     Training average loss at step 98100: 0.180182
2025-12-13 15:10:19,922 INFO     Training average regularization at step 98200: 0.164176
2025-12-13 15:10:19,922 INFO     Training average positive_sample_loss at step 98200: 0.007349
2025-12-13 15:10:19,923 INFO     Training average negative_sample_loss at step 98200: 0.018438
2025-12-13 15:10:19,923 INFO     Training average loss at step 98200: 0.177070
2025-12-13 15:10:24,862 INFO     Training average regularization at step 98300: 0.164172
2025-12-13 15:10:24,862 INFO     Training average positive_sample_loss at step 98300: 0.007066
2025-12-13 15:10:24,862 INFO     Training average negative_sample_loss at step 98300: 0.019491
2025-12-13 15:10:24,862 INFO     Training average loss at step 98300: 0.177450
2025-12-13 15:10:30,317 INFO     Training average regularization at step 98400: 0.164167
2025-12-13 15:10:30,318 INFO     Training average positive_sample_loss at step 98400: 0.007059
2025-12-13 15:10:30,318 INFO     Training average negative_sample_loss at step 98400: 0.023964
2025-12-13 15:10:30,318 INFO     Training average loss at step 98400: 0.179679
2025-12-13 15:10:35,573 INFO     Training average regularization at step 98500: 0.164163
2025-12-13 15:10:35,573 INFO     Training average positive_sample_loss at step 98500: 0.007093
2025-12-13 15:10:35,573 INFO     Training average negative_sample_loss at step 98500: 0.017015
2025-12-13 15:10:35,573 INFO     Training average loss at step 98500: 0.176217
2025-12-13 15:10:40,388 INFO     Training average regularization at step 98600: 0.164159
2025-12-13 15:10:40,389 INFO     Training average positive_sample_loss at step 98600: 0.007142
2025-12-13 15:10:40,389 INFO     Training average negative_sample_loss at step 98600: 0.021891
2025-12-13 15:10:40,389 INFO     Training average loss at step 98600: 0.178675
2025-12-13 15:10:45,462 INFO     Training average regularization at step 98700: 0.164155
2025-12-13 15:10:45,465 INFO     Training average positive_sample_loss at step 98700: 0.008236
2025-12-13 15:10:45,465 INFO     Training average negative_sample_loss at step 98700: 0.021568
2025-12-13 15:10:45,465 INFO     Training average loss at step 98700: 0.179057
2025-12-13 15:10:50,480 INFO     Training average regularization at step 98800: 0.164150
2025-12-13 15:10:50,480 INFO     Training average positive_sample_loss at step 98800: 0.007414
2025-12-13 15:10:50,480 INFO     Training average negative_sample_loss at step 98800: 0.020685
2025-12-13 15:10:50,480 INFO     Training average loss at step 98800: 0.178200
2025-12-13 15:10:55,294 INFO     Training average regularization at step 98900: 0.164146
2025-12-13 15:10:55,294 INFO     Training average positive_sample_loss at step 98900: 0.007982
2025-12-13 15:10:55,294 INFO     Training average negative_sample_loss at step 98900: 0.026116
2025-12-13 15:10:55,294 INFO     Training average loss at step 98900: 0.181195
2025-12-13 15:11:00,563 INFO     Training average regularization at step 99000: 0.164142
2025-12-13 15:11:00,564 INFO     Training average positive_sample_loss at step 99000: 0.006825
2025-12-13 15:11:00,564 INFO     Training average negative_sample_loss at step 99000: 0.019939
2025-12-13 15:11:00,564 INFO     Training average loss at step 99000: 0.177524
2025-12-13 15:11:05,902 INFO     Training average regularization at step 99100: 0.164137
2025-12-13 15:11:05,903 INFO     Training average positive_sample_loss at step 99100: 0.008833
2025-12-13 15:11:05,903 INFO     Training average negative_sample_loss at step 99100: 0.018801
2025-12-13 15:11:05,903 INFO     Training average loss at step 99100: 0.177954
2025-12-13 15:11:10,822 INFO     Training average regularization at step 99200: 0.164133
2025-12-13 15:11:10,822 INFO     Training average positive_sample_loss at step 99200: 0.006739
2025-12-13 15:11:10,822 INFO     Training average negative_sample_loss at step 99200: 0.018089
2025-12-13 15:11:10,822 INFO     Training average loss at step 99200: 0.176547
2025-12-13 15:11:15,784 INFO     Training average regularization at step 99300: 0.164129
2025-12-13 15:11:15,785 INFO     Training average positive_sample_loss at step 99300: 0.007428
2025-12-13 15:11:15,785 INFO     Training average negative_sample_loss at step 99300: 0.018219
2025-12-13 15:11:15,785 INFO     Training average loss at step 99300: 0.176952
2025-12-13 15:11:20,804 INFO     Training average regularization at step 99400: 0.164125
2025-12-13 15:11:20,804 INFO     Training average positive_sample_loss at step 99400: 0.007511
2025-12-13 15:11:20,804 INFO     Training average negative_sample_loss at step 99400: 0.023526
2025-12-13 15:11:20,804 INFO     Training average loss at step 99400: 0.179643
2025-12-13 15:11:25,779 INFO     Training average regularization at step 99500: 0.164120
2025-12-13 15:11:25,779 INFO     Training average positive_sample_loss at step 99500: 0.007111
2025-12-13 15:11:25,779 INFO     Training average negative_sample_loss at step 99500: 0.018652
2025-12-13 15:11:25,780 INFO     Training average loss at step 99500: 0.177002
2025-12-13 15:11:30,684 INFO     Training average regularization at step 99600: 0.164116
2025-12-13 15:11:30,684 INFO     Training average positive_sample_loss at step 99600: 0.007479
2025-12-13 15:11:30,684 INFO     Training average negative_sample_loss at step 99600: 0.018049
2025-12-13 15:11:30,684 INFO     Training average loss at step 99600: 0.176880
2025-12-13 15:11:35,724 INFO     Training average regularization at step 99700: 0.164112
2025-12-13 15:11:35,724 INFO     Training average positive_sample_loss at step 99700: 0.008397
2025-12-13 15:11:35,724 INFO     Training average negative_sample_loss at step 99700: 0.022374
2025-12-13 15:11:35,724 INFO     Training average loss at step 99700: 0.179498
2025-12-13 15:11:40,790 INFO     Training average regularization at step 99800: 0.164108
2025-12-13 15:11:40,791 INFO     Training average positive_sample_loss at step 99800: 0.007496
2025-12-13 15:11:40,791 INFO     Training average negative_sample_loss at step 99800: 0.021777
2025-12-13 15:11:40,791 INFO     Training average loss at step 99800: 0.178744
2025-12-13 15:11:45,645 INFO     Training average regularization at step 99900: 0.164104
2025-12-13 15:11:45,645 INFO     Training average positive_sample_loss at step 99900: 0.007366
2025-12-13 15:11:45,645 INFO     Training average negative_sample_loss at step 99900: 0.021266
2025-12-13 15:11:45,645 INFO     Training average loss at step 99900: 0.178420
2025-12-13 15:11:52,196 INFO     Training average regularization at step 100000: 0.164100
2025-12-13 15:11:52,200 INFO     Training average positive_sample_loss at step 100000: 0.009727
2025-12-13 15:11:52,200 INFO     Training average negative_sample_loss at step 100000: 0.018881
2025-12-13 15:11:52,200 INFO     Training average loss at step 100000: 0.178404
2025-12-13 15:11:52,200 INFO     Evaluating on Valid Dataset...
2025-12-13 15:11:53,237 INFO     Evaluating the model... (0/50000)
2025-12-13 15:11:58,681 INFO     Evaluating the model... (500/50000)
2025-12-13 15:12:03,427 INFO     Evaluating the model... (1000/50000)
2025-12-13 15:12:10,669 INFO     Evaluating the model... (1500/50000)
2025-12-13 15:12:16,341 INFO     Evaluating the model... (2000/50000)
2025-12-13 15:12:21,117 INFO     Evaluating the model... (2500/50000)
2025-12-13 15:12:27,911 INFO     Evaluating the model... (3000/50000)
2025-12-13 15:12:33,762 INFO     Evaluating the model... (3500/50000)
2025-12-13 15:12:38,938 INFO     Evaluating the model... (4000/50000)
2025-12-13 15:12:44,153 INFO     Evaluating the model... (4500/50000)
2025-12-13 15:12:49,306 INFO     Evaluating the model... (5000/50000)
2025-12-13 15:12:53,903 INFO     Evaluating the model... (5500/50000)
2025-12-13 15:12:59,848 INFO     Evaluating the model... (6000/50000)
2025-12-13 15:13:06,216 INFO     Evaluating the model... (6500/50000)
2025-12-13 15:13:10,960 INFO     Evaluating the model... (7000/50000)
2025-12-13 15:13:16,805 INFO     Evaluating the model... (7500/50000)
2025-12-13 15:13:22,824 INFO     Evaluating the model... (8000/50000)
2025-12-13 15:13:28,883 INFO     Evaluating the model... (8500/50000)
2025-12-13 15:13:34,093 INFO     Evaluating the model... (9000/50000)
2025-12-13 15:13:38,742 INFO     Evaluating the model... (9500/50000)
2025-12-13 15:13:43,502 INFO     Evaluating the model... (10000/50000)
2025-12-13 15:13:48,172 INFO     Evaluating the model... (10500/50000)
2025-12-13 15:13:54,082 INFO     Evaluating the model... (11000/50000)
2025-12-13 15:13:59,196 INFO     Evaluating the model... (11500/50000)
2025-12-13 15:14:04,001 INFO     Evaluating the model... (12000/50000)
2025-12-13 15:14:09,951 INFO     Evaluating the model... (12500/50000)
2025-12-13 15:14:16,022 INFO     Evaluating the model... (13000/50000)
2025-12-13 15:14:22,610 INFO     Evaluating the model... (13500/50000)
2025-12-13 15:14:29,120 INFO     Evaluating the model... (14000/50000)
2025-12-13 15:14:35,084 INFO     Evaluating the model... (14500/50000)
2025-12-13 15:14:40,235 INFO     Evaluating the model... (15000/50000)
2025-12-13 15:14:45,846 INFO     Evaluating the model... (15500/50000)
2025-12-13 15:14:52,309 INFO     Evaluating the model... (16000/50000)
2025-12-13 15:14:57,213 INFO     Evaluating the model... (16500/50000)
2025-12-13 15:15:03,925 INFO     Evaluating the model... (17000/50000)
2025-12-13 15:15:09,705 INFO     Evaluating the model... (17500/50000)
2025-12-13 15:15:14,573 INFO     Evaluating the model... (18000/50000)
2025-12-13 15:15:22,424 INFO     Evaluating the model... (18500/50000)
2025-12-13 15:15:28,133 INFO     Evaluating the model... (19000/50000)
2025-12-13 15:15:33,119 INFO     Evaluating the model... (19500/50000)
2025-12-13 15:15:39,269 INFO     Evaluating the model... (20000/50000)
2025-12-13 15:15:44,394 INFO     Evaluating the model... (20500/50000)
2025-12-13 15:15:50,631 INFO     Evaluating the model... (21000/50000)
2025-12-13 15:15:56,105 INFO     Evaluating the model... (21500/50000)
2025-12-13 15:16:01,813 INFO     Evaluating the model... (22000/50000)
2025-12-13 15:16:06,672 INFO     Evaluating the model... (22500/50000)
2025-12-13 15:16:11,269 INFO     Evaluating the model... (23000/50000)
2025-12-13 15:16:17,224 INFO     Evaluating the model... (23500/50000)
2025-12-13 15:16:21,983 INFO     Evaluating the model... (24000/50000)
2025-12-13 15:16:27,091 INFO     Evaluating the model... (24500/50000)
2025-12-13 15:16:33,751 INFO     Evaluating the model... (25000/50000)
2025-12-13 15:16:38,632 INFO     Evaluating the model... (25500/50000)
2025-12-13 15:16:44,455 INFO     Evaluating the model... (26000/50000)
2025-12-13 15:16:49,923 INFO     Evaluating the model... (26500/50000)
2025-12-13 15:16:54,805 INFO     Evaluating the model... (27000/50000)
2025-12-13 15:16:59,976 INFO     Evaluating the model... (27500/50000)
2025-12-13 15:17:06,349 INFO     Evaluating the model... (28000/50000)
2025-12-13 15:17:12,337 INFO     Evaluating the model... (28500/50000)
2025-12-13 15:17:16,996 INFO     Evaluating the model... (29000/50000)
2025-12-13 15:17:22,846 INFO     Evaluating the model... (29500/50000)
2025-12-13 15:17:28,370 INFO     Evaluating the model... (30000/50000)
2025-12-13 15:17:32,912 INFO     Evaluating the model... (30500/50000)
2025-12-13 15:17:39,098 INFO     Evaluating the model... (31000/50000)
2025-12-13 15:17:44,550 INFO     Evaluating the model... (31500/50000)
2025-12-13 15:17:49,127 INFO     Evaluating the model... (32000/50000)
2025-12-13 15:17:53,965 INFO     Evaluating the model... (32500/50000)
2025-12-13 15:17:59,160 INFO     Evaluating the model... (33000/50000)
2025-12-13 15:18:04,853 INFO     Evaluating the model... (33500/50000)
2025-12-13 15:18:10,015 INFO     Evaluating the model... (34000/50000)
2025-12-13 15:18:16,095 INFO     Evaluating the model... (34500/50000)
2025-12-13 15:18:20,913 INFO     Evaluating the model... (35000/50000)
2025-12-13 15:18:26,376 INFO     Evaluating the model... (35500/50000)
2025-12-13 15:18:31,000 INFO     Evaluating the model... (36000/50000)
2025-12-13 15:18:36,736 INFO     Evaluating the model... (36500/50000)
2025-12-13 15:18:41,388 INFO     Evaluating the model... (37000/50000)
2025-12-13 15:18:46,570 INFO     Evaluating the model... (37500/50000)
2025-12-13 15:18:53,079 INFO     Evaluating the model... (38000/50000)
2025-12-13 15:18:57,818 INFO     Evaluating the model... (38500/50000)
2025-12-13 15:19:02,895 INFO     Evaluating the model... (39000/50000)
2025-12-13 15:19:08,963 INFO     Evaluating the model... (39500/50000)
2025-12-13 15:19:13,868 INFO     Evaluating the model... (40000/50000)
2025-12-13 15:19:19,677 INFO     Evaluating the model... (40500/50000)
2025-12-13 15:19:25,755 INFO     Evaluating the model... (41000/50000)
2025-12-13 15:19:30,720 INFO     Evaluating the model... (41500/50000)
2025-12-13 15:19:35,210 INFO     Evaluating the model... (42000/50000)
2025-12-13 15:19:40,669 INFO     Evaluating the model... (42500/50000)
2025-12-13 15:19:47,155 INFO     Evaluating the model... (43000/50000)
2025-12-13 15:19:51,610 INFO     Evaluating the model... (43500/50000)
2025-12-13 15:19:56,428 INFO     Evaluating the model... (44000/50000)
2025-12-13 15:20:01,301 INFO     Evaluating the model... (44500/50000)
2025-12-13 15:20:06,159 INFO     Evaluating the model... (45000/50000)
2025-12-13 15:20:12,001 INFO     Evaluating the model... (45500/50000)
2025-12-13 15:20:17,830 INFO     Evaluating the model... (46000/50000)
2025-12-13 15:20:22,987 INFO     Evaluating the model... (46500/50000)
2025-12-13 15:20:27,711 INFO     Evaluating the model... (47000/50000)
2025-12-13 15:20:32,219 INFO     Evaluating the model... (47500/50000)
2025-12-13 15:20:37,836 INFO     Evaluating the model... (48000/50000)
2025-12-13 15:20:42,706 INFO     Evaluating the model... (48500/50000)
2025-12-13 15:20:47,312 INFO     Evaluating the model... (49000/50000)
2025-12-13 15:20:52,298 INFO     Evaluating the model... (49500/50000)
2025-12-13 15:20:58,362 INFO     Valid MRR at step 100000: 0.733661
2025-12-13 15:20:58,362 INFO     Valid MR at step 100000: 255.726560
2025-12-13 15:20:58,363 INFO     Valid HITS@1 at step 100000: 0.669360
2025-12-13 15:20:58,363 INFO     Valid HITS@3 at step 100000: 0.779330
2025-12-13 15:20:58,363 INFO     Valid HITS@10 at step 100000: 0.843510
2025-12-13 15:20:59,701 INFO     Evaluating on Test Dataset...
2025-12-13 15:21:00,677 INFO     Evaluating the model... (0/59072)
2025-12-13 15:21:07,153 INFO     Evaluating the model... (500/59072)
2025-12-13 15:21:13,314 INFO     Evaluating the model... (1000/59072)
2025-12-13 15:21:19,265 INFO     Evaluating the model... (1500/59072)
2025-12-13 15:21:24,146 INFO     Evaluating the model... (2000/59072)
2025-12-13 15:21:30,128 INFO     Evaluating the model... (2500/59072)
2025-12-13 15:21:37,519 INFO     Evaluating the model... (3000/59072)
2025-12-13 15:21:42,273 INFO     Evaluating the model... (3500/59072)
2025-12-13 15:21:47,008 INFO     Evaluating the model... (4000/59072)
2025-12-13 15:21:52,614 INFO     Evaluating the model... (4500/59072)
2025-12-13 15:21:57,757 INFO     Evaluating the model... (5000/59072)
2025-12-13 15:22:03,097 INFO     Evaluating the model... (5500/59072)
2025-12-13 15:22:08,998 INFO     Evaluating the model... (6000/59072)
2025-12-13 15:22:14,450 INFO     Evaluating the model... (6500/59072)
2025-12-13 15:22:19,543 INFO     Evaluating the model... (7000/59072)
2025-12-13 15:22:24,660 INFO     Evaluating the model... (7500/59072)
2025-12-13 15:22:31,000 INFO     Evaluating the model... (8000/59072)
2025-12-13 15:22:35,798 INFO     Evaluating the model... (8500/59072)
2025-12-13 15:22:40,484 INFO     Evaluating the model... (9000/59072)
2025-12-13 15:22:45,313 INFO     Evaluating the model... (9500/59072)
2025-12-13 15:22:51,395 INFO     Evaluating the model... (10000/59072)
2025-12-13 15:22:56,025 INFO     Evaluating the model... (10500/59072)
2025-12-13 15:23:00,844 INFO     Evaluating the model... (11000/59072)
2025-12-13 15:23:07,321 INFO     Evaluating the model... (11500/59072)
2025-12-13 15:23:13,122 INFO     Evaluating the model... (12000/59072)
2025-12-13 15:23:19,523 INFO     Evaluating the model... (12500/59072)
2025-12-13 15:23:26,297 INFO     Evaluating the model... (13000/59072)
2025-12-13 15:23:31,416 INFO     Evaluating the model... (13500/59072)
2025-12-13 15:23:35,956 INFO     Evaluating the model... (14000/59072)
2025-12-13 15:23:41,098 INFO     Evaluating the model... (14500/59072)
2025-12-13 15:23:47,468 INFO     Evaluating the model... (15000/59072)
2025-12-13 15:23:51,961 INFO     Evaluating the model... (15500/59072)
2025-12-13 15:23:56,585 INFO     Evaluating the model... (16000/59072)
2025-12-13 15:24:03,255 INFO     Evaluating the model... (16500/59072)
2025-12-13 15:24:08,958 INFO     Evaluating the model... (17000/59072)
2025-12-13 15:24:14,663 INFO     Evaluating the model... (17500/59072)
2025-12-13 15:24:20,872 INFO     Evaluating the model... (18000/59072)
2025-12-13 15:24:26,646 INFO     Evaluating the model... (18500/59072)
2025-12-13 15:24:31,261 INFO     Evaluating the model... (19000/59072)
2025-12-13 15:24:36,429 INFO     Evaluating the model... (19500/59072)
2025-12-13 15:24:42,645 INFO     Evaluating the model... (20000/59072)
2025-12-13 15:24:47,389 INFO     Evaluating the model... (20500/59072)
2025-12-13 15:24:51,929 INFO     Evaluating the model... (21000/59072)
2025-12-13 15:24:57,335 INFO     Evaluating the model... (21500/59072)
2025-12-13 15:25:02,275 INFO     Evaluating the model... (22000/59072)
2025-12-13 15:25:08,159 INFO     Evaluating the model... (22500/59072)
2025-12-13 15:25:12,929 INFO     Evaluating the model... (23000/59072)
2025-12-13 15:25:18,207 INFO     Evaluating the model... (23500/59072)
2025-12-13 15:25:23,672 INFO     Evaluating the model... (24000/59072)
2025-12-13 15:25:28,957 INFO     Evaluating the model... (24500/59072)
2025-12-13 15:25:36,841 INFO     Evaluating the model... (25000/59072)
2025-12-13 15:25:41,925 INFO     Evaluating the model... (25500/59072)
2025-12-13 15:25:46,758 INFO     Evaluating the model... (26000/59072)
2025-12-13 15:25:52,283 INFO     Evaluating the model... (26500/59072)
2025-12-13 15:25:57,675 INFO     Evaluating the model... (27000/59072)
2025-12-13 15:26:04,331 INFO     Evaluating the model... (27500/59072)
2025-12-13 15:26:10,751 INFO     Evaluating the model... (28000/59072)
2025-12-13 15:26:16,235 INFO     Evaluating the model... (28500/59072)
2025-12-13 15:26:21,262 INFO     Evaluating the model... (29000/59072)
2025-12-13 15:26:28,309 INFO     Evaluating the model... (29500/59072)
2025-12-13 15:26:34,038 INFO     Evaluating the model... (30000/59072)
2025-12-13 15:26:39,079 INFO     Evaluating the model... (30500/59072)
2025-12-13 15:26:44,451 INFO     Evaluating the model... (31000/59072)
2025-12-13 15:26:49,444 INFO     Evaluating the model... (31500/59072)
2025-12-13 15:26:54,945 INFO     Evaluating the model... (32000/59072)
2025-12-13 15:27:00,706 INFO     Evaluating the model... (32500/59072)
2025-12-13 15:27:06,555 INFO     Evaluating the model... (33000/59072)
2025-12-13 15:27:11,199 INFO     Evaluating the model... (33500/59072)
2025-12-13 15:27:16,344 INFO     Evaluating the model... (34000/59072)
2025-12-13 15:27:22,148 INFO     Evaluating the model... (34500/59072)
2025-12-13 15:27:27,137 INFO     Evaluating the model... (35000/59072)
2025-12-13 15:27:31,889 INFO     Evaluating the model... (35500/59072)
2025-12-13 15:27:37,148 INFO     Evaluating the model... (36000/59072)
2025-12-13 15:27:41,952 INFO     Evaluating the model... (36500/59072)
2025-12-13 15:27:47,052 INFO     Evaluating the model... (37000/59072)
2025-12-13 15:27:52,394 INFO     Evaluating the model... (37500/59072)
2025-12-13 15:27:57,750 INFO     Evaluating the model... (38000/59072)
2025-12-13 15:28:02,455 INFO     Evaluating the model... (38500/59072)
2025-12-13 15:28:08,311 INFO     Evaluating the model... (39000/59072)
2025-12-13 15:28:15,331 INFO     Evaluating the model... (39500/59072)
2025-12-13 15:28:20,108 INFO     Evaluating the model... (40000/59072)
2025-12-13 15:28:26,120 INFO     Evaluating the model... (40500/59072)
2025-12-13 15:28:32,137 INFO     Evaluating the model... (41000/59072)
2025-12-13 15:28:36,922 INFO     Evaluating the model... (41500/59072)
2025-12-13 15:28:42,428 INFO     Evaluating the model... (42000/59072)
2025-12-13 15:28:47,807 INFO     Evaluating the model... (42500/59072)
2025-12-13 15:28:52,656 INFO     Evaluating the model... (43000/59072)
2025-12-13 15:28:57,342 INFO     Evaluating the model... (43500/59072)
2025-12-13 15:29:03,014 INFO     Evaluating the model... (44000/59072)
2025-12-13 15:29:08,512 INFO     Evaluating the model... (44500/59072)
2025-12-13 15:29:13,304 INFO     Evaluating the model... (45000/59072)
2025-12-13 15:29:19,429 INFO     Evaluating the model... (45500/59072)
2025-12-13 15:29:25,377 INFO     Evaluating the model... (46000/59072)
2025-12-13 15:29:30,600 INFO     Evaluating the model... (46500/59072)
2025-12-13 15:29:35,476 INFO     Evaluating the model... (47000/59072)
2025-12-13 15:29:40,266 INFO     Evaluating the model... (47500/59072)
2025-12-13 15:29:45,045 INFO     Evaluating the model... (48000/59072)
2025-12-13 15:29:49,514 INFO     Evaluating the model... (48500/59072)
2025-12-13 15:29:55,754 INFO     Evaluating the model... (49000/59072)
2025-12-13 15:30:01,168 INFO     Evaluating the model... (49500/59072)
2025-12-13 15:30:06,187 INFO     Evaluating the model... (50000/59072)
2025-12-13 15:30:11,719 INFO     Evaluating the model... (50500/59072)
2025-12-13 15:30:17,989 INFO     Evaluating the model... (51000/59072)
2025-12-13 15:30:23,106 INFO     Evaluating the model... (51500/59072)
2025-12-13 15:30:28,968 INFO     Evaluating the model... (52000/59072)
2025-12-13 15:30:35,206 INFO     Evaluating the model... (52500/59072)
2025-12-13 15:30:39,943 INFO     Evaluating the model... (53000/59072)
2025-12-13 15:30:45,191 INFO     Evaluating the model... (53500/59072)
2025-12-13 15:30:51,030 INFO     Evaluating the model... (54000/59072)
2025-12-13 15:30:55,679 INFO     Evaluating the model... (54500/59072)
2025-12-13 15:31:00,814 INFO     Evaluating the model... (55000/59072)
2025-12-13 15:31:06,919 INFO     Evaluating the model... (55500/59072)
2025-12-13 15:31:12,214 INFO     Evaluating the model... (56000/59072)
2025-12-13 15:31:17,806 INFO     Evaluating the model... (56500/59072)
2025-12-13 15:31:23,143 INFO     Evaluating the model... (57000/59072)
2025-12-13 15:31:28,218 INFO     Evaluating the model... (57500/59072)
2025-12-13 15:31:32,792 INFO     Evaluating the model... (58000/59072)
2025-12-13 15:31:38,611 INFO     Evaluating the model... (58500/59072)
2025-12-13 15:31:44,889 INFO     Evaluating the model... (59000/59072)
2025-12-13 15:31:45,811 INFO     Test MRR at step 100000: 0.728200
2025-12-13 15:31:45,811 INFO     Test MR at step 100000: 258.505790
2025-12-13 15:31:45,811 INFO     Test HITS@1 at step 100000: 0.663185
2025-12-13 15:31:45,811 INFO     Test HITS@3 at step 100000: 0.773857
2025-12-13 15:31:45,811 INFO     Test HITS@10 at step 100000: 0.839287
2025-12-13 15:31:50,641 INFO     Training average regularization at step 100100: 0.164096
2025-12-13 15:31:50,641 INFO     Training average positive_sample_loss at step 100100: 0.007480
2025-12-13 15:31:50,641 INFO     Training average negative_sample_loss at step 100100: 0.018716
2025-12-13 15:31:50,641 INFO     Training average loss at step 100100: 0.177193
2025-12-13 15:31:55,653 INFO     Training average regularization at step 100200: 0.164092
2025-12-13 15:31:55,653 INFO     Training average positive_sample_loss at step 100200: 0.007875
2025-12-13 15:31:55,653 INFO     Training average negative_sample_loss at step 100200: 0.019462
2025-12-13 15:31:55,653 INFO     Training average loss at step 100200: 0.177760
2025-12-13 15:32:00,757 INFO     Training average regularization at step 100300: 0.164088
2025-12-13 15:32:00,757 INFO     Training average positive_sample_loss at step 100300: 0.007673
2025-12-13 15:32:00,757 INFO     Training average negative_sample_loss at step 100300: 0.027491
2025-12-13 15:32:00,757 INFO     Training average loss at step 100300: 0.181669
2025-12-13 15:32:05,603 INFO     Training average regularization at step 100400: 0.164084
2025-12-13 15:32:05,603 INFO     Training average positive_sample_loss at step 100400: 0.007226
2025-12-13 15:32:05,603 INFO     Training average negative_sample_loss at step 100400: 0.015193
2025-12-13 15:32:05,603 INFO     Training average loss at step 100400: 0.175293
2025-12-13 15:32:10,747 INFO     Training average regularization at step 100500: 0.164080
2025-12-13 15:32:10,748 INFO     Training average positive_sample_loss at step 100500: 0.007061
2025-12-13 15:32:10,748 INFO     Training average negative_sample_loss at step 100500: 0.021215
2025-12-13 15:32:10,748 INFO     Training average loss at step 100500: 0.178218
2025-12-13 15:32:16,103 INFO     Training average regularization at step 100600: 0.164075
2025-12-13 15:32:16,103 INFO     Training average positive_sample_loss at step 100600: 0.006778
2025-12-13 15:32:16,103 INFO     Training average negative_sample_loss at step 100600: 0.019162
2025-12-13 15:32:16,103 INFO     Training average loss at step 100600: 0.177045
2025-12-13 15:32:21,005 INFO     Training average regularization at step 100700: 0.164071
2025-12-13 15:32:21,005 INFO     Training average positive_sample_loss at step 100700: 0.007785
2025-12-13 15:32:21,005 INFO     Training average negative_sample_loss at step 100700: 0.019731
2025-12-13 15:32:21,006 INFO     Training average loss at step 100700: 0.177829
2025-12-13 15:32:25,986 INFO     Training average regularization at step 100800: 0.164067
2025-12-13 15:32:25,986 INFO     Training average positive_sample_loss at step 100800: 0.007626
2025-12-13 15:32:25,986 INFO     Training average negative_sample_loss at step 100800: 0.022001
2025-12-13 15:32:25,986 INFO     Training average loss at step 100800: 0.178881
2025-12-13 15:32:31,004 INFO     Training average regularization at step 100900: 0.164063
2025-12-13 15:32:31,004 INFO     Training average positive_sample_loss at step 100900: 0.007534
2025-12-13 15:32:31,004 INFO     Training average negative_sample_loss at step 100900: 0.021095
2025-12-13 15:32:31,004 INFO     Training average loss at step 100900: 0.178377
2025-12-13 15:32:36,207 INFO     Training average regularization at step 101000: 0.164059
2025-12-13 15:32:36,207 INFO     Training average positive_sample_loss at step 101000: 0.007156
2025-12-13 15:32:36,207 INFO     Training average negative_sample_loss at step 101000: 0.014497
2025-12-13 15:32:36,207 INFO     Training average loss at step 101000: 0.174885
2025-12-13 15:32:41,054 INFO     Training average regularization at step 101100: 0.164055
2025-12-13 15:32:41,054 INFO     Training average positive_sample_loss at step 101100: 0.007779
2025-12-13 15:32:41,054 INFO     Training average negative_sample_loss at step 101100: 0.026689
2025-12-13 15:32:41,054 INFO     Training average loss at step 101100: 0.181289
2025-12-13 15:32:46,231 INFO     Training average regularization at step 101200: 0.164051
2025-12-13 15:32:46,231 INFO     Training average positive_sample_loss at step 101200: 0.007438
2025-12-13 15:32:46,231 INFO     Training average negative_sample_loss at step 101200: 0.021008
2025-12-13 15:32:46,231 INFO     Training average loss at step 101200: 0.178274
2025-12-13 15:32:51,353 INFO     Training average regularization at step 101300: 0.164047
2025-12-13 15:32:51,354 INFO     Training average positive_sample_loss at step 101300: 0.007478
2025-12-13 15:32:51,354 INFO     Training average negative_sample_loss at step 101300: 0.026633
2025-12-13 15:32:51,354 INFO     Training average loss at step 101300: 0.181102
2025-12-13 15:32:56,156 INFO     Training average regularization at step 101400: 0.164043
2025-12-13 15:32:56,156 INFO     Training average positive_sample_loss at step 101400: 0.007234
2025-12-13 15:32:56,156 INFO     Training average negative_sample_loss at step 101400: 0.023745
2025-12-13 15:32:56,156 INFO     Training average loss at step 101400: 0.179532
2025-12-13 15:33:03,018 INFO     Training average regularization at step 101500: 0.164039
2025-12-13 15:33:03,019 INFO     Training average positive_sample_loss at step 101500: 0.007553
2025-12-13 15:33:03,019 INFO     Training average negative_sample_loss at step 101500: 0.022778
2025-12-13 15:33:03,019 INFO     Training average loss at step 101500: 0.179204
2025-12-13 15:33:08,478 INFO     Training average regularization at step 101600: 0.164034
2025-12-13 15:33:08,479 INFO     Training average positive_sample_loss at step 101600: 0.006894
2025-12-13 15:33:08,479 INFO     Training average negative_sample_loss at step 101600: 0.018403
2025-12-13 15:33:08,479 INFO     Training average loss at step 101600: 0.176683
2025-12-13 15:33:13,309 INFO     Training average regularization at step 101700: 0.164030
2025-12-13 15:33:13,310 INFO     Training average positive_sample_loss at step 101700: 0.006863
2025-12-13 15:33:13,310 INFO     Training average negative_sample_loss at step 101700: 0.023497
2025-12-13 15:33:13,310 INFO     Training average loss at step 101700: 0.179210
2025-12-13 15:33:18,707 INFO     Training average regularization at step 101800: 0.164026
2025-12-13 15:33:18,708 INFO     Training average positive_sample_loss at step 101800: 0.006840
2025-12-13 15:33:18,708 INFO     Training average negative_sample_loss at step 101800: 0.016551
2025-12-13 15:33:18,708 INFO     Training average loss at step 101800: 0.175721
2025-12-13 15:33:24,194 INFO     Training average regularization at step 101900: 0.164021
2025-12-13 15:33:24,194 INFO     Training average positive_sample_loss at step 101900: 0.007629
2025-12-13 15:33:24,195 INFO     Training average negative_sample_loss at step 101900: 0.018290
2025-12-13 15:33:24,195 INFO     Training average loss at step 101900: 0.176981
2025-12-13 15:33:29,189 INFO     Training average regularization at step 102000: 0.164017
2025-12-13 15:33:29,189 INFO     Training average positive_sample_loss at step 102000: 0.007300
2025-12-13 15:33:29,189 INFO     Training average negative_sample_loss at step 102000: 0.024030
2025-12-13 15:33:29,189 INFO     Training average loss at step 102000: 0.179682
2025-12-13 15:33:34,227 INFO     Training average regularization at step 102100: 0.164013
2025-12-13 15:33:34,243 INFO     Training average positive_sample_loss at step 102100: 0.007570
2025-12-13 15:33:34,243 INFO     Training average negative_sample_loss at step 102100: 0.019836
2025-12-13 15:33:34,243 INFO     Training average loss at step 102100: 0.177716
2025-12-13 15:33:39,332 INFO     Training average regularization at step 102200: 0.164008
2025-12-13 15:33:39,333 INFO     Training average positive_sample_loss at step 102200: 0.007571
2025-12-13 15:33:39,333 INFO     Training average negative_sample_loss at step 102200: 0.024834
2025-12-13 15:33:39,333 INFO     Training average loss at step 102200: 0.180211
2025-12-13 15:33:44,315 INFO     Training average regularization at step 102300: 0.164004
2025-12-13 15:33:44,316 INFO     Training average positive_sample_loss at step 102300: 0.007043
2025-12-13 15:33:44,316 INFO     Training average negative_sample_loss at step 102300: 0.018395
2025-12-13 15:33:44,316 INFO     Training average loss at step 102300: 0.176723
2025-12-13 15:33:49,156 INFO     Training average regularization at step 102400: 0.164000
2025-12-13 15:33:49,157 INFO     Training average positive_sample_loss at step 102400: 0.006633
2025-12-13 15:33:49,157 INFO     Training average negative_sample_loss at step 102400: 0.021483
2025-12-13 15:33:49,157 INFO     Training average loss at step 102400: 0.178058
2025-12-13 15:33:54,161 INFO     Training average regularization at step 102500: 0.163995
2025-12-13 15:33:54,237 INFO     Training average positive_sample_loss at step 102500: 0.006909
2025-12-13 15:33:54,237 INFO     Training average negative_sample_loss at step 102500: 0.027816
2025-12-13 15:33:54,237 INFO     Training average loss at step 102500: 0.181358
2025-12-13 15:33:59,301 INFO     Training average regularization at step 102600: 0.163991
2025-12-13 15:33:59,301 INFO     Training average positive_sample_loss at step 102600: 0.006732
2025-12-13 15:33:59,301 INFO     Training average negative_sample_loss at step 102600: 0.019906
2025-12-13 15:33:59,301 INFO     Training average loss at step 102600: 0.177310
2025-12-13 15:34:04,142 INFO     Training average regularization at step 102700: 0.163987
2025-12-13 15:34:04,142 INFO     Training average positive_sample_loss at step 102700: 0.006962
2025-12-13 15:34:04,142 INFO     Training average negative_sample_loss at step 102700: 0.021645
2025-12-13 15:34:04,142 INFO     Training average loss at step 102700: 0.178290
2025-12-13 15:34:09,357 INFO     Training average regularization at step 102800: 0.163982
2025-12-13 15:34:09,361 INFO     Training average positive_sample_loss at step 102800: 0.007630
2025-12-13 15:34:09,361 INFO     Training average negative_sample_loss at step 102800: 0.022399
2025-12-13 15:34:09,361 INFO     Training average loss at step 102800: 0.178996
2025-12-13 15:34:14,707 INFO     Training average regularization at step 102900: 0.163978
2025-12-13 15:34:14,711 INFO     Training average positive_sample_loss at step 102900: 0.007142
2025-12-13 15:34:14,711 INFO     Training average negative_sample_loss at step 102900: 0.019490
2025-12-13 15:34:14,711 INFO     Training average loss at step 102900: 0.177294
2025-12-13 15:34:19,568 INFO     Training average regularization at step 103000: 0.163974
2025-12-13 15:34:19,568 INFO     Training average positive_sample_loss at step 103000: 0.007291
2025-12-13 15:34:19,568 INFO     Training average negative_sample_loss at step 103000: 0.024315
2025-12-13 15:34:19,568 INFO     Training average loss at step 103000: 0.179777
2025-12-13 15:34:24,649 INFO     Training average regularization at step 103100: 0.163970
2025-12-13 15:34:24,660 INFO     Training average positive_sample_loss at step 103100: 0.007964
2025-12-13 15:34:24,660 INFO     Training average negative_sample_loss at step 103100: 0.018233
2025-12-13 15:34:24,660 INFO     Training average loss at step 103100: 0.177068
2025-12-13 15:34:30,025 INFO     Training average regularization at step 103200: 0.163965
2025-12-13 15:34:30,025 INFO     Training average positive_sample_loss at step 103200: 0.006968
2025-12-13 15:34:30,025 INFO     Training average negative_sample_loss at step 103200: 0.020550
2025-12-13 15:34:30,025 INFO     Training average loss at step 103200: 0.177724
2025-12-13 15:34:35,125 INFO     Training average regularization at step 103300: 0.163961
2025-12-13 15:34:35,126 INFO     Training average positive_sample_loss at step 103300: 0.007207
2025-12-13 15:34:35,126 INFO     Training average negative_sample_loss at step 103300: 0.017365
2025-12-13 15:34:35,126 INFO     Training average loss at step 103300: 0.176247
2025-12-13 15:34:39,953 INFO     Training average regularization at step 103400: 0.163957
2025-12-13 15:34:39,954 INFO     Training average positive_sample_loss at step 103400: 0.007591
2025-12-13 15:34:39,954 INFO     Training average negative_sample_loss at step 103400: 0.024146
2025-12-13 15:34:39,954 INFO     Training average loss at step 103400: 0.179825
2025-12-13 15:34:45,041 INFO     Training average regularization at step 103500: 0.163953
2025-12-13 15:34:45,042 INFO     Training average positive_sample_loss at step 103500: 0.007509
2025-12-13 15:34:45,042 INFO     Training average negative_sample_loss at step 103500: 0.023861
2025-12-13 15:34:45,042 INFO     Training average loss at step 103500: 0.179638
2025-12-13 15:34:50,044 INFO     Training average regularization at step 103600: 0.163949
2025-12-13 15:34:50,044 INFO     Training average positive_sample_loss at step 103600: 0.007343
2025-12-13 15:34:50,044 INFO     Training average negative_sample_loss at step 103600: 0.020397
2025-12-13 15:34:50,044 INFO     Training average loss at step 103600: 0.177819
2025-12-13 15:34:54,862 INFO     Training average regularization at step 103700: 0.163944
2025-12-13 15:34:54,872 INFO     Training average positive_sample_loss at step 103700: 0.007391
2025-12-13 15:34:54,872 INFO     Training average negative_sample_loss at step 103700: 0.020576
2025-12-13 15:34:54,872 INFO     Training average loss at step 103700: 0.177928
2025-12-13 15:34:59,842 INFO     Training average regularization at step 103800: 0.163940
2025-12-13 15:34:59,842 INFO     Training average positive_sample_loss at step 103800: 0.007447
2025-12-13 15:34:59,842 INFO     Training average negative_sample_loss at step 103800: 0.024318
2025-12-13 15:34:59,842 INFO     Training average loss at step 103800: 0.179823
2025-12-13 15:35:05,066 INFO     Training average regularization at step 103900: 0.163936
2025-12-13 15:35:05,066 INFO     Training average positive_sample_loss at step 103900: 0.007194
2025-12-13 15:35:05,066 INFO     Training average negative_sample_loss at step 103900: 0.022098
2025-12-13 15:35:05,067 INFO     Training average loss at step 103900: 0.178582
2025-12-13 15:35:09,912 INFO     Training average regularization at step 104000: 0.163932
2025-12-13 15:35:09,913 INFO     Training average positive_sample_loss at step 104000: 0.007025
2025-12-13 15:35:09,913 INFO     Training average negative_sample_loss at step 104000: 0.020382
2025-12-13 15:35:09,913 INFO     Training average loss at step 104000: 0.177636
2025-12-13 15:35:14,992 INFO     Training average regularization at step 104100: 0.163928
2025-12-13 15:35:14,994 INFO     Training average positive_sample_loss at step 104100: 0.007363
2025-12-13 15:35:14,994 INFO     Training average negative_sample_loss at step 104100: 0.023709
2025-12-13 15:35:14,994 INFO     Training average loss at step 104100: 0.179464
2025-12-13 15:35:20,168 INFO     Training average regularization at step 104200: 0.163924
2025-12-13 15:35:20,169 INFO     Training average positive_sample_loss at step 104200: 0.007324
2025-12-13 15:35:20,169 INFO     Training average negative_sample_loss at step 104200: 0.020702
2025-12-13 15:35:20,169 INFO     Training average loss at step 104200: 0.177937
2025-12-13 15:35:25,249 INFO     Training average regularization at step 104300: 0.163920
2025-12-13 15:35:25,250 INFO     Training average positive_sample_loss at step 104300: 0.007403
2025-12-13 15:35:25,250 INFO     Training average negative_sample_loss at step 104300: 0.016933
2025-12-13 15:35:25,250 INFO     Training average loss at step 104300: 0.176088
2025-12-13 15:35:30,164 INFO     Training average regularization at step 104400: 0.163916
2025-12-13 15:35:30,164 INFO     Training average positive_sample_loss at step 104400: 0.007531
2025-12-13 15:35:30,164 INFO     Training average negative_sample_loss at step 104400: 0.019265
2025-12-13 15:35:30,164 INFO     Training average loss at step 104400: 0.177314
2025-12-13 15:35:35,278 INFO     Training average regularization at step 104500: 0.163912
2025-12-13 15:35:35,278 INFO     Training average positive_sample_loss at step 104500: 0.007757
2025-12-13 15:35:35,278 INFO     Training average negative_sample_loss at step 104500: 0.023250
2025-12-13 15:35:35,278 INFO     Training average loss at step 104500: 0.179415
2025-12-13 15:35:40,271 INFO     Training average regularization at step 104600: 0.163908
2025-12-13 15:35:40,272 INFO     Training average positive_sample_loss at step 104600: 0.007937
2025-12-13 15:35:40,272 INFO     Training average negative_sample_loss at step 104600: 0.020293
2025-12-13 15:35:40,272 INFO     Training average loss at step 104600: 0.178023
2025-12-13 15:35:45,211 INFO     Training average regularization at step 104700: 0.163904
2025-12-13 15:35:45,212 INFO     Training average positive_sample_loss at step 104700: 0.007314
2025-12-13 15:35:45,212 INFO     Training average negative_sample_loss at step 104700: 0.023807
2025-12-13 15:35:45,212 INFO     Training average loss at step 104700: 0.179464
2025-12-13 15:35:50,194 INFO     Training average regularization at step 104800: 0.163900
2025-12-13 15:35:50,194 INFO     Training average positive_sample_loss at step 104800: 0.008010
2025-12-13 15:35:50,194 INFO     Training average negative_sample_loss at step 104800: 0.018009
2025-12-13 15:35:50,194 INFO     Training average loss at step 104800: 0.176909
2025-12-13 15:35:55,293 INFO     Training average regularization at step 104900: 0.163896
2025-12-13 15:35:55,293 INFO     Training average positive_sample_loss at step 104900: 0.007138
2025-12-13 15:35:55,293 INFO     Training average negative_sample_loss at step 104900: 0.022790
2025-12-13 15:35:55,293 INFO     Training average loss at step 104900: 0.178860
2025-12-13 15:36:00,096 INFO     Training average regularization at step 105000: 0.163892
2025-12-13 15:36:00,096 INFO     Training average positive_sample_loss at step 105000: 0.007615
2025-12-13 15:36:00,096 INFO     Training average negative_sample_loss at step 105000: 0.022364
2025-12-13 15:36:00,096 INFO     Training average loss at step 105000: 0.178881
2025-12-13 15:36:05,199 INFO     Training average regularization at step 105100: 0.163888
2025-12-13 15:36:05,199 INFO     Training average positive_sample_loss at step 105100: 0.007094
2025-12-13 15:36:05,199 INFO     Training average negative_sample_loss at step 105100: 0.021384
2025-12-13 15:36:05,199 INFO     Training average loss at step 105100: 0.178127
2025-12-13 15:36:10,341 INFO     Training average regularization at step 105200: 0.163884
2025-12-13 15:36:10,342 INFO     Training average positive_sample_loss at step 105200: 0.007414
2025-12-13 15:36:10,342 INFO     Training average negative_sample_loss at step 105200: 0.025363
2025-12-13 15:36:10,342 INFO     Training average loss at step 105200: 0.180272
2025-12-13 15:36:15,484 INFO     Training average regularization at step 105300: 0.163880
2025-12-13 15:36:15,484 INFO     Training average positive_sample_loss at step 105300: 0.007373
2025-12-13 15:36:15,484 INFO     Training average negative_sample_loss at step 105300: 0.021974
2025-12-13 15:36:15,484 INFO     Training average loss at step 105300: 0.178553
2025-12-13 15:36:20,416 INFO     Training average regularization at step 105400: 0.163876
2025-12-13 15:36:20,416 INFO     Training average positive_sample_loss at step 105400: 0.007957
2025-12-13 15:36:20,416 INFO     Training average negative_sample_loss at step 105400: 0.018376
2025-12-13 15:36:20,416 INFO     Training average loss at step 105400: 0.177042
2025-12-13 15:36:25,835 INFO     Training average regularization at step 105500: 0.163872
2025-12-13 15:36:25,839 INFO     Training average positive_sample_loss at step 105500: 0.008103
2025-12-13 15:36:25,839 INFO     Training average negative_sample_loss at step 105500: 0.021696
2025-12-13 15:36:25,839 INFO     Training average loss at step 105500: 0.178772
2025-12-13 15:36:31,129 INFO     Training average regularization at step 105600: 0.163868
2025-12-13 15:36:31,130 INFO     Training average positive_sample_loss at step 105600: 0.007884
2025-12-13 15:36:31,130 INFO     Training average negative_sample_loss at step 105600: 0.022577
2025-12-13 15:36:31,130 INFO     Training average loss at step 105600: 0.179098
2025-12-13 15:36:36,097 INFO     Training average regularization at step 105700: 0.163864
2025-12-13 15:36:36,097 INFO     Training average positive_sample_loss at step 105700: 0.007271
2025-12-13 15:36:36,098 INFO     Training average negative_sample_loss at step 105700: 0.018833
2025-12-13 15:36:36,098 INFO     Training average loss at step 105700: 0.176916
2025-12-13 15:36:41,164 INFO     Training average regularization at step 105800: 0.163860
2025-12-13 15:36:41,165 INFO     Training average positive_sample_loss at step 105800: 0.006980
2025-12-13 15:36:41,165 INFO     Training average negative_sample_loss at step 105800: 0.017050
2025-12-13 15:36:41,165 INFO     Training average loss at step 105800: 0.175875
2025-12-13 15:36:46,200 INFO     Training average regularization at step 105900: 0.163856
2025-12-13 15:36:46,201 INFO     Training average positive_sample_loss at step 105900: 0.008757
2025-12-13 15:36:46,201 INFO     Training average negative_sample_loss at step 105900: 0.025512
2025-12-13 15:36:46,201 INFO     Training average loss at step 105900: 0.180991
2025-12-13 15:36:51,087 INFO     Training average regularization at step 106000: 0.163852
2025-12-13 15:36:51,087 INFO     Training average positive_sample_loss at step 106000: 0.008067
2025-12-13 15:36:51,087 INFO     Training average negative_sample_loss at step 106000: 0.024318
2025-12-13 15:36:51,087 INFO     Training average loss at step 106000: 0.180045
2025-12-13 15:36:56,086 INFO     Training average regularization at step 106100: 0.163849
2025-12-13 15:36:56,088 INFO     Training average positive_sample_loss at step 106100: 0.007916
2025-12-13 15:36:56,088 INFO     Training average negative_sample_loss at step 106100: 0.025068
2025-12-13 15:36:56,088 INFO     Training average loss at step 106100: 0.180340
2025-12-13 15:37:01,245 INFO     Training average regularization at step 106200: 0.163845
2025-12-13 15:37:01,246 INFO     Training average positive_sample_loss at step 106200: 0.007380
2025-12-13 15:37:01,246 INFO     Training average negative_sample_loss at step 106200: 0.018517
2025-12-13 15:37:01,246 INFO     Training average loss at step 106200: 0.176794
2025-12-13 15:37:06,398 INFO     Training average regularization at step 106300: 0.163841
2025-12-13 15:37:06,399 INFO     Training average positive_sample_loss at step 106300: 0.007679
2025-12-13 15:37:06,399 INFO     Training average negative_sample_loss at step 106300: 0.019293
2025-12-13 15:37:06,399 INFO     Training average loss at step 106300: 0.177327
2025-12-13 15:37:12,856 INFO     Training average regularization at step 106400: 0.163837
2025-12-13 15:37:12,857 INFO     Training average positive_sample_loss at step 106400: 0.007518
2025-12-13 15:37:12,857 INFO     Training average negative_sample_loss at step 106400: 0.019708
2025-12-13 15:37:12,857 INFO     Training average loss at step 106400: 0.177450
2025-12-13 15:37:18,209 INFO     Training average regularization at step 106500: 0.163833
2025-12-13 15:37:18,209 INFO     Training average positive_sample_loss at step 106500: 0.007168
2025-12-13 15:37:18,209 INFO     Training average negative_sample_loss at step 106500: 0.019495
2025-12-13 15:37:18,209 INFO     Training average loss at step 106500: 0.177164
2025-12-13 15:37:23,157 INFO     Training average regularization at step 106600: 0.163829
2025-12-13 15:37:23,157 INFO     Training average positive_sample_loss at step 106600: 0.007289
2025-12-13 15:37:23,157 INFO     Training average negative_sample_loss at step 106600: 0.020559
2025-12-13 15:37:23,157 INFO     Training average loss at step 106600: 0.177753
2025-12-13 15:37:28,215 INFO     Training average regularization at step 106700: 0.163825
2025-12-13 15:37:28,215 INFO     Training average positive_sample_loss at step 106700: 0.007547
2025-12-13 15:37:28,215 INFO     Training average negative_sample_loss at step 106700: 0.021691
2025-12-13 15:37:28,215 INFO     Training average loss at step 106700: 0.178443
2025-12-13 15:37:33,567 INFO     Training average regularization at step 106800: 0.163821
2025-12-13 15:37:33,567 INFO     Training average positive_sample_loss at step 106800: 0.007866
2025-12-13 15:37:33,567 INFO     Training average negative_sample_loss at step 106800: 0.017711
2025-12-13 15:37:33,567 INFO     Training average loss at step 106800: 0.176609
2025-12-13 15:37:38,736 INFO     Training average regularization at step 106900: 0.163816
2025-12-13 15:37:38,737 INFO     Training average positive_sample_loss at step 106900: 0.008035
2025-12-13 15:37:38,737 INFO     Training average negative_sample_loss at step 106900: 0.021579
2025-12-13 15:37:38,737 INFO     Training average loss at step 106900: 0.178623
2025-12-13 15:37:43,589 INFO     Training average regularization at step 107000: 0.163812
2025-12-13 15:37:43,589 INFO     Training average positive_sample_loss at step 107000: 0.007699
2025-12-13 15:37:43,589 INFO     Training average negative_sample_loss at step 107000: 0.015292
2025-12-13 15:37:43,589 INFO     Training average loss at step 107000: 0.175308
2025-12-13 15:37:48,489 INFO     Training average regularization at step 107100: 0.163808
2025-12-13 15:37:48,489 INFO     Training average positive_sample_loss at step 107100: 0.007534
2025-12-13 15:37:48,490 INFO     Training average negative_sample_loss at step 107100: 0.016732
2025-12-13 15:37:48,490 INFO     Training average loss at step 107100: 0.175941
2025-12-13 15:37:53,420 INFO     Training average regularization at step 107200: 0.163804
2025-12-13 15:37:53,420 INFO     Training average positive_sample_loss at step 107200: 0.007307
2025-12-13 15:37:53,420 INFO     Training average negative_sample_loss at step 107200: 0.020118
2025-12-13 15:37:53,420 INFO     Training average loss at step 107200: 0.177516
2025-12-13 15:37:58,337 INFO     Training average regularization at step 107300: 0.163800
2025-12-13 15:37:58,337 INFO     Training average positive_sample_loss at step 107300: 0.006581
2025-12-13 15:37:58,337 INFO     Training average negative_sample_loss at step 107300: 0.019318
2025-12-13 15:37:58,337 INFO     Training average loss at step 107300: 0.176749
2025-12-13 15:38:03,512 INFO     Training average regularization at step 107400: 0.163796
2025-12-13 15:38:03,515 INFO     Training average positive_sample_loss at step 107400: 0.007367
2025-12-13 15:38:03,515 INFO     Training average negative_sample_loss at step 107400: 0.020933
2025-12-13 15:38:03,515 INFO     Training average loss at step 107400: 0.177945
2025-12-13 15:38:08,927 INFO     Training average regularization at step 107500: 0.163791
2025-12-13 15:38:08,927 INFO     Training average positive_sample_loss at step 107500: 0.007300
2025-12-13 15:38:08,927 INFO     Training average negative_sample_loss at step 107500: 0.020919
2025-12-13 15:38:08,927 INFO     Training average loss at step 107500: 0.177901
2025-12-13 15:38:14,015 INFO     Training average regularization at step 107600: 0.163787
2025-12-13 15:38:14,016 INFO     Training average positive_sample_loss at step 107600: 0.006864
2025-12-13 15:38:14,016 INFO     Training average negative_sample_loss at step 107600: 0.018725
2025-12-13 15:38:14,016 INFO     Training average loss at step 107600: 0.176582
2025-12-13 15:38:19,000 INFO     Training average regularization at step 107700: 0.163783
2025-12-13 15:38:19,001 INFO     Training average positive_sample_loss at step 107700: 0.008104
2025-12-13 15:38:19,001 INFO     Training average negative_sample_loss at step 107700: 0.018614
2025-12-13 15:38:19,001 INFO     Training average loss at step 107700: 0.177142
2025-12-13 15:38:24,411 INFO     Training average regularization at step 107800: 0.163779
2025-12-13 15:38:24,411 INFO     Training average positive_sample_loss at step 107800: 0.007277
2025-12-13 15:38:24,411 INFO     Training average negative_sample_loss at step 107800: 0.017201
2025-12-13 15:38:24,411 INFO     Training average loss at step 107800: 0.176018
2025-12-13 15:38:29,531 INFO     Training average regularization at step 107900: 0.163775
2025-12-13 15:38:29,531 INFO     Training average positive_sample_loss at step 107900: 0.006884
2025-12-13 15:38:29,532 INFO     Training average negative_sample_loss at step 107900: 0.022255
2025-12-13 15:38:29,532 INFO     Training average loss at step 107900: 0.178345
2025-12-13 15:38:34,372 INFO     Training average regularization at step 108000: 0.163770
2025-12-13 15:38:34,372 INFO     Training average positive_sample_loss at step 108000: 0.007297
2025-12-13 15:38:34,372 INFO     Training average negative_sample_loss at step 108000: 0.020697
2025-12-13 15:38:34,372 INFO     Training average loss at step 108000: 0.177768
2025-12-13 15:38:39,485 INFO     Training average regularization at step 108100: 0.163766
2025-12-13 15:38:39,485 INFO     Training average positive_sample_loss at step 108100: 0.007849
2025-12-13 15:38:39,485 INFO     Training average negative_sample_loss at step 108100: 0.022661
2025-12-13 15:38:39,485 INFO     Training average loss at step 108100: 0.179021
2025-12-13 15:38:44,586 INFO     Training average regularization at step 108200: 0.163762
2025-12-13 15:38:44,586 INFO     Training average positive_sample_loss at step 108200: 0.007080
2025-12-13 15:38:44,586 INFO     Training average negative_sample_loss at step 108200: 0.024155
2025-12-13 15:38:44,586 INFO     Training average loss at step 108200: 0.179380
2025-12-13 15:38:49,433 INFO     Training average regularization at step 108300: 0.163758
2025-12-13 15:38:49,436 INFO     Training average positive_sample_loss at step 108300: 0.007800
2025-12-13 15:38:49,436 INFO     Training average negative_sample_loss at step 108300: 0.018886
2025-12-13 15:38:49,436 INFO     Training average loss at step 108300: 0.177101
2025-12-13 15:38:54,367 INFO     Training average regularization at step 108400: 0.163754
2025-12-13 15:38:54,367 INFO     Training average positive_sample_loss at step 108400: 0.007272
2025-12-13 15:38:54,367 INFO     Training average negative_sample_loss at step 108400: 0.022478
2025-12-13 15:38:54,367 INFO     Training average loss at step 108400: 0.178629
2025-12-13 15:38:59,518 INFO     Training average regularization at step 108500: 0.163750
2025-12-13 15:38:59,519 INFO     Training average positive_sample_loss at step 108500: 0.007244
2025-12-13 15:38:59,519 INFO     Training average negative_sample_loss at step 108500: 0.017785
2025-12-13 15:38:59,519 INFO     Training average loss at step 108500: 0.176264
2025-12-13 15:39:04,435 INFO     Training average regularization at step 108600: 0.163746
2025-12-13 15:39:04,435 INFO     Training average positive_sample_loss at step 108600: 0.008675
2025-12-13 15:39:04,435 INFO     Training average negative_sample_loss at step 108600: 0.021925
2025-12-13 15:39:04,435 INFO     Training average loss at step 108600: 0.179046
2025-12-13 15:39:09,335 INFO     Training average regularization at step 108700: 0.163742
2025-12-13 15:39:09,335 INFO     Training average positive_sample_loss at step 108700: 0.007128
2025-12-13 15:39:09,335 INFO     Training average negative_sample_loss at step 108700: 0.020806
2025-12-13 15:39:09,335 INFO     Training average loss at step 108700: 0.177709
2025-12-13 15:39:14,580 INFO     Training average regularization at step 108800: 0.163738
2025-12-13 15:39:14,581 INFO     Training average positive_sample_loss at step 108800: 0.007476
2025-12-13 15:39:14,581 INFO     Training average negative_sample_loss at step 108800: 0.018046
2025-12-13 15:39:14,581 INFO     Training average loss at step 108800: 0.176498
2025-12-13 15:39:19,739 INFO     Training average regularization at step 108900: 0.163733
2025-12-13 15:39:19,740 INFO     Training average positive_sample_loss at step 108900: 0.007907
2025-12-13 15:39:19,740 INFO     Training average negative_sample_loss at step 108900: 0.019832
2025-12-13 15:39:19,740 INFO     Training average loss at step 108900: 0.177603
2025-12-13 15:39:24,617 INFO     Training average regularization at step 109000: 0.163729
2025-12-13 15:39:24,617 INFO     Training average positive_sample_loss at step 109000: 0.007249
2025-12-13 15:39:24,617 INFO     Training average negative_sample_loss at step 109000: 0.019217
2025-12-13 15:39:24,617 INFO     Training average loss at step 109000: 0.176963
2025-12-13 15:39:29,863 INFO     Training average regularization at step 109100: 0.163725
2025-12-13 15:39:29,864 INFO     Training average positive_sample_loss at step 109100: 0.007175
2025-12-13 15:39:29,865 INFO     Training average negative_sample_loss at step 109100: 0.019188
2025-12-13 15:39:29,865 INFO     Training average loss at step 109100: 0.176907
2025-12-13 15:39:35,132 INFO     Training average regularization at step 109200: 0.163721
2025-12-13 15:39:35,132 INFO     Training average positive_sample_loss at step 109200: 0.007735
2025-12-13 15:39:35,132 INFO     Training average negative_sample_loss at step 109200: 0.015499
2025-12-13 15:39:35,132 INFO     Training average loss at step 109200: 0.175338
2025-12-13 15:39:39,993 INFO     Training average regularization at step 109300: 0.163717
2025-12-13 15:39:39,993 INFO     Training average positive_sample_loss at step 109300: 0.007398
2025-12-13 15:39:39,993 INFO     Training average negative_sample_loss at step 109300: 0.018957
2025-12-13 15:39:39,993 INFO     Training average loss at step 109300: 0.176895
2025-12-13 15:39:44,984 INFO     Training average regularization at step 109400: 0.163713
2025-12-13 15:39:44,984 INFO     Training average positive_sample_loss at step 109400: 0.007566
2025-12-13 15:39:44,984 INFO     Training average negative_sample_loss at step 109400: 0.023471
2025-12-13 15:39:44,984 INFO     Training average loss at step 109400: 0.179232
2025-12-13 15:39:50,043 INFO     Training average regularization at step 109500: 0.163709
2025-12-13 15:39:50,044 INFO     Training average positive_sample_loss at step 109500: 0.007605
2025-12-13 15:39:50,044 INFO     Training average negative_sample_loss at step 109500: 0.017317
2025-12-13 15:39:50,044 INFO     Training average loss at step 109500: 0.176170
2025-12-13 15:39:55,029 INFO     Training average regularization at step 109600: 0.163705
2025-12-13 15:39:55,029 INFO     Training average positive_sample_loss at step 109600: 0.006930
2025-12-13 15:39:55,029 INFO     Training average negative_sample_loss at step 109600: 0.021515
2025-12-13 15:39:55,029 INFO     Training average loss at step 109600: 0.177928
2025-12-13 15:39:59,982 INFO     Training average regularization at step 109700: 0.163701
2025-12-13 15:39:59,983 INFO     Training average positive_sample_loss at step 109700: 0.006711
2025-12-13 15:39:59,983 INFO     Training average negative_sample_loss at step 109700: 0.018918
2025-12-13 15:39:59,983 INFO     Training average loss at step 109700: 0.176516
2025-12-13 15:40:05,021 INFO     Training average regularization at step 109800: 0.163697
2025-12-13 15:40:05,021 INFO     Training average positive_sample_loss at step 109800: 0.007120
2025-12-13 15:40:05,021 INFO     Training average negative_sample_loss at step 109800: 0.024434
2025-12-13 15:40:05,022 INFO     Training average loss at step 109800: 0.179474
2025-12-13 15:40:09,965 INFO     Training average regularization at step 109900: 0.163693
2025-12-13 15:40:09,965 INFO     Training average positive_sample_loss at step 109900: 0.006913
2025-12-13 15:40:09,965 INFO     Training average negative_sample_loss at step 109900: 0.020741
2025-12-13 15:40:09,965 INFO     Training average loss at step 109900: 0.177520
2025-12-13 15:40:14,878 INFO     Training average regularization at step 110000: 0.163689
2025-12-13 15:40:14,882 INFO     Training average positive_sample_loss at step 110000: 0.007435
2025-12-13 15:40:14,882 INFO     Training average negative_sample_loss at step 110000: 0.025083
2025-12-13 15:40:14,882 INFO     Training average loss at step 110000: 0.179948
2025-12-13 15:40:14,882 INFO     Evaluating on Valid Dataset...
2025-12-13 15:40:15,922 INFO     Evaluating the model... (0/50000)
2025-12-13 15:40:22,447 INFO     Evaluating the model... (500/50000)
2025-12-13 15:40:27,938 INFO     Evaluating the model... (1000/50000)
2025-12-13 15:40:32,597 INFO     Evaluating the model... (1500/50000)
2025-12-13 15:40:39,060 INFO     Evaluating the model... (2000/50000)
2025-12-13 15:40:43,932 INFO     Evaluating the model... (2500/50000)
2025-12-13 15:40:48,540 INFO     Evaluating the model... (3000/50000)
2025-12-13 15:40:53,431 INFO     Evaluating the model... (3500/50000)
2025-12-13 15:40:58,949 INFO     Evaluating the model... (4000/50000)
2025-12-13 15:41:04,167 INFO     Evaluating the model... (4500/50000)
2025-12-13 15:41:09,478 INFO     Evaluating the model... (5000/50000)
2025-12-13 15:41:15,654 INFO     Evaluating the model... (5500/50000)
2025-12-13 15:41:20,531 INFO     Evaluating the model... (6000/50000)
2025-12-13 15:41:25,795 INFO     Evaluating the model... (6500/50000)
2025-12-13 15:41:32,144 INFO     Evaluating the model... (7000/50000)
2025-12-13 15:41:37,344 INFO     Evaluating the model... (7500/50000)
2025-12-13 15:41:41,871 INFO     Evaluating the model... (8000/50000)
2025-12-13 15:41:47,338 INFO     Evaluating the model... (8500/50000)
2025-12-13 15:41:52,930 INFO     Evaluating the model... (9000/50000)
2025-12-13 15:41:57,464 INFO     Evaluating the model... (9500/50000)
2025-12-13 15:42:03,395 INFO     Evaluating the model... (10000/50000)
2025-12-13 15:42:09,059 INFO     Evaluating the model... (10500/50000)
2025-12-13 15:42:13,696 INFO     Evaluating the model... (11000/50000)
2025-12-13 15:42:19,138 INFO     Evaluating the model... (11500/50000)
2025-12-13 15:42:23,838 INFO     Evaluating the model... (12000/50000)
2025-12-13 15:42:28,612 INFO     Evaluating the model... (12500/50000)
2025-12-13 15:42:33,276 INFO     Evaluating the model... (13000/50000)
2025-12-13 15:42:38,453 INFO     Evaluating the model... (13500/50000)
2025-12-13 15:42:44,219 INFO     Evaluating the model... (14000/50000)
2025-12-13 15:42:48,758 INFO     Evaluating the model... (14500/50000)
2025-12-13 15:42:53,519 INFO     Evaluating the model... (15000/50000)
2025-12-13 15:42:58,845 INFO     Evaluating the model... (15500/50000)
2025-12-13 15:43:03,812 INFO     Evaluating the model... (16000/50000)
2025-12-13 15:43:09,934 INFO     Evaluating the model... (16500/50000)
2025-12-13 15:43:16,120 INFO     Evaluating the model... (17000/50000)
2025-12-13 15:43:21,215 INFO     Evaluating the model... (17500/50000)
2025-12-13 15:43:26,156 INFO     Evaluating the model... (18000/50000)
2025-12-13 15:43:32,269 INFO     Evaluating the model... (18500/50000)
2025-12-13 15:43:38,674 INFO     Evaluating the model... (19000/50000)
2025-12-13 15:43:43,256 INFO     Evaluating the model... (19500/50000)
2025-12-13 15:43:48,911 INFO     Evaluating the model... (20000/50000)
2025-12-13 15:43:54,065 INFO     Evaluating the model... (20500/50000)
2025-12-13 15:43:58,637 INFO     Evaluating the model... (21000/50000)
2025-12-13 15:44:05,740 INFO     Evaluating the model... (21500/50000)
2025-12-13 15:44:11,147 INFO     Evaluating the model... (22000/50000)
2025-12-13 15:44:15,851 INFO     Evaluating the model... (22500/50000)
2025-12-13 15:44:21,291 INFO     Evaluating the model... (23000/50000)
2025-12-13 15:44:26,074 INFO     Evaluating the model... (23500/50000)
2025-12-13 15:44:31,607 INFO     Evaluating the model... (24000/50000)
2025-12-13 15:44:36,142 INFO     Evaluating the model... (24500/50000)
2025-12-13 15:44:41,206 INFO     Evaluating the model... (25000/50000)
2025-12-13 15:44:45,900 INFO     Evaluating the model... (25500/50000)
2025-12-13 15:44:50,452 INFO     Evaluating the model... (26000/50000)
2025-12-13 15:44:56,477 INFO     Evaluating the model... (26500/50000)
2025-12-13 15:45:01,626 INFO     Evaluating the model... (27000/50000)
2025-12-13 15:45:06,288 INFO     Evaluating the model... (27500/50000)
2025-12-13 15:45:11,356 INFO     Evaluating the model... (28000/50000)
2025-12-13 15:45:17,516 INFO     Evaluating the model... (28500/50000)
2025-12-13 15:45:23,075 INFO     Evaluating the model... (29000/50000)
2025-12-13 15:45:28,033 INFO     Evaluating the model... (29500/50000)
2025-12-13 15:45:33,760 INFO     Evaluating the model... (30000/50000)
2025-12-13 15:45:38,970 INFO     Evaluating the model... (30500/50000)
2025-12-13 15:45:43,481 INFO     Evaluating the model... (31000/50000)
2025-12-13 15:45:49,795 INFO     Evaluating the model... (31500/50000)
2025-12-13 15:45:55,160 INFO     Evaluating the model... (32000/50000)
2025-12-13 15:45:59,632 INFO     Evaluating the model... (32500/50000)
2025-12-13 15:46:05,724 INFO     Evaluating the model... (33000/50000)
2025-12-13 15:46:11,575 INFO     Evaluating the model... (33500/50000)
2025-12-13 15:46:16,803 INFO     Evaluating the model... (34000/50000)
2025-12-13 15:46:22,421 INFO     Evaluating the model... (34500/50000)
2025-12-13 15:46:28,067 INFO     Evaluating the model... (35000/50000)
2025-12-13 15:46:32,892 INFO     Evaluating the model... (35500/50000)
2025-12-13 15:46:38,404 INFO     Evaluating the model... (36000/50000)
2025-12-13 15:46:43,125 INFO     Evaluating the model... (36500/50000)
2025-12-13 15:46:47,773 INFO     Evaluating the model... (37000/50000)
2025-12-13 15:46:52,378 INFO     Evaluating the model... (37500/50000)
2025-12-13 15:46:57,115 INFO     Evaluating the model... (38000/50000)
2025-12-13 15:47:02,646 INFO     Evaluating the model... (38500/50000)
2025-12-13 15:47:07,326 INFO     Evaluating the model... (39000/50000)
2025-12-13 15:47:12,848 INFO     Evaluating the model... (39500/50000)
2025-12-13 15:47:19,188 INFO     Evaluating the model... (40000/50000)
2025-12-13 15:47:24,297 INFO     Evaluating the model... (40500/50000)
2025-12-13 15:47:30,799 INFO     Evaluating the model... (41000/50000)
2025-12-13 15:47:36,764 INFO     Evaluating the model... (41500/50000)
2025-12-13 15:47:41,764 INFO     Evaluating the model... (42000/50000)
2025-12-13 15:47:46,750 INFO     Evaluating the model... (42500/50000)
2025-12-13 15:47:52,123 INFO     Evaluating the model... (43000/50000)
2025-12-13 15:47:57,944 INFO     Evaluating the model... (43500/50000)
2025-12-13 15:48:02,813 INFO     Evaluating the model... (44000/50000)
2025-12-13 15:48:08,807 INFO     Evaluating the model... (44500/50000)
2025-12-13 15:48:13,945 INFO     Evaluating the model... (45000/50000)
2025-12-13 15:48:18,586 INFO     Evaluating the model... (45500/50000)
2025-12-13 15:48:25,419 INFO     Evaluating the model... (46000/50000)
2025-12-13 15:48:30,676 INFO     Evaluating the model... (46500/50000)
2025-12-13 15:48:35,561 INFO     Evaluating the model... (47000/50000)
2025-12-13 15:48:40,848 INFO     Evaluating the model... (47500/50000)
2025-12-13 15:48:46,273 INFO     Evaluating the model... (48000/50000)
2025-12-13 15:48:51,862 INFO     Evaluating the model... (48500/50000)
2025-12-13 15:48:56,848 INFO     Evaluating the model... (49000/50000)
2025-12-13 15:49:02,546 INFO     Evaluating the model... (49500/50000)
2025-12-13 15:49:07,508 INFO     Valid MRR at step 110000: 0.733775
2025-12-13 15:49:07,508 INFO     Valid MR at step 110000: 256.051060
2025-12-13 15:49:07,508 INFO     Valid HITS@1 at step 110000: 0.669600
2025-12-13 15:49:07,509 INFO     Valid HITS@3 at step 110000: 0.779320
2025-12-13 15:49:07,509 INFO     Valid HITS@10 at step 110000: 0.843610
2025-12-13 15:49:08,912 INFO     Evaluating on Test Dataset...
2025-12-13 15:49:09,656 INFO     Evaluating the model... (0/59072)
2025-12-13 15:49:14,326 INFO     Evaluating the model... (500/59072)
2025-12-13 15:49:20,303 INFO     Evaluating the model... (1000/59072)
2025-12-13 15:49:25,323 INFO     Evaluating the model... (1500/59072)
2025-12-13 15:49:30,590 INFO     Evaluating the model... (2000/59072)
2025-12-13 15:49:36,662 INFO     Evaluating the model... (2500/59072)
2025-12-13 15:49:41,620 INFO     Evaluating the model... (3000/59072)
2025-12-13 15:49:47,392 INFO     Evaluating the model... (3500/59072)
2025-12-13 15:49:53,382 INFO     Evaluating the model... (4000/59072)
2025-12-13 15:49:58,593 INFO     Evaluating the model... (4500/59072)
2025-12-13 15:50:03,209 INFO     Evaluating the model... (5000/59072)
2025-12-13 15:50:10,620 INFO     Evaluating the model... (5500/59072)
2025-12-13 15:50:17,082 INFO     Evaluating the model... (6000/59072)
2025-12-13 15:50:21,743 INFO     Evaluating the model... (6500/59072)
2025-12-13 15:50:28,263 INFO     Evaluating the model... (7000/59072)
2025-12-13 15:50:34,210 INFO     Evaluating the model... (7500/59072)
2025-12-13 15:50:38,914 INFO     Evaluating the model... (8000/59072)
2025-12-13 15:50:44,481 INFO     Evaluating the model... (8500/59072)
2025-12-13 15:50:49,953 INFO     Evaluating the model... (9000/59072)
2025-12-13 15:50:54,942 INFO     Evaluating the model... (9500/59072)
2025-12-13 15:51:00,157 INFO     Evaluating the model... (10000/59072)
2025-12-13 15:51:06,840 INFO     Evaluating the model... (10500/59072)
2025-12-13 15:51:12,461 INFO     Evaluating the model... (11000/59072)
2025-12-13 15:51:17,711 INFO     Evaluating the model... (11500/59072)
2025-12-13 15:51:24,411 INFO     Evaluating the model... (12000/59072)
2025-12-13 15:51:29,608 INFO     Evaluating the model... (12500/59072)
2025-12-13 15:51:35,181 INFO     Evaluating the model... (13000/59072)
2025-12-13 15:51:41,228 INFO     Evaluating the model... (13500/59072)
2025-12-13 15:51:46,279 INFO     Evaluating the model... (14000/59072)
2025-12-13 15:51:50,911 INFO     Evaluating the model... (14500/59072)
2025-12-13 15:51:56,638 INFO     Evaluating the model... (15000/59072)
2025-12-13 15:52:03,915 INFO     Evaluating the model... (15500/59072)
2025-12-13 15:52:08,525 INFO     Evaluating the model... (16000/59072)
2025-12-13 15:52:14,488 INFO     Evaluating the model... (16500/59072)
2025-12-13 15:52:20,601 INFO     Evaluating the model... (17000/59072)
2025-12-13 15:52:25,566 INFO     Evaluating the model... (17500/59072)
2025-12-13 15:52:31,519 INFO     Evaluating the model... (18000/59072)
2025-12-13 15:52:37,747 INFO     Evaluating the model... (18500/59072)
2025-12-13 15:52:42,486 INFO     Evaluating the model... (19000/59072)
2025-12-13 15:52:47,427 INFO     Evaluating the model... (19500/59072)
2025-12-13 15:52:52,982 INFO     Evaluating the model... (20000/59072)
2025-12-13 15:52:58,758 INFO     Evaluating the model... (20500/59072)
2025-12-13 15:53:03,506 INFO     Evaluating the model... (21000/59072)
2025-12-13 15:53:10,272 INFO     Evaluating the model... (21500/59072)
2025-12-13 15:53:15,902 INFO     Evaluating the model... (22000/59072)
2025-12-13 15:53:20,587 INFO     Evaluating the model... (22500/59072)
2025-12-13 15:53:28,335 INFO     Evaluating the model... (23000/59072)
2025-12-13 15:53:34,226 INFO     Evaluating the model... (23500/59072)
2025-12-13 15:53:38,963 INFO     Evaluating the model... (24000/59072)
2025-12-13 15:53:44,366 INFO     Evaluating the model... (24500/59072)
2025-12-13 15:53:49,640 INFO     Evaluating the model... (25000/59072)
2025-12-13 15:53:55,452 INFO     Evaluating the model... (25500/59072)
2025-12-13 15:54:01,370 INFO     Evaluating the model... (26000/59072)
2025-12-13 15:54:07,876 INFO     Evaluating the model... (26500/59072)
2025-12-13 15:54:12,920 INFO     Evaluating the model... (27000/59072)
2025-12-13 15:54:17,959 INFO     Evaluating the model... (27500/59072)
2025-12-13 15:54:26,705 INFO     Evaluating the model... (28000/59072)
2025-12-13 15:54:31,406 INFO     Evaluating the model... (28500/59072)
2025-12-13 15:54:36,700 INFO     Evaluating the model... (29000/59072)
2025-12-13 15:54:42,692 INFO     Evaluating the model... (29500/59072)
2025-12-13 15:54:49,024 INFO     Evaluating the model... (30000/59072)
2025-12-13 15:54:53,681 INFO     Evaluating the model... (30500/59072)
2025-12-13 15:54:59,732 INFO     Evaluating the model... (31000/59072)
2025-12-13 15:55:05,540 INFO     Evaluating the model... (31500/59072)
2025-12-13 15:55:10,234 INFO     Evaluating the model... (32000/59072)
2025-12-13 15:55:17,581 INFO     Evaluating the model... (32500/59072)
2025-12-13 15:55:22,953 INFO     Evaluating the model... (33000/59072)
2025-12-13 15:55:27,596 INFO     Evaluating the model... (33500/59072)
2025-12-13 15:55:33,921 INFO     Evaluating the model... (34000/59072)
2025-12-13 15:55:40,004 INFO     Evaluating the model... (34500/59072)
2025-12-13 15:55:45,507 INFO     Evaluating the model... (35000/59072)
2025-12-13 15:55:50,696 INFO     Evaluating the model... (35500/59072)
2025-12-13 15:55:55,944 INFO     Evaluating the model... (36000/59072)
2025-12-13 15:56:00,995 INFO     Evaluating the model... (36500/59072)
2025-12-13 15:56:07,074 INFO     Evaluating the model... (37000/59072)
2025-12-13 15:56:14,074 INFO     Evaluating the model... (37500/59072)
2025-12-13 15:56:19,170 INFO     Evaluating the model... (38000/59072)
2025-12-13 15:56:24,336 INFO     Evaluating the model... (38500/59072)
2025-12-13 15:56:31,044 INFO     Evaluating the model... (39000/59072)
2025-12-13 15:56:36,499 INFO     Evaluating the model... (39500/59072)
2025-12-13 15:56:42,114 INFO     Evaluating the model... (40000/59072)
2025-12-13 15:56:47,957 INFO     Evaluating the model... (40500/59072)
2025-12-13 15:56:53,107 INFO     Evaluating the model... (41000/59072)
2025-12-13 15:56:57,792 INFO     Evaluating the model... (41500/59072)
2025-12-13 15:57:04,030 INFO     Evaluating the model... (42000/59072)
2025-12-13 15:57:10,656 INFO     Evaluating the model... (42500/59072)
2025-12-13 15:57:15,471 INFO     Evaluating the model... (43000/59072)
2025-12-13 15:57:21,470 INFO     Evaluating the model... (43500/59072)
2025-12-13 15:57:27,550 INFO     Evaluating the model... (44000/59072)
2025-12-13 15:57:33,592 INFO     Evaluating the model... (44500/59072)
2025-12-13 15:57:39,141 INFO     Evaluating the model... (45000/59072)
2025-12-13 15:57:45,003 INFO     Evaluating the model... (45500/59072)
2025-12-13 15:57:49,907 INFO     Evaluating the model... (46000/59072)
2025-12-13 15:57:55,095 INFO     Evaluating the model... (46500/59072)
2025-12-13 15:58:02,737 INFO     Evaluating the model... (47000/59072)
2025-12-13 15:58:07,768 INFO     Evaluating the model... (47500/59072)
2025-12-13 15:58:13,145 INFO     Evaluating the model... (48000/59072)
2025-12-13 15:58:19,490 INFO     Evaluating the model... (48500/59072)
2025-12-13 15:58:25,043 INFO     Evaluating the model... (49000/59072)
2025-12-13 15:58:31,404 INFO     Evaluating the model... (49500/59072)
2025-12-13 15:58:38,221 INFO     Evaluating the model... (50000/59072)
2025-12-13 15:58:43,719 INFO     Evaluating the model... (50500/59072)
2025-12-13 15:58:48,921 INFO     Evaluating the model... (51000/59072)
2025-12-13 15:58:54,441 INFO     Evaluating the model... (51500/59072)
2025-12-13 15:59:01,235 INFO     Evaluating the model... (52000/59072)
2025-12-13 15:59:06,592 INFO     Evaluating the model... (52500/59072)
2025-12-13 15:59:12,644 INFO     Evaluating the model... (53000/59072)
2025-12-13 15:59:17,948 INFO     Evaluating the model... (53500/59072)
2025-12-13 15:59:22,785 INFO     Evaluating the model... (54000/59072)
2025-12-13 15:59:30,739 INFO     Evaluating the model... (54500/59072)
2025-12-13 15:59:36,394 INFO     Evaluating the model... (55000/59072)
2025-12-13 15:59:40,967 INFO     Evaluating the model... (55500/59072)
2025-12-13 15:59:46,726 INFO     Evaluating the model... (56000/59072)
2025-12-13 15:59:51,950 INFO     Evaluating the model... (56500/59072)
2025-12-13 15:59:59,078 INFO     Evaluating the model... (57000/59072)
2025-12-13 16:00:05,548 INFO     Evaluating the model... (57500/59072)
2025-12-13 16:00:11,475 INFO     Evaluating the model... (58000/59072)
2025-12-13 16:00:16,359 INFO     Evaluating the model... (58500/59072)
2025-12-13 16:00:22,503 INFO     Evaluating the model... (59000/59072)
2025-12-13 16:00:23,915 INFO     Test MRR at step 110000: 0.728086
2025-12-13 16:00:23,916 INFO     Test MR at step 110000: 258.923905
2025-12-13 16:00:23,916 INFO     Test HITS@1 at step 110000: 0.663066
2025-12-13 16:00:23,916 INFO     Test HITS@3 at step 110000: 0.773865
2025-12-13 16:00:23,916 INFO     Test HITS@10 at step 110000: 0.839634
2025-12-13 16:00:29,159 INFO     Training average regularization at step 110100: 0.163685
2025-12-13 16:00:29,159 INFO     Training average positive_sample_loss at step 110100: 0.006954
2025-12-13 16:00:29,159 INFO     Training average negative_sample_loss at step 110100: 0.018395
2025-12-13 16:00:29,159 INFO     Training average loss at step 110100: 0.176360
2025-12-13 16:00:33,974 INFO     Training average regularization at step 110200: 0.163681
2025-12-13 16:00:33,974 INFO     Training average positive_sample_loss at step 110200: 0.007255
2025-12-13 16:00:33,974 INFO     Training average negative_sample_loss at step 110200: 0.027252
2025-12-13 16:00:33,974 INFO     Training average loss at step 110200: 0.180934
2025-12-13 16:00:39,244 INFO     Training average regularization at step 110300: 0.163677
2025-12-13 16:00:39,244 INFO     Training average positive_sample_loss at step 110300: 0.007172
2025-12-13 16:00:39,244 INFO     Training average negative_sample_loss at step 110300: 0.019262
2025-12-13 16:00:39,244 INFO     Training average loss at step 110300: 0.176894
2025-12-13 16:00:44,295 INFO     Training average regularization at step 110400: 0.163673
2025-12-13 16:00:44,295 INFO     Training average positive_sample_loss at step 110400: 0.007657
2025-12-13 16:00:44,295 INFO     Training average negative_sample_loss at step 110400: 0.020186
2025-12-13 16:00:44,295 INFO     Training average loss at step 110400: 0.177595
2025-12-13 16:00:49,216 INFO     Training average regularization at step 110500: 0.163669
2025-12-13 16:00:49,216 INFO     Training average positive_sample_loss at step 110500: 0.006982
2025-12-13 16:00:49,216 INFO     Training average negative_sample_loss at step 110500: 0.024421
2025-12-13 16:00:49,216 INFO     Training average loss at step 110500: 0.179371
2025-12-13 16:00:54,184 INFO     Training average regularization at step 110600: 0.163665
2025-12-13 16:00:54,185 INFO     Training average positive_sample_loss at step 110600: 0.007128
2025-12-13 16:00:54,185 INFO     Training average negative_sample_loss at step 110600: 0.022730
2025-12-13 16:00:54,185 INFO     Training average loss at step 110600: 0.178594
2025-12-13 16:00:59,361 INFO     Training average regularization at step 110700: 0.163661
2025-12-13 16:00:59,362 INFO     Training average positive_sample_loss at step 110700: 0.007307
2025-12-13 16:00:59,362 INFO     Training average negative_sample_loss at step 110700: 0.020385
2025-12-13 16:00:59,362 INFO     Training average loss at step 110700: 0.177507
2025-12-13 16:01:04,611 INFO     Training average regularization at step 110800: 0.163657
2025-12-13 16:01:04,611 INFO     Training average positive_sample_loss at step 110800: 0.007150
2025-12-13 16:01:04,611 INFO     Training average negative_sample_loss at step 110800: 0.026130
2025-12-13 16:01:04,611 INFO     Training average loss at step 110800: 0.180297
2025-12-13 16:01:09,524 INFO     Training average regularization at step 110900: 0.163653
2025-12-13 16:01:09,527 INFO     Training average positive_sample_loss at step 110900: 0.007479
2025-12-13 16:01:09,527 INFO     Training average negative_sample_loss at step 110900: 0.021186
2025-12-13 16:01:09,527 INFO     Training average loss at step 110900: 0.177986
2025-12-13 16:01:15,122 INFO     Training average regularization at step 111000: 0.163649
2025-12-13 16:01:15,122 INFO     Training average positive_sample_loss at step 111000: 0.007056
2025-12-13 16:01:15,122 INFO     Training average negative_sample_loss at step 111000: 0.019666
2025-12-13 16:01:15,122 INFO     Training average loss at step 111000: 0.177010
2025-12-13 16:01:20,305 INFO     Training average regularization at step 111100: 0.163645
2025-12-13 16:01:20,305 INFO     Training average positive_sample_loss at step 111100: 0.007169
2025-12-13 16:01:20,305 INFO     Training average negative_sample_loss at step 111100: 0.019364
2025-12-13 16:01:20,305 INFO     Training average loss at step 111100: 0.176912
2025-12-13 16:01:26,719 INFO     Training average regularization at step 111200: 0.163641
2025-12-13 16:01:26,720 INFO     Training average positive_sample_loss at step 111200: 0.007055
2025-12-13 16:01:26,720 INFO     Training average negative_sample_loss at step 111200: 0.021858
2025-12-13 16:01:26,720 INFO     Training average loss at step 111200: 0.178098
2025-12-13 16:01:31,996 INFO     Training average regularization at step 111300: 0.163637
2025-12-13 16:01:31,996 INFO     Training average positive_sample_loss at step 111300: 0.006977
2025-12-13 16:01:31,996 INFO     Training average negative_sample_loss at step 111300: 0.022041
2025-12-13 16:01:31,996 INFO     Training average loss at step 111300: 0.178146
2025-12-13 16:01:37,526 INFO     Training average regularization at step 111400: 0.163633
2025-12-13 16:01:37,532 INFO     Training average positive_sample_loss at step 111400: 0.007501
2025-12-13 16:01:37,532 INFO     Training average negative_sample_loss at step 111400: 0.022047
2025-12-13 16:01:37,532 INFO     Training average loss at step 111400: 0.178407
2025-12-13 16:01:42,436 INFO     Training average regularization at step 111500: 0.163629
2025-12-13 16:01:42,436 INFO     Training average positive_sample_loss at step 111500: 0.007573
2025-12-13 16:01:42,436 INFO     Training average negative_sample_loss at step 111500: 0.020683
2025-12-13 16:01:42,436 INFO     Training average loss at step 111500: 0.177758
2025-12-13 16:01:47,562 INFO     Training average regularization at step 111600: 0.163625
2025-12-13 16:01:47,562 INFO     Training average positive_sample_loss at step 111600: 0.007232
2025-12-13 16:01:47,562 INFO     Training average negative_sample_loss at step 111600: 0.023471
2025-12-13 16:01:47,562 INFO     Training average loss at step 111600: 0.178976
2025-12-13 16:01:52,790 INFO     Training average regularization at step 111700: 0.163621
2025-12-13 16:01:52,791 INFO     Training average positive_sample_loss at step 111700: 0.006950
2025-12-13 16:01:52,791 INFO     Training average negative_sample_loss at step 111700: 0.020130
2025-12-13 16:01:52,791 INFO     Training average loss at step 111700: 0.177161
2025-12-13 16:01:57,776 INFO     Training average regularization at step 111800: 0.163617
2025-12-13 16:01:57,776 INFO     Training average positive_sample_loss at step 111800: 0.006890
2025-12-13 16:01:57,776 INFO     Training average negative_sample_loss at step 111800: 0.023463
2025-12-13 16:01:57,776 INFO     Training average loss at step 111800: 0.178793
2025-12-13 16:02:02,735 INFO     Training average regularization at step 111900: 0.163613
2025-12-13 16:02:02,736 INFO     Training average positive_sample_loss at step 111900: 0.006894
2025-12-13 16:02:02,736 INFO     Training average negative_sample_loss at step 111900: 0.024259
2025-12-13 16:02:02,736 INFO     Training average loss at step 111900: 0.179189
2025-12-13 16:02:08,142 INFO     Training average regularization at step 112000: 0.163608
2025-12-13 16:02:08,143 INFO     Training average positive_sample_loss at step 112000: 0.007208
2025-12-13 16:02:08,143 INFO     Training average negative_sample_loss at step 112000: 0.031467
2025-12-13 16:02:08,143 INFO     Training average loss at step 112000: 0.182946
2025-12-13 16:02:13,449 INFO     Training average regularization at step 112100: 0.163604
2025-12-13 16:02:13,450 INFO     Training average positive_sample_loss at step 112100: 0.007819
2025-12-13 16:02:13,450 INFO     Training average negative_sample_loss at step 112100: 0.019910
2025-12-13 16:02:13,450 INFO     Training average loss at step 112100: 0.177468
2025-12-13 16:02:18,285 INFO     Training average regularization at step 112200: 0.163600
2025-12-13 16:02:18,285 INFO     Training average positive_sample_loss at step 112200: 0.007818
2025-12-13 16:02:18,285 INFO     Training average negative_sample_loss at step 112200: 0.022452
2025-12-13 16:02:18,285 INFO     Training average loss at step 112200: 0.178735
2025-12-13 16:02:23,672 INFO     Training average regularization at step 112300: 0.163596
2025-12-13 16:02:23,672 INFO     Training average positive_sample_loss at step 112300: 0.007673
2025-12-13 16:02:23,672 INFO     Training average negative_sample_loss at step 112300: 0.019782
2025-12-13 16:02:23,672 INFO     Training average loss at step 112300: 0.177323
2025-12-13 16:02:29,007 INFO     Training average regularization at step 112400: 0.163592
2025-12-13 16:02:29,008 INFO     Training average positive_sample_loss at step 112400: 0.006827
2025-12-13 16:02:29,008 INFO     Training average negative_sample_loss at step 112400: 0.018083
2025-12-13 16:02:29,008 INFO     Training average loss at step 112400: 0.176047
2025-12-13 16:02:33,922 INFO     Training average regularization at step 112500: 0.163588
2025-12-13 16:02:33,923 INFO     Training average positive_sample_loss at step 112500: 0.007035
2025-12-13 16:02:33,923 INFO     Training average negative_sample_loss at step 112500: 0.019119
2025-12-13 16:02:33,923 INFO     Training average loss at step 112500: 0.176665
2025-12-13 16:02:38,921 INFO     Training average regularization at step 112600: 0.163584
2025-12-13 16:02:38,921 INFO     Training average positive_sample_loss at step 112600: 0.007978
2025-12-13 16:02:38,921 INFO     Training average negative_sample_loss at step 112600: 0.021076
2025-12-13 16:02:38,922 INFO     Training average loss at step 112600: 0.178110
2025-12-13 16:02:43,902 INFO     Training average regularization at step 112700: 0.163580
2025-12-13 16:02:43,903 INFO     Training average positive_sample_loss at step 112700: 0.007290
2025-12-13 16:02:43,903 INFO     Training average negative_sample_loss at step 112700: 0.017573
2025-12-13 16:02:43,903 INFO     Training average loss at step 112700: 0.176011
2025-12-13 16:02:49,246 INFO     Training average regularization at step 112800: 0.163575
2025-12-13 16:02:49,246 INFO     Training average positive_sample_loss at step 112800: 0.007610
2025-12-13 16:02:49,246 INFO     Training average negative_sample_loss at step 112800: 0.021658
2025-12-13 16:02:49,246 INFO     Training average loss at step 112800: 0.178210
2025-12-13 16:02:54,710 INFO     Training average regularization at step 112900: 0.163571
2025-12-13 16:02:54,710 INFO     Training average positive_sample_loss at step 112900: 0.007820
2025-12-13 16:02:54,710 INFO     Training average negative_sample_loss at step 112900: 0.017697
2025-12-13 16:02:54,710 INFO     Training average loss at step 112900: 0.176330
2025-12-13 16:02:59,874 INFO     Training average regularization at step 113000: 0.163567
2025-12-13 16:02:59,875 INFO     Training average positive_sample_loss at step 113000: 0.007104
2025-12-13 16:02:59,875 INFO     Training average negative_sample_loss at step 113000: 0.019317
2025-12-13 16:02:59,875 INFO     Training average loss at step 113000: 0.176778
2025-12-13 16:03:05,257 INFO     Training average regularization at step 113100: 0.163563
2025-12-13 16:03:05,258 INFO     Training average positive_sample_loss at step 113100: 0.007185
2025-12-13 16:03:05,258 INFO     Training average negative_sample_loss at step 113100: 0.017931
2025-12-13 16:03:05,258 INFO     Training average loss at step 113100: 0.176121
2025-12-13 16:03:10,102 INFO     Training average regularization at step 113200: 0.163559
2025-12-13 16:03:10,103 INFO     Training average positive_sample_loss at step 113200: 0.007828
2025-12-13 16:03:10,103 INFO     Training average negative_sample_loss at step 113200: 0.020121
2025-12-13 16:03:10,103 INFO     Training average loss at step 113200: 0.177534
2025-12-13 16:03:15,301 INFO     Training average regularization at step 113300: 0.163555
2025-12-13 16:03:15,304 INFO     Training average positive_sample_loss at step 113300: 0.008095
2025-12-13 16:03:15,304 INFO     Training average negative_sample_loss at step 113300: 0.020187
2025-12-13 16:03:15,304 INFO     Training average loss at step 113300: 0.177696
2025-12-13 16:03:20,706 INFO     Training average regularization at step 113400: 0.163551
2025-12-13 16:03:20,707 INFO     Training average positive_sample_loss at step 113400: 0.007306
2025-12-13 16:03:20,707 INFO     Training average negative_sample_loss at step 113400: 0.019700
2025-12-13 16:03:20,707 INFO     Training average loss at step 113400: 0.177054
2025-12-13 16:03:25,739 INFO     Training average regularization at step 113500: 0.163547
2025-12-13 16:03:25,739 INFO     Training average positive_sample_loss at step 113500: 0.007105
2025-12-13 16:03:25,739 INFO     Training average negative_sample_loss at step 113500: 0.022148
2025-12-13 16:03:25,739 INFO     Training average loss at step 113500: 0.178174
2025-12-13 16:03:30,626 INFO     Training average regularization at step 113600: 0.163543
2025-12-13 16:03:30,627 INFO     Training average positive_sample_loss at step 113600: 0.007634
2025-12-13 16:03:30,627 INFO     Training average negative_sample_loss at step 113600: 0.025797
2025-12-13 16:03:30,627 INFO     Training average loss at step 113600: 0.180259
2025-12-13 16:03:36,104 INFO     Training average regularization at step 113700: 0.163539
2025-12-13 16:03:36,108 INFO     Training average positive_sample_loss at step 113700: 0.007812
2025-12-13 16:03:36,108 INFO     Training average negative_sample_loss at step 113700: 0.021368
2025-12-13 16:03:36,108 INFO     Training average loss at step 113700: 0.178129
2025-12-13 16:03:41,299 INFO     Training average regularization at step 113800: 0.163535
2025-12-13 16:03:41,299 INFO     Training average positive_sample_loss at step 113800: 0.007010
2025-12-13 16:03:41,299 INFO     Training average negative_sample_loss at step 113800: 0.022640
2025-12-13 16:03:41,299 INFO     Training average loss at step 113800: 0.178360
2025-12-13 16:03:46,143 INFO     Training average regularization at step 113900: 0.163531
2025-12-13 16:03:46,144 INFO     Training average positive_sample_loss at step 113900: 0.007226
2025-12-13 16:03:46,144 INFO     Training average negative_sample_loss at step 113900: 0.022731
2025-12-13 16:03:46,144 INFO     Training average loss at step 113900: 0.178509
2025-12-13 16:03:51,201 INFO     Training average regularization at step 114000: 0.163527
2025-12-13 16:03:51,201 INFO     Training average positive_sample_loss at step 114000: 0.007104
2025-12-13 16:03:51,201 INFO     Training average negative_sample_loss at step 114000: 0.019748
2025-12-13 16:03:51,202 INFO     Training average loss at step 114000: 0.176953
2025-12-13 16:03:56,175 INFO     Training average regularization at step 114100: 0.163523
2025-12-13 16:03:56,176 INFO     Training average positive_sample_loss at step 114100: 0.007155
2025-12-13 16:03:56,176 INFO     Training average negative_sample_loss at step 114100: 0.019021
2025-12-13 16:03:56,176 INFO     Training average loss at step 114100: 0.176611
2025-12-13 16:04:01,161 INFO     Training average regularization at step 114200: 0.163519
2025-12-13 16:04:01,162 INFO     Training average positive_sample_loss at step 114200: 0.007312
2025-12-13 16:04:01,162 INFO     Training average negative_sample_loss at step 114200: 0.020359
2025-12-13 16:04:01,162 INFO     Training average loss at step 114200: 0.177354
2025-12-13 16:04:06,143 INFO     Training average regularization at step 114300: 0.163515
2025-12-13 16:04:06,144 INFO     Training average positive_sample_loss at step 114300: 0.007339
2025-12-13 16:04:06,144 INFO     Training average negative_sample_loss at step 114300: 0.023130
2025-12-13 16:04:06,144 INFO     Training average loss at step 114300: 0.178750
2025-12-13 16:04:11,435 INFO     Training average regularization at step 114400: 0.163511
2025-12-13 16:04:11,440 INFO     Training average positive_sample_loss at step 114400: 0.007500
2025-12-13 16:04:11,440 INFO     Training average negative_sample_loss at step 114400: 0.020215
2025-12-13 16:04:11,440 INFO     Training average loss at step 114400: 0.177369
2025-12-13 16:04:16,644 INFO     Training average regularization at step 114500: 0.163507
2025-12-13 16:04:16,644 INFO     Training average positive_sample_loss at step 114500: 0.007280
2025-12-13 16:04:16,644 INFO     Training average negative_sample_loss at step 114500: 0.021550
2025-12-13 16:04:16,644 INFO     Training average loss at step 114500: 0.177922
2025-12-13 16:04:21,475 INFO     Training average regularization at step 114600: 0.163503
2025-12-13 16:04:21,475 INFO     Training average positive_sample_loss at step 114600: 0.007525
2025-12-13 16:04:21,475 INFO     Training average negative_sample_loss at step 114600: 0.022502
2025-12-13 16:04:21,475 INFO     Training average loss at step 114600: 0.178517
2025-12-13 16:04:26,880 INFO     Training average regularization at step 114700: 0.163499
2025-12-13 16:04:26,882 INFO     Training average positive_sample_loss at step 114700: 0.007302
2025-12-13 16:04:26,882 INFO     Training average negative_sample_loss at step 114700: 0.019994
2025-12-13 16:04:26,883 INFO     Training average loss at step 114700: 0.177147
2025-12-13 16:04:32,209 INFO     Training average regularization at step 114800: 0.163495
2025-12-13 16:04:32,210 INFO     Training average positive_sample_loss at step 114800: 0.007918
2025-12-13 16:04:32,210 INFO     Training average negative_sample_loss at step 114800: 0.017825
2025-12-13 16:04:32,210 INFO     Training average loss at step 114800: 0.176367
2025-12-13 16:04:37,083 INFO     Training average regularization at step 114900: 0.163491
2025-12-13 16:04:37,083 INFO     Training average positive_sample_loss at step 114900: 0.006647
2025-12-13 16:04:37,083 INFO     Training average negative_sample_loss at step 114900: 0.020009
2025-12-13 16:04:37,083 INFO     Training average loss at step 114900: 0.176819
2025-12-13 16:04:42,083 INFO     Training average regularization at step 115000: 0.163487
2025-12-13 16:04:42,086 INFO     Training average positive_sample_loss at step 115000: 0.007122
2025-12-13 16:04:42,086 INFO     Training average negative_sample_loss at step 115000: 0.020096
2025-12-13 16:04:42,086 INFO     Training average loss at step 115000: 0.177096
2025-12-13 16:04:47,420 INFO     Training average regularization at step 115100: 0.163483
2025-12-13 16:04:47,420 INFO     Training average positive_sample_loss at step 115100: 0.007394
2025-12-13 16:04:47,420 INFO     Training average negative_sample_loss at step 115100: 0.021786
2025-12-13 16:04:47,420 INFO     Training average loss at step 115100: 0.178073
2025-12-13 16:04:52,315 INFO     Training average regularization at step 115200: 0.163479
2025-12-13 16:04:52,315 INFO     Training average positive_sample_loss at step 115200: 0.007383
2025-12-13 16:04:52,315 INFO     Training average negative_sample_loss at step 115200: 0.021422
2025-12-13 16:04:52,315 INFO     Training average loss at step 115200: 0.177882
2025-12-13 16:04:57,202 INFO     Training average regularization at step 115300: 0.163475
2025-12-13 16:04:57,212 INFO     Training average positive_sample_loss at step 115300: 0.006960
2025-12-13 16:04:57,212 INFO     Training average negative_sample_loss at step 115300: 0.017851
2025-12-13 16:04:57,212 INFO     Training average loss at step 115300: 0.175881
2025-12-13 16:05:02,623 INFO     Training average regularization at step 115400: 0.163471
2025-12-13 16:05:02,623 INFO     Training average positive_sample_loss at step 115400: 0.007206
2025-12-13 16:05:02,624 INFO     Training average negative_sample_loss at step 115400: 0.024505
2025-12-13 16:05:02,624 INFO     Training average loss at step 115400: 0.179327
2025-12-13 16:05:07,870 INFO     Training average regularization at step 115500: 0.163467
2025-12-13 16:05:07,870 INFO     Training average positive_sample_loss at step 115500: 0.008139
2025-12-13 16:05:07,870 INFO     Training average negative_sample_loss at step 115500: 0.023043
2025-12-13 16:05:07,871 INFO     Training average loss at step 115500: 0.179058
2025-12-13 16:05:12,871 INFO     Training average regularization at step 115600: 0.163464
2025-12-13 16:05:12,872 INFO     Training average positive_sample_loss at step 115600: 0.007233
2025-12-13 16:05:12,872 INFO     Training average negative_sample_loss at step 115600: 0.020109
2025-12-13 16:05:12,872 INFO     Training average loss at step 115600: 0.177135
2025-12-13 16:05:18,206 INFO     Training average regularization at step 115700: 0.163460
2025-12-13 16:05:18,207 INFO     Training average positive_sample_loss at step 115700: 0.006773
2025-12-13 16:05:18,207 INFO     Training average negative_sample_loss at step 115700: 0.025613
2025-12-13 16:05:18,207 INFO     Training average loss at step 115700: 0.179653
2025-12-13 16:05:23,473 INFO     Training average regularization at step 115800: 0.163456
2025-12-13 16:05:23,473 INFO     Training average positive_sample_loss at step 115800: 0.007837
2025-12-13 16:05:23,474 INFO     Training average negative_sample_loss at step 115800: 0.022705
2025-12-13 16:05:23,474 INFO     Training average loss at step 115800: 0.178727
2025-12-13 16:05:28,589 INFO     Training average regularization at step 115900: 0.163452
2025-12-13 16:05:28,589 INFO     Training average positive_sample_loss at step 115900: 0.007370
2025-12-13 16:05:28,589 INFO     Training average negative_sample_loss at step 115900: 0.023963
2025-12-13 16:05:28,589 INFO     Training average loss at step 115900: 0.179119
2025-12-13 16:05:35,308 INFO     Training average regularization at step 116000: 0.163448
2025-12-13 16:05:35,310 INFO     Training average positive_sample_loss at step 116000: 0.007565
2025-12-13 16:05:35,310 INFO     Training average negative_sample_loss at step 116000: 0.022671
2025-12-13 16:05:35,310 INFO     Training average loss at step 116000: 0.178566
2025-12-13 16:05:40,612 INFO     Training average regularization at step 116100: 0.163444
2025-12-13 16:05:40,612 INFO     Training average positive_sample_loss at step 116100: 0.007087
2025-12-13 16:05:40,612 INFO     Training average negative_sample_loss at step 116100: 0.023200
2025-12-13 16:05:40,612 INFO     Training average loss at step 116100: 0.178588
2025-12-13 16:05:45,546 INFO     Training average regularization at step 116200: 0.163440
2025-12-13 16:05:45,547 INFO     Training average positive_sample_loss at step 116200: 0.006944
2025-12-13 16:05:45,547 INFO     Training average negative_sample_loss at step 116200: 0.022663
2025-12-13 16:05:45,547 INFO     Training average loss at step 116200: 0.178244
2025-12-13 16:05:50,406 INFO     Training average regularization at step 116300: 0.163436
2025-12-13 16:05:50,406 INFO     Training average positive_sample_loss at step 116300: 0.007539
2025-12-13 16:05:50,406 INFO     Training average negative_sample_loss at step 116300: 0.016956
2025-12-13 16:05:50,406 INFO     Training average loss at step 116300: 0.175683
2025-12-13 16:05:55,525 INFO     Training average regularization at step 116400: 0.163432
2025-12-13 16:05:55,525 INFO     Training average positive_sample_loss at step 116400: 0.006707
2025-12-13 16:05:55,525 INFO     Training average negative_sample_loss at step 116400: 0.021210
2025-12-13 16:05:55,525 INFO     Training average loss at step 116400: 0.177391
2025-12-13 16:06:00,589 INFO     Training average regularization at step 116500: 0.163428
2025-12-13 16:06:00,589 INFO     Training average positive_sample_loss at step 116500: 0.007291
2025-12-13 16:06:00,589 INFO     Training average negative_sample_loss at step 116500: 0.021698
2025-12-13 16:06:00,589 INFO     Training average loss at step 116500: 0.177922
2025-12-13 16:06:05,444 INFO     Training average regularization at step 116600: 0.163424
2025-12-13 16:06:05,445 INFO     Training average positive_sample_loss at step 116600: 0.006994
2025-12-13 16:06:05,445 INFO     Training average negative_sample_loss at step 116600: 0.019308
2025-12-13 16:06:05,445 INFO     Training average loss at step 116600: 0.176575
2025-12-13 16:06:10,606 INFO     Training average regularization at step 116700: 0.163419
2025-12-13 16:06:10,606 INFO     Training average positive_sample_loss at step 116700: 0.007667
2025-12-13 16:06:10,606 INFO     Training average negative_sample_loss at step 116700: 0.021862
2025-12-13 16:06:10,606 INFO     Training average loss at step 116700: 0.178184
2025-12-13 16:06:15,885 INFO     Training average regularization at step 116800: 0.163415
2025-12-13 16:06:15,887 INFO     Training average positive_sample_loss at step 116800: 0.006985
2025-12-13 16:06:15,887 INFO     Training average negative_sample_loss at step 116800: 0.021010
2025-12-13 16:06:15,887 INFO     Training average loss at step 116800: 0.177413
2025-12-13 16:06:20,853 INFO     Training average regularization at step 116900: 0.163411
2025-12-13 16:06:20,854 INFO     Training average positive_sample_loss at step 116900: 0.007450
2025-12-13 16:06:20,854 INFO     Training average negative_sample_loss at step 116900: 0.018075
2025-12-13 16:06:20,854 INFO     Training average loss at step 116900: 0.176174
2025-12-13 16:06:26,066 INFO     Training average regularization at step 117000: 0.163407
2025-12-13 16:06:26,066 INFO     Training average positive_sample_loss at step 117000: 0.007191
2025-12-13 16:06:26,066 INFO     Training average negative_sample_loss at step 117000: 0.025095
2025-12-13 16:06:26,066 INFO     Training average loss at step 117000: 0.179550
2025-12-13 16:06:31,415 INFO     Training average regularization at step 117100: 0.163403
2025-12-13 16:06:31,419 INFO     Training average positive_sample_loss at step 117100: 0.007396
2025-12-13 16:06:31,419 INFO     Training average negative_sample_loss at step 117100: 0.021494
2025-12-13 16:06:31,419 INFO     Training average loss at step 117100: 0.177848
2025-12-13 16:06:36,625 INFO     Training average regularization at step 117200: 0.163399
2025-12-13 16:06:36,626 INFO     Training average positive_sample_loss at step 117200: 0.007869
2025-12-13 16:06:36,626 INFO     Training average negative_sample_loss at step 117200: 0.025285
2025-12-13 16:06:36,626 INFO     Training average loss at step 117200: 0.179976
2025-12-13 16:06:41,428 INFO     Training average regularization at step 117300: 0.163395
2025-12-13 16:06:41,429 INFO     Training average positive_sample_loss at step 117300: 0.007395
2025-12-13 16:06:41,429 INFO     Training average negative_sample_loss at step 117300: 0.021645
2025-12-13 16:06:41,429 INFO     Training average loss at step 117300: 0.177915
2025-12-13 16:06:47,002 INFO     Training average regularization at step 117400: 0.163391
2025-12-13 16:06:47,002 INFO     Training average positive_sample_loss at step 117400: 0.007110
2025-12-13 16:06:47,002 INFO     Training average negative_sample_loss at step 117400: 0.020207
2025-12-13 16:06:47,002 INFO     Training average loss at step 117400: 0.177049
2025-12-13 16:06:52,065 INFO     Training average regularization at step 117500: 0.163387
2025-12-13 16:06:52,065 INFO     Training average positive_sample_loss at step 117500: 0.006760
2025-12-13 16:06:52,065 INFO     Training average negative_sample_loss at step 117500: 0.021867
2025-12-13 16:06:52,065 INFO     Training average loss at step 117500: 0.177700
2025-12-13 16:06:56,902 INFO     Training average regularization at step 117600: 0.163383
2025-12-13 16:06:56,902 INFO     Training average positive_sample_loss at step 117600: 0.007122
2025-12-13 16:06:56,902 INFO     Training average negative_sample_loss at step 117600: 0.020583
2025-12-13 16:06:56,902 INFO     Training average loss at step 117600: 0.177235
2025-12-13 16:07:01,999 INFO     Training average regularization at step 117700: 0.163379
2025-12-13 16:07:02,004 INFO     Training average positive_sample_loss at step 117700: 0.007270
2025-12-13 16:07:02,004 INFO     Training average negative_sample_loss at step 117700: 0.023228
2025-12-13 16:07:02,004 INFO     Training average loss at step 117700: 0.178628
2025-12-13 16:07:07,170 INFO     Training average regularization at step 117800: 0.163374
2025-12-13 16:07:07,170 INFO     Training average positive_sample_loss at step 117800: 0.006798
2025-12-13 16:07:07,170 INFO     Training average negative_sample_loss at step 117800: 0.025727
2025-12-13 16:07:07,170 INFO     Training average loss at step 117800: 0.179637
2025-12-13 16:07:12,521 INFO     Training average regularization at step 117900: 0.163370
2025-12-13 16:07:12,521 INFO     Training average positive_sample_loss at step 117900: 0.007095
2025-12-13 16:07:12,522 INFO     Training average negative_sample_loss at step 117900: 0.022534
2025-12-13 16:07:12,522 INFO     Training average loss at step 117900: 0.178185
2025-12-13 16:07:17,545 INFO     Training average regularization at step 118000: 0.163366
2025-12-13 16:07:17,545 INFO     Training average positive_sample_loss at step 118000: 0.006917
2025-12-13 16:07:17,545 INFO     Training average negative_sample_loss at step 118000: 0.017052
2025-12-13 16:07:17,545 INFO     Training average loss at step 118000: 0.175351
2025-12-13 16:07:22,964 INFO     Training average regularization at step 118100: 0.163362
2025-12-13 16:07:22,965 INFO     Training average positive_sample_loss at step 118100: 0.007429
2025-12-13 16:07:22,965 INFO     Training average negative_sample_loss at step 118100: 0.018438
2025-12-13 16:07:22,965 INFO     Training average loss at step 118100: 0.176296
2025-12-13 16:07:28,251 INFO     Training average regularization at step 118200: 0.163358
2025-12-13 16:07:28,252 INFO     Training average positive_sample_loss at step 118200: 0.006954
2025-12-13 16:07:28,252 INFO     Training average negative_sample_loss at step 118200: 0.023218
2025-12-13 16:07:28,252 INFO     Training average loss at step 118200: 0.178444
2025-12-13 16:07:33,059 INFO     Training average regularization at step 118300: 0.163354
2025-12-13 16:07:33,059 INFO     Training average positive_sample_loss at step 118300: 0.008330
2025-12-13 16:07:33,060 INFO     Training average negative_sample_loss at step 118300: 0.019618
2025-12-13 16:07:33,060 INFO     Training average loss at step 118300: 0.177329
2025-12-13 16:07:38,270 INFO     Training average regularization at step 118400: 0.163350
2025-12-13 16:07:38,270 INFO     Training average positive_sample_loss at step 118400: 0.007280
2025-12-13 16:07:38,270 INFO     Training average negative_sample_loss at step 118400: 0.023784
2025-12-13 16:07:38,270 INFO     Training average loss at step 118400: 0.178883
2025-12-13 16:07:43,327 INFO     Training average regularization at step 118500: 0.163347
2025-12-13 16:07:43,333 INFO     Training average positive_sample_loss at step 118500: 0.007873
2025-12-13 16:07:43,333 INFO     Training average negative_sample_loss at step 118500: 0.020206
2025-12-13 16:07:43,333 INFO     Training average loss at step 118500: 0.177386
2025-12-13 16:07:48,173 INFO     Training average regularization at step 118600: 0.163343
2025-12-13 16:07:48,173 INFO     Training average positive_sample_loss at step 118600: 0.006946
2025-12-13 16:07:48,173 INFO     Training average negative_sample_loss at step 118600: 0.017656
2025-12-13 16:07:48,173 INFO     Training average loss at step 118600: 0.175643
2025-12-13 16:07:53,178 INFO     Training average regularization at step 118700: 0.163339
2025-12-13 16:07:53,178 INFO     Training average positive_sample_loss at step 118700: 0.008225
2025-12-13 16:07:53,178 INFO     Training average negative_sample_loss at step 118700: 0.022224
2025-12-13 16:07:53,178 INFO     Training average loss at step 118700: 0.178563
2025-12-13 16:07:58,311 INFO     Training average regularization at step 118800: 0.163335
2025-12-13 16:07:58,311 INFO     Training average positive_sample_loss at step 118800: 0.007280
2025-12-13 16:07:58,312 INFO     Training average negative_sample_loss at step 118800: 0.023995
2025-12-13 16:07:58,312 INFO     Training average loss at step 118800: 0.178972
2025-12-13 16:08:03,243 INFO     Training average regularization at step 118900: 0.163331
2025-12-13 16:08:03,244 INFO     Training average positive_sample_loss at step 118900: 0.007576
2025-12-13 16:08:03,244 INFO     Training average negative_sample_loss at step 118900: 0.019431
2025-12-13 16:08:03,244 INFO     Training average loss at step 118900: 0.176834
2025-12-13 16:08:08,095 INFO     Training average regularization at step 119000: 0.163327
2025-12-13 16:08:08,095 INFO     Training average positive_sample_loss at step 119000: 0.007571
2025-12-13 16:08:08,095 INFO     Training average negative_sample_loss at step 119000: 0.017737
2025-12-13 16:08:08,095 INFO     Training average loss at step 119000: 0.175981
2025-12-13 16:08:13,338 INFO     Training average regularization at step 119100: 0.163323
2025-12-13 16:08:13,343 INFO     Training average positive_sample_loss at step 119100: 0.007118
2025-12-13 16:08:13,343 INFO     Training average negative_sample_loss at step 119100: 0.023633
2025-12-13 16:08:13,343 INFO     Training average loss at step 119100: 0.178698
2025-12-13 16:08:18,577 INFO     Training average regularization at step 119200: 0.163319
2025-12-13 16:08:18,577 INFO     Training average positive_sample_loss at step 119200: 0.006937
2025-12-13 16:08:18,577 INFO     Training average negative_sample_loss at step 119200: 0.017796
2025-12-13 16:08:18,577 INFO     Training average loss at step 119200: 0.175686
2025-12-13 16:08:23,380 INFO     Training average regularization at step 119300: 0.163315
2025-12-13 16:08:23,380 INFO     Training average positive_sample_loss at step 119300: 0.007372
2025-12-13 16:08:23,380 INFO     Training average negative_sample_loss at step 119300: 0.020359
2025-12-13 16:08:23,380 INFO     Training average loss at step 119300: 0.177181
2025-12-13 16:08:28,439 INFO     Training average regularization at step 119400: 0.163311
2025-12-13 16:08:28,439 INFO     Training average positive_sample_loss at step 119400: 0.007110
2025-12-13 16:08:28,439 INFO     Training average negative_sample_loss at step 119400: 0.017951
2025-12-13 16:08:28,439 INFO     Training average loss at step 119400: 0.175842
2025-12-13 16:08:33,447 INFO     Training average regularization at step 119500: 0.163307
2025-12-13 16:08:33,448 INFO     Training average positive_sample_loss at step 119500: 0.007046
2025-12-13 16:08:33,448 INFO     Training average negative_sample_loss at step 119500: 0.022057
2025-12-13 16:08:33,448 INFO     Training average loss at step 119500: 0.177859
2025-12-13 16:08:38,386 INFO     Training average regularization at step 119600: 0.163303
2025-12-13 16:08:38,387 INFO     Training average positive_sample_loss at step 119600: 0.006993
2025-12-13 16:08:38,387 INFO     Training average negative_sample_loss at step 119600: 0.018911
2025-12-13 16:08:38,387 INFO     Training average loss at step 119600: 0.176255
2025-12-13 16:08:43,469 INFO     Training average regularization at step 119700: 0.163299
2025-12-13 16:08:43,470 INFO     Training average positive_sample_loss at step 119700: 0.007000
2025-12-13 16:08:43,470 INFO     Training average negative_sample_loss at step 119700: 0.023322
2025-12-13 16:08:43,470 INFO     Training average loss at step 119700: 0.178460
2025-12-13 16:08:50,405 INFO     Training average regularization at step 119800: 0.163295
2025-12-13 16:08:50,405 INFO     Training average positive_sample_loss at step 119800: 0.009276
2025-12-13 16:08:50,406 INFO     Training average negative_sample_loss at step 119800: 0.020945
2025-12-13 16:08:50,406 INFO     Training average loss at step 119800: 0.178406
2025-12-13 16:08:55,738 INFO     Training average regularization at step 119900: 0.163291
2025-12-13 16:08:55,738 INFO     Training average positive_sample_loss at step 119900: 0.008945
2025-12-13 16:08:55,739 INFO     Training average negative_sample_loss at step 119900: 0.021874
2025-12-13 16:08:55,739 INFO     Training average loss at step 119900: 0.178701
2025-12-13 16:09:03,425 INFO     Training average regularization at step 120000: 0.163288
2025-12-13 16:09:03,426 INFO     Training average positive_sample_loss at step 120000: 0.007289
2025-12-13 16:09:03,426 INFO     Training average negative_sample_loss at step 120000: 0.017537
2025-12-13 16:09:03,426 INFO     Training average loss at step 120000: 0.175701
2025-12-13 16:09:03,426 INFO     Evaluating on Valid Dataset...
2025-12-13 16:09:04,796 INFO     Evaluating the model... (0/50000)
2025-12-13 16:09:16,521 INFO     Evaluating the model... (500/50000)
2025-12-13 16:09:23,275 INFO     Evaluating the model... (1000/50000)
2025-12-13 16:09:29,716 INFO     Evaluating the model... (1500/50000)
2025-12-13 16:09:35,999 INFO     Evaluating the model... (2000/50000)
2025-12-13 16:09:42,384 INFO     Evaluating the model... (2500/50000)
2025-12-13 16:09:48,129 INFO     Evaluating the model... (3000/50000)
2025-12-13 16:09:53,899 INFO     Evaluating the model... (3500/50000)
2025-12-13 16:09:59,020 INFO     Evaluating the model... (4000/50000)
2025-12-13 16:10:04,762 INFO     Evaluating the model... (4500/50000)
2025-12-13 16:10:12,210 INFO     Evaluating the model... (5000/50000)
2025-12-13 16:10:17,466 INFO     Evaluating the model... (5500/50000)
2025-12-13 16:10:23,027 INFO     Evaluating the model... (6000/50000)
2025-12-13 16:10:29,630 INFO     Evaluating the model... (6500/50000)
2025-12-13 16:10:34,760 INFO     Evaluating the model... (7000/50000)
2025-12-13 16:10:40,352 INFO     Evaluating the model... (7500/50000)
2025-12-13 16:10:46,421 INFO     Evaluating the model... (8000/50000)
2025-12-13 16:10:51,716 INFO     Evaluating the model... (8500/50000)
2025-12-13 16:10:56,457 INFO     Evaluating the model... (9000/50000)
2025-12-13 16:11:02,652 INFO     Evaluating the model... (9500/50000)
2025-12-13 16:11:09,612 INFO     Evaluating the model... (10000/50000)
2025-12-13 16:11:14,553 INFO     Evaluating the model... (10500/50000)
2025-12-13 16:11:20,575 INFO     Evaluating the model... (11000/50000)
2025-12-13 16:11:27,044 INFO     Evaluating the model... (11500/50000)
2025-12-13 16:11:32,572 INFO     Evaluating the model... (12000/50000)
2025-12-13 16:11:38,471 INFO     Evaluating the model... (12500/50000)
Traceback (most recent call last):
  File "/home/25171213997/ITI/codes/run.py", line 469, in <module>
    accuracy = objective()
  File "/home/25171213997/ITI/codes/run.py", line 407, in objective
    metrics = kge_model.test_step(kge_model, valid_triples, all_true_triples, args)
  File "/home/25171213997/ITI/codes/mult.py", line 1108, in test_step
    ranking = (argsort[i, :] == positive_arg[i]).nonzero()
KeyboardInterrupt
